# test_iceberg_basic.py
"""
ê¸°ë³¸ì ì¸ Iceberg ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ê°„ë‹¨í•œ ìŠ¤í¬ë¦½íŠ¸
"""

def test_iceberg_features():
    """Iceberg ê³ ê¸‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸ¯ Iceberg ê³ ê¸‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        from pyspark.sql import SparkSession
        from pyspark.sql.functions import col, current_timestamp, to_timestamp
        from pyspark.sql.types import StringType, IntegerType, TimestampType, DateType
        
        print("âœ… PySpark ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
        
        # SparkSession ìƒì„± (ê°„ë‹¨í•œ ì„¤ì •)
        spark = SparkSession.builder \
            .appName("IcebergBasicTest") \
            .master("local[2]") \
            .config("spark.jars.packages", "org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.4.3") \
            .config("spark.sql.extensions", "org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions") \
            .config("spark.sql.catalog.demo", "org.apache.iceberg.spark.SparkCatalog") \
            .config("spark.sql.catalog.demo.type", "hadoop") \
            .config("spark.sql.catalog.demo.warehouse", "/tmp/iceberg-warehouse") \
            .getOrCreate()
        
        spark.sparkContext.setLogLevel("WARN")
        print("âœ… SparkSession ìƒì„± ì„±ê³µ")
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        test_data = [
            ("evt001", "page_view", "user001", "2024-01-15 10:30:00"),
            ("evt002", "recipe_search", "user001", "2024-01-15 10:31:00"),
            ("evt003", "recipe_view", "user002", "2024-01-15 11:30:00"),
            ("evt004", "recipe_bookmark", "user002", "2024-01-15 11:31:00"),
            ("evt005", "comment_write", "user003", "2024-01-16 09:15:00")
        ]
        
        df = spark.createDataFrame(test_data, ["event_id", "event_name", "user_id", "timestamp"]) \
            .withColumn("event_timestamp", to_timestamp(col("timestamp"))) \
            .withColumn("ingestion_time", current_timestamp()) \
            .drop("timestamp")
        
        print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ì„±ê³µ: {df.count()}í–‰")
        df.show()
        
        # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
        try:
            spark.sql("CREATE NAMESPACE IF NOT EXISTS demo.test")
            print("âœ… ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„± ì„±ê³µ")
        except Exception as e:
            print(f"âš ï¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
        
        # Iceberg í…Œì´ë¸” ìƒì„±
        try:
            spark.sql("DROP TABLE IF EXISTS demo.test.events")
            
            df.writeTo("demo.test.events") \
                .tableProperty("format-version", "2") \
                .create()
            
            print("âœ… Iceberg í…Œì´ë¸” ìƒì„± ì„±ê³µ")
            
            # í…Œì´ë¸”ì—ì„œ ë°ì´í„° ì½ê¸°
            result = spark.table("demo.test.events")
            print(f"âœ… í…Œì´ë¸” ì½ê¸° ì„±ê³µ: {result.count()}í–‰")
            result.show()
            
            # ìŠ¤ëƒ…ìƒ· ì •ë³´ ì¡°íšŒ
            try:
                snapshots = spark.sql("SELECT snapshot_id, committed_at FROM demo.test.events.snapshots")
                print("âœ… ìŠ¤ëƒ…ìƒ· ì¡°íšŒ ì„±ê³µ:")
                snapshots.show()
            except Exception as e:
                print(f"âš ï¸ ìŠ¤ëƒ…ìƒ· ì¡°íšŒ ì‹¤íŒ¨: {e}")
            
            # ì¶”ê°€ ë°ì´í„° ì‚½ì…
            new_data = [
                ("evt006", "recipe_rating", "user004", "2024-01-16 15:30:00")
            ]
            
            df_new = spark.createDataFrame(new_data, ["event_id", "event_name", "user_id", "timestamp"]) \
                .withColumn("event_timestamp", to_timestamp(col("timestamp"))) \
                .withColumn("ingestion_time", current_timestamp()) \
                .drop("timestamp")
            
            df_new.writeTo("demo.test.events").append()
            print("âœ… ë°ì´í„° ì¶”ê°€ ì„±ê³µ")
            
            # ì—…ë°ì´íŠ¸ í›„ ë°ì´í„° í™•ì¸
            updated_result = spark.table("demo.test.events")
            print(f"âœ… ì—…ë°ì´íŠ¸ í›„ í–‰ ìˆ˜: {updated_result.count()}")
            
            print("\nğŸ“ˆ Iceberg ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
            print("âœ… í…Œì´ë¸” ìƒì„±/ì¡°íšŒ")
            print("âœ… ë°ì´í„° ì¶”ê°€ (append)")
            print("âœ… ìŠ¤ëƒ…ìƒ· ì¡°íšŒ")
            print("âœ… ë©”íƒ€ë°ì´í„° ê´€ë¦¬")
            
        except Exception as e:
            print(f"âŒ Iceberg í…Œì´ë¸” ì¡°ì‘ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
        
        spark.stop()
        
    except Exception as e:
        print(f"âŒ ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_iceberg_features()
