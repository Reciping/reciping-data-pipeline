{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5476b90",
   "metadata": {},
   "source": [
    "# ìœ ì € í–‰ë™ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73fe827c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 1ï¸âƒ£ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ Import\n",
    "# ===================================================================\n",
    "\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import random\n",
    "import gc\n",
    "from datetime import datetime, timedelta, timezone, date\n",
    "from typing import List, Dict, Any, Optional\n",
    "import warnings\n",
    "\n",
    "# ë°ì´í„° ì²˜ë¦¬\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Dask (ë¶„ì‚° ì²˜ë¦¬)\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.bag as db\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask import delayed\n",
    "\n",
    "# ì‹œê°í™” (í•„ìš”ì‹œ)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ì„¤ì •\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.family'] = 'Nanum Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690b2361",
   "metadata": {},
   "source": [
    "## 1. DB ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a378119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ:\n",
      "   - ë ˆì‹œí”¼: 208,183ê°œ\n",
      "   - ì‚¬ìš©ì: 30,000ëª…\n",
      "   - í”„ë¡œí•„: 30,000ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 2ï¸âƒ£ ë°ì´í„° ë¡œë”© ë° ê¸°ë³¸ ì„¤ì •\n",
    "# ===================================================================\n",
    "\n",
    "# ë ˆì‹œí”¼ ë°ì´í„° ì½ê¸°\n",
    "recipes_df = pd.read_parquet('data/output/total_recipes.parquet')\n",
    "\n",
    "# ì‚¬ìš©ì ë°ì´í„° ì½ê¸°\n",
    "users_df = pd.read_parquet('data/output/user.parquet')\n",
    "\n",
    "# ì‚¬ìš©ì í”„ë¡œí•„ ë°ì´í„° ì½ê¸°\n",
    "profiles_df = pd.read_parquet('data/output/user_profiles.parquet')\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ:\")\n",
    "print(f\"   - ë ˆì‹œí”¼: {len(recipes_df):,}ê°œ\")\n",
    "print(f\"   - ì‚¬ìš©ì: {len(users_df):,}ëª…\")\n",
    "print(f\"   - í”„ë¡œí•„: {len(profiles_df):,}ê°œ\")\n",
    "\n",
    "# Demographic Segment ë¶„í¬ ì •ì˜\n",
    "DEMOGRAPHIC_DISTRIBUTION = {\n",
    "    'FEMALE_20S': 0.142,    # 14.2%\n",
    "    'FEMALE_30S': 0.207,    # 20.7%\n",
    "    'FEMALE_40_PLUS': 0.356, # 35.6%\n",
    "    'MALE_20S': 0.062,      # 6.2%\n",
    "    'MALE_30S': 0.085,      # 8.5%\n",
    "    'MALE_40_PLUS': 0.148   # 14.8%\n",
    "}\n",
    "\n",
    "# í–‰ë™ íƒœê·¸ ì •ì˜\n",
    "INTENSITY_PERSONAS = {\n",
    "    'POWER_USER': {'ratio': 0.15, 'description': 'íŒŒì›Œ_ìœ ì €, ì£¼ 5íšŒ ì´ìƒ í™œë™'},\n",
    "    'ACTIVE_USER': {'ratio': 0.55, 'description': 'í™œì„±_ìœ ì €, ì£¼ 2-4íšŒ í™œë™'},\n",
    "    'CASUAL_USER': {'ratio': 0.30, 'description': 'ìºì£¼ì–¼_ìœ ì €, ì£¼ 1íšŒ ì´í•˜ í™œë™'}\n",
    "}\n",
    "\n",
    "COOKING_STYLE_PERSONAS = {\n",
    "    'DESSERT_FOCUSED': {'ratio': 0.20, 'description': 'ë””ì €íŠ¸_ì¤‘ì‹¬, ë² ì´í‚¹ ë””ì €íŠ¸ ì œì‘ ì„ í˜¸'},\n",
    "    'HEALTHY_CONSCIOUS': {'ratio': 0.25, 'description': 'ê±´ê°•ì‹_ì§€í–¥, ë‹¤ì´ì–´íŠ¸ ì›°ë¹™ ìš”ë¦¬ ì„ í˜¸'},\n",
    "    'COMFORT_FOOD': {'ratio': 0.25, 'description': 'ë“ ë“ í•œ_ì‹ì‚¬, ë©”ì¸ ìš”ë¦¬ í•œ ë¼ ì‹ì‚¬ ì„ í˜¸'},\n",
    "    'QUICK_CONVENIENT': {'ratio': 0.20, 'description': 'ê°„í¸_ìš”ë¦¬, ì‹œê°„ì ˆì•½ ê°„ë‹¨ ìš”ë¦¬ ì„ í˜¸'},\n",
    "    'DIVERSE_EXPLORER': {'ratio': 0.10, 'description': 'ë‹¤ì–‘í•œ_íƒí—˜, íŠ¹ë³„í•œ íŒ¨í„´ ì—†ì´ ë‹¤ì–‘í•˜ê²Œ íƒìƒ‰'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18dc4d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ ì„¤ì • ì™„ë£Œ (ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ ì¦ê°€ ë²„ì „)\n",
      "ğŸ“… ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„: 2024-08-01 ~ 2025-07-23\n",
      "ğŸ¯ ëª©í‘œ DAU: 2,000ëª…, MAU: 30,000ëª… (ì›ë˜ ê°’ ìœ ì§€)\n",
      "ğŸ“Š í™œì„± ìœ ì € ë¹„ìœ¨: 40.0%\n",
      "ğŸ“ ì¶œë ¥ ê²½ë¡œ: event_logs/\n",
      "ğŸ“ˆ ì „ëµ: ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ ì¦ê°€ë¡œ ì•½ 10,000,000ê°œ ëª©í‘œ\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 3ï¸âƒ£ ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ ì„¤ì • ë° S-ì»¤ë¸Œ ì„±ì¥ ëª¨ë¸\n",
    "# ===================================================================\n",
    "\n",
    "import math\n",
    "\n",
    "# ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„ (1ë…„)\n",
    "SIMULATION_START_DATE = datetime(2024, 8, 1)\n",
    "SIMULATION_END_DATE = datetime(2025, 7, 23)\n",
    "\n",
    "# ëª©í‘œ DAU ë° MAU (ì›ë˜ ê°’ìœ¼ë¡œ ë³µê·€)\n",
    "TARGET_DAU = 2000  # ì›ë˜ ê°’ ìœ ì§€\n",
    "TARGET_MAU = 30000  # ì›ë˜ ê°’ ìœ ì§€\n",
    "\n",
    "# ì „ì²´ ì‚¬ìš©ì ëŒ€ë¹„ í™œì„± ì‚¬ìš©ì ë¹„ìœ¨ (DAU/ë“±ë¡ì‚¬ìš©ì)\n",
    "ACTIVE_USER_RATIO = 0.40\n",
    "\n",
    "# S-ì»¤ë¸Œ ì„±ì¥ í•¨ìˆ˜ ì •ì˜ (ì›ë˜ ê°’ìœ¼ë¡œ ë³µê·€)\n",
    "def calculate_s_curve_dau(day_of_year, start_dau=100, end_dau=2000, inflection_point=0.45):\n",
    "    \"\"\"\n",
    "    S-ì»¤ë¸Œ í˜•íƒœì˜ DAU ì„±ì¥ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜\n",
    "    \n",
    "    ì„±ì¥ ë‹¨ê³„:\n",
    "    - 0-120ì¼(~4ê°œì›”): ì•ˆì •í™” ë‹¨ê³„ (100 â†’ 200ëª…)\n",
    "    - 120-270ì¼(4-9ê°œì›”): ê¸‰ì„±ì¥ ë‹¨ê³„ (200 â†’ 1,600ëª…) \n",
    "    - 270-365ì¼(9-12ê°œì›”): ì„±ìˆ™ ë‹¨ê³„ (1,600 â†’ 2,000ëª…)\n",
    "    \"\"\"\n",
    "    # ì •ê·œí™”ëœ ì‹œê°„ (0~1)\n",
    "    t = day_of_year / 365.0\n",
    "    \n",
    "    # S-ì»¤ë¸Œ íŒŒë¼ë¯¸í„° ì¡°ì •\n",
    "    steepness = 12  # ì„±ì¥ ê¸‰ê²©í•¨ ì •ë„\n",
    "    shift = inflection_point  # ë³€ê³¡ì  ìœ„ì¹˜\n",
    "    \n",
    "    # Logistic í•¨ìˆ˜ (S-ì»¤ë¸Œ)\n",
    "    s_value = 1 / (1 + math.exp(-steepness * (t - shift)))\n",
    "    \n",
    "    # ëª©í‘œ DAU ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§\n",
    "    dau = start_dau + (end_dau - start_dau) * s_value\n",
    "    \n",
    "    return int(dau)\n",
    "\n",
    "# ì´ë²¤íŠ¸ ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
    "EVENT_SCHEMA = {\n",
    "    'view_page': {\n",
    "        'required_props': ['page_type'],\n",
    "        'optional_props': ['page_id', 'referrer_type'],\n",
    "        'next_events': ['search_recipe', 'view_recipe_list', 'click_auth_button', 'view_ads']\n",
    "    },\n",
    "    'click_auth_button': {\n",
    "        'required_props': ['type'],\n",
    "        'optional_props': [],\n",
    "        'next_events': ['auth_success']\n",
    "    },\n",
    "    'auth_success': {\n",
    "        'required_props': ['method', 'type'],\n",
    "        'optional_props': [],\n",
    "        'next_events': ['view_page', 'search_recipe']\n",
    "    },\n",
    "    'search_recipe': {\n",
    "        'required_props': ['search_type'],\n",
    "        'optional_props': ['search_keyword', 'selected_filters', 'result_count'],\n",
    "        'next_events': ['view_recipe_list', 'click_recipe_from_list']\n",
    "    },\n",
    "    'view_recipe_list': {\n",
    "        'required_props': ['list_type'],\n",
    "        'optional_props': ['displayed_recipe_ids'],\n",
    "        'next_events': ['click_recipe_from_list', 'search_recipe']\n",
    "    },\n",
    "    'click_recipe_from_list': {\n",
    "        'required_props': ['recipe_id'],\n",
    "        'optional_props': ['rank'],\n",
    "        'next_events': ['click_bookmark', 'click_like', 'create_comment']\n",
    "    },\n",
    "    'click_bookmark': {\n",
    "        'required_props': ['recipe_id', 'action'],\n",
    "        'optional_props': [],\n",
    "        'next_events': ['view_page', 'click_recipe_from_list']\n",
    "    },\n",
    "    'click_like': {\n",
    "        'required_props': ['recipe_id', 'action'],\n",
    "        'optional_props': [],\n",
    "        'next_events': ['view_page', 'click_recipe_from_list', 'create_comment']\n",
    "    },\n",
    "    'create_comment': {\n",
    "        'required_props': ['recipe_id'],\n",
    "        'optional_props': ['comment_length'],\n",
    "        'next_events': ['view_page', 'click_recipe_from_list']\n",
    "    },\n",
    "    'create_recipe_success': {\n",
    "        'required_props': ['recipe_id'],\n",
    "        'optional_props': ['category', 'ingredient_count'],\n",
    "        'next_events': ['view_page']\n",
    "    },\n",
    "    'view_ads': {\n",
    "        'required_props': ['ad_id'],\n",
    "        'optional_props': ['ad_type', 'position'],\n",
    "        'next_events': ['click_ads', 'view_page']\n",
    "    },\n",
    "    'click_ads': {\n",
    "        'required_props': ['ad_id'],\n",
    "        'optional_props': ['ad_type', 'position', 'target_url'],\n",
    "        'next_events': ['view_page']\n",
    "    }\n",
    "}\n",
    "\n",
    "# ê¸°íƒ€ ì„¤ì •\n",
    "INPUT_DATA_PATH = 'data/output/'\n",
    "OUTPUT_LOG_PATH = 'event_logs/'\n",
    "AB_TEST_START_DATE = datetime(2024, 10, 1)\n",
    "AB_TEST_END_DATE = datetime(2024, 12, 31)\n",
    "AB_TEST_SCENARIO_CODE = 'BOOKMARK_RECOMMENDATION_TEST'\n",
    "AB_TEST_CONTROL_CTR = 0.05  # ê¸°ë³¸ í´ë¦­ë¥ \n",
    "AB_TEST_TREATMENT_CTR = 0.08  # ê°œì„ ëœ í´ë¦­ë¥ \n",
    "\n",
    "print(\"âœ… ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ ì„¤ì • ì™„ë£Œ (ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ ì¦ê°€ ë²„ì „)\")\n",
    "print(f\"ğŸ“… ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„: {SIMULATION_START_DATE.strftime('%Y-%m-%d')} ~ {SIMULATION_END_DATE.strftime('%Y-%m-%d')}\")\n",
    "print(f\"ğŸ¯ ëª©í‘œ DAU: {TARGET_DAU:,}ëª…, MAU: {TARGET_MAU:,}ëª… (ì›ë˜ ê°’ ìœ ì§€)\")\n",
    "print(f\"ğŸ“Š í™œì„± ìœ ì € ë¹„ìœ¨: {ACTIVE_USER_RATIO:.1%}\")\n",
    "print(f\"ğŸ“ ì¶œë ¥ ê²½ë¡œ: {OUTPUT_LOG_PATH}\")\n",
    "print(f\"ğŸ“ˆ ì „ëµ: ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ ì¦ê°€ë¡œ ì•½ 10,000,000ê°œ ëª©í‘œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38b98bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì‚¬ìš©ì í˜ë¥´ì†Œë‚˜ í• ë‹¹ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 4ï¸âƒ£ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ë° í–‰ë™ íƒœê·¸ í• ë‹¹\n",
    "# ===================================================================\n",
    "\n",
    "def assign_user_personas(users_df, profiles_df):\n",
    "    \"\"\"ì‚¬ìš©ìë³„ í–‰ë™ íƒœê·¸ ë° ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹\"\"\"\n",
    "    \n",
    "    print(\"ğŸ­ ì‚¬ìš©ì í˜ë¥´ì†Œë‚˜ í• ë‹¹ ì‹œì‘...\")\n",
    "    \n",
    "    # ì‚¬ìš©ìì™€ í”„ë¡œí•„ ë³‘í•©\n",
    "    merged_df = pd.merge(users_df, profiles_df, left_on='id', right_on='user_id', how='inner')\n",
    "    \n",
    "    # Demographic Segment í• ë‹¹ (ì‹¤ì œ ë¶„í¬ì— ë§ê²Œ)\n",
    "    segment_list = list(DEMOGRAPHIC_DISTRIBUTION.keys())\n",
    "    segment_weights = list(DEMOGRAPHIC_DISTRIBUTION.values())\n",
    "    \n",
    "    merged_df['demographic_segment'] = np.random.choice(\n",
    "        segment_list, \n",
    "        size=len(merged_df), \n",
    "        p=segment_weights\n",
    "    )\n",
    "    \n",
    "    # í–‰ë™ íƒœê·¸ 1: ì„œë¹„ìŠ¤ ì´ìš© ê°•ë„\n",
    "    intensity_list = list(INTENSITY_PERSONAS.keys())\n",
    "    intensity_weights = [persona['ratio'] for persona in INTENSITY_PERSONAS.values()]\n",
    "    \n",
    "    merged_df['intensity_persona'] = np.random.choice(\n",
    "        intensity_list,\n",
    "        size=len(merged_df),\n",
    "        p=intensity_weights\n",
    "    )\n",
    "    \n",
    "    # í–‰ë™ íƒœê·¸ 2: ìš”ë¦¬ ìŠ¤íƒ€ì¼ ì„ í˜¸ë„\n",
    "    cooking_list = list(COOKING_STYLE_PERSONAS.keys())\n",
    "    cooking_weights = [persona['ratio'] for persona in COOKING_STYLE_PERSONAS.values()]\n",
    "    \n",
    "    merged_df['cooking_style_persona'] = np.random.choice(\n",
    "        cooking_list,\n",
    "        size=len(merged_df),\n",
    "        p=cooking_weights\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… í˜ë¥´ì†Œë‚˜ í• ë‹¹ ì™„ë£Œ: {len(merged_df):,}ëª…\")\n",
    "    \n",
    "    # ë¶„í¬ í™•ì¸\n",
    "    print(f\"\\nğŸ“Š Demographic Segment ë¶„í¬:\")\n",
    "    segment_dist = merged_df['demographic_segment'].value_counts(normalize=True)\n",
    "    for segment, ratio in segment_dist.items():\n",
    "        print(f\"   - {segment}: {ratio:.1%}\")\n",
    "    \n",
    "    print(f\"\\nâš¡ ì´ìš© ê°•ë„ ë¶„í¬:\")\n",
    "    intensity_dist = merged_df['intensity_persona'].value_counts(normalize=True)\n",
    "    for intensity, ratio in intensity_dist.items():\n",
    "        print(f\"   - {intensity}: {ratio:.1%}\")\n",
    "    \n",
    "    print(f\"\\nğŸ³ ìš”ë¦¬ ìŠ¤íƒ€ì¼ ë¶„í¬:\")\n",
    "    cooking_dist = merged_df['cooking_style_persona'].value_counts(normalize=True)\n",
    "    for cooking, ratio in cooking_dist.items():\n",
    "        print(f\"   - {cooking}: {ratio:.1%}\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "print(\"âœ… ì‚¬ìš©ì í˜ë¥´ì†Œë‚˜ í• ë‹¹ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86dccffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì´ë²¤íŠ¸ ìƒì„± í•µì‹¬ í•¨ìˆ˜ë“¤ ì¤€ë¹„ ì™„ë£Œ (ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ 2.24ë°° ì¦ê°€)\n",
      "ğŸ“Š ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸ ìˆ˜:\n",
      "   - POWER_USER: 8-15ê°œ â†’ 18-34ê°œ (ì•½ 2.24ë°°)\n",
      "   - ACTIVE_USER: 4-8ê°œ â†’ 9-18ê°œ (ì•½ 2.24ë°°)\n",
      "   - CASUAL_USER: 2-4ê°œ â†’ 4-9ê°œ (ì•½ 2.24ë°°)\n",
      "\n",
      "ğŸ“Š ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸ ìˆ˜:\n",
      "   - POWER_USER: 8-15ê°œ â†’ 18-34ê°œ (ì•½ 2.24ë°°)\n",
      "   - ACTIVE_USER: 4-8ê°œ â†’ 9-18ê°œ (ì•½ 2.24ë°°)\n",
      "   - CASUAL_USER: 2-4ê°œ â†’ 4-9ê°œ (ì•½ 2.24ë°°)\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 5ï¸âƒ£ ì´ë²¤íŠ¸ ìƒì„± í•µì‹¬ í•¨ìˆ˜ë“¤\n",
    "# ===================================================================\n",
    "\n",
    "def generate_event_properties(event_name, context, recipes_df):\n",
    "    \"\"\"ì´ë²¤íŠ¸ë³„ ì†ì„± ìƒì„± (ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ)\"\"\"\n",
    "    \n",
    "    properties = {}\n",
    "    \n",
    "    if event_name == 'view_page':\n",
    "        pages = ['start', 'main', 'recipe_detail', 'profile', 'search_result']\n",
    "        properties['page_name'] = context.get('page_name', random.choice(pages))\n",
    "        \n",
    "        if random.random() < 0.3:  # 30% í™•ë¥ ë¡œ referrer í¬í•¨\n",
    "            properties['referrer'] = random.choice(['https://google.com', 'https://naver.com', 'https://facebook.com', ''])\n",
    "        \n",
    "        if properties['page_name'] == 'recipe_detail' and context.get('recipe_id'):\n",
    "            properties['path'] = f\"/recipes/{context['recipe_id']}\"\n",
    "    \n",
    "    elif event_name == 'click_auth_button':\n",
    "        properties['type'] = random.choice(['signup', 'login'])\n",
    "    \n",
    "    elif event_name == 'auth_success':\n",
    "        properties['method'] = random.choice(['email', 'kakao', 'google', 'naver'])\n",
    "        properties['type'] = random.choice(['signup', 'login'])\n",
    "    \n",
    "    elif event_name == 'search_recipe':\n",
    "        properties['search_type'] = random.choice(['category', 'ingredient', 'menu'])\n",
    "        \n",
    "        if random.random() < 0.7:  # 70% í™•ë¥ ë¡œ ê²€ìƒ‰ì–´ í¬í•¨\n",
    "            keywords = ['ì¹˜í‚¨', 'íŒŒìŠ¤íƒ€', 'ìƒëŸ¬ë“œ', 'ìŠ¤í…Œì´í¬', 'ì¼€ì´í¬', 'ë³¶ìŒë°¥', 'êµ­ë¬¼ìš”ë¦¬']\n",
    "            properties['search_keyword'] = random.choice(keywords)\n",
    "        \n",
    "        if random.random() < 0.4:  # 40% í™•ë¥ ë¡œ í•„í„° ì ìš©\n",
    "            filters = ['cooking_time:30min', 'difficulty:easy', 'vegetarian:true']\n",
    "            properties['selected_filters'] = random.sample(filters, random.randint(1, 2))\n",
    "        \n",
    "        properties['result_count'] = random.randint(5, 50)\n",
    "    \n",
    "    elif event_name == 'view_recipe_list':\n",
    "        list_types = ['popular', 'recommended', 'search_result', 'trending']\n",
    "        properties['list_type'] = random.choice(list_types)\n",
    "        \n",
    "        if random.random() < 0.6:  # 60% í™•ë¥ ë¡œ í‘œì‹œëœ ë ˆì‹œí”¼ ID í¬í•¨\n",
    "            displayed_count = random.randint(5, 20)\n",
    "            if not recipes_df.empty and 'id' in recipes_df.columns:\n",
    "                recipe_sample = recipes_df.sample(n=min(displayed_count, len(recipes_df)))\n",
    "                # String íƒ€ì…ìœ¼ë¡œ ë³€í™˜\n",
    "                properties['displayed_recipe_ids'] = [str(x) for x in recipe_sample['id'].tolist()]\n",
    "    \n",
    "    elif event_name == 'click_recipe_from_list':\n",
    "        if context and context.get('recipe_id'):\n",
    "            properties['recipe_id'] = str(context['recipe_id']) if pd.notna(context['recipe_id']) else None\n",
    "        elif not recipes_df.empty and 'id' in recipes_df.columns:\n",
    "            recipe_id = recipes_df.sample(1)['id'].iloc[0]\n",
    "            properties['recipe_id'] = str(recipe_id) if pd.notna(recipe_id) else None\n",
    "        else:\n",
    "            properties['recipe_id'] = f\"recipe_{random.randint(1, 1000)}\"\n",
    "        \n",
    "        if random.random() < 0.5:  # 50% í™•ë¥ ë¡œ ìˆœìœ„ í¬í•¨\n",
    "            properties['rank'] = random.randint(1, 20)\n",
    "    \n",
    "    elif event_name in ['click_bookmark', 'click_like']:\n",
    "        if context and context.get('recipe_id'):\n",
    "            properties['recipe_id'] = str(context['recipe_id']) if pd.notna(context['recipe_id']) else None\n",
    "        elif not recipes_df.empty and 'id' in recipes_df.columns:\n",
    "            recipe_id = recipes_df.sample(1)['id'].iloc[0]\n",
    "            properties['recipe_id'] = str(recipe_id) if pd.notna(recipe_id) else None\n",
    "        \n",
    "        properties['action'] = random.choice(['add', 'remove']) if event_name == 'click_bookmark' else random.choice(['like', 'unlike'])\n",
    "    \n",
    "    elif event_name == 'create_comment':\n",
    "        if context and context.get('recipe_id'):\n",
    "            properties['recipe_id'] = str(context['recipe_id']) if pd.notna(context['recipe_id']) else None\n",
    "        elif not recipes_df.empty and 'id' in recipes_df.columns:\n",
    "            recipe_id = recipes_df.sample(1)['id'].iloc[0]\n",
    "            properties['recipe_id'] = str(recipe_id) if pd.notna(recipe_id) else None\n",
    "        \n",
    "        if random.random() < 0.6:  # 60% í™•ë¥ ë¡œ ëŒ“ê¸€ ê¸¸ì´ í¬í•¨\n",
    "            properties['comment_length'] = random.randint(10, 200)\n",
    "    \n",
    "    elif event_name == 'create_recipe_success':\n",
    "        if not recipes_df.empty and 'id' in recipes_df.columns:\n",
    "            recipe_id = recipes_df.sample(1)['id'].iloc[0]\n",
    "            properties['recipe_id'] = str(recipe_id) if pd.notna(recipe_id) else None\n",
    "        \n",
    "        if random.random() < 0.8:  # 80% í™•ë¥ ë¡œ ì¹´í…Œê³ ë¦¬ í¬í•¨\n",
    "            categories = ['í•œì‹', 'ì¤‘ì‹', 'ì¼ì‹', 'ì–‘ì‹', 'ë””ì €íŠ¸', 'ìŒë£Œ']\n",
    "            properties['category'] = random.choice(categories)\n",
    "        \n",
    "        if random.random() < 0.7:  # 70% í™•ë¥ ë¡œ ì¬ë£Œ ìˆ˜ í¬í•¨\n",
    "            properties['ingredient_count'] = random.randint(3, 15)\n",
    "    \n",
    "    elif event_name == 'view_ads':\n",
    "        properties['ad_id'] = f\"ad_{random.randint(1000, 9999)}\"\n",
    "        \n",
    "        if random.random() < 0.8:  # 80% í™•ë¥ ë¡œ ê´‘ê³  íƒ€ì… í¬í•¨\n",
    "            properties['ad_type'] = random.choice(['banner', 'video', 'native'])\n",
    "        \n",
    "        if random.random() < 0.6:  # 60% í™•ë¥ ë¡œ ìœ„ì¹˜ í¬í•¨\n",
    "            properties['position'] = random.choice(['top', 'middle', 'bottom', 'sidebar'])\n",
    "    \n",
    "    elif event_name == 'click_ads':\n",
    "        properties['ad_id'] = context.get('ad_id', f\"ad_{random.randint(1000, 9999)}\")\n",
    "        \n",
    "        if random.random() < 0.8:\n",
    "            properties['ad_type'] = random.choice(['banner', 'video', 'native'])\n",
    "        \n",
    "        if random.random() < 0.6:\n",
    "            properties['position'] = random.choice(['top', 'middle', 'bottom', 'sidebar'])\n",
    "        \n",
    "        if random.random() < 0.9:  # 90% í™•ë¥ ë¡œ ëª©ì ì§€ URL í¬í•¨\n",
    "            properties['target_url'] = f\"https://partner-site.com/promotion/{random.randint(1, 100)}\"\n",
    "    \n",
    "    return properties\n",
    "\n",
    "def generate_user_session_flow(user_data, session_time, recipes_df):\n",
    "    \"\"\"ì‚¬ìš©ìë³„ ì„¸ì…˜ í”Œë¡œìš° ìƒì„± (ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ê¸°ë°˜, ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ ëŒ€í­ ì¦ê°€ ë²„ì „)\"\"\"\n",
    "    \n",
    "    session_id = str(uuid.uuid4())\n",
    "    events = []\n",
    "    current_time = session_time\n",
    "    context = {}\n",
    "    \n",
    "    # í˜ë¥´ì†Œë‚˜ë³„ ì„¸ì…˜ ê¸¸ì´ ê²°ì • (ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ 2.24ë°° ì¦ê°€)\n",
    "    intensity = user_data['intensity_persona']\n",
    "    session_lengths = {\n",
    "        'POWER_USER': random.randint(18, 34),   # 8-15 â†’ 18-34 (ì•½ 2.24ë°°)\n",
    "        'ACTIVE_USER': random.randint(9, 18),  # 4-8 â†’ 9-18 (ì•½ 2.24ë°°)\n",
    "        'CASUAL_USER': random.randint(4, 9)    # 2-4 â†’ 4-9 (ì•½ 2.24ë°°)\n",
    "    }\n",
    "    \n",
    "    max_events = session_lengths.get(intensity, 5)\n",
    "    \n",
    "    # ì„¸ì…˜ ì‹œì‘ ì´ë²¤íŠ¸ (í•­ìƒ view_page ë˜ëŠ” auth_successë¡œ ì‹œì‘)\n",
    "    start_events = ['view_page', 'auth_success']\n",
    "    current_event = random.choice(start_events)\n",
    "    \n",
    "    for _ in range(max_events):\n",
    "        # ì´ë²¤íŠ¸ ì†ì„± ìƒì„±\n",
    "        properties = generate_event_properties(current_event, context, recipes_df)\n",
    "        \n",
    "        # í˜„ì¬ í˜ì´ì§€ ì •ë³´ ì„¤ì •\n",
    "        page_name = properties.get('page_name', 'main')\n",
    "        page_url = f\"https://reciping.co.kr/{page_name}\"\n",
    "        page_path = f\"/{page_name}\"\n",
    "        \n",
    "        # context ê°ì²´ êµ¬ì„± (ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ)\n",
    "        context_obj = {\n",
    "            \"page\": {\n",
    "                \"name\": page_name,\n",
    "                \"url\": page_url,\n",
    "                \"path\": page_path\n",
    "            },\n",
    "            \"user_segment\": str(user_data['demographic_segment'])\n",
    "        }\n",
    "        \n",
    "        # anonymous_id ìƒì„± (ë¹ˆ ê°’ì´ë©´ UUID ìƒì„±)\n",
    "        anonymous_id = str(user_data.get('anonymous_id', ''))\n",
    "        if not anonymous_id or anonymous_id == '':\n",
    "            anonymous_id = str(uuid.uuid4())\n",
    "        \n",
    "        # ì´ë²¤íŠ¸ ê¸°ë¡ (ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ)\n",
    "        event = {\n",
    "            'event_name': current_event,\n",
    "            'event_id': str(uuid.uuid4()),\n",
    "            'user_id': str(user_data['id']) if pd.notna(user_data['id']) else None,\n",
    "            'anonymous_id': anonymous_id,\n",
    "            'session_id': session_id,\n",
    "            'context': json.dumps(context_obj, ensure_ascii=False),\n",
    "            'event_properties': json.dumps(properties, default=str, ensure_ascii=False),\n",
    "            'timestamp': current_time.strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "        }\n",
    "        \n",
    "        events.append(event)\n",
    "        \n",
    "        # ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ (ì•ˆì „í•œ íƒ€ì… ë³€í™˜)\n",
    "        if 'recipe_id' in properties and properties['recipe_id'] is not None:\n",
    "            context['recipe_id'] = str(properties['recipe_id'])\n",
    "        if 'ad_id' in properties:\n",
    "            context['ad_id'] = str(properties['ad_id'])\n",
    "        \n",
    "        # ë‹¤ìŒ ì´ë²¤íŠ¸ ê²°ì •\n",
    "        schema = EVENT_SCHEMA.get(current_event, {})\n",
    "        next_events = schema.get('next_events', ['view_page'])\n",
    "        \n",
    "        if next_events and random.random() < 0.8:  # 80% í™•ë¥ ë¡œ ìŠ¤í‚¤ë§ˆ ë”°ë¦„\n",
    "            current_event = random.choice(next_events)\n",
    "        else:\n",
    "            current_event = random.choice(['view_page', 'search_recipe', 'view_recipe_list'])\n",
    "        \n",
    "        # ì‹œê°„ ì¦ê°€ (5ì´ˆ ~ 2ë¶„)\n",
    "        current_time += timedelta(seconds=random.randint(5, 120))\n",
    "    \n",
    "    return events\n",
    "\n",
    "print(\"âœ… ì´ë²¤íŠ¸ ìƒì„± í•µì‹¬ í•¨ìˆ˜ë“¤ ì¤€ë¹„ ì™„ë£Œ (ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ 2.24ë°° ì¦ê°€)\")\n",
    "print(\"ğŸ“Š ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸ ìˆ˜:\")\n",
    "print(\"   - POWER_USER: 8-15ê°œ â†’ 18-34ê°œ (ì•½ 2.24ë°°)\")\n",
    "print(\"   - ACTIVE_USER: 4-8ê°œ â†’ 9-18ê°œ (ì•½ 2.24ë°°)\")\n",
    "print(\"   - CASUAL_USER: 2-4ê°œ â†’ 4-9ê°œ (ì•½ 2.24ë°°)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27353128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ (í˜„ì‹¤ì ì¸ ì‹œê°„ëŒ€ ë¶„í¬ + ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ ì¦ê°€)\n",
      "ğŸ“Š ì „ëµ: DAU/MAU ì›ë˜ê°’ ìœ ì§€ + ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ 2.24ë°° ì¦ê°€ + í˜„ì‹¤ì ì¸ ì‹œê°„ëŒ€ ë¶„í¬\n",
      "ğŸ• ì‹œê°„ëŒ€ íŠ¹ì„±:\n",
      "   - ğŸ”¥ ì €ë… í”¼í¬: 17-20ì‹œ (í‡´ê·¼ í›„ ì €ë… ì¤€ë¹„)\n",
      "   - ğŸ½ï¸ ì ì‹¬ í”¼í¬: 11-13ì‹œ (ì ì‹¬ ì¤€ë¹„ ì‹œê°„)\n",
      "   - ğŸŒ… ì•„ì¹¨ ì‹œê°„: 6-9ì‹œ (ì•„ì¹¨ì‹ì‚¬ ì¤€ë¹„)\n",
      "   - ğŸŒ™ ì‹¬ì•¼/ìƒˆë²½: 0-5ì‹œ (ë§¤ìš° ë‚®ì€ í™œë™)\n",
      "   - ğŸ“… ì£¼ë§: ë¸ŒëŸ°ì¹˜ ë¬¸í™” ë°˜ì˜, ì €ë… ì‹œê°„ ë¶„ì‚°\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 6ï¸âƒ£ ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± í•¨ìˆ˜\n",
    "# ===================================================================\n",
    "\n",
    "def get_realistic_session_time(target_date):\n",
    "    \"\"\"í˜„ì‹¤ì ì¸ ì‹œê°„ëŒ€ ë¶„í¬ë¥¼ ê°€ì§„ ì„¸ì…˜ ì‹œì‘ ì‹œê°„ ìƒì„±\"\"\"\n",
    "    \n",
    "    # ì‹œê°„ëŒ€ë³„ ê°€ì¤‘ì¹˜ (ë ˆì‹œí”¼ ê²€ìƒ‰ ì„œë¹„ìŠ¤ íŠ¹ì„± ë°˜ì˜)\n",
    "    hourly_weights = {\n",
    "        0: 0.5,   # 00ì‹œ - ë§¤ìš° ë‚®ìŒ (ì‹¬ì•¼)\n",
    "        1: 0.3,   # 01ì‹œ - ë§¤ìš° ë‚®ìŒ\n",
    "        2: 0.2,   # 02ì‹œ - ë§¤ìš° ë‚®ìŒ\n",
    "        3: 0.2,   # 03ì‹œ - ë§¤ìš° ë‚®ìŒ\n",
    "        4: 0.3,   # 04ì‹œ - ë§¤ìš° ë‚®ìŒ\n",
    "        5: 0.8,   # 05ì‹œ - ë‚®ìŒ (ìƒˆë²½ ìš´ë™ í›„)\n",
    "        6: 3.2,   # 06ì‹œ - ì•„ì¹¨ ì¤€ë¹„ ì‹œì‘\n",
    "        7: 5.8,   # 07ì‹œ - ì•„ì¹¨ì‹ì‚¬ ì¤€ë¹„ í”¼í¬\n",
    "        8: 4.1,   # 08ì‹œ - ì•„ì¹¨ ë§ˆë¬´ë¦¬\n",
    "        9: 2.3,   # 09ì‹œ - ì˜¤ì „ ê°„ì‹\n",
    "        10: 1.8,  # 10ì‹œ - ë¸ŒëŸ°ì¹˜ ì¤€ë¹„\n",
    "        11: 4.5,  # 11ì‹œ - ì ì‹¬ ì¤€ë¹„ ì‹œì‘\n",
    "        12: 6.2,  # 12ì‹œ - ì ì‹¬ì‹œê°„ í”¼í¬\n",
    "        13: 3.9,  # 13ì‹œ - ì ì‹¬ ë§ˆë¬´ë¦¬\n",
    "        14: 2.1,  # 14ì‹œ - ì˜¤í›„ ê°„ì‹\n",
    "        15: 2.8,  # 15ì‹œ - ê°„ì‹/ë””ì €íŠ¸ ì‹œê°„\n",
    "        16: 3.4,  # 16ì‹œ - ì €ë… ì¤€ë¹„ ê³ ë¯¼ ì‹œì‘\n",
    "        17: 7.8,  # 17ì‹œ - í‡´ê·¼ í›„ ì €ë… ì¤€ë¹„ ì‹œì‘ ğŸ”¥\n",
    "        18: 12.5, # 18ì‹œ - ì €ë… ì¤€ë¹„ ëŒ€í”¼í¬ ğŸ”¥ğŸ”¥ğŸ”¥\n",
    "        19: 11.3, # 19ì‹œ - ì €ë… ìš”ë¦¬ ì‹œê°„ ğŸ”¥ğŸ”¥\n",
    "        20: 8.7,  # 20ì‹œ - ì €ë… ë§ˆë¬´ë¦¬ ğŸ”¥\n",
    "        21: 5.4,  # 21ì‹œ - ë‹¤ìŒë‚  ì¤€ë¹„ or ì•¼ì‹\n",
    "        22: 3.8,  # 22ì‹œ - ì•¼ì‹ ë ˆì‹œí”¼\n",
    "        23: 2.1   # 23ì‹œ - ëŠ¦ì€ ì•¼ì‹\n",
    "    }\n",
    "    \n",
    "    # ìš”ì¼ë³„ ê°€ì¤‘ì¹˜ (ì£¼ë§ vs í‰ì¼)\n",
    "    weekday = target_date.weekday()  # 0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼\n",
    "    \n",
    "    if weekday >= 5:  # ì£¼ë§ (í† , ì¼)\n",
    "        # ì£¼ë§ì—ëŠ” ë” ëŠ¦ê²Œ ì¼ì–´ë‚˜ê³ , ë¸ŒëŸ°ì¹˜ ë¬¸í™”, ì €ë…ë„ ì¡°ê¸ˆ ëŠ¦ì–´ì§\n",
    "        weekend_multiplier = {\n",
    "            0: 0.8, 1: 0.6, 2: 0.4, 3: 0.4, 4: 0.5, 5: 0.6,\n",
    "            6: 0.7, 7: 0.8, 8: 1.2, 9: 1.8, 10: 2.5, 11: 2.8,  # ë¸ŒëŸ°ì¹˜ ì‹œê°„ ì¦ê°€\n",
    "            12: 1.8, 13: 1.5, 14: 1.3, 15: 1.4, 16: 1.2,\n",
    "            17: 1.1, 18: 1.3, 19: 1.4, 20: 1.2, 21: 1.1,  # ì €ë… ì‹œê°„ ë¶„ì‚°\n",
    "            22: 1.2, 23: 1.1  # ì£¼ë§ ì•¼ì‹ ì¦ê°€\n",
    "        }\n",
    "    else:  # í‰ì¼\n",
    "        weekend_multiplier = {hour: 1.0 for hour in range(24)}\n",
    "    \n",
    "    # ìµœì¢… ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "    final_weights = []\n",
    "    hours = []\n",
    "    \n",
    "    for hour in range(24):\n",
    "        weight = hourly_weights[hour] * weekend_multiplier[hour]\n",
    "        final_weights.append(weight)\n",
    "        hours.append(hour)\n",
    "    \n",
    "    # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì‹œê°„ ì„ íƒ\n",
    "    selected_hour = random.choices(hours, weights=final_weights)[0]\n",
    "    selected_minute = random.randint(0, 59)\n",
    "    selected_second = random.randint(0, 59)\n",
    "    \n",
    "    return target_date + timedelta(\n",
    "        hours=selected_hour,\n",
    "        minutes=selected_minute,\n",
    "        seconds=selected_second\n",
    "    )\n",
    "\n",
    "def generate_correct_schema_event_logs():\n",
    "    \"\"\"ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆì— ë§ëŠ” ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„±\"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆë¡œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì‹œì‘!\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Step 1: ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "    os.makedirs(OUTPUT_LOG_PATH, exist_ok=True)\n",
    "    \n",
    "    # Step 2: ì‚¬ìš©ì í˜ë¥´ì†Œë‚˜ í• ë‹¹\n",
    "    print(\"ğŸ‘¥ Step 1: ì‚¬ìš©ì í˜ë¥´ì†Œë‚˜ í• ë‹¹...\")\n",
    "    profiles_with_personas = assign_user_personas(users_df, profiles_df)\n",
    "    \n",
    "    # Step 3: ë°ì´í„° ì¤€ë¹„\n",
    "    print(\"ğŸ“‚ Step 2: ë°ì´í„° ì¤€ë¹„...\")\n",
    "    recipes_sample = recipes_df.sample(n=min(50000, len(recipes_df)), random_state=42)\n",
    "    \n",
    "    print(f\"   ì‚¬ìš©ì: {len(users_df):,}ëª…\")\n",
    "    print(f\"   ë ˆì‹œí”¼: {len(recipes_sample):,}ê°œ (ìƒ˜í”Œë§)\")\n",
    "    print(f\"   í”„ë¡œí•„: {len(profiles_with_personas):,}ê°œ\")\n",
    "    \n",
    "    # Step 4: ì‹œë®¬ë ˆì´ì…˜ ì¼ì • ìƒì„±\n",
    "    print(\"\\nğŸ“… Step 3: ì‹œë®¬ë ˆì´ì…˜ ì¼ì • ìƒì„±...\")\n",
    "    \n",
    "    current_date = SIMULATION_START_DATE\n",
    "    date_info_list = []\n",
    "    total_days = 0\n",
    "    \n",
    "    while current_date <= SIMULATION_END_DATE:\n",
    "        day_of_year = (current_date - SIMULATION_START_DATE).days\n",
    "        dau = calculate_s_curve_dau(day_of_year)\n",
    "        \n",
    "        date_info_list.append({\n",
    "            'date': current_date,\n",
    "            'dau': dau,\n",
    "            'day_of_year': day_of_year\n",
    "        })\n",
    "        \n",
    "        current_date += timedelta(days=1)\n",
    "        total_days += 1\n",
    "    \n",
    "    print(f\"   ì´ {total_days}ì¼ ì‹œë®¬ë ˆì´ì…˜\")\n",
    "    print(f\"   ì‹œì‘ DAU: {date_info_list[0]['dau']:,}ëª…\")\n",
    "    print(f\"   ì¢…ë£Œ DAU: {date_info_list[-1]['dau']:,}ëª…\")\n",
    "    \n",
    "    # Step 5: ì‚¬ìš©ì ë°°ì¹˜ ìƒì„±\n",
    "    print(\"\\nğŸ‘¥ Step 4: ì‚¬ìš©ì ë°°ì¹˜ ìƒì„±...\")\n",
    "    user_batches = []\n",
    "    for month in range(12):\n",
    "        batch_users = profiles_with_personas.sample(n=min(TARGET_MAU, len(profiles_with_personas)), \n",
    "                                               random_state=42 + month)\n",
    "        user_batches.append(batch_users)\n",
    "    \n",
    "    print(f\"   ì›”ë³„ ì‚¬ìš©ì ë°°ì¹˜: {len(user_batches)}ê°œ\")\n",
    "    \n",
    "    # Step 6: ì´ë²¤íŠ¸ ìƒì„± (ì›”ë³„ ì²˜ë¦¬)\n",
    "    print(\"\\nğŸ”„ Step 5: ì´ë²¤íŠ¸ ìƒì„± ì‹œì‘...\")\n",
    "    print(\"ğŸ• í˜„ì‹¤ì ì¸ ì‹œê°„ëŒ€ ë¶„í¬ ì ìš© - ì €ë… í”¼í¬(17-20ì‹œ), ì ì‹¬(11-13ì‹œ), ì•„ì¹¨(6-9ì‹œ)\")\n",
    "    \n",
    "    all_events = []\n",
    "    \n",
    "    # ì›”ë³„ë¡œ ì²˜ë¦¬\n",
    "    monthly_batches = []\n",
    "    current_month_days = []\n",
    "    current_month = SIMULATION_START_DATE.month\n",
    "    \n",
    "    for date_info in date_info_list:\n",
    "        if date_info['date'].month == current_month:\n",
    "            current_month_days.append(date_info)\n",
    "        else:\n",
    "            if current_month_days:\n",
    "                monthly_batches.append(current_month_days)\n",
    "            current_month_days = [date_info]\n",
    "            current_month = date_info['date'].month\n",
    "    \n",
    "    if current_month_days:\n",
    "        monthly_batches.append(current_month_days)\n",
    "    \n",
    "    # ì›”ë³„ ì²˜ë¦¬ ì‹¤í–‰\n",
    "    for month_idx, month_days in enumerate(monthly_batches):\n",
    "        print(f\"\\n   ğŸ“† {month_idx + 1}ì›” ì²˜ë¦¬ ì¤‘... ({len(month_days)}ì¼)\")\n",
    "        \n",
    "        # í•´ë‹¹ ì›”ì˜ ì‚¬ìš©ì ë°°ì¹˜ ì„ íƒ\n",
    "        user_batch = user_batches[month_idx % len(user_batches)]\n",
    "        \n",
    "        month_events = []\n",
    "        \n",
    "        for day_info in month_days:\n",
    "            target_date = day_info['date']\n",
    "            target_dau = day_info['dau']\n",
    "            \n",
    "            # í•´ë‹¹ ì¼ì˜ í™œì„± ì‚¬ìš©ì ìƒ˜í”Œë§\n",
    "            active_users = user_batch.sample(n=min(target_dau, len(user_batch)), random_state=42)\n",
    "            \n",
    "            for _, user_data in active_users.iterrows():\n",
    "                # ì‚¬ìš©ìë³„ ì„¸ì…˜ ìˆ˜ ê²°ì • (ì›ë˜ ê°’ìœ¼ë¡œ ë³µê·€)\n",
    "                intensity = user_data['intensity_persona']\n",
    "                session_counts = {\n",
    "                    'POWER_USER': random.randint(2, 4),  # ì›ë˜ ê°’\n",
    "                    'ACTIVE_USER': random.randint(1, 2), # ì›ë˜ ê°’\n",
    "                    'CASUAL_USER': 1                     # ì›ë˜ ê°’\n",
    "                }\n",
    "                \n",
    "                num_sessions = session_counts.get(intensity, 1)\n",
    "                \n",
    "                for session_idx in range(num_sessions):\n",
    "                    # í˜„ì‹¤ì ì¸ ì‹œê°„ëŒ€ ë¶„í¬ë¥¼ ì ìš©í•œ ì„¸ì…˜ ì‹œì‘ ì‹œê°„ ìƒì„±\n",
    "                    session_start = get_realistic_session_time(target_date)\n",
    "                    \n",
    "                    # ì„¸ì…˜ ì´ë²¤íŠ¸ ìƒì„± (ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ëŠ” ì¦ê°€ë¨)\n",
    "                    session_events = generate_user_session_flow(user_data, session_start, recipes_sample)\n",
    "                    month_events.extend(session_events)\n",
    "        \n",
    "        all_events.extend(month_events)\n",
    "        print(f\"      âœ… {len(month_events):,}ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : {len(all_events):,}ê°œ)\")\n",
    "        \n",
    "        # ì¤‘ê°„ ì €ì¥ (ë©”ëª¨ë¦¬ ê´€ë¦¬)\n",
    "        if len(all_events) > 500000:  # 50ë§Œê°œë§ˆë‹¤ ì¤‘ê°„ ì €ì¥\n",
    "            print(f\"      ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... ({len(all_events):,}ê°œ)\")\n",
    "            \n",
    "            temp_df = pd.DataFrame(all_events)\n",
    "            temp_file = os.path.join(OUTPUT_LOG_PATH, f'correct_temp_events_month_{month_idx + 1}.parquet')\n",
    "            temp_df.to_parquet(temp_file, index=False)\n",
    "            \n",
    "            all_events = []\n",
    "            del temp_df\n",
    "            gc.collect()\n",
    "    \n",
    "    # Step 7: ìµœì¢… í†µí•© ë° ì €ì¥\n",
    "    print(f\"\\nğŸ’¾ Step 6: ìµœì¢… ë°ì´í„° í†µí•© ë° ì €ì¥...\")\n",
    "    \n",
    "    try:\n",
    "        # ì„ì‹œ íŒŒì¼ë“¤ í™•ì¸\n",
    "        temp_files = [f for f in os.listdir(OUTPUT_LOG_PATH) if f.startswith('correct_temp_events_')]\n",
    "        \n",
    "        if temp_files:\n",
    "            print(f\"   ì„ì‹œ íŒŒì¼ {len(temp_files)}ê°œ í†µí•© ì¤‘...\")\n",
    "            \n",
    "            all_dfs = []\n",
    "            for temp_file in temp_files:\n",
    "                temp_path = os.path.join(OUTPUT_LOG_PATH, temp_file)\n",
    "                df = pd.read_parquet(temp_path)\n",
    "                all_dfs.append(df)\n",
    "            \n",
    "            if all_events:\n",
    "                final_df = pd.DataFrame(all_events)\n",
    "                all_dfs.append(final_df)\n",
    "            \n",
    "            combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "            \n",
    "        else:\n",
    "            combined_df = pd.DataFrame(all_events)\n",
    "        \n",
    "        # ìµœì¢… íŒŒì¼ ì €ì¥\n",
    "        output_file = os.path.join(OUTPUT_LOG_PATH, 'event_logs_10m.parquet')\n",
    "        \n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"   ê¸°ì¡´ íŒŒì¼ ì‚­ì œ: {output_file}\")\n",
    "            os.remove(output_file)\n",
    "        \n",
    "        print(f\"   ìµœì¢… íŒŒì¼ ì €ì¥ ì¤‘: {output_file}\")\n",
    "        combined_df.to_parquet(output_file, index=False)\n",
    "        \n",
    "        # ì„ì‹œ íŒŒì¼ ì •ë¦¬\n",
    "        for temp_file in temp_files:\n",
    "            temp_path = os.path.join(OUTPUT_LOG_PATH, temp_file)\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "        \n",
    "        # ìµœì¢… í†µê³„\n",
    "        file_size_mb = os.path.getsize(output_file) / (1024 * 1024)\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\"ğŸ‰ ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì™„ë£Œ!\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_file}\")\n",
    "        print(f\"ğŸ“Š ì´ ì´ë²¤íŠ¸ ìˆ˜: {len(combined_df):,}ê°œ\")\n",
    "        print(f\"ğŸ’½ íŒŒì¼ í¬ê¸°: {file_size_mb:.2f} MB\")\n",
    "        print(f\"ğŸ“… ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„: {total_days}ì¼\")\n",
    "        print(f\"ğŸ‘¥ ê³ ìœ  ì‚¬ìš©ì: {combined_df['user_id'].nunique():,}ëª…\")\n",
    "        print(f\"ğŸ¯ ì´ë²¤íŠ¸ íƒ€ì…: {combined_df['event_name'].nunique()}ê°œ\")\n",
    "        print(f\"ğŸ• í˜„ì‹¤ì ì¸ ì‹œê°„ëŒ€ ë¶„í¬ ì ìš©ë¨!\")\n",
    "        \n",
    "        # ìŠ¤í‚¤ë§ˆ ê²€ì¦\n",
    "        print(f\"\\nğŸ” ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ê²€ì¦:\")\n",
    "        required_columns = ['event_name', 'event_id', 'user_id', 'anonymous_id', 'session_id', 'context', 'event_properties', 'timestamp']\n",
    "        \n",
    "        missing_columns = [col for col in required_columns if col not in combined_df.columns]\n",
    "        if missing_columns:\n",
    "            print(f\"âŒ ëˆ„ë½ëœ ì»¬ëŸ¼: {missing_columns}\")\n",
    "        else:\n",
    "            print(\"âœ… ëª¨ë“  í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬\")\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ ìƒì„±ëœ ì»¬ëŸ¼:\")\n",
    "        for col in combined_df.columns:\n",
    "            print(f\"   - {col}: {combined_df[col].dtype}\")\n",
    "        \n",
    "        return combined_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ìµœì¢… ì €ì¥ ì˜¤ë¥˜: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ… ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ (í˜„ì‹¤ì ì¸ ì‹œê°„ëŒ€ ë¶„í¬ + ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ ì¦ê°€)\")\n",
    "print(\"ğŸ“Š ì „ëµ: DAU/MAU ì›ë˜ê°’ ìœ ì§€ + ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ 2.24ë°° ì¦ê°€ + í˜„ì‹¤ì ì¸ ì‹œê°„ëŒ€ ë¶„í¬\")\n",
    "print(\"ğŸ• ì‹œê°„ëŒ€ íŠ¹ì„±:\")\n",
    "print(\"   - ğŸ”¥ ì €ë… í”¼í¬: 17-20ì‹œ (í‡´ê·¼ í›„ ì €ë… ì¤€ë¹„)\")\n",
    "print(\"   - ğŸ½ï¸ ì ì‹¬ í”¼í¬: 11-13ì‹œ (ì ì‹¬ ì¤€ë¹„ ì‹œê°„)\")  \n",
    "print(\"   - ğŸŒ… ì•„ì¹¨ ì‹œê°„: 6-9ì‹œ (ì•„ì¹¨ì‹ì‚¬ ì¤€ë¹„)\")\n",
    "print(\"   - ğŸŒ™ ì‹¬ì•¼/ìƒˆë²½: 0-5ì‹œ (ë§¤ìš° ë‚®ì€ í™œë™)\")\n",
    "print(\"   - ğŸ“… ì£¼ë§: ë¸ŒëŸ°ì¹˜ ë¬¸í™” ë°˜ì˜, ì €ë… ì‹œê°„ ë¶„ì‚°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00d95d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ë¶„ì„ ë° ë³€í™˜ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ (ì‹œê°„ëŒ€ ë¶„í¬ ë¶„ì„ í¬í•¨)\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 7ï¸âƒ£ ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ì´ë²¤íŠ¸ ë¡œê·¸ ë¶„ì„ ë° ê²€ì¦ í•¨ìˆ˜\n",
    "# ===================================================================\n",
    "\n",
    "def validate_correct_schema(df):\n",
    "    \"\"\"ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆì— ë§ëŠ”ì§€ ê²€ì¦í•˜ê³  ìƒ˜í”Œ ë°ì´í„° í‘œì‹œ\"\"\"\n",
    "    \n",
    "    print(\"ğŸ” ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ë° ìƒ˜í”Œ ë°ì´í„° í™•ì¸\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦\n",
    "    required_columns = [\n",
    "        'event_name',        # String, No\n",
    "        'event_id',          # String (UUID), No  \n",
    "        'user_id',           # String, Yes\n",
    "        'anonymous_id',      # String, No\n",
    "        'session_id',        # String, No\n",
    "        'context',           # JSON Object, No\n",
    "        'event_properties',  # JSON Object, Yes\n",
    "        'timestamp'          # Datetime (ISO 8601), No\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ“‹ í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦:\")\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        print(f\"âŒ ëˆ„ë½ëœ ì»¬ëŸ¼: {missing_columns}\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"âœ… ëª¨ë“  í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬\")\n",
    "    \n",
    "    # ë°ì´í„° íƒ€ì… ê²€ì¦\n",
    "    print(f\"\\nğŸ“Š ë°ì´í„° íƒ€ì… ê²€ì¦:\")\n",
    "    for col in df.columns:\n",
    "        dtype = df[col].dtype\n",
    "        print(f\"   {col}: {dtype}\")\n",
    "    \n",
    "    # ìƒ˜í”Œ ë°ì´í„° ê²€ì¦\n",
    "    print(f\"\\nğŸ” ì²« ë²ˆì§¸ ì´ë²¤íŠ¸ ìƒ˜í”Œ ë°ì´í„°:\")\n",
    "    first_row = df.iloc[0]\n",
    "    \n",
    "    for col in required_columns:\n",
    "        value = first_row[col]\n",
    "        if col in ['context', 'event_properties']:\n",
    "            try:\n",
    "                parsed = json.loads(value)\n",
    "                print(f\"   {col}: {json.dumps(parsed, indent=4, ensure_ascii=False)}\")\n",
    "            except:\n",
    "                print(f\"   {col}: [JSON íŒŒì‹± ì˜¤ë¥˜] {value}\")\n",
    "        else:\n",
    "            print(f\"   {col}: {value}\")\n",
    "    \n",
    "    # context êµ¬ì¡° ê²€ì¦\n",
    "    print(f\"\\nğŸ“± context êµ¬ì¡° ê²€ì¦:\")\n",
    "    try:\n",
    "        context_sample = json.loads(df['context'].iloc[0])\n",
    "        \n",
    "        # context.page ê²€ì¦\n",
    "        if 'page' in context_sample:\n",
    "            page_obj = context_sample['page']\n",
    "            required_page_fields = ['name', 'url', 'path']\n",
    "            missing_page_fields = [field for field in required_page_fields if field not in page_obj]\n",
    "            \n",
    "            if missing_page_fields:\n",
    "                print(f\"âŒ context.page ëˆ„ë½ í•„ë“œ: {missing_page_fields}\")\n",
    "            else:\n",
    "                print(\"âœ… context.page êµ¬ì¡° ì •ìƒ\")\n",
    "                print(f\"   - name: {page_obj['name']}\")\n",
    "                print(f\"   - url: {page_obj['url']}\")\n",
    "                print(f\"   - path: {page_obj['path']}\")\n",
    "        else:\n",
    "            print(\"âŒ context.page ëˆ„ë½\")\n",
    "        \n",
    "        # context.user_segment ê²€ì¦\n",
    "        if 'user_segment' in context_sample:\n",
    "            print(f\"âœ… context.user_segment ì¡´ì¬: {context_sample['user_segment']}\")\n",
    "        else:\n",
    "            print(\"âŒ context.user_segment ëˆ„ë½\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ context JSON íŒŒì‹± ì˜¤ë¥˜: {e}\")\n",
    "    \n",
    "    # event_properties ìƒ˜í”Œ ê²€ì¦\n",
    "    print(f\"\\nğŸ¯ event_properties ìƒ˜í”Œ ê²€ì¦:\")\n",
    "    event_name_samples = df['event_name'].value_counts().head(5)\n",
    "    \n",
    "    for event_name, count in event_name_samples.items():\n",
    "        print(f\"\\n   ğŸ“Œ {event_name} ì´ë²¤íŠ¸ ìƒ˜í”Œ:\")\n",
    "        event_sample = df[df['event_name'] == event_name].iloc[0]\n",
    "        \n",
    "        try:\n",
    "            properties = json.loads(event_sample['event_properties'])\n",
    "            print(f\"      ì†ì„±: {json.dumps(properties, indent=6, ensure_ascii=False)}\")\n",
    "        except:\n",
    "            print(f\"      ì†ì„± íŒŒì‹± ì˜¤ë¥˜: {event_sample['event_properties']}\")\n",
    "    \n",
    "    # ê¸°ë³¸ í†µê³„\n",
    "    print(f\"\\nğŸ“ˆ ê¸°ë³¸ í†µê³„:\")\n",
    "    print(f\"   ì´ ì´ë²¤íŠ¸ ìˆ˜: {len(df):,}ê°œ\")\n",
    "    print(f\"   ê³ ìœ  ì‚¬ìš©ì ìˆ˜: {df['user_id'].nunique():,}ëª…\")\n",
    "    print(f\"   ê³ ìœ  ì„¸ì…˜ ìˆ˜: {df['session_id'].nunique():,}ê°œ\")\n",
    "    print(f\"   ì´ë²¤íŠ¸ íƒ€ì… ìˆ˜: {df['event_name'].nunique()}ê°œ\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ ì´ë²¤íŠ¸ íƒ€ì…ë³„ ë¶„í¬:\")\n",
    "    event_counts = df['event_name'].value_counts()\n",
    "    for event_name, count in event_counts.items():\n",
    "        percentage = (count / len(df)) * 100\n",
    "        print(f\"   {event_name}: {count:,}ê°œ ({percentage:.1f}%)\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def analyze_hourly_distribution(df):\n",
    "    \"\"\"ì‹œê°„ëŒ€ë³„ ì´ë²¤íŠ¸ ë¶„í¬ ìƒì„¸ ë¶„ì„\"\"\"\n",
    "    \n",
    "    print(\"ğŸ• ì‹œê°„ëŒ€ë³„ ì´ë²¤íŠ¸ ë¶„í¬ ë¶„ì„\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # timestampë¥¼ datetimeìœ¼ë¡œ ë³€í™˜\n",
    "    df_copy = df.copy()\n",
    "    df_copy['timestamp'] = pd.to_datetime(df_copy['timestamp'])\n",
    "    df_copy['hour'] = df_copy['timestamp'].dt.hour\n",
    "    df_copy['day_of_week'] = df_copy['timestamp'].dt.day_name()\n",
    "    \n",
    "    # ì „ì²´ ì‹œê°„ëŒ€ë³„ ë¶„í¬\n",
    "    print(\"ğŸ“Š ì „ì²´ ì‹œê°„ëŒ€ë³„ ì´ë²¤íŠ¸ ë¶„í¬:\")\n",
    "    hourly_counts = df_copy['hour'].value_counts().sort_index()\n",
    "    total_events = len(df_copy)\n",
    "    \n",
    "    for hour in range(24):\n",
    "        count = hourly_counts.get(hour, 0)\n",
    "        percentage = (count / total_events) * 100\n",
    "        \n",
    "        # ì‹œê°„ëŒ€ë³„ íŠ¹ì„± í‘œì‹œ\n",
    "        if hour in [18, 19, 20]:\n",
    "            icon = \"ğŸ”¥ğŸ”¥\"  # ì €ë… í”¼í¬\n",
    "        elif hour in [11, 12, 13]:\n",
    "            icon = \"ğŸ½ï¸\"   # ì ì‹¬ ì‹œê°„\n",
    "        elif hour in [6, 7, 8, 9]:\n",
    "            icon = \"ğŸŒ…\"   # ì•„ì¹¨ ì‹œê°„\n",
    "        elif hour in [21, 22, 23]:\n",
    "            icon = \"ğŸŒƒ\"   # ì €ë… ëŠ¦ì€ ì‹œê°„\n",
    "        elif hour in [0, 1, 2, 3, 4, 5]:\n",
    "            icon = \"ğŸŒ™\"   # ì‹¬ì•¼/ìƒˆë²½\n",
    "        else:\n",
    "            icon = \"ğŸ“±\"   # ì¼ë°˜ ì‹œê°„\n",
    "        \n",
    "        print(f\"   {hour:02d}ì‹œ: {count:,}ê°œ ({percentage:.1f}%) {icon}\")\n",
    "    \n",
    "    # í”¼í¬ ì‹œê°„ëŒ€ ë¶„ì„\n",
    "    print(f\"\\nğŸ”¥ í”¼í¬ ì‹œê°„ëŒ€ ë¶„ì„:\")\n",
    "    top_5_hours = hourly_counts.nlargest(5)\n",
    "    for hour, count in top_5_hours.items():\n",
    "        percentage = (count / total_events) * 100\n",
    "        print(f\"   {hour:02d}ì‹œ: {count:,}ê°œ ({percentage:.1f}%)\")\n",
    "    \n",
    "    # ìµœì € ì‹œê°„ëŒ€ ë¶„ì„\n",
    "    print(f\"\\nğŸŒ™ ìµœì € í™œë™ ì‹œê°„ëŒ€:\")\n",
    "    bottom_5_hours = hourly_counts.nsmallest(5)\n",
    "    for hour, count in bottom_5_hours.items():\n",
    "        percentage = (count / total_events) * 100\n",
    "        print(f\"   {hour:02d}ì‹œ: {count:,}ê°œ ({percentage:.1f}%)\")\n",
    "    \n",
    "    # ìš”ì¼ë³„ ì‹œê°„ëŒ€ íŒ¨í„´ (ì£¼ë§ vs í‰ì¼)\n",
    "    print(f\"\\nğŸ“… ìš”ì¼ë³„ íŒ¨í„´ ë¶„ì„:\")\n",
    "    \n",
    "    # í‰ì¼ (ì›”-ê¸ˆ)\n",
    "    weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "    weekday_data = df_copy[df_copy['day_of_week'].isin(weekdays)]\n",
    "    \n",
    "    if len(weekday_data) > 0:\n",
    "        weekday_hourly = weekday_data['hour'].value_counts().sort_index()\n",
    "        weekday_total = len(weekday_data)\n",
    "        \n",
    "        print(f\"\\n   ğŸ“Š í‰ì¼ í”¼í¬ ì‹œê°„ëŒ€ TOP 3:\")\n",
    "        for hour, count in weekday_hourly.nlargest(3).items():\n",
    "            percentage = (count / weekday_total) * 100\n",
    "            print(f\"     {hour:02d}ì‹œ: {count:,}ê°œ ({percentage:.1f}%)\")\n",
    "    \n",
    "    # ì£¼ë§ (í† -ì¼)\n",
    "    weekends = ['Saturday', 'Sunday']\n",
    "    weekend_data = df_copy[df_copy['day_of_week'].isin(weekends)]\n",
    "    \n",
    "    if len(weekend_data) > 0:\n",
    "        weekend_hourly = weekend_data['hour'].value_counts().sort_index()\n",
    "        weekend_total = len(weekend_data)\n",
    "        \n",
    "        print(f\"\\n   ğŸ“Š ì£¼ë§ í”¼í¬ ì‹œê°„ëŒ€ TOP 3:\")\n",
    "        for hour, count in weekend_hourly.nlargest(3).items():\n",
    "            percentage = (count / weekend_total) * 100\n",
    "            print(f\"     {hour:02d}ì‹œ: {count:,}ê°œ ({percentage:.1f}%)\")\n",
    "    \n",
    "    # í˜„ì‹¤ì„± ì²´í¬\n",
    "    print(f\"\\nâœ… í˜„ì‹¤ì„± ì²´í¬:\")\n",
    "    \n",
    "    # ì €ë… í”¼í¬ ì²´í¬ (17-20ì‹œ)\n",
    "    evening_peak = hourly_counts[17:21].sum()\n",
    "    evening_percentage = (evening_peak / total_events) * 100\n",
    "    print(f\"   ì €ë… í”¼í¬ (17-20ì‹œ): {evening_peak:,}ê°œ ({evening_percentage:.1f}%)\")\n",
    "    \n",
    "    # ì ì‹¬ ì‹œê°„ ì²´í¬ (11-13ì‹œ)\n",
    "    lunch_time = hourly_counts[11:14].sum()\n",
    "    lunch_percentage = (lunch_time / total_events) * 100\n",
    "    print(f\"   ì ì‹¬ ì‹œê°„ (11-13ì‹œ): {lunch_time:,}ê°œ ({lunch_percentage:.1f}%)\")\n",
    "    \n",
    "    # ì‹¬ì•¼ ì‹œê°„ ì²´í¬ (0-5ì‹œ)\n",
    "    midnight = hourly_counts[0:6].sum()\n",
    "    midnight_percentage = (midnight / total_events) * 100\n",
    "    print(f\"   ì‹¬ì•¼ ì‹œê°„ (0-5ì‹œ): {midnight:,}ê°œ ({midnight_percentage:.1f}%)\")\n",
    "    \n",
    "    # í˜„ì‹¤ì„± í‰ê°€\n",
    "    if evening_percentage > lunch_percentage and evening_percentage > midnight_percentage:\n",
    "        print(f\"   âœ… ì €ë… í”¼í¬ê°€ ê°€ì¥ ë†’ìŒ - í˜„ì‹¤ì !\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸ ì‹œê°„ëŒ€ ë¶„í¬ ì¬ê²€í†  í•„ìš”\")\n",
    "    \n",
    "    if midnight_percentage < 5:\n",
    "        print(f\"   âœ… ì‹¬ì•¼ ì‹œê°„ í™œë™ ì ì ˆíˆ ë‚®ìŒ\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸ ì‹¬ì•¼ ì‹œê°„ í™œë™ì´ ë„ˆë¬´ ë†’ìŒ\")\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def convert_to_csv_with_estimation(file_name='event_logs_10m.parquet'):\n",
    "    \"\"\"ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ Parquet íŒŒì¼ì„ CSVë¡œ ë³€í™˜í•˜ê³  í¬ê¸° ì¶”ì •\"\"\"\n",
    "    \n",
    "    print(\"ğŸ”„ ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ CSV ë³€í™˜ ë° í¬ê¸° ì¶”ì •\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Parquet íŒŒì¼ ë¡œë“œ\n",
    "    parquet_file = os.path.join(OUTPUT_LOG_PATH, file_name)\n",
    "    \n",
    "    if not os.path.exists(parquet_file):\n",
    "        print(f\"âŒ Parquet íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {parquet_file}\")\n",
    "        return\n",
    "    \n",
    "    # íŒŒì¼ ì •ë³´\n",
    "    parquet_size_mb = os.path.getsize(parquet_file) / (1024 * 1024)\n",
    "    print(f\"ğŸ“ Parquet íŒŒì¼ í¬ê¸°: {parquet_size_mb:.2f} MB\")\n",
    "    \n",
    "    # ìƒ˜í”Œ ë°ì´í„°ë¡œ í¬ê¸° ì¶”ì •\n",
    "    print(\"\\nğŸ“Š CSV í¬ê¸° ì¶”ì • ì¤‘...\")\n",
    "    \n",
    "    df = pd.read_parquet(parquet_file)\n",
    "    \n",
    "    # ì „ì²´ ë°ì´í„° ìƒ˜í”Œë§\n",
    "    sample_size = min(10000, len(df))\n",
    "    sample_df = df.sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ê¸°ë°˜ CSV í¬ê¸° ì¸¡ì •\n",
    "    import io\n",
    "    csv_buffer = io.StringIO()\n",
    "    sample_df.to_csv(csv_buffer, index=False)\n",
    "    csv_sample_size = len(csv_buffer.getvalue().encode('utf-8'))\n",
    "    \n",
    "    # ì „ì²´ í¬ê¸° ì¶”ì •\n",
    "    estimated_csv_size_bytes = (csv_sample_size / sample_size) * len(df)\n",
    "    estimated_csv_size_mb = estimated_csv_size_bytes / (1024 * 1024)\n",
    "    estimated_csv_size_gb = estimated_csv_size_mb / 1024\n",
    "    \n",
    "    print(f\"   ìƒ˜í”Œ ë°ì´í„°: {sample_size:,}í–‰\")\n",
    "    print(f\"   ìƒ˜í”Œ CSV í¬ê¸°: {csv_sample_size / 1024:.2f} KB\")\n",
    "    print(f\"   ì „ì²´ ì˜ˆìƒ CSV í¬ê¸°: {estimated_csv_size_mb:.2f} MB ({estimated_csv_size_gb:.2f} GB)\")\n",
    "    \n",
    "    # ì»¬ëŸ¼ë³„ í¬ê¸° ë¶„ì„\n",
    "    print(\"\\nğŸ“‹ ì»¬ëŸ¼ë³„ í¬ê¸° ë¶„ì„:\")\n",
    "    for col in sample_df.columns:\n",
    "        col_series = sample_df[col].astype(str)\n",
    "        avg_char_count = col_series.str.len().mean()\n",
    "        print(f\"   {col}: í‰ê·  {avg_char_count:.1f}ì\")\n",
    "    \n",
    "    # ì••ì¶•ë¥  ë¶„ì„\n",
    "    compression_ratio = estimated_csv_size_mb / parquet_size_mb\n",
    "    print(f\"\\nğŸ“ˆ ì••ì¶•ë¥  ë¶„ì„:\")\n",
    "    print(f\"   Parquet â†’ CSV í™•ì¥ ë¹„ìœ¨: {compression_ratio:.1f}x\")\n",
    "    print(f\"   Parquet ì••ì¶• íš¨ìœ¨: {(1 - 1/compression_ratio)*100:.1f}%\")\n",
    "    \n",
    "    # ì‚¬ìš©ì ì„ íƒ\n",
    "    if estimated_csv_size_gb > 1.0:\n",
    "        print(f\"\\nâš ï¸  ì£¼ì˜: ì˜ˆìƒ CSV í¬ê¸°ê°€ {estimated_csv_size_gb:.2f} GBì…ë‹ˆë‹¤!\")\n",
    "        user_input = input(\"ë³€í™˜ì„ ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): \")\n",
    "        if user_input.lower() != 'y':\n",
    "            print(\"CSV ë³€í™˜ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "    \n",
    "    # CSV ë³€í™˜ ì‹¤í–‰\n",
    "    print(f\"\\nğŸ”„ CSV ë³€í™˜ ì‹œì‘...\")\n",
    "    csv_file = os.path.join(OUTPUT_LOG_PATH, 'event_logs_10m.csv')\n",
    "    \n",
    "    try:\n",
    "        # ì²­í¬ ë‹¨ìœ„ë¡œ ë³€í™˜ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)\n",
    "        chunk_size = 50000\n",
    "        first_chunk = True\n",
    "        \n",
    "        total_chunks = len(df) // chunk_size + (1 if len(df) % chunk_size else 0)\n",
    "        print(f\"   ì´ {total_chunks}ê°œ ì²­í¬ë¡œ ë¶„í•  ì²˜ë¦¬\")\n",
    "        \n",
    "        for i in range(0, len(df), chunk_size):\n",
    "            chunk = df.iloc[i:i+chunk_size]\n",
    "            \n",
    "            # ì²« ë²ˆì§¸ ì²­í¬ëŠ” í—¤ë” í¬í•¨, ë‚˜ë¨¸ì§€ëŠ” í—¤ë” ì—†ì´\n",
    "            mode = 'w' if first_chunk else 'a'\n",
    "            header = first_chunk\n",
    "            \n",
    "            chunk.to_csv(csv_file, mode=mode, header=header, index=False)\n",
    "            \n",
    "            current_chunk = (i // chunk_size) + 1\n",
    "            print(f\"   ì²˜ë¦¬ ì™„ë£Œ: {current_chunk}/{total_chunks} ì²­í¬\")\n",
    "            \n",
    "            first_chunk = False\n",
    "        \n",
    "        # ìµœì¢… í¬ê¸° í™•ì¸\n",
    "        actual_csv_size_mb = os.path.getsize(csv_file) / (1024 * 1024)\n",
    "        actual_csv_size_gb = actual_csv_size_mb / 1024\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "        print(\"âœ… CSV ë³€í™˜ ì™„ë£Œ!\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"ğŸ“ CSV íŒŒì¼: {csv_file}\")\n",
    "        print(f\"ğŸ’½ ì‹¤ì œ í¬ê¸°: {actual_csv_size_mb:.2f} MB ({actual_csv_size_gb:.2f} GB)\")\n",
    "        print(f\"ğŸ“Š ì˜ˆìƒ ëŒ€ë¹„: {(actual_csv_size_mb/estimated_csv_size_mb)*100:.1f}% ì •í™•ë„\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ CSV ë³€í™˜ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "print(\"âœ… ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ë¶„ì„ ë° ë³€í™˜ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ (ì‹œê°„ëŒ€ ë¶„í¬ ë¶„ì„ í¬í•¨)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5d1de2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆë¡œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì‹œì‘!\n",
      "============================================================\n",
      "ğŸš€ ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆë¡œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì‹œì‘!\n",
      "======================================================================\n",
      "ğŸ‘¥ Step 1: ì‚¬ìš©ì í˜ë¥´ì†Œë‚˜ í• ë‹¹...\n",
      "ğŸ­ ì‚¬ìš©ì í˜ë¥´ì†Œë‚˜ í• ë‹¹ ì‹œì‘...\n",
      "âœ… í˜ë¥´ì†Œë‚˜ í• ë‹¹ ì™„ë£Œ: 30,000ëª…\n",
      "\n",
      "ğŸ“Š Demographic Segment ë¶„í¬:\n",
      "   - FEMALE_40_PLUS: 35.8%\n",
      "   - FEMALE_30S: 20.5%\n",
      "   - MALE_40_PLUS: 14.4%\n",
      "   - FEMALE_20S: 14.4%\n",
      "   - MALE_30S: 8.7%\n",
      "   - MALE_20S: 6.3%\n",
      "\n",
      "âš¡ ì´ìš© ê°•ë„ ë¶„í¬:\n",
      "   - ACTIVE_USER: 54.7%\n",
      "   - CASUAL_USER: 30.0%\n",
      "   - POWER_USER: 15.3%\n",
      "\n",
      "ğŸ³ ìš”ë¦¬ ìŠ¤íƒ€ì¼ ë¶„í¬:\n",
      "   - HEALTHY_CONSCIOUS: 25.4%\n",
      "   - COMFORT_FOOD: 24.9%\n",
      "   - DESSERT_FOCUSED: 20.1%\n",
      "   - QUICK_CONVENIENT: 19.6%\n",
      "   - DIVERSE_EXPLORER: 10.0%\n",
      "ğŸ“‚ Step 2: ë°ì´í„° ì¤€ë¹„...\n",
      "   ì‚¬ìš©ì: 30,000ëª…\n",
      "   ë ˆì‹œí”¼: 50,000ê°œ (ìƒ˜í”Œë§)\n",
      "   í”„ë¡œí•„: 30,000ê°œ\n",
      "\n",
      "ğŸ“… Step 3: ì‹œë®¬ë ˆì´ì…˜ ì¼ì • ìƒì„±...\n",
      "   ì´ 357ì¼ ì‹œë®¬ë ˆì´ì…˜\n",
      "   ì‹œì‘ DAU: 108ëª…\n",
      "   ì¢…ë£Œ DAU: 1,996ëª…\n",
      "\n",
      "ğŸ‘¥ Step 4: ì‚¬ìš©ì ë°°ì¹˜ ìƒì„±...\n",
      "   ì‚¬ìš©ì: 30,000ëª…\n",
      "   ë ˆì‹œí”¼: 50,000ê°œ (ìƒ˜í”Œë§)\n",
      "   í”„ë¡œí•„: 30,000ê°œ\n",
      "\n",
      "ğŸ“… Step 3: ì‹œë®¬ë ˆì´ì…˜ ì¼ì • ìƒì„±...\n",
      "   ì´ 357ì¼ ì‹œë®¬ë ˆì´ì…˜\n",
      "   ì‹œì‘ DAU: 108ëª…\n",
      "   ì¢…ë£Œ DAU: 1,996ëª…\n",
      "\n",
      "ğŸ‘¥ Step 4: ì‚¬ìš©ì ë°°ì¹˜ ìƒì„±...\n",
      "   ì›”ë³„ ì‚¬ìš©ì ë°°ì¹˜: 12ê°œ   ì›”ë³„ ì‚¬ìš©ì ë°°ì¹˜: 12ê°œ\n",
      "\n",
      "ğŸ”„ Step 5: ì´ë²¤íŠ¸ ìƒì„± ì‹œì‘...\n",
      "ğŸ• í˜„ì‹¤ì ì¸ ì‹œê°„ëŒ€ ë¶„í¬ ì ìš© - ì €ë… í”¼í¬(17-20ì‹œ), ì ì‹¬(11-13ì‹œ), ì•„ì¹¨(6-9ì‹œ)\n",
      "\n",
      "   ğŸ“† 1ì›” ì²˜ë¦¬ ì¤‘... (31ì¼)\n",
      "\n",
      "\n",
      "ğŸ”„ Step 5: ì´ë²¤íŠ¸ ìƒì„± ì‹œì‘...\n",
      "ğŸ• í˜„ì‹¤ì ì¸ ì‹œê°„ëŒ€ ë¶„í¬ ì ìš© - ì €ë… í”¼í¬(17-20ì‹œ), ì ì‹¬(11-13ì‹œ), ì•„ì¹¨(6-9ì‹œ)\n",
      "\n",
      "   ğŸ“† 1ì›” ì²˜ë¦¬ ì¤‘... (31ì¼)\n",
      "      âœ… 89,841ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 89,841ê°œ)\n",
      "\n",
      "   ğŸ“† 2ì›” ì²˜ë¦¬ ì¤‘... (30ì¼)\n",
      "      âœ… 89,841ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 89,841ê°œ)\n",
      "\n",
      "   ğŸ“† 2ì›” ì²˜ë¦¬ ì¤‘... (30ì¼)\n",
      "      âœ… 92,656ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 182,497ê°œ)\n",
      "\n",
      "   ğŸ“† 3ì›” ì²˜ë¦¬ ì¤‘... (31ì¼)\n",
      "      âœ… 92,656ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 182,497ê°œ)\n",
      "\n",
      "   ğŸ“† 3ì›” ì²˜ë¦¬ ì¤‘... (31ì¼)\n",
      "      âœ… 157,148ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 339,645ê°œ)\n",
      "\n",
      "   ğŸ“† 4ì›” ì²˜ë¦¬ ì¤‘... (30ì¼)\n",
      "      âœ… 157,148ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 339,645ê°œ)\n",
      "\n",
      "   ğŸ“† 4ì›” ì²˜ë¦¬ ì¤‘... (30ì¼)\n",
      "      âœ… 276,894ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 616,539ê°œ)\n",
      "      ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... (616,539ê°œ)\n",
      "      âœ… 276,894ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 616,539ê°œ)\n",
      "      ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... (616,539ê°œ)\n",
      "\n",
      "   ğŸ“† 5ì›” ì²˜ë¦¬ ì¤‘... (31ì¼)\n",
      "\n",
      "   ğŸ“† 5ì›” ì²˜ë¦¬ ì¤‘... (31ì¼)\n",
      "      âœ… 521,710ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 521,710ê°œ)\n",
      "      ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... (521,710ê°œ)\n",
      "      âœ… 521,710ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 521,710ê°œ)\n",
      "      ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... (521,710ê°œ)\n",
      "\n",
      "   ğŸ“† 6ì›” ì²˜ë¦¬ ì¤‘... (31ì¼)\n",
      "\n",
      "   ğŸ“† 6ì›” ì²˜ë¦¬ ì¤‘... (31ì¼)\n",
      "      âœ… 862,332ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 862,332ê°œ)\n",
      "      ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... (862,332ê°œ)\n",
      "      âœ… 862,332ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 862,332ê°œ)\n",
      "      ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... (862,332ê°œ)\n",
      "\n",
      "   ğŸ“† 7ì›” ì²˜ë¦¬ ì¤‘... (28ì¼)\n",
      "\n",
      "   ğŸ“† 7ì›” ì²˜ë¦¬ ì¤‘... (28ì¼)\n",
      "      âœ… 1,078,972ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 1,078,972ê°œ)\n",
      "      ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... (1,078,972ê°œ)\n",
      "      âœ… 1,078,972ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 1,078,972ê°œ)\n",
      "      ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... (1,078,972ê°œ)\n",
      "\n",
      "   ğŸ“† 8ì›” ì²˜ë¦¬ ì¤‘... (31ì¼)\n",
      "\n",
      "   ğŸ“† 8ì›” ì²˜ë¦¬ ì¤‘... (31ì¼)\n",
      "      âœ… 1,308,384ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 1,308,384ê°œ)\n",
      "      ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... (1,308,384ê°œ)\n",
      "      âœ… 1,308,384ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 1,308,384ê°œ)\n",
      "      ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... (1,308,384ê°œ)\n",
      "\n",
      "   ğŸ“† 9ì›” ì²˜ë¦¬ ì¤‘... (30ì¼)\n",
      "\n",
      "   ğŸ“† 9ì›” ì²˜ë¦¬ ì¤‘... (30ì¼)\n",
      "      âœ… 1,475,553ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 1,475,553ê°œ)\n",
      "      ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... (1,475,553ê°œ)\n",
      "      âœ… 1,475,553ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 1,475,553ê°œ)\n",
      "      ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... (1,475,553ê°œ)\n",
      "\n",
      "   ğŸ“† 10ì›” ì²˜ë¦¬ ì¤‘... (31ì¼)\n",
      "\n",
      "   ğŸ“† 10ì›” ì²˜ë¦¬ ì¤‘... (31ì¼)\n",
      "      âœ… 1,537,269ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 1,537,269ê°œ)\n",
      "      ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... (1,537,269ê°œ)\n",
      "      âœ… 1,537,269ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 1,537,269ê°œ)\n",
      "      ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... (1,537,269ê°œ)\n",
      "\n",
      "   ğŸ“† 11ì›” ì²˜ë¦¬ ì¤‘... (30ì¼)\n",
      "\n",
      "   ğŸ“† 11ì›” ì²˜ë¦¬ ì¤‘... (30ì¼)\n",
      "      âœ… 1,461,558ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 1,461,558ê°œ)\n",
      "      ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... (1,461,558ê°œ)\n",
      "      âœ… 1,461,558ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 1,461,558ê°œ)\n",
      "      ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... (1,461,558ê°œ)\n",
      "\n",
      "   ğŸ“† 12ì›” ì²˜ë¦¬ ì¤‘... (23ì¼)\n",
      "\n",
      "   ğŸ“† 12ì›” ì²˜ë¦¬ ì¤‘... (23ì¼)\n",
      "      âœ… 1,168,835ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 1,168,835ê°œ)\n",
      "      ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... (1,168,835ê°œ)\n",
      "      âœ… 1,168,835ê°œ ì´ë²¤íŠ¸ ìƒì„±ë¨ (ëˆ„ì : 1,168,835ê°œ)\n",
      "      ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... (1,168,835ê°œ)\n",
      "\n",
      "ğŸ’¾ Step 6: ìµœì¢… ë°ì´í„° í†µí•© ë° ì €ì¥...\n",
      "   ì„ì‹œ íŒŒì¼ 9ê°œ í†µí•© ì¤‘...\n",
      "\n",
      "ğŸ’¾ Step 6: ìµœì¢… ë°ì´í„° í†µí•© ë° ì €ì¥...\n",
      "   ì„ì‹œ íŒŒì¼ 9ê°œ í†µí•© ì¤‘...\n",
      "   ìµœì¢… íŒŒì¼ ì €ì¥ ì¤‘: event_logs/event_logs_10m.parquet\n",
      "   ìµœì¢… íŒŒì¼ ì €ì¥ ì¤‘: event_logs/event_logs_10m.parquet\n",
      "======================================================================\n",
      "ğŸ‰ ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì™„ë£Œ!\n",
      "======================================================================\n",
      "ğŸ“ ì €ì¥ ìœ„ì¹˜: event_logs/event_logs_10m.parquet\n",
      "ğŸ“Š ì´ ì´ë²¤íŠ¸ ìˆ˜: 10,031,152ê°œ\n",
      "ğŸ’½ íŒŒì¼ í¬ê¸°: 970.72 MB\n",
      "ğŸ“… ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„: 357ì¼\n",
      "======================================================================\n",
      "ğŸ‰ ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì™„ë£Œ!\n",
      "======================================================================\n",
      "ğŸ“ ì €ì¥ ìœ„ì¹˜: event_logs/event_logs_10m.parquet\n",
      "ğŸ“Š ì´ ì´ë²¤íŠ¸ ìˆ˜: 10,031,152ê°œ\n",
      "ğŸ’½ íŒŒì¼ í¬ê¸°: 970.72 MB\n",
      "ğŸ“… ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„: 357ì¼\n",
      "ğŸ‘¥ ê³ ìœ  ì‚¬ìš©ì: 11,855ëª…\n",
      "ğŸ‘¥ ê³ ìœ  ì‚¬ìš©ì: 11,855ëª…\n",
      "ğŸ¯ ì´ë²¤íŠ¸ íƒ€ì…: 11ê°œ\n",
      "ğŸ• í˜„ì‹¤ì ì¸ ì‹œê°„ëŒ€ ë¶„í¬ ì ìš©ë¨!\n",
      "\n",
      "ğŸ” ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ê²€ì¦:\n",
      "âœ… ëª¨ë“  í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬\n",
      "\n",
      "ğŸ“‹ ìƒì„±ëœ ì»¬ëŸ¼:\n",
      "   - event_name: object\n",
      "   - event_id: object\n",
      "   - user_id: object\n",
      "   - anonymous_id: object\n",
      "   - session_id: object\n",
      "   - context: object\n",
      "   - event_properties: object\n",
      "   - timestamp: object\n",
      "ğŸ¯ ì´ë²¤íŠ¸ íƒ€ì…: 11ê°œ\n",
      "ğŸ• í˜„ì‹¤ì ì¸ ì‹œê°„ëŒ€ ë¶„í¬ ì ìš©ë¨!\n",
      "\n",
      "ğŸ” ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ê²€ì¦:\n",
      "âœ… ëª¨ë“  í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬\n",
      "\n",
      "ğŸ“‹ ìƒì„±ëœ ì»¬ëŸ¼:\n",
      "   - event_name: object\n",
      "   - event_id: object\n",
      "   - user_id: object\n",
      "   - anonymous_id: object\n",
      "   - session_id: object\n",
      "   - context: object\n",
      "   - event_properties: object\n",
      "   - timestamp: object\n",
      "\n",
      "âœ… ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì„±ê³µ!\n",
      "ğŸ“‚ íŒŒì¼ ìœ„ì¹˜: event_logs/event_logs_10m.parquet\n",
      "\n",
      "ğŸ” ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹œì‘!\n",
      "ğŸ” ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ë° ìƒ˜í”Œ ë°ì´í„° í™•ì¸\n",
      "======================================================================\n",
      "ğŸ“‹ í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦:\n",
      "âœ… ëª¨ë“  í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬\n",
      "\n",
      "ğŸ“Š ë°ì´í„° íƒ€ì… ê²€ì¦:\n",
      "   event_name: object\n",
      "   event_id: object\n",
      "   user_id: object\n",
      "   anonymous_id: object\n",
      "   session_id: object\n",
      "   context: object\n",
      "   event_properties: object\n",
      "   timestamp: object\n",
      "\n",
      "ğŸ” ì²« ë²ˆì§¸ ì´ë²¤íŠ¸ ìƒ˜í”Œ ë°ì´í„°:\n",
      "   event_name: auth_success\n",
      "   event_id: 6c81ec3a-1b44-40ab-93b8-d395665777ca\n",
      "   user_id: 15107\n",
      "   anonymous_id: 370379f1-3f5a-4ca7-abc7-fbd66ea52e38\n",
      "   session_id: 7df7009f-e421-47a8-b180-a574cbaba76e\n",
      "   context: {\n",
      "    \"page\": {\n",
      "        \"name\": \"main\",\n",
      "        \"url\": \"https://reciping.co.kr/main\",\n",
      "        \"path\": \"/main\"\n",
      "    },\n",
      "    \"user_segment\": \"FEMALE_40_PLUS\"\n",
      "}\n",
      "   event_properties: {\n",
      "    \"method\": \"kakao\",\n",
      "    \"type\": \"login\"\n",
      "}\n",
      "   timestamp: 2025-05-01T18:03:08.000000Z\n",
      "\n",
      "ğŸ“± context êµ¬ì¡° ê²€ì¦:\n",
      "âœ… context.page êµ¬ì¡° ì •ìƒ\n",
      "   - name: main\n",
      "   - url: https://reciping.co.kr/main\n",
      "   - path: /main\n",
      "âœ… context.user_segment ì¡´ì¬: FEMALE_40_PLUS\n",
      "\n",
      "ğŸ¯ event_properties ìƒ˜í”Œ ê²€ì¦:\n",
      "\n",
      "   ğŸ“Œ view_page ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "\n",
      "âœ… ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì„±ê³µ!\n",
      "ğŸ“‚ íŒŒì¼ ìœ„ì¹˜: event_logs/event_logs_10m.parquet\n",
      "\n",
      "ğŸ” ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹œì‘!\n",
      "ğŸ” ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ë° ìƒ˜í”Œ ë°ì´í„° í™•ì¸\n",
      "======================================================================\n",
      "ğŸ“‹ í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦:\n",
      "âœ… ëª¨ë“  í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬\n",
      "\n",
      "ğŸ“Š ë°ì´í„° íƒ€ì… ê²€ì¦:\n",
      "   event_name: object\n",
      "   event_id: object\n",
      "   user_id: object\n",
      "   anonymous_id: object\n",
      "   session_id: object\n",
      "   context: object\n",
      "   event_properties: object\n",
      "   timestamp: object\n",
      "\n",
      "ğŸ” ì²« ë²ˆì§¸ ì´ë²¤íŠ¸ ìƒ˜í”Œ ë°ì´í„°:\n",
      "   event_name: auth_success\n",
      "   event_id: 6c81ec3a-1b44-40ab-93b8-d395665777ca\n",
      "   user_id: 15107\n",
      "   anonymous_id: 370379f1-3f5a-4ca7-abc7-fbd66ea52e38\n",
      "   session_id: 7df7009f-e421-47a8-b180-a574cbaba76e\n",
      "   context: {\n",
      "    \"page\": {\n",
      "        \"name\": \"main\",\n",
      "        \"url\": \"https://reciping.co.kr/main\",\n",
      "        \"path\": \"/main\"\n",
      "    },\n",
      "    \"user_segment\": \"FEMALE_40_PLUS\"\n",
      "}\n",
      "   event_properties: {\n",
      "    \"method\": \"kakao\",\n",
      "    \"type\": \"login\"\n",
      "}\n",
      "   timestamp: 2025-05-01T18:03:08.000000Z\n",
      "\n",
      "ğŸ“± context êµ¬ì¡° ê²€ì¦:\n",
      "âœ… context.page êµ¬ì¡° ì •ìƒ\n",
      "   - name: main\n",
      "   - url: https://reciping.co.kr/main\n",
      "   - path: /main\n",
      "âœ… context.user_segment ì¡´ì¬: FEMALE_40_PLUS\n",
      "\n",
      "ğŸ¯ event_properties ìƒ˜í”Œ ê²€ì¦:\n",
      "\n",
      "   ğŸ“Œ view_page ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "      ì†ì„±: {\n",
      "      \"page_name\": \"main\"\n",
      "}\n",
      "\n",
      "   ğŸ“Œ search_recipe ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "      ì†ì„±: {\n",
      "      \"page_name\": \"main\"\n",
      "}\n",
      "\n",
      "   ğŸ“Œ search_recipe ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "      ì†ì„±: {\n",
      "      \"search_type\": \"menu\",\n",
      "      \"search_keyword\": \"ì¼€ì´í¬\",\n",
      "      \"selected_filters\": [\n",
      "            \"cooking_time:30min\"\n",
      "      ],\n",
      "      \"result_count\": 29\n",
      "}\n",
      "\n",
      "   ğŸ“Œ click_recipe_from_list ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "      ì†ì„±: {\n",
      "      \"search_type\": \"menu\",\n",
      "      \"search_keyword\": \"ì¼€ì´í¬\",\n",
      "      \"selected_filters\": [\n",
      "            \"cooking_time:30min\"\n",
      "      ],\n",
      "      \"result_count\": 29\n",
      "}\n",
      "\n",
      "   ğŸ“Œ click_recipe_from_list ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "      ì†ì„±: {\n",
      "      \"recipe_id\": \"6887527\",\n",
      "      \"rank\": 15\n",
      "}\n",
      "\n",
      "   ğŸ“Œ view_recipe_list ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "      ì†ì„±: {\n",
      "      \"recipe_id\": \"6887527\",\n",
      "      \"rank\": 15\n",
      "}\n",
      "\n",
      "   ğŸ“Œ view_recipe_list ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "      ì†ì„±: {\n",
      "      \"list_type\": \"recommended\",\n",
      "      \"displayed_recipe_ids\": [\n",
      "            \"6907236\",\n",
      "            \"6932804\",\n",
      "            \"7030920\",\n",
      "            \"6976413\",\n",
      "            \"6962512\",\n",
      "            \"6914026\",\n",
      "            \"5749393\",\n",
      "            \"6844278\",\n",
      "            \"7035494\",\n",
      "            \"6935339\",\n",
      "            \"6894794\"\n",
      "      ]\n",
      "}\n",
      "\n",
      "   ğŸ“Œ auth_success ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "      ì†ì„±: {\n",
      "      \"list_type\": \"recommended\",\n",
      "      \"displayed_recipe_ids\": [\n",
      "            \"6907236\",\n",
      "            \"6932804\",\n",
      "            \"7030920\",\n",
      "            \"6976413\",\n",
      "            \"6962512\",\n",
      "            \"6914026\",\n",
      "            \"5749393\",\n",
      "            \"6844278\",\n",
      "            \"7035494\",\n",
      "            \"6935339\",\n",
      "            \"6894794\"\n",
      "      ]\n",
      "}\n",
      "\n",
      "   ğŸ“Œ auth_success ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "      ì†ì„±: {\n",
      "      \"method\": \"kakao\",\n",
      "      \"type\": \"login\"\n",
      "}\n",
      "\n",
      "ğŸ“ˆ ê¸°ë³¸ í†µê³„:\n",
      "   ì´ ì´ë²¤íŠ¸ ìˆ˜: 10,031,152ê°œ\n",
      "      ì†ì„±: {\n",
      "      \"method\": \"kakao\",\n",
      "      \"type\": \"login\"\n",
      "}\n",
      "\n",
      "ğŸ“ˆ ê¸°ë³¸ í†µê³„:\n",
      "   ì´ ì´ë²¤íŠ¸ ìˆ˜: 10,031,152ê°œ\n",
      "   ê³ ìœ  ì‚¬ìš©ì ìˆ˜: 11,855ëª…\n",
      "   ê³ ìœ  ì‚¬ìš©ì ìˆ˜: 11,855ëª…\n",
      "   ê³ ìœ  ì„¸ì…˜ ìˆ˜: 633,587ê°œ\n",
      "   ê³ ìœ  ì„¸ì…˜ ìˆ˜: 633,587ê°œ\n",
      "   ì´ë²¤íŠ¸ íƒ€ì… ìˆ˜: 11ê°œ\n",
      "\n",
      "ğŸ¯ ì´ë²¤íŠ¸ íƒ€ì…ë³„ ë¶„í¬:\n",
      "   ì´ë²¤íŠ¸ íƒ€ì… ìˆ˜: 11ê°œ\n",
      "\n",
      "ğŸ¯ ì´ë²¤íŠ¸ íƒ€ì…ë³„ ë¶„í¬:\n",
      "   view_page: 1,878,487ê°œ (18.7%)\n",
      "   search_recipe: 1,831,844ê°œ (18.3%)\n",
      "   click_recipe_from_list: 1,786,735ê°œ (17.8%)\n",
      "   view_recipe_list: 1,668,894ê°œ (16.6%)\n",
      "   auth_success: 584,787ê°œ (5.8%)\n",
      "   create_comment: 550,788ê°œ (5.5%)\n",
      "   click_bookmark: 443,220ê°œ (4.4%)\n",
      "   click_like: 441,637ê°œ (4.4%)\n",
      "   click_auth_button: 355,312ê°œ (3.5%)\n",
      "   view_ads: 355,090ê°œ (3.5%)\n",
      "   click_ads: 134,358ê°œ (1.3%)\n",
      "\n",
      "ğŸ‰ ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì™„ë£Œ!\n",
      "ğŸ“Š ì´ 10,031,152ê°œì˜ ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ì´ë²¤íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "============================================================\n",
      "ğŸ• í˜„ì‹¤ì ì¸ ì‹œê°„ëŒ€ ë¶„í¬ ê²€ì¦ì„ ìœ„í•œ ìƒì„¸ ë¶„ì„ ì‹œì‘!\n",
      "============================================================\n",
      "ğŸ• ì‹œê°„ëŒ€ë³„ ì´ë²¤íŠ¸ ë¶„í¬ ë¶„ì„\n",
      "==================================================\n",
      "   view_page: 1,878,487ê°œ (18.7%)\n",
      "   search_recipe: 1,831,844ê°œ (18.3%)\n",
      "   click_recipe_from_list: 1,786,735ê°œ (17.8%)\n",
      "   view_recipe_list: 1,668,894ê°œ (16.6%)\n",
      "   auth_success: 584,787ê°œ (5.8%)\n",
      "   create_comment: 550,788ê°œ (5.5%)\n",
      "   click_bookmark: 443,220ê°œ (4.4%)\n",
      "   click_like: 441,637ê°œ (4.4%)\n",
      "   click_auth_button: 355,312ê°œ (3.5%)\n",
      "   view_ads: 355,090ê°œ (3.5%)\n",
      "   click_ads: 134,358ê°œ (1.3%)\n",
      "\n",
      "ğŸ‰ ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì™„ë£Œ!\n",
      "ğŸ“Š ì´ 10,031,152ê°œì˜ ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ì´ë²¤íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "============================================================\n",
      "ğŸ• í˜„ì‹¤ì ì¸ ì‹œê°„ëŒ€ ë¶„í¬ ê²€ì¦ì„ ìœ„í•œ ìƒì„¸ ë¶„ì„ ì‹œì‘!\n",
      "============================================================\n",
      "ğŸ• ì‹œê°„ëŒ€ë³„ ì´ë²¤íŠ¸ ë¶„í¬ ë¶„ì„\n",
      "==================================================\n",
      "ğŸ“Š ì „ì²´ ì‹œê°„ëŒ€ë³„ ì´ë²¤íŠ¸ ë¶„í¬:\n",
      "   00ì‹œ: 74,750ê°œ (0.7%) ğŸŒ™\n",
      "   01ì‹œ: 31,418ê°œ (0.3%) ğŸŒ™\n",
      "   02ì‹œ: 18,403ê°œ (0.2%) ğŸŒ™\n",
      "   03ì‹œ: 17,786ê°œ (0.2%) ğŸŒ™\n",
      "   04ì‹œ: 24,470ê°œ (0.2%) ğŸŒ™\n",
      "   05ì‹œ: 63,578ê°œ (0.6%) ğŸŒ™\n",
      "   06ì‹œ: 257,577ê°œ (2.6%) ğŸŒ…\n",
      "   07ì‹œ: 507,305ê°œ (5.1%) ğŸŒ…\n",
      "   08ì‹œ: 446,896ê°œ (4.5%) ğŸŒ…\n",
      "   09ì‹œ: 295,284ê°œ (2.9%) ğŸŒ…\n",
      "   10ì‹œ: 245,257ê°œ (2.4%) ğŸ“±\n",
      "   11ì‹œ: 566,237ê°œ (5.6%) ğŸ½ï¸\n",
      "   12ì‹œ: 715,214ê°œ (7.1%) ğŸ½ï¸\n",
      "   13ì‹œ: 473,524ê°œ (4.7%) ğŸ½ï¸\n",
      "   14ì‹œ: 254,650ê°œ (2.5%) ğŸ“±\n",
      "   15ì‹œ: 289,637ê°œ (2.9%) ğŸ“±\n",
      "   16ì‹œ: 344,934ê°œ (3.4%) ğŸ“±\n",
      "   17ì‹œ: 720,101ê°œ (7.2%) ğŸ“±\n",
      "   18ì‹œ: 1,232,984ê°œ (12.3%) ğŸ”¥ğŸ”¥\n",
      "   19ì‹œ: 1,236,154ê°œ (12.3%) ğŸ”¥ğŸ”¥\n",
      "   20ì‹œ: 949,107ê°œ (9.5%) ğŸ”¥ğŸ”¥\n",
      "   21ì‹œ: 601,774ê°œ (6.0%) ğŸŒƒ\n",
      "   22ì‹œ: 417,870ê°œ (4.2%) ğŸŒƒ\n",
      "   23ì‹œ: 246,242ê°œ (2.5%) ğŸŒƒ\n",
      "\n",
      "ğŸ”¥ í”¼í¬ ì‹œê°„ëŒ€ ë¶„ì„:\n",
      "   19ì‹œ: 1,236,154ê°œ (12.3%)\n",
      "   18ì‹œ: 1,232,984ê°œ (12.3%)\n",
      "   20ì‹œ: 949,107ê°œ (9.5%)\n",
      "   17ì‹œ: 720,101ê°œ (7.2%)\n",
      "   12ì‹œ: 715,214ê°œ (7.1%)\n",
      "\n",
      "ğŸŒ™ ìµœì € í™œë™ ì‹œê°„ëŒ€:\n",
      "   03ì‹œ: 17,786ê°œ (0.2%)\n",
      "   02ì‹œ: 18,403ê°œ (0.2%)\n",
      "   04ì‹œ: 24,470ê°œ (0.2%)\n",
      "   01ì‹œ: 31,418ê°œ (0.3%)\n",
      "   05ì‹œ: 63,578ê°œ (0.6%)\n",
      "\n",
      "ğŸ“… ìš”ì¼ë³„ íŒ¨í„´ ë¶„ì„:\n",
      "ğŸ“Š ì „ì²´ ì‹œê°„ëŒ€ë³„ ì´ë²¤íŠ¸ ë¶„í¬:\n",
      "   00ì‹œ: 74,750ê°œ (0.7%) ğŸŒ™\n",
      "   01ì‹œ: 31,418ê°œ (0.3%) ğŸŒ™\n",
      "   02ì‹œ: 18,403ê°œ (0.2%) ğŸŒ™\n",
      "   03ì‹œ: 17,786ê°œ (0.2%) ğŸŒ™\n",
      "   04ì‹œ: 24,470ê°œ (0.2%) ğŸŒ™\n",
      "   05ì‹œ: 63,578ê°œ (0.6%) ğŸŒ™\n",
      "   06ì‹œ: 257,577ê°œ (2.6%) ğŸŒ…\n",
      "   07ì‹œ: 507,305ê°œ (5.1%) ğŸŒ…\n",
      "   08ì‹œ: 446,896ê°œ (4.5%) ğŸŒ…\n",
      "   09ì‹œ: 295,284ê°œ (2.9%) ğŸŒ…\n",
      "   10ì‹œ: 245,257ê°œ (2.4%) ğŸ“±\n",
      "   11ì‹œ: 566,237ê°œ (5.6%) ğŸ½ï¸\n",
      "   12ì‹œ: 715,214ê°œ (7.1%) ğŸ½ï¸\n",
      "   13ì‹œ: 473,524ê°œ (4.7%) ğŸ½ï¸\n",
      "   14ì‹œ: 254,650ê°œ (2.5%) ğŸ“±\n",
      "   15ì‹œ: 289,637ê°œ (2.9%) ğŸ“±\n",
      "   16ì‹œ: 344,934ê°œ (3.4%) ğŸ“±\n",
      "   17ì‹œ: 720,101ê°œ (7.2%) ğŸ“±\n",
      "   18ì‹œ: 1,232,984ê°œ (12.3%) ğŸ”¥ğŸ”¥\n",
      "   19ì‹œ: 1,236,154ê°œ (12.3%) ğŸ”¥ğŸ”¥\n",
      "   20ì‹œ: 949,107ê°œ (9.5%) ğŸ”¥ğŸ”¥\n",
      "   21ì‹œ: 601,774ê°œ (6.0%) ğŸŒƒ\n",
      "   22ì‹œ: 417,870ê°œ (4.2%) ğŸŒƒ\n",
      "   23ì‹œ: 246,242ê°œ (2.5%) ğŸŒƒ\n",
      "\n",
      "ğŸ”¥ í”¼í¬ ì‹œê°„ëŒ€ ë¶„ì„:\n",
      "   19ì‹œ: 1,236,154ê°œ (12.3%)\n",
      "   18ì‹œ: 1,232,984ê°œ (12.3%)\n",
      "   20ì‹œ: 949,107ê°œ (9.5%)\n",
      "   17ì‹œ: 720,101ê°œ (7.2%)\n",
      "   12ì‹œ: 715,214ê°œ (7.1%)\n",
      "\n",
      "ğŸŒ™ ìµœì € í™œë™ ì‹œê°„ëŒ€:\n",
      "   03ì‹œ: 17,786ê°œ (0.2%)\n",
      "   02ì‹œ: 18,403ê°œ (0.2%)\n",
      "   04ì‹œ: 24,470ê°œ (0.2%)\n",
      "   01ì‹œ: 31,418ê°œ (0.3%)\n",
      "   05ì‹œ: 63,578ê°œ (0.6%)\n",
      "\n",
      "ğŸ“… ìš”ì¼ë³„ íŒ¨í„´ ë¶„ì„:\n",
      "\n",
      "   ğŸ“Š í‰ì¼ í”¼í¬ ì‹œê°„ëŒ€ TOP 3:\n",
      "     18ì‹œ: 891,767ê°œ (12.4%)\n",
      "     19ì‹œ: 874,358ê°œ (12.2%)\n",
      "     20ì‹œ: 692,791ê°œ (9.7%)\n",
      "\n",
      "   ğŸ“Š í‰ì¼ í”¼í¬ ì‹œê°„ëŒ€ TOP 3:\n",
      "     18ì‹œ: 891,767ê°œ (12.4%)\n",
      "     19ì‹œ: 874,358ê°œ (12.2%)\n",
      "     20ì‹œ: 692,791ê°œ (9.7%)\n",
      "\n",
      "   ğŸ“Š ì£¼ë§ í”¼í¬ ì‹œê°„ëŒ€ TOP 3:\n",
      "     19ì‹œ: 361,796ê°œ (12.6%)\n",
      "     18ì‹œ: 341,217ê°œ (11.9%)\n",
      "     12ì‹œ: 260,201ê°œ (9.1%)\n",
      "\n",
      "âœ… í˜„ì‹¤ì„± ì²´í¬:\n",
      "   ì €ë… í”¼í¬ (17-20ì‹œ): 4,138,346ê°œ (41.3%)\n",
      "   ì ì‹¬ ì‹œê°„ (11-13ì‹œ): 1,754,975ê°œ (17.5%)\n",
      "   ì‹¬ì•¼ ì‹œê°„ (0-5ì‹œ): 230,405ê°œ (2.3%)\n",
      "   âœ… ì €ë… í”¼í¬ê°€ ê°€ì¥ ë†’ìŒ - í˜„ì‹¤ì !\n",
      "   âœ… ì‹¬ì•¼ ì‹œê°„ í™œë™ ì ì ˆíˆ ë‚®ìŒ\n",
      "\n",
      "ğŸ¯ ì‹œê°„ëŒ€ ë¶„í¬ ë¶„ì„ ì™„ë£Œ!\n",
      "ğŸ“ˆ ì €ë… í”¼í¬(17-20ì‹œ), ì ì‹¬(11-13ì‹œ), ì•„ì¹¨(6-9ì‹œ) íŒ¨í„´ì´ ì˜¬ë°”ë¥´ê²Œ ì ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n",
      "\n",
      "   ğŸ“Š ì£¼ë§ í”¼í¬ ì‹œê°„ëŒ€ TOP 3:\n",
      "     19ì‹œ: 361,796ê°œ (12.6%)\n",
      "     18ì‹œ: 341,217ê°œ (11.9%)\n",
      "     12ì‹œ: 260,201ê°œ (9.1%)\n",
      "\n",
      "âœ… í˜„ì‹¤ì„± ì²´í¬:\n",
      "   ì €ë… í”¼í¬ (17-20ì‹œ): 4,138,346ê°œ (41.3%)\n",
      "   ì ì‹¬ ì‹œê°„ (11-13ì‹œ): 1,754,975ê°œ (17.5%)\n",
      "   ì‹¬ì•¼ ì‹œê°„ (0-5ì‹œ): 230,405ê°œ (2.3%)\n",
      "   âœ… ì €ë… í”¼í¬ê°€ ê°€ì¥ ë†’ìŒ - í˜„ì‹¤ì !\n",
      "   âœ… ì‹¬ì•¼ ì‹œê°„ í™œë™ ì ì ˆíˆ ë‚®ìŒ\n",
      "\n",
      "ğŸ¯ ì‹œê°„ëŒ€ ë¶„í¬ ë¶„ì„ ì™„ë£Œ!\n",
      "ğŸ“ˆ ì €ë… í”¼í¬(17-20ì‹œ), ì ì‹¬(11-13ì‹œ), ì•„ì¹¨(6-9ì‹œ) íŒ¨í„´ì´ ì˜¬ë°”ë¥´ê²Œ ì ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 8ï¸âƒ£ ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ë° ê²€ì¦ ì‹¤í–‰\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸš€ ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆë¡œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì‹œì‘!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆë¡œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„±\n",
    "correct_event_df = generate_correct_schema_event_logs()\n",
    "\n",
    "if correct_event_df is not None:\n",
    "    print(f\"\\nâœ… ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì„±ê³µ!\")\n",
    "    print(f\"ğŸ“‚ íŒŒì¼ ìœ„ì¹˜: {OUTPUT_LOG_PATH}event_logs_10m.parquet\")\n",
    "    \n",
    "    # ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤í–‰\n",
    "    print(f\"\\nğŸ” ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹œì‘!\")\n",
    "    schema_valid = validate_correct_schema(correct_event_df)\n",
    "    \n",
    "    if schema_valid:\n",
    "        print(f\"\\nğŸ‰ ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì™„ë£Œ!\")\n",
    "        print(f\"ğŸ“Š ì´ {len(correct_event_df):,}ê°œì˜ ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ì´ë²¤íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        # ì‹œê°„ëŒ€ë³„ ë¶„í¬ ë¶„ì„ ì‹¤í–‰\n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ• í˜„ì‹¤ì ì¸ ì‹œê°„ëŒ€ ë¶„í¬ ê²€ì¦ì„ ìœ„í•œ ìƒì„¸ ë¶„ì„ ì‹œì‘!\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        analyzed_df = analyze_hourly_distribution(correct_event_df)\n",
    "        \n",
    "        print(f\"\\nğŸ¯ ì‹œê°„ëŒ€ ë¶„í¬ ë¶„ì„ ì™„ë£Œ!\")\n",
    "        print(f\"ğŸ“ˆ ì €ë… í”¼í¬(17-20ì‹œ), ì ì‹¬(11-13ì‹œ), ì•„ì¹¨(6-9ì‹œ) íŒ¨í„´ì´ ì˜¬ë°”ë¥´ê²Œ ì ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nâŒ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤íŒ¨!\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì‹¤íŒ¨!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb81d2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€\n",
      "ğŸ“¤ ì¹´í”„ì¹´ ì „ì†¡ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì‹œì‘!\n",
      "============================================================\n",
      "ğŸ“Š ì›ë³¸ ë°ì´í„°: 10,031,152ê°œ ì´ë²¤íŠ¸\n",
      "\n",
      "ğŸ”„ 1/10 ìƒ˜í”Œ (10%) ìƒì„± ì¤‘...\n",
      "   ğŸ“ ìƒ˜í”Œë§ ë¹„ìœ¨: 10.0%\n",
      "   ğŸ“Š ìƒ˜í”Œ í¬ê¸°: 1,003,116ê°œ ì´ë²¤íŠ¸\n",
      "   ğŸ“ ìƒ˜í”Œë§ ë¹„ìœ¨: 10.0%\n",
      "   ğŸ“Š ìƒ˜í”Œ í¬ê¸°: 1,003,116ê°œ ì´ë²¤íŠ¸\n",
      "   â° ì‹œê°„ ë²”ìœ„: 2024-08-01T00:09:24.000000Z ~ 2025-07-24T00:29:42.000000Z\n",
      "   â° ì‹œê°„ ë²”ìœ„: 2024-08-01T00:09:24.000000Z ~ 2025-07-24T00:29:42.000000Z\n",
      "   ğŸ’¾ JSONL í¬ë§·ìœ¼ë¡œ ì €ì¥ ì¤‘...\n",
      "   ğŸ’¾ JSONL í¬ë§·ìœ¼ë¡œ ì €ì¥ ì¤‘...\n",
      "   âœ… ì €ì¥ ì™„ë£Œ:\n",
      "      ğŸ“ Parquet: event_logs/kafka_samples\\kafka_sample_1_10.parquet (114.76 MB)\n",
      "      ğŸ“„ JSONL: event_logs/kafka_samples\\kafka_sample_1_10.jsonl (450.36 MB)\n",
      "   ğŸ“ˆ ìƒ˜í”Œ í†µê³„:\n",
      "      ê³ ìœ  ì‚¬ìš©ì: 11,844ëª…\n",
      "   âœ… ì €ì¥ ì™„ë£Œ:\n",
      "      ğŸ“ Parquet: event_logs/kafka_samples\\kafka_sample_1_10.parquet (114.76 MB)\n",
      "      ğŸ“„ JSONL: event_logs/kafka_samples\\kafka_sample_1_10.jsonl (450.36 MB)\n",
      "   ğŸ“ˆ ìƒ˜í”Œ í†µê³„:\n",
      "      ê³ ìœ  ì‚¬ìš©ì: 11,844ëª…\n",
      "      ê³ ìœ  ì„¸ì…˜: 478,109ê°œ\n",
      "      ì´ë²¤íŠ¸ íƒ€ì…: 11ê°œ\n",
      "      ê³ ìœ  ì„¸ì…˜: 478,109ê°œ\n",
      "      ì´ë²¤íŠ¸ íƒ€ì…: 11ê°œ\n",
      "      í”¼í¬ ì‹œê°„ëŒ€:\n",
      "        19ì‹œ: 123,608ê°œ (12.3%)\n",
      "        18ì‹œ: 123,311ê°œ (12.3%)\n",
      "        20ì‹œ: 94,896ê°œ (9.5%)\n",
      "\n",
      "ğŸ”„ 1/50 ìƒ˜í”Œ (2%) ìƒì„± ì¤‘...\n",
      "      í”¼í¬ ì‹œê°„ëŒ€:\n",
      "        19ì‹œ: 123,608ê°œ (12.3%)\n",
      "        18ì‹œ: 123,311ê°œ (12.3%)\n",
      "        20ì‹œ: 94,896ê°œ (9.5%)\n",
      "\n",
      "ğŸ”„ 1/50 ìƒ˜í”Œ (2%) ìƒì„± ì¤‘...\n",
      "   ğŸ“ ìƒ˜í”Œë§ ë¹„ìœ¨: 2.0%\n",
      "   ğŸ“Š ìƒ˜í”Œ í¬ê¸°: 200,624ê°œ ì´ë²¤íŠ¸\n",
      "   â° ì‹œê°„ ë²”ìœ„: 2024-08-01T00:09:24.000000Z ~ 2025-07-24T00:29:42.000000Z\n",
      "   ğŸ“ ìƒ˜í”Œë§ ë¹„ìœ¨: 2.0%\n",
      "   ğŸ“Š ìƒ˜í”Œ í¬ê¸°: 200,624ê°œ ì´ë²¤íŠ¸\n",
      "   â° ì‹œê°„ ë²”ìœ„: 2024-08-01T00:09:24.000000Z ~ 2025-07-24T00:29:42.000000Z\n",
      "   ğŸ’¾ JSONL í¬ë§·ìœ¼ë¡œ ì €ì¥ ì¤‘...\n",
      "   ğŸ’¾ JSONL í¬ë§·ìœ¼ë¡œ ì €ì¥ ì¤‘...\n",
      "   âœ… ì €ì¥ ì™„ë£Œ:\n",
      "      ğŸ“ Parquet: event_logs/kafka_samples\\kafka_sample_1_50.parquet (25.59 MB)\n",
      "      ğŸ“„ JSONL: event_logs/kafka_samples\\kafka_sample_1_50.jsonl (90.08 MB)\n",
      "   ğŸ“ˆ ìƒ˜í”Œ í†µê³„:\n",
      "      ê³ ìœ  ì‚¬ìš©ì: 11,694ëª…\n",
      "      ê³ ìœ  ì„¸ì…˜: 169,918ê°œ\n",
      "      ì´ë²¤íŠ¸ íƒ€ì…: 11ê°œ\n",
      "   âœ… ì €ì¥ ì™„ë£Œ:\n",
      "      ğŸ“ Parquet: event_logs/kafka_samples\\kafka_sample_1_50.parquet (25.59 MB)\n",
      "      ğŸ“„ JSONL: event_logs/kafka_samples\\kafka_sample_1_50.jsonl (90.08 MB)\n",
      "   ğŸ“ˆ ìƒ˜í”Œ í†µê³„:\n",
      "      ê³ ìœ  ì‚¬ìš©ì: 11,694ëª…\n",
      "      ê³ ìœ  ì„¸ì…˜: 169,918ê°œ\n",
      "      ì´ë²¤íŠ¸ íƒ€ì…: 11ê°œ\n",
      "      í”¼í¬ ì‹œê°„ëŒ€:\n",
      "        19ì‹œ: 24,723ê°œ (12.3%)\n",
      "        18ì‹œ: 24,661ê°œ (12.3%)\n",
      "        20ì‹œ: 18,967ê°œ (9.5%)\n",
      "\n",
      "ğŸ”„ 1/100 ìƒ˜í”Œ (1%) ìƒì„± ì¤‘...\n",
      "      í”¼í¬ ì‹œê°„ëŒ€:\n",
      "        19ì‹œ: 24,723ê°œ (12.3%)\n",
      "        18ì‹œ: 24,661ê°œ (12.3%)\n",
      "        20ì‹œ: 18,967ê°œ (9.5%)\n",
      "\n",
      "ğŸ”„ 1/100 ìƒ˜í”Œ (1%) ìƒì„± ì¤‘...\n",
      "   ğŸ“ ìƒ˜í”Œë§ ë¹„ìœ¨: 1.0%\n",
      "   ğŸ“Š ìƒ˜í”Œ í¬ê¸°: 100,312ê°œ ì´ë²¤íŠ¸\n",
      "   â° ì‹œê°„ ë²”ìœ„: 2024-08-01T00:09:24.000000Z ~ 2025-07-24T00:16:01.000000Z\n",
      "   ğŸ“ ìƒ˜í”Œë§ ë¹„ìœ¨: 1.0%\n",
      "   ğŸ“Š ìƒ˜í”Œ í¬ê¸°: 100,312ê°œ ì´ë²¤íŠ¸\n",
      "   â° ì‹œê°„ ë²”ìœ„: 2024-08-01T00:09:24.000000Z ~ 2025-07-24T00:16:01.000000Z\n",
      "   ğŸ’¾ JSONL í¬ë§·ìœ¼ë¡œ ì €ì¥ ì¤‘...\n",
      "   ğŸ’¾ JSONL í¬ë§·ìœ¼ë¡œ ì €ì¥ ì¤‘...\n",
      "   âœ… ì €ì¥ ì™„ë£Œ:\n",
      "      ğŸ“ Parquet: event_logs/kafka_samples\\kafka_sample_1_100.parquet (13.19 MB)\n",
      "      ğŸ“„ JSONL: event_logs/kafka_samples\\kafka_sample_1_100.jsonl (45.06 MB)\n",
      "   ğŸ“ˆ ìƒ˜í”Œ í†µê³„:\n",
      "      ê³ ìœ  ì‚¬ìš©ì: 11,214ëª…\n",
      "      ê³ ìœ  ì„¸ì…˜: 92,606ê°œ\n",
      "      ì´ë²¤íŠ¸ íƒ€ì…: 11ê°œ\n",
      "   âœ… ì €ì¥ ì™„ë£Œ:\n",
      "      ğŸ“ Parquet: event_logs/kafka_samples\\kafka_sample_1_100.parquet (13.19 MB)\n",
      "      ğŸ“„ JSONL: event_logs/kafka_samples\\kafka_sample_1_100.jsonl (45.06 MB)\n",
      "   ğŸ“ˆ ìƒ˜í”Œ í†µê³„:\n",
      "      ê³ ìœ  ì‚¬ìš©ì: 11,214ëª…\n",
      "      ê³ ìœ  ì„¸ì…˜: 92,606ê°œ\n",
      "      ì´ë²¤íŠ¸ íƒ€ì…: 11ê°œ\n",
      "      í”¼í¬ ì‹œê°„ëŒ€:\n",
      "        19ì‹œ: 12,371ê°œ (12.3%)\n",
      "        18ì‹œ: 12,322ê°œ (12.3%)\n",
      "        20ì‹œ: 9,484ê°œ (9.5%)\n",
      "\n",
      "============================================================\n",
      "ğŸ‰ ì¹´í”„ì¹´ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "============================================================\n",
      "ğŸ“ ì €ì¥ ìœ„ì¹˜: event_logs/kafka_samples\n",
      "\n",
      "ğŸ“¦ 1/10 ìƒ˜í”Œ (10%):\n",
      "   ğŸ“Š ì´ë²¤íŠ¸ ìˆ˜: 1,003,116ê°œ\n",
      "   ğŸ“ Parquet: kafka_sample_1_10.parquet\n",
      "   ğŸ“„ JSONL: kafka_sample_1_10.jsonl\n",
      "\n",
      "ğŸ“¦ 1/50 ìƒ˜í”Œ (2%):\n",
      "   ğŸ“Š ì´ë²¤íŠ¸ ìˆ˜: 200,624ê°œ\n",
      "   ğŸ“ Parquet: kafka_sample_1_50.parquet\n",
      "   ğŸ“„ JSONL: kafka_sample_1_50.jsonl\n",
      "\n",
      "ğŸ“¦ 1/100 ìƒ˜í”Œ (1%):\n",
      "   ğŸ“Š ì´ë²¤íŠ¸ ìˆ˜: 100,312ê°œ\n",
      "   ğŸ“ Parquet: kafka_sample_1_100.parquet\n",
      "   ğŸ“„ JSONL: kafka_sample_1_100.jsonl\n",
      "\n",
      "ğŸ”§ ì¹´í”„ì¹´ í”„ë¡œë“€ì„œ ì˜ˆì‹œ ì½”ë“œ: kafka_producer_example.py\n",
      "\n",
      "ğŸ’¡ ì‚¬ìš© ê°€ì´ë“œ:\n",
      "   1. JSONL íŒŒì¼ì€ ì¹´í”„ì¹´ í”„ë¡œë“€ì„œì—ì„œ ì§ì ‘ ì‚¬ìš© ê°€ëŠ¥\n",
      "   2. Parquet íŒŒì¼ì€ íŒë‹¤ìŠ¤ë¡œ ì½ì–´ì„œ ë¶„ì„ ê°€ëŠ¥\n",
      "   3. kafka_producer_example.pyë¥¼ ì°¸ê³ í•˜ì—¬ ì¹´í”„ì¹´ ì „ì†¡\n",
      "\n",
      "ğŸ“‹ ì¹´í”„ì¹´ í† í”½ ê¶Œì¥ ì„¤ì •:\n",
      "   - í† í”½ëª…: recipe-events\n",
      "   - íŒŒí‹°ì…˜: 3-6ê°œ (ë°ì´í„° ë³¼ë¥¨ì— ë”°ë¼)\n",
      "   - ë³µì œë³¸: 2-3ê°œ (ì•ˆì •ì„±)\n",
      "   - ì••ì¶•: gzip ë˜ëŠ” snappy\n",
      "\n",
      "âœ… ëª¨ë“  ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ë° ê²€ì¦ ì™„ë£Œ!\n",
      "ğŸ¯ í•„ìš”ì‹œ ìœ„ ì£¼ì„ì„ í•´ì œí•˜ì—¬ CSV ë³€í™˜ì„ ì‹¤í–‰í•˜ì„¸ìš”.\n",
      "ğŸ“¤ ì¹´í”„ì¹´ ìƒ˜í”Œ ë°ì´í„°ë„ í•¨ê»˜ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "      í”¼í¬ ì‹œê°„ëŒ€:\n",
      "        19ì‹œ: 12,371ê°œ (12.3%)\n",
      "        18ì‹œ: 12,322ê°œ (12.3%)\n",
      "        20ì‹œ: 9,484ê°œ (9.5%)\n",
      "\n",
      "============================================================\n",
      "ğŸ‰ ì¹´í”„ì¹´ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "============================================================\n",
      "ğŸ“ ì €ì¥ ìœ„ì¹˜: event_logs/kafka_samples\n",
      "\n",
      "ğŸ“¦ 1/10 ìƒ˜í”Œ (10%):\n",
      "   ğŸ“Š ì´ë²¤íŠ¸ ìˆ˜: 1,003,116ê°œ\n",
      "   ğŸ“ Parquet: kafka_sample_1_10.parquet\n",
      "   ğŸ“„ JSONL: kafka_sample_1_10.jsonl\n",
      "\n",
      "ğŸ“¦ 1/50 ìƒ˜í”Œ (2%):\n",
      "   ğŸ“Š ì´ë²¤íŠ¸ ìˆ˜: 200,624ê°œ\n",
      "   ğŸ“ Parquet: kafka_sample_1_50.parquet\n",
      "   ğŸ“„ JSONL: kafka_sample_1_50.jsonl\n",
      "\n",
      "ğŸ“¦ 1/100 ìƒ˜í”Œ (1%):\n",
      "   ğŸ“Š ì´ë²¤íŠ¸ ìˆ˜: 100,312ê°œ\n",
      "   ğŸ“ Parquet: kafka_sample_1_100.parquet\n",
      "   ğŸ“„ JSONL: kafka_sample_1_100.jsonl\n",
      "\n",
      "ğŸ”§ ì¹´í”„ì¹´ í”„ë¡œë“€ì„œ ì˜ˆì‹œ ì½”ë“œ: kafka_producer_example.py\n",
      "\n",
      "ğŸ’¡ ì‚¬ìš© ê°€ì´ë“œ:\n",
      "   1. JSONL íŒŒì¼ì€ ì¹´í”„ì¹´ í”„ë¡œë“€ì„œì—ì„œ ì§ì ‘ ì‚¬ìš© ê°€ëŠ¥\n",
      "   2. Parquet íŒŒì¼ì€ íŒë‹¤ìŠ¤ë¡œ ì½ì–´ì„œ ë¶„ì„ ê°€ëŠ¥\n",
      "   3. kafka_producer_example.pyë¥¼ ì°¸ê³ í•˜ì—¬ ì¹´í”„ì¹´ ì „ì†¡\n",
      "\n",
      "ğŸ“‹ ì¹´í”„ì¹´ í† í”½ ê¶Œì¥ ì„¤ì •:\n",
      "   - í† í”½ëª…: recipe-events\n",
      "   - íŒŒí‹°ì…˜: 3-6ê°œ (ë°ì´í„° ë³¼ë¥¨ì— ë”°ë¼)\n",
      "   - ë³µì œë³¸: 2-3ê°œ (ì•ˆì •ì„±)\n",
      "   - ì••ì¶•: gzip ë˜ëŠ” snappy\n",
      "\n",
      "âœ… ëª¨ë“  ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ë° ê²€ì¦ ì™„ë£Œ!\n",
      "ğŸ¯ í•„ìš”ì‹œ ìœ„ ì£¼ì„ì„ í•´ì œí•˜ì—¬ CSV ë³€í™˜ì„ ì‹¤í–‰í•˜ì„¸ìš”.\n",
      "ğŸ“¤ ì¹´í”„ì¹´ ìƒ˜í”Œ ë°ì´í„°ë„ í•¨ê»˜ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 9ï¸âƒ£ ì¹´í”„ì¹´ ì „ì†¡ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„±\n",
    "# ===================================================================\n",
    "\n",
    "def generate_kafka_sample_data(original_df, sample_ratios=[0.1, 0.02, 0.01]):\n",
    "    \"\"\"\n",
    "    ì¹´í”„ì¹´ ì „ì†¡ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„±\n",
    "    \n",
    "    Args:\n",
    "        original_df: ì›ë³¸ ì´ë²¤íŠ¸ ë¡œê·¸ ë°ì´í„°í”„ë ˆì„\n",
    "        sample_ratios: ìƒ˜í”Œë§ ë¹„ìœ¨ ë¦¬ìŠ¤íŠ¸ [1/10, 1/50, 1/100]\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸ“¤ ì¹´í”„ì¹´ ì „ì†¡ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì‹œì‘!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if original_df is None or len(original_df) == 0:\n",
    "        print(\"âŒ ì›ë³¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        return\n",
    "    \n",
    "    original_count = len(original_df)\n",
    "    print(f\"ğŸ“Š ì›ë³¸ ë°ì´í„°: {original_count:,}ê°œ ì´ë²¤íŠ¸\")\n",
    "    \n",
    "    # ì¹´í”„ì¹´ ìƒ˜í”Œ ë°ì´í„° ì €ì¥ ë””ë ‰í† ë¦¬\n",
    "    kafka_sample_path = os.path.join(OUTPUT_LOG_PATH, 'kafka_samples')\n",
    "    os.makedirs(kafka_sample_path, exist_ok=True)\n",
    "    \n",
    "    # ê° ë¹„ìœ¨ë³„ë¡œ ìƒ˜í”Œ ìƒì„±\n",
    "    sample_info = {\n",
    "        0.1: {'name': '1_10', 'description': '1/10 ìƒ˜í”Œ (10%)'},\n",
    "        0.02: {'name': '1_50', 'description': '1/50 ìƒ˜í”Œ (2%)'},\n",
    "        0.01: {'name': '1_100', 'description': '1/100 ìƒ˜í”Œ (1%)'}\n",
    "    }\n",
    "    \n",
    "    generated_samples = {}\n",
    "    \n",
    "    for ratio in sample_ratios:\n",
    "        if ratio not in sample_info:\n",
    "            continue\n",
    "            \n",
    "        sample_name = sample_info[ratio]['name']\n",
    "        sample_desc = sample_info[ratio]['description']\n",
    "        \n",
    "        print(f\"\\nğŸ”„ {sample_desc} ìƒì„± ì¤‘...\")\n",
    "        \n",
    "        # ìƒ˜í”Œë§ (ì‹œê°„ìˆœ ìœ ì§€ë¥¼ ìœ„í•´ ì •ë ¬ í›„ ê· ë“± ìƒ˜í”Œë§)\n",
    "        df_sorted = original_df.sort_values('timestamp').reset_index(drop=True)\n",
    "        \n",
    "        # ê· ë“± ê°„ê²©ìœ¼ë¡œ ìƒ˜í”Œë§\n",
    "        step = int(1 / ratio)\n",
    "        sample_indices = range(0, len(df_sorted), step)\n",
    "        sample_df = df_sorted.iloc[sample_indices].copy()\n",
    "        \n",
    "        sample_count = len(sample_df)\n",
    "        \n",
    "        print(f\"   ğŸ“ ìƒ˜í”Œë§ ë¹„ìœ¨: {ratio:.1%}\")\n",
    "        print(f\"   ğŸ“Š ìƒ˜í”Œ í¬ê¸°: {sample_count:,}ê°œ ì´ë²¤íŠ¸\")\n",
    "        print(f\"   â° ì‹œê°„ ë²”ìœ„: {sample_df['timestamp'].min()} ~ {sample_df['timestamp'].max()}\")\n",
    "        \n",
    "        # íŒŒì¼ ì €ì¥\n",
    "        parquet_file = os.path.join(kafka_sample_path, f'kafka_sample_{sample_name}.parquet')\n",
    "        json_file = os.path.join(kafka_sample_path, f'kafka_sample_{sample_name}.jsonl')\n",
    "        \n",
    "        # Parquet ì €ì¥\n",
    "        sample_df.to_parquet(parquet_file, index=False)\n",
    "        parquet_size_mb = os.path.getsize(parquet_file) / (1024 * 1024)\n",
    "        \n",
    "        # JSONL ì €ì¥ (ì¹´í”„ì¹´ì—ì„œ ìì£¼ ì‚¬ìš©)\n",
    "        print(f\"   ğŸ’¾ JSONL í¬ë§·ìœ¼ë¡œ ì €ì¥ ì¤‘...\")\n",
    "        with open(json_file, 'w', encoding='utf-8') as f:\n",
    "            for _, row in sample_df.iterrows():\n",
    "                # ê° í–‰ì„ JSONìœ¼ë¡œ ë³€í™˜\n",
    "                json_record = {\n",
    "                    'event_name': row['event_name'],\n",
    "                    'event_id': row['event_id'],\n",
    "                    'user_id': row['user_id'],\n",
    "                    'anonymous_id': row['anonymous_id'],\n",
    "                    'session_id': row['session_id'],\n",
    "                    'context': json.loads(row['context']),  # JSON ë¬¸ìì—´ì„ ê°ì²´ë¡œ ë³€í™˜\n",
    "                    'event_properties': json.loads(row['event_properties']),  # JSON ë¬¸ìì—´ì„ ê°ì²´ë¡œ ë³€í™˜\n",
    "                    'timestamp': row['timestamp']\n",
    "                }\n",
    "                f.write(json.dumps(json_record, ensure_ascii=False) + '\\n')\n",
    "        \n",
    "        jsonl_size_mb = os.path.getsize(json_file) / (1024 * 1024)\n",
    "        \n",
    "        print(f\"   âœ… ì €ì¥ ì™„ë£Œ:\")\n",
    "        print(f\"      ğŸ“ Parquet: {parquet_file} ({parquet_size_mb:.2f} MB)\")\n",
    "        print(f\"      ğŸ“„ JSONL: {json_file} ({jsonl_size_mb:.2f} MB)\")\n",
    "        \n",
    "        # ìƒ˜í”Œ í†µê³„\n",
    "        print(f\"   ğŸ“ˆ ìƒ˜í”Œ í†µê³„:\")\n",
    "        print(f\"      ê³ ìœ  ì‚¬ìš©ì: {sample_df['user_id'].nunique():,}ëª…\")\n",
    "        print(f\"      ê³ ìœ  ì„¸ì…˜: {sample_df['session_id'].nunique():,}ê°œ\")\n",
    "        print(f\"      ì´ë²¤íŠ¸ íƒ€ì…: {sample_df['event_name'].nunique()}ê°œ\")\n",
    "        \n",
    "        # ì‹œê°„ëŒ€ë³„ ë¶„í¬ í™•ì¸\n",
    "        sample_df_copy = sample_df.copy()\n",
    "        sample_df_copy['timestamp'] = pd.to_datetime(sample_df_copy['timestamp'])\n",
    "        sample_df_copy['hour'] = sample_df_copy['timestamp'].dt.hour\n",
    "        \n",
    "        hourly_dist = sample_df_copy['hour'].value_counts().sort_index()\n",
    "        peak_hours = hourly_dist.nlargest(3)\n",
    "        \n",
    "        print(f\"      í”¼í¬ ì‹œê°„ëŒ€:\")\n",
    "        for hour, count in peak_hours.items():\n",
    "            percentage = (count / len(sample_df_copy)) * 100\n",
    "            print(f\"        {hour:02d}ì‹œ: {count:,}ê°œ ({percentage:.1f}%)\")\n",
    "        \n",
    "        generated_samples[sample_name] = {\n",
    "            'dataframe': sample_df,\n",
    "            'parquet_file': parquet_file,\n",
    "            'jsonl_file': json_file,\n",
    "            'count': sample_count,\n",
    "            'ratio': ratio\n",
    "        }\n",
    "    \n",
    "    # ì¹´í”„ì¹´ í”„ë¡œë“€ì„œ ì˜ˆì‹œ ì½”ë“œ ìƒì„±\n",
    "    producer_code_file = os.path.join(kafka_sample_path, 'kafka_producer_example.py')\n",
    "    \n",
    "    producer_code = '''#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "ì¹´í”„ì¹´ í”„ë¡œë“€ì„œ ì˜ˆì‹œ ì½”ë“œ\n",
    "ìƒì„±ëœ JSONL ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì¹´í”„ì¹´ë¡œ ì „ì†¡í•˜ëŠ” ì˜ˆì‹œ\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import time\n",
    "from kafka import KafkaProducer\n",
    "from datetime import datetime\n",
    "\n",
    "def create_kafka_producer(bootstrap_servers=['localhost:9092']):\n",
    "    \"\"\"ì¹´í”„ì¹´ í”„ë¡œë“€ì„œ ìƒì„±\"\"\"\n",
    "    return KafkaProducer(\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        value_serializer=lambda v: json.dumps(v, ensure_ascii=False).encode('utf-8'),\n",
    "        key_serializer=lambda k: k.encode('utf-8') if k else None,\n",
    "        acks='all',  # ëª¨ë“  ë³µì œë³¸ì—ì„œ í™•ì¸\n",
    "        retries=3,\n",
    "        batch_size=16384,\n",
    "        linger_ms=10,\n",
    "        buffer_memory=33554432\n",
    "    )\n",
    "\n",
    "def send_jsonl_to_kafka(jsonl_file, topic_name, producer, delay_ms=100):\n",
    "    \"\"\"JSONL íŒŒì¼ì„ ì¹´í”„ì¹´ í† í”½ìœ¼ë¡œ ì „ì†¡\"\"\"\n",
    "    \n",
    "    print(f\"ğŸ“¤ ì¹´í”„ì¹´ ì „ì†¡ ì‹œì‘: {jsonl_file} -> {topic_name}\")\n",
    "    \n",
    "    sent_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    with open(jsonl_file, 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f, 1):\n",
    "            try:\n",
    "                # JSON íŒŒì‹±\n",
    "                event_data = json.loads(line.strip())\n",
    "                \n",
    "                # í‚¤ ìƒì„± (ì„ íƒì )\n",
    "                key = f\"{event_data['user_id']}_{event_data['session_id']}\"\n",
    "                \n",
    "                # ì¹´í”„ì¹´ë¡œ ì „ì†¡\n",
    "                future = producer.send(\n",
    "                    topic=topic_name,\n",
    "                    key=key,\n",
    "                    value=event_data,\n",
    "                    timestamp_ms=int(time.time() * 1000)\n",
    "                )\n",
    "                \n",
    "                # ì „ì†¡ ê²°ê³¼ í™•ì¸ (ë¹„ë™ê¸°)\n",
    "                future.add_callback(lambda metadata: None)\n",
    "                future.add_errback(lambda e: print(f\"âŒ ì „ì†¡ ì‹¤íŒ¨: {e}\"))\n",
    "                \n",
    "                sent_count += 1\n",
    "                \n",
    "                # ì§„í–‰ë¥  í‘œì‹œ\n",
    "                if sent_count % 1000 == 0:\n",
    "                    print(f\"   ğŸ“Š ì§„í–‰ë¥ : {sent_count:,}ê°œ ì „ì†¡ë¨\")\n",
    "                \n",
    "                # ì „ì†¡ ê°„ê²© ì¡°ì ˆ\n",
    "                if delay_ms > 0:\n",
    "                    time.sleep(delay_ms / 1000.0)\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_count += 1\n",
    "                print(f\"âŒ ë¼ì¸ {line_num} ì²˜ë¦¬ ì˜¤ë¥˜: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # ëª¨ë“  ë©”ì‹œì§€ ì „ì†¡ ì™„ë£Œ ëŒ€ê¸°\n",
    "    producer.flush()\n",
    "    \n",
    "    print(f\"âœ… ì¹´í”„ì¹´ ì „ì†¡ ì™„ë£Œ!\")\n",
    "    print(f\"   ğŸ“Š ì„±ê³µ: {sent_count:,}ê°œ\")\n",
    "    print(f\"   âŒ ì‹¤íŒ¨: {error_count:,}ê°œ\")\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # ì¹´í”„ì¹´ ì„¤ì •\n",
    "    KAFKA_SERVERS = ['localhost:9092']\n",
    "    TOPIC_NAME = 'recipe-events'\n",
    "    \n",
    "    # ìƒ˜í”Œ íŒŒì¼ ê²½ë¡œ\n",
    "    SAMPLE_FILES = {\n",
    "        '1/10 ìƒ˜í”Œ': 'kafka_sample_1_10.jsonl',\n",
    "        '1/50 ìƒ˜í”Œ': 'kafka_sample_1_50.jsonl', \n",
    "        '1/100 ìƒ˜í”Œ': 'kafka_sample_1_100.jsonl'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # í”„ë¡œë“€ì„œ ìƒì„±\n",
    "        producer = create_kafka_producer(KAFKA_SERVERS)\n",
    "        \n",
    "        # ì›í•˜ëŠ” ìƒ˜í”Œ íŒŒì¼ ì„ íƒ (ì˜ˆ: 1/100 ìƒ˜í”Œ)\n",
    "        selected_file = SAMPLE_FILES['1/100 ìƒ˜í”Œ']\n",
    "        \n",
    "        # ì¹´í”„ì¹´ë¡œ ì „ì†¡\n",
    "        send_jsonl_to_kafka(\n",
    "            jsonl_file=selected_file,\n",
    "            topic_name=TOPIC_NAME,\n",
    "            producer=producer,\n",
    "            delay_ms=50  # 50ms ê°„ê²© (ì´ˆë‹¹ 20ê°œ)\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì¹´í”„ì¹´ ì „ì†¡ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        if 'producer' in locals():\n",
    "            producer.close()\n",
    "'''\n",
    "\n",
    "    with open(producer_code_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(producer_code)\n",
    "    \n",
    "    # ìš”ì•½ ì •ë³´ ì¶œë ¥\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ‰ ì¹´í”„ì¹´ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(f\"ğŸ“ ì €ì¥ ìœ„ì¹˜: {kafka_sample_path}\")\n",
    "    \n",
    "    for sample_name, info in generated_samples.items():\n",
    "        ratio_desc = sample_info[info['ratio']]['description']\n",
    "        print(f\"\\nğŸ“¦ {ratio_desc}:\")\n",
    "        print(f\"   ğŸ“Š ì´ë²¤íŠ¸ ìˆ˜: {info['count']:,}ê°œ\")\n",
    "        print(f\"   ğŸ“ Parquet: kafka_sample_{sample_name}.parquet\")\n",
    "        print(f\"   ğŸ“„ JSONL: kafka_sample_{sample_name}.jsonl\")\n",
    "    \n",
    "    print(f\"\\nğŸ”§ ì¹´í”„ì¹´ í”„ë¡œë“€ì„œ ì˜ˆì‹œ ì½”ë“œ: kafka_producer_example.py\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ ì‚¬ìš© ê°€ì´ë“œ:\")\n",
    "    print(f\"   1. JSONL íŒŒì¼ì€ ì¹´í”„ì¹´ í”„ë¡œë“€ì„œì—ì„œ ì§ì ‘ ì‚¬ìš© ê°€ëŠ¥\")\n",
    "    print(f\"   2. Parquet íŒŒì¼ì€ íŒë‹¤ìŠ¤ë¡œ ì½ì–´ì„œ ë¶„ì„ ê°€ëŠ¥\")\n",
    "    print(f\"   3. kafka_producer_example.pyë¥¼ ì°¸ê³ í•˜ì—¬ ì¹´í”„ì¹´ ì „ì†¡\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ ì¹´í”„ì¹´ í† í”½ ê¶Œì¥ ì„¤ì •:\")\n",
    "    print(f\"   - í† í”½ëª…: recipe-events\")\n",
    "    print(f\"   - íŒŒí‹°ì…˜: 3-6ê°œ (ë°ì´í„° ë³¼ë¥¨ì— ë”°ë¼)\")\n",
    "    print(f\"   - ë³µì œë³¸: 2-3ê°œ (ì•ˆì •ì„±)\")\n",
    "    print(f\"   - ì••ì¶•: gzip ë˜ëŠ” snappy\")\n",
    "    \n",
    "    return generated_samples\n",
    "\n",
    "# ì¹´í”„ì¹´ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì‹¤í–‰\n",
    "if 'correct_event_df' in locals() and correct_event_df is not None:\n",
    "    print(\"\\n\" + \"ğŸš€\" * 20)\n",
    "    kafka_samples = generate_kafka_sample_data(\n",
    "        original_df=correct_event_df,\n",
    "        sample_ratios=[0.1, 0.02, 0.01]  # 1/10, 1/50, 1/100\n",
    "    )\n",
    "else:\n",
    "    print(\"âš ï¸ ë¨¼ì € ì´ë²¤íŠ¸ ë¡œê·¸ë¥¼ ìƒì„±í•œ í›„ ì¹´í”„ì¹´ ìƒ˜í”Œì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# CSV ë³€í™˜ì´ í•„ìš”í•œ ê²½ìš° ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ê³  ì‹¤í–‰\n",
    "# convert_to_csv_with_estimation('event_logs_10m.parquet')\n",
    "\n",
    "print(\"\\nâœ… ëª¨ë“  ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ë° ê²€ì¦ ì™„ë£Œ!\")\n",
    "print(\"ğŸ¯ í•„ìš”ì‹œ ìœ„ ì£¼ì„ì„ í•´ì œí•˜ì—¬ CSV ë³€í™˜ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "print(\"ğŸ“¤ ì¹´í”„ì¹´ ìƒ˜í”Œ ë°ì´í„°ë„ í•¨ê»˜ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af32041e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”\n",
      "ì´ë²¤íŠ¸ íƒ€ì…ë³„ ìƒì„¸ ìƒ˜í”Œ ë°ì´í„°ë¥¼ Nested Dictionary í˜•íƒœë¡œ í‘œì‹œí•©ë‹ˆë‹¤!\n",
      "ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”\n",
      "\n",
      "ğŸ“Š ì´ë²¤íŠ¸ íƒ€ì…ë³„ ìš”ì•½ í…Œì´ë¸”\n",
      "================================================================================\n",
      "Event Type                Count      %      Users    Sessions   Properties\n",
      "--------------------------------------------------------------------------------\n",
      "auth_success              584,787    5.8%   11,844   439,395    method, type\n",
      "click_ads                 134,358    1.3%   11,486   117,821    ad_id, ad_type, target_ur\n",
      "click_auth_button         355,312    3.5%   11,809   271,188    type\n",
      "click_bookmark            443,220    4.4%   11,775   303,775    recipe_id, action\n",
      "click_like                441,637    4.4%   11,785   306,144    recipe_id, action\n",
      "click_recipe_from_list    1,786,735  17.8%  11,848   577,245    recipe_id, rank\n",
      "create_comment            550,788    5.5%   11,807   350,399    recipe_id, comment_length\n",
      "search_recipe             1,831,844  18.3%  11,851   593,840    search_type, search_keywo\n",
      "view_ads                  355,090    3.5%   11,793   255,168    ad_id, ad_type, position\n",
      "view_page                 1,878,487  18.7%  11,854   603,187    page_name\n",
      "view_recipe_list          1,668,894  16.6%  11,851   571,632    list_type, displayed_reci\n",
      "================================================================================\n",
      "ğŸ“‹ ì´ë²¤íŠ¸ íƒ€ì…ë³„ ìƒ˜í”Œ ë°ì´í„° (Nested Dictionary í˜•íƒœ)\n",
      "======================================================================\n",
      "Event Type                Count      %      Users    Sessions   Properties\n",
      "--------------------------------------------------------------------------------\n",
      "auth_success              584,787    5.8%   11,844   439,395    method, type\n",
      "click_ads                 134,358    1.3%   11,486   117,821    ad_id, ad_type, target_ur\n",
      "click_auth_button         355,312    3.5%   11,809   271,188    type\n",
      "click_bookmark            443,220    4.4%   11,775   303,775    recipe_id, action\n",
      "click_like                441,637    4.4%   11,785   306,144    recipe_id, action\n",
      "click_recipe_from_list    1,786,735  17.8%  11,848   577,245    recipe_id, rank\n",
      "create_comment            550,788    5.5%   11,807   350,399    recipe_id, comment_length\n",
      "search_recipe             1,831,844  18.3%  11,851   593,840    search_type, search_keywo\n",
      "view_ads                  355,090    3.5%   11,793   255,168    ad_id, ad_type, position\n",
      "view_page                 1,878,487  18.7%  11,854   603,187    page_name\n",
      "view_recipe_list          1,668,894  16.6%  11,851   571,632    list_type, displayed_reci\n",
      "================================================================================\n",
      "ğŸ“‹ ì´ë²¤íŠ¸ íƒ€ì…ë³„ ìƒ˜í”Œ ë°ì´í„° (Nested Dictionary í˜•íƒœ)\n",
      "======================================================================\n",
      "ğŸ“Š ì´ 11ê°œì˜ ì´ë²¤íŠ¸ íƒ€ì… ë°œê²¬:\n",
      "   - auth_success: 584,787ê°œ (5.8%)\n",
      "   - click_ads: 134,358ê°œ (1.3%)\n",
      "   - click_auth_button: 355,312ê°œ (3.5%)\n",
      "   - click_bookmark: 443,220ê°œ (4.4%)\n",
      "   - click_like: 441,637ê°œ (4.4%)\n",
      "   - click_recipe_from_list: 1,786,735ê°œ (17.8%)\n",
      "   - create_comment: 550,788ê°œ (5.5%)\n",
      "   - search_recipe: 1,831,844ê°œ (18.3%)\n",
      "   - view_ads: 355,090ê°œ (3.5%)\n",
      "   - view_page: 1,878,487ê°œ (18.7%)\n",
      "   - view_recipe_list: 1,668,894ê°œ (16.6%)\n",
      "\n",
      "======================================================================\n",
      "ğŸ” ê° ì´ë²¤íŠ¸ íƒ€ì…ë³„ ìƒ˜í”Œ ë°ì´í„° (ê° 1ê°œì”©)\n",
      "======================================================================\n",
      "\n",
      "ğŸ¯ [auth_success] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "ğŸ“Š ì´ 11ê°œì˜ ì´ë²¤íŠ¸ íƒ€ì… ë°œê²¬:\n",
      "   - auth_success: 584,787ê°œ (5.8%)\n",
      "   - click_ads: 134,358ê°œ (1.3%)\n",
      "   - click_auth_button: 355,312ê°œ (3.5%)\n",
      "   - click_bookmark: 443,220ê°œ (4.4%)\n",
      "   - click_like: 441,637ê°œ (4.4%)\n",
      "   - click_recipe_from_list: 1,786,735ê°œ (17.8%)\n",
      "   - create_comment: 550,788ê°œ (5.5%)\n",
      "   - search_recipe: 1,831,844ê°œ (18.3%)\n",
      "   - view_ads: 355,090ê°œ (3.5%)\n",
      "   - view_page: 1,878,487ê°œ (18.7%)\n",
      "   - view_recipe_list: 1,668,894ê°œ (16.6%)\n",
      "\n",
      "======================================================================\n",
      "ğŸ” ê° ì´ë²¤íŠ¸ íƒ€ì…ë³„ ìƒ˜í”Œ ë°ì´í„° (ê° 1ê°œì”©)\n",
      "======================================================================\n",
      "\n",
      "ğŸ¯ [auth_success] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': '370379f1-3f5a-4ca7-abc7-fbd66ea52e38',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_40_PLUS'},\n",
      "  'event_id': '6c81ec3a-1b44-40ab-93b8-d395665777ca',\n",
      "  'event_name': 'auth_success',\n",
      "  'event_properties': {'method': 'kakao', 'type': 'login'},\n",
      "  'session_id': '7df7009f-e421-47a8-b180-a574cbaba76e',\n",
      "  'timestamp': '2025-05-01T18:03:08.000000Z',\n",
      "  'user_id': '15107'}\n",
      "\n",
      "ğŸ¯ [click_ads] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': '370379f1-3f5a-4ca7-abc7-fbd66ea52e38',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_40_PLUS'},\n",
      "  'event_id': '6c81ec3a-1b44-40ab-93b8-d395665777ca',\n",
      "  'event_name': 'auth_success',\n",
      "  'event_properties': {'method': 'kakao', 'type': 'login'},\n",
      "  'session_id': '7df7009f-e421-47a8-b180-a574cbaba76e',\n",
      "  'timestamp': '2025-05-01T18:03:08.000000Z',\n",
      "  'user_id': '15107'}\n",
      "\n",
      "ğŸ¯ [click_ads] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': 'e7e56066-720e-4900-82aa-364758512869',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_30S'},\n",
      "  'event_id': '1c2a9b61-4139-49e9-a8ae-eda2085d68b9',\n",
      "  'event_name': 'click_ads',\n",
      "  'event_properties': { 'ad_id': 'ad_2802',\n",
      "                        'ad_type': 'video',\n",
      "                        'target_url': 'https://partner-site.com/promotion/44'},\n",
      "  'session_id': 'e25ebc62-503e-4eca-83c0-69eb47f786be',\n",
      "  'timestamp': '2025-05-01T16:54:54.000000Z',\n",
      "  'user_id': '23992'}\n",
      "\n",
      "ğŸ¯ [click_auth_button] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': 'e7e56066-720e-4900-82aa-364758512869',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_30S'},\n",
      "  'event_id': '1c2a9b61-4139-49e9-a8ae-eda2085d68b9',\n",
      "  'event_name': 'click_ads',\n",
      "  'event_properties': { 'ad_id': 'ad_2802',\n",
      "                        'ad_type': 'video',\n",
      "                        'target_url': 'https://partner-site.com/promotion/44'},\n",
      "  'session_id': 'e25ebc62-503e-4eca-83c0-69eb47f786be',\n",
      "  'timestamp': '2025-05-01T16:54:54.000000Z',\n",
      "  'user_id': '23992'}\n",
      "\n",
      "ğŸ¯ [click_auth_button] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': 'f4678382-9be6-4047-a277-cc0252e5a100',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_40_PLUS'},\n",
      "  'event_id': 'c3a4b5dd-b95d-4a5e-8011-593fb6a3be71',\n",
      "  'event_name': 'click_auth_button',\n",
      "  'event_properties': {'type': 'signup'},\n",
      "  'session_id': '7df7009f-e421-47a8-b180-a574cbaba76e',\n",
      "  'timestamp': '2025-05-01T18:11:45.000000Z',\n",
      "  'user_id': '15107'}\n",
      "\n",
      "ğŸ¯ [click_bookmark] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': 'f4678382-9be6-4047-a277-cc0252e5a100',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_40_PLUS'},\n",
      "  'event_id': 'c3a4b5dd-b95d-4a5e-8011-593fb6a3be71',\n",
      "  'event_name': 'click_auth_button',\n",
      "  'event_properties': {'type': 'signup'},\n",
      "  'session_id': '7df7009f-e421-47a8-b180-a574cbaba76e',\n",
      "  'timestamp': '2025-05-01T18:11:45.000000Z',\n",
      "  'user_id': '15107'}\n",
      "\n",
      "ğŸ¯ [click_bookmark] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': '7be9bef9-ca19-4f2c-b3a4-0665ab1dbbd9',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_30S'},\n",
      "  'event_id': 'a628bf2b-184e-486c-bc24-ba1751449b34',\n",
      "  'event_name': 'click_bookmark',\n",
      "  'event_properties': {'action': 'remove', 'recipe_id': '6950481'},\n",
      "  'session_id': '104ecf95-45ec-41f4-88a3-de7481023254',\n",
      "  'timestamp': '2025-05-01T18:42:41.000000Z',\n",
      "  'user_id': '23992'}\n",
      "\n",
      "ğŸ¯ [click_like] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': '7be9bef9-ca19-4f2c-b3a4-0665ab1dbbd9',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_30S'},\n",
      "  'event_id': 'a628bf2b-184e-486c-bc24-ba1751449b34',\n",
      "  'event_name': 'click_bookmark',\n",
      "  'event_properties': {'action': 'remove', 'recipe_id': '6950481'},\n",
      "  'session_id': '104ecf95-45ec-41f4-88a3-de7481023254',\n",
      "  'timestamp': '2025-05-01T18:42:41.000000Z',\n",
      "  'user_id': '23992'}\n",
      "\n",
      "ğŸ¯ [click_like] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': '65ed3171-9b43-4e1b-9823-067ef8073fa2',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_40_PLUS'},\n",
      "  'event_id': 'b48d5ca3-c46b-4ad2-ac02-1d7a93f2d37c',\n",
      "  'event_name': 'click_like',\n",
      "  'event_properties': {'action': 'like', 'recipe_id': '6887527'},\n",
      "  'session_id': '7df7009f-e421-47a8-b180-a574cbaba76e',\n",
      "  'timestamp': '2025-05-01T18:06:37.000000Z',\n",
      "  'user_id': '15107'}\n",
      "\n",
      "ğŸ¯ [click_recipe_from_list] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': '65ed3171-9b43-4e1b-9823-067ef8073fa2',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_40_PLUS'},\n",
      "  'event_id': 'b48d5ca3-c46b-4ad2-ac02-1d7a93f2d37c',\n",
      "  'event_name': 'click_like',\n",
      "  'event_properties': {'action': 'like', 'recipe_id': '6887527'},\n",
      "  'session_id': '7df7009f-e421-47a8-b180-a574cbaba76e',\n",
      "  'timestamp': '2025-05-01T18:06:37.000000Z',\n",
      "  'user_id': '15107'}\n",
      "\n",
      "ğŸ¯ [click_recipe_from_list] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': 'fe83de50-6992-4fbf-ae4e-1578ca4249d9',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_40_PLUS'},\n",
      "  'event_id': '4865a927-6f8d-4a4d-89d8-8f1b482f3036',\n",
      "  'event_name': 'click_recipe_from_list',\n",
      "  'event_properties': {'rank': 15, 'recipe_id': '6887527'},\n",
      "  'session_id': '7df7009f-e421-47a8-b180-a574cbaba76e',\n",
      "  'timestamp': '2025-05-01T18:05:25.000000Z',\n",
      "  'user_id': '15107'}\n",
      "\n",
      "ğŸ¯ [create_comment] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': 'fe83de50-6992-4fbf-ae4e-1578ca4249d9',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_40_PLUS'},\n",
      "  'event_id': '4865a927-6f8d-4a4d-89d8-8f1b482f3036',\n",
      "  'event_name': 'click_recipe_from_list',\n",
      "  'event_properties': {'rank': 15, 'recipe_id': '6887527'},\n",
      "  'session_id': '7df7009f-e421-47a8-b180-a574cbaba76e',\n",
      "  'timestamp': '2025-05-01T18:05:25.000000Z',\n",
      "  'user_id': '15107'}\n",
      "\n",
      "ğŸ¯ [create_comment] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': 'aa9514a6-19e4-4f0b-899d-9321991222c4',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_40_PLUS'},\n",
      "  'event_id': '07fc10af-674c-418f-8d42-345eead39d82',\n",
      "  'event_name': 'create_comment',\n",
      "  'event_properties': {'comment_length': 54, 'recipe_id': '6887527'},\n",
      "  'session_id': '7df7009f-e421-47a8-b180-a574cbaba76e',\n",
      "  'timestamp': '2025-05-01T18:08:32.000000Z',\n",
      "  'user_id': '15107'}\n",
      "\n",
      "ğŸ¯ [search_recipe] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': 'aa9514a6-19e4-4f0b-899d-9321991222c4',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_40_PLUS'},\n",
      "  'event_id': '07fc10af-674c-418f-8d42-345eead39d82',\n",
      "  'event_name': 'create_comment',\n",
      "  'event_properties': {'comment_length': 54, 'recipe_id': '6887527'},\n",
      "  'session_id': '7df7009f-e421-47a8-b180-a574cbaba76e',\n",
      "  'timestamp': '2025-05-01T18:08:32.000000Z',\n",
      "  'user_id': '15107'}\n",
      "\n",
      "ğŸ¯ [search_recipe] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': '3764148d-21d4-4e72-a58e-c6b330deaeec',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_40_PLUS'},\n",
      "  'event_id': '58a854b0-ccf7-46c2-ad91-c53f3be59975',\n",
      "  'event_name': 'search_recipe',\n",
      "  'event_properties': { 'result_count': 29,\n",
      "                        'search_keyword': 'ì¼€ì´í¬',\n",
      "                        'search_type': 'menu',\n",
      "                        'selected_filters': ['cooking_time:30min']},\n",
      "  'session_id': '7df7009f-e421-47a8-b180-a574cbaba76e',\n",
      "  'timestamp': '2025-05-01T18:03:23.000000Z',\n",
      "  'user_id': '15107'}\n",
      "\n",
      "ğŸ¯ [view_ads] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': '3764148d-21d4-4e72-a58e-c6b330deaeec',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_40_PLUS'},\n",
      "  'event_id': '58a854b0-ccf7-46c2-ad91-c53f3be59975',\n",
      "  'event_name': 'search_recipe',\n",
      "  'event_properties': { 'result_count': 29,\n",
      "                        'search_keyword': 'ì¼€ì´í¬',\n",
      "                        'search_type': 'menu',\n",
      "                        'selected_filters': ['cooking_time:30min']},\n",
      "  'session_id': '7df7009f-e421-47a8-b180-a574cbaba76e',\n",
      "  'timestamp': '2025-05-01T18:03:23.000000Z',\n",
      "  'user_id': '15107'}\n",
      "\n",
      "ğŸ¯ [view_ads] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': '2a88e0d7-0205-49a0-9067-de36a4911472',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_30S'},\n",
      "  'event_id': '959a2cd4-525b-4b89-8215-5201a878866d',\n",
      "  'event_name': 'view_ads',\n",
      "  'event_properties': { 'ad_id': 'ad_2802',\n",
      "                        'ad_type': 'video',\n",
      "                        'position': 'middle'},\n",
      "  'session_id': 'e25ebc62-503e-4eca-83c0-69eb47f786be',\n",
      "  'timestamp': '2025-05-01T16:53:51.000000Z',\n",
      "  'user_id': '23992'}\n",
      "\n",
      "ğŸ¯ [view_page] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': '2a88e0d7-0205-49a0-9067-de36a4911472',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_30S'},\n",
      "  'event_id': '959a2cd4-525b-4b89-8215-5201a878866d',\n",
      "  'event_name': 'view_ads',\n",
      "  'event_properties': { 'ad_id': 'ad_2802',\n",
      "                        'ad_type': 'video',\n",
      "                        'position': 'middle'},\n",
      "  'session_id': 'e25ebc62-503e-4eca-83c0-69eb47f786be',\n",
      "  'timestamp': '2025-05-01T16:53:51.000000Z',\n",
      "  'user_id': '23992'}\n",
      "\n",
      "ğŸ¯ [view_page] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': 'c4c73c3b-ad4c-4770-94a2-06d996e839ca',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_40_PLUS'},\n",
      "  'event_id': 'dfa2310c-10ee-40d1-a41b-04908c3aedc3',\n",
      "  'event_name': 'view_page',\n",
      "  'event_properties': {'page_name': 'main'},\n",
      "  'session_id': '7df7009f-e421-47a8-b180-a574cbaba76e',\n",
      "  'timestamp': '2025-05-01T18:10:20.000000Z',\n",
      "  'user_id': '15107'}\n",
      "\n",
      "ğŸ¯ [view_recipe_list] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': 'c4c73c3b-ad4c-4770-94a2-06d996e839ca',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_40_PLUS'},\n",
      "  'event_id': 'dfa2310c-10ee-40d1-a41b-04908c3aedc3',\n",
      "  'event_name': 'view_page',\n",
      "  'event_properties': {'page_name': 'main'},\n",
      "  'session_id': '7df7009f-e421-47a8-b180-a574cbaba76e',\n",
      "  'timestamp': '2025-05-01T18:10:20.000000Z',\n",
      "  'user_id': '15107'}\n",
      "\n",
      "ğŸ¯ [view_recipe_list] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': 'e4c6eaac-b02f-4048-a687-5c7b779c568f',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_40_PLUS'},\n",
      "  'event_id': '1a2bd6c0-8bf2-42a7-9e56-77319e5e4dda',\n",
      "  'event_name': 'view_recipe_list',\n",
      "  'event_properties': { 'displayed_recipe_ids': [ '6907236',\n",
      "                                                  '6932804',\n",
      "                                                  '7030920',\n",
      "                                                  '6976413',\n",
      "                                                  '6962512',\n",
      "                                                  '6914026',\n",
      "                                                  '5749393',\n",
      "                                                  '6844278',\n",
      "                                                  '7035494',\n",
      "                                                  '6935339',\n",
      "                                                  '6894794'],\n",
      "                        'list_type': 'recommended'},\n",
      "  'session_id': '7df7009f-e421-47a8-b180-a574cbaba76e',\n",
      "  'timestamp': '2025-05-01T18:04:02.000000Z',\n",
      "  'user_id': '15107'}\n",
      "\n",
      "======================================================================\n",
      "âœ… ì´ë²¤íŠ¸ íƒ€ì…ë³„ ìƒ˜í”Œ ë°ì´í„° í‘œì‹œ ì™„ë£Œ!\n",
      "======================================================================\n",
      "\n",
      "ğŸ’¡ ë°˜í™˜ëœ ë°ì´í„° êµ¬ì¡°:\n",
      "   - samples_dict ë³€ìˆ˜ì— ëª¨ë“  ìƒ˜í”Œì´ nested dictionary í˜•íƒœë¡œ ì €ì¥ë¨\n",
      "   - êµ¬ì¡°: samples_dict[event_name][sample_index] = {...}\n",
      "   - ì˜ˆì‹œ: samples_dict['view_page'][0]['context']['page']['name']\n",
      "\n",
      "ğŸ”§ ë” ë§ì€ ìƒ˜í”Œì„ ë³´ë ¤ë©´:\n",
      "   samples_dict = display_event_samples(correct_event_df, max_samples_per_event=2)\n",
      "\n",
      "ğŸ“‹ íŠ¹ì • ì´ë²¤íŠ¸ë§Œ ë³´ë ¤ë©´:\n",
      "   import pprint\n",
      "   pprint.pprint(samples_dict['view_page'])  # view_page ì´ë²¤íŠ¸ë§Œ\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ #1:\n",
      "{ 'anonymous_id': 'e4c6eaac-b02f-4048-a687-5c7b779c568f',\n",
      "  'context': { 'page': { 'name': 'main',\n",
      "                         'path': '/main',\n",
      "                         'url': 'https://reciping.co.kr/main'},\n",
      "               'user_segment': 'FEMALE_40_PLUS'},\n",
      "  'event_id': '1a2bd6c0-8bf2-42a7-9e56-77319e5e4dda',\n",
      "  'event_name': 'view_recipe_list',\n",
      "  'event_properties': { 'displayed_recipe_ids': [ '6907236',\n",
      "                                                  '6932804',\n",
      "                                                  '7030920',\n",
      "                                                  '6976413',\n",
      "                                                  '6962512',\n",
      "                                                  '6914026',\n",
      "                                                  '5749393',\n",
      "                                                  '6844278',\n",
      "                                                  '7035494',\n",
      "                                                  '6935339',\n",
      "                                                  '6894794'],\n",
      "                        'list_type': 'recommended'},\n",
      "  'session_id': '7df7009f-e421-47a8-b180-a574cbaba76e',\n",
      "  'timestamp': '2025-05-01T18:04:02.000000Z',\n",
      "  'user_id': '15107'}\n",
      "\n",
      "======================================================================\n",
      "âœ… ì´ë²¤íŠ¸ íƒ€ì…ë³„ ìƒ˜í”Œ ë°ì´í„° í‘œì‹œ ì™„ë£Œ!\n",
      "======================================================================\n",
      "\n",
      "ğŸ’¡ ë°˜í™˜ëœ ë°ì´í„° êµ¬ì¡°:\n",
      "   - samples_dict ë³€ìˆ˜ì— ëª¨ë“  ìƒ˜í”Œì´ nested dictionary í˜•íƒœë¡œ ì €ì¥ë¨\n",
      "   - êµ¬ì¡°: samples_dict[event_name][sample_index] = {...}\n",
      "   - ì˜ˆì‹œ: samples_dict['view_page'][0]['context']['page']['name']\n",
      "\n",
      "ğŸ”§ ë” ë§ì€ ìƒ˜í”Œì„ ë³´ë ¤ë©´:\n",
      "   samples_dict = display_event_samples(correct_event_df, max_samples_per_event=2)\n",
      "\n",
      "ğŸ“‹ íŠ¹ì • ì´ë²¤íŠ¸ë§Œ ë³´ë ¤ë©´:\n",
      "   import pprint\n",
      "   pprint.pprint(samples_dict['view_page'])  # view_page ì´ë²¤íŠ¸ë§Œ\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ”Ÿ ì´ë²¤íŠ¸ íƒ€ì…ë³„ ìƒ˜í”Œ ë°ì´í„° í‘œì‹œ (Nested Dictionary í˜•íƒœ)\n",
    "# ===================================================================\n",
    "\n",
    "def display_event_samples(df, max_samples_per_event=1):\n",
    "    \"\"\"\n",
    "    ê° event_nameë³„ë¡œ ìƒ˜í”Œ ë°ì´í„°ë¥¼ nested dictionary í˜•íƒœë¡œ í‘œì‹œ\n",
    "    \n",
    "    Args:\n",
    "        df: ì´ë²¤íŠ¸ ë¡œê·¸ ë°ì´í„°í”„ë ˆì„\n",
    "        max_samples_per_event: ê° ì´ë²¤íŠ¸ íƒ€ì…ë³„ë¡œ í‘œì‹œí•  ìµœëŒ€ ìƒ˜í”Œ ìˆ˜\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸ“‹ ì´ë²¤íŠ¸ íƒ€ì…ë³„ ìƒ˜í”Œ ë°ì´í„° (Nested Dictionary í˜•íƒœ)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if df is None or len(df) == 0:\n",
    "        print(\"âŒ í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        return\n",
    "    \n",
    "    # ëª¨ë“  ê³ ìœ  ì´ë²¤íŠ¸ íƒ€ì… ê°€ì ¸ì˜¤ê¸°\n",
    "    event_types = df['event_name'].unique()\n",
    "    event_counts = df['event_name'].value_counts()\n",
    "    \n",
    "    print(f\"ğŸ“Š ì´ {len(event_types)}ê°œì˜ ì´ë²¤íŠ¸ íƒ€ì… ë°œê²¬:\")\n",
    "    for event_type in sorted(event_types):\n",
    "        count = event_counts[event_type]\n",
    "        percentage = (count / len(df)) * 100\n",
    "        print(f\"   - {event_type}: {count:,}ê°œ ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(f\"ğŸ” ê° ì´ë²¤íŠ¸ íƒ€ì…ë³„ ìƒ˜í”Œ ë°ì´í„° (ê° {max_samples_per_event}ê°œì”©)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # ì „ì²´ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë‹´ì„ nested dictionary\n",
    "    samples_dict = {}\n",
    "    \n",
    "    for event_type in sorted(event_types):\n",
    "        print(f\"\\nğŸ¯ [{event_type}] ì´ë²¤íŠ¸ ìƒ˜í”Œ:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # í•´ë‹¹ ì´ë²¤íŠ¸ íƒ€ì…ì˜ ìƒ˜í”Œ ê°€ì ¸ì˜¤ê¸°\n",
    "        event_samples = df[df['event_name'] == event_type].head(max_samples_per_event)\n",
    "        \n",
    "        # ì´ë²¤íŠ¸ íƒ€ì…ë³„ ìƒ˜í”Œ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "        samples_dict[event_type] = []\n",
    "        \n",
    "        for idx, (_, row) in enumerate(event_samples.iterrows(), 1):\n",
    "            \n",
    "            # nested dictionary êµ¬ì¡°ë¡œ ë°ì´í„° êµ¬ì„±\n",
    "            sample_data = {\n",
    "                'event_name': row['event_name'],\n",
    "                'event_id': row['event_id'],\n",
    "                'user_id': row['user_id'],\n",
    "                'anonymous_id': row['anonymous_id'],\n",
    "                'session_id': row['session_id'],\n",
    "                'timestamp': row['timestamp']\n",
    "            }\n",
    "            \n",
    "            # Context íŒŒì‹±\n",
    "            try:\n",
    "                context = json.loads(row['context'])\n",
    "                sample_data['context'] = context\n",
    "            except Exception as e:\n",
    "                sample_data['context'] = {'parsing_error': str(e)}\n",
    "            \n",
    "            # Event Properties íŒŒì‹±\n",
    "            try:\n",
    "                properties = json.loads(row['event_properties'])\n",
    "                sample_data['event_properties'] = properties\n",
    "            except Exception as e:\n",
    "                sample_data['event_properties'] = {'parsing_error': str(e)}\n",
    "            \n",
    "            # ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "            samples_dict[event_type].append(sample_data)\n",
    "            \n",
    "            # Pretty printë¡œ nested dictionary ì¶œë ¥\n",
    "            print(f\"\\nğŸ“ ìƒ˜í”Œ #{idx}:\")\n",
    "            import pprint\n",
    "            pp = pprint.PrettyPrinter(indent=2, width=80, depth=None)\n",
    "            pp.pprint(sample_data)\n",
    "            \n",
    "            if idx < len(event_samples):\n",
    "                print(\"   \" + \"Â·\" * 40)\n",
    "    \n",
    "    return samples_dict\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(\"âœ… ì´ë²¤íŠ¸ íƒ€ì…ë³„ ìƒ˜í”Œ ë°ì´í„° í‘œì‹œ ì™„ë£Œ!\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "def display_event_summary_table(df):\n",
    "    \"\"\"ì´ë²¤íŠ¸ íƒ€ì…ë³„ ìš”ì•½ í…Œì´ë¸” í‘œì‹œ\"\"\"\n",
    "    \n",
    "    if df is None or len(df) == 0:\n",
    "        print(\"âŒ ìš”ì•½í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nğŸ“Š ì´ë²¤íŠ¸ íƒ€ì…ë³„ ìš”ì•½ í…Œì´ë¸”\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ì´ë²¤íŠ¸ë³„ í†µê³„ ê³„ì‚°\n",
    "    event_stats = []\n",
    "    \n",
    "    for event_type in sorted(df['event_name'].unique()):\n",
    "        event_data = df[df['event_name'] == event_type]\n",
    "        \n",
    "        # ê¸°ë³¸ í†µê³„\n",
    "        count = len(event_data)\n",
    "        percentage = (count / len(df)) * 100\n",
    "        unique_users = event_data['user_id'].nunique()\n",
    "        unique_sessions = event_data['session_id'].nunique()\n",
    "        \n",
    "        # ì‹œê°„ ë²”ìœ„\n",
    "        timestamps = pd.to_datetime(event_data['timestamp'])\n",
    "        time_range = f\"{timestamps.min().strftime('%m-%d %H:%M')} ~ {timestamps.max().strftime('%m-%d %H:%M')}\"\n",
    "        \n",
    "        # ìƒ˜í”Œ properties í‚¤\n",
    "        try:\n",
    "            sample_properties = json.loads(event_data['event_properties'].iloc[0])\n",
    "            property_keys = list(sample_properties.keys()) if sample_properties else []\n",
    "            property_preview = \", \".join(property_keys[:3])\n",
    "            if len(property_keys) > 3:\n",
    "                property_preview += f\", ... (ì´ {len(property_keys)}ê°œ)\"\n",
    "        except:\n",
    "            property_preview = \"íŒŒì‹± ì˜¤ë¥˜\"\n",
    "        \n",
    "        event_stats.append({\n",
    "            'Event Type': event_type,\n",
    "            'Count': f\"{count:,}\",\n",
    "            'Percentage': f\"{percentage:.1f}%\",\n",
    "            'Users': f\"{unique_users:,}\",\n",
    "            'Sessions': f\"{unique_sessions:,}\",\n",
    "            'Time Range': time_range,\n",
    "            'Properties': property_preview\n",
    "        })\n",
    "    \n",
    "    # í…Œì´ë¸” í˜•íƒœë¡œ ì¶œë ¥\n",
    "    if event_stats:\n",
    "        # í—¤ë”\n",
    "        headers = ['Event Type', 'Count', '%', 'Users', 'Sessions', 'Properties']\n",
    "        \n",
    "        print(f\"{'Event Type':<25} {'Count':<10} {'%':<6} {'Users':<8} {'Sessions':<10} {'Properties'}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for stat in event_stats:\n",
    "            print(f\"{stat['Event Type']:<25} {stat['Count']:<10} {stat['Percentage']:<6} \"\n",
    "                  f\"{stat['Users']:<8} {stat['Sessions']:<10} {stat['Properties'][:25]}\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# ìƒì„±ëœ ì´ë²¤íŠ¸ ë¡œê·¸ì˜ ìƒ˜í”Œ ë°ì´í„° í‘œì‹œ\n",
    "if 'correct_event_df' in locals() and correct_event_df is not None:\n",
    "    print(\"\\n\" + \"ğŸ”\" * 20)\n",
    "    print(\"ì´ë²¤íŠ¸ íƒ€ì…ë³„ ìƒì„¸ ìƒ˜í”Œ ë°ì´í„°ë¥¼ Nested Dictionary í˜•íƒœë¡œ í‘œì‹œí•©ë‹ˆë‹¤!\")\n",
    "    print(\"ğŸ”\" * 20)\n",
    "    \n",
    "    # ìš”ì•½ í…Œì´ë¸” ë¨¼ì € í‘œì‹œ\n",
    "    display_event_summary_table(correct_event_df)\n",
    "    \n",
    "    # ê° ì´ë²¤íŠ¸ë³„ ìƒì„¸ ìƒ˜í”Œ í‘œì‹œ (nested dictionary ë°˜í™˜)\n",
    "    samples_dict = display_event_samples(correct_event_df, max_samples_per_event=1)\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(\"âœ… ì´ë²¤íŠ¸ íƒ€ì…ë³„ ìƒ˜í”Œ ë°ì´í„° í‘œì‹œ ì™„ë£Œ!\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ ë°˜í™˜ëœ ë°ì´í„° êµ¬ì¡°:\")\n",
    "    print(f\"   - samples_dict ë³€ìˆ˜ì— ëª¨ë“  ìƒ˜í”Œì´ nested dictionary í˜•íƒœë¡œ ì €ì¥ë¨\")\n",
    "    print(f\"   - êµ¬ì¡°: samples_dict[event_name][sample_index] = {{...}}\")\n",
    "    print(f\"   - ì˜ˆì‹œ: samples_dict['view_page'][0]['context']['page']['name']\")\n",
    "    \n",
    "    print(f\"\\nğŸ”§ ë” ë§ì€ ìƒ˜í”Œì„ ë³´ë ¤ë©´:\")\n",
    "    print(f\"   samples_dict = display_event_samples(correct_event_df, max_samples_per_event=2)\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ íŠ¹ì • ì´ë²¤íŠ¸ë§Œ ë³´ë ¤ë©´:\")\n",
    "    print(f\"   import pprint\")\n",
    "    print(f\"   pprint.pprint(samples_dict['view_page'])  # view_page ì´ë²¤íŠ¸ë§Œ\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ ë¨¼ì € ì´ë²¤íŠ¸ ë¡œê·¸ë¥¼ ìƒì„±í•œ í›„ ìƒ˜í”Œ ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65b97177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ìƒì„±ëœ ì´ë²¤íŠ¸ ë¡œê·¸ íŒŒì¼ì˜ CSV ë³€í™˜ í¬ê¸°ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤!\n",
      "======================================================================\n",
      "ğŸ“ Parquet â†’ CSV í¬ê¸° ì¶”ì • ì‹œì‘!\n",
      "============================================================\n",
      "ğŸ“ Parquet íŒŒì¼ ì •ë³´:\n",
      "   íŒŒì¼ëª…: event_logs_10m.parquet\n",
      "   í¬ê¸°: 970.72 MB (0.948 GB)\n",
      "   ë°”ì´íŠ¸: 1,017,875,899 bytes\n",
      "\n",
      "ğŸ“Š CSV í¬ê¸° ì¶”ì • ì¤‘...\n",
      "   ì´ ë°ì´í„°: 10,031,152í–‰ Ã— 8ì—´\n",
      "   ì´ ë°ì´í„°: 10,031,152í–‰ Ã— 8ì—´\n",
      "   ìƒ˜í”Œ í¬ê¸°: 50,000í–‰ìœ¼ë¡œ ì¶”ì •\n",
      "   ìƒ˜í”Œ í¬ê¸°: 50,000í–‰ìœ¼ë¡œ ì¶”ì •\n",
      "\n",
      "ğŸ“ˆ í¬ê¸° ì¶”ì • ê²°ê³¼:\n",
      "   ìƒ˜í”Œ CSV í¬ê¸°: 18084.73 KB (50,000í–‰)\n",
      "   í–‰ë‹¹ í‰ê·  í¬ê¸°: 370.4 bytes\n",
      "\n",
      "ğŸ¯ ì „ì²´ CSV ì˜ˆìƒ í¬ê¸°:\n",
      "   ì˜ˆìƒ í¬ê¸°: 3543.18 MB\n",
      "   ì˜ˆìƒ í¬ê¸°: 3.460 GB\n",
      "   ì˜ˆìƒ ë°”ì´íŠ¸: 3,715,290,129 bytes\n",
      "\n",
      "ğŸ“Š ì••ì¶•ë¥  ë¶„ì„:\n",
      "   Parquet vs CSV: 3.7x ì°¨ì´\n",
      "   Parquet ì••ì¶• íš¨ìœ¨: 72.6%\n",
      "   CSVê°€ Parquetë³´ë‹¤ 3.7ë°° ë” í¼\n",
      "\n",
      "ğŸ“‹ ì»¬ëŸ¼ë³„ í‰ê·  í¬ê¸° ë¶„ì„:\n",
      "   context: í‰ê·  114.9ì\n",
      "   event_properties: í‰ê·  60.4ì\n",
      "   event_id: í‰ê·  36.0ì\n",
      "   anonymous_id: í‰ê·  36.0ì\n",
      "   session_id: í‰ê·  36.0ì\n",
      "   timestamp: í‰ê·  27.0ì\n",
      "   event_name: í‰ê·  14.2ì\n",
      "   user_id: í‰ê·  4.6ì\n",
      "\n",
      "âš ï¸  ì£¼ì˜ì‚¬í•­:\n",
      "   - ì˜ˆìƒ CSV í¬ê¸°ê°€ 3.5 GBë¡œ ë§¤ìš° í½ë‹ˆë‹¤!\n",
      "   - ë©”ëª¨ë¦¬ ë¶€ì¡±ì´ë‚˜ ë¡œë”© ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
      "   - ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ê±°ë‚˜ Parquet ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤\n",
      "\n",
      "â±ï¸  ì˜ˆìƒ ë¡œë”© ì‹œê°„:\n",
      "   CSV íŒŒì¼ ì½ê¸°: ì•½ 35.4ì´ˆ (SSD ê¸°ì¤€)\n",
      "   Parquet íŒŒì¼ ì½ê¸°: ì•½ 4.9ì´ˆ (ë” ë¹ ë¦„)\n",
      "\n",
      "ğŸ”§ ì‹¤ì œ CSV ë³€í™˜:\n",
      "   ë³€í™˜ì„ ì›í•˜ë©´ ë‹¤ìŒ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”:\n",
      "   convert_to_csv_with_estimation('event_logs_10m.parquet')\n",
      "\n",
      "ğŸ“Š ìš”ì•½:\n",
      "   ğŸ“ Parquet: 970.72 MB\n",
      "   ğŸ“„ ì˜ˆìƒ CSV: 3543.18 MB\n",
      "   ğŸ—œï¸  ì••ì¶•ë¥ : 3.7x\n",
      "   ğŸ“ ì´ ë°ì´í„°: 10,031,152í–‰\n",
      "\n",
      "ğŸ’¡ ì°¸ê³ :\n",
      "   - Parquetì€ ì»¬ëŸ¼í˜• ì••ì¶•ìœ¼ë¡œ ì €ì¥ ê³µê°„ íš¨ìœ¨ì \n",
      "   - CSVëŠ” í…ìŠ¤íŠ¸ í˜•íƒœë¡œ í˜¸í™˜ì„±ì´ ì¢‹ì§€ë§Œ ìš©ëŸ‰ì´ í¼\n",
      "   - ë¶„ì„ìš©ë„ë¼ë©´ Parquet ì‚¬ìš© ê¶Œì¥\n",
      "   - ë‹¤ë¥¸ ì‹œìŠ¤í…œ ì—°ë™ì‹œì—ë§Œ CSV ë³€í™˜ ê³ ë ¤\n",
      "\n",
      "ğŸ“ˆ í¬ê¸° ì¶”ì • ê²°ê³¼:\n",
      "   ìƒ˜í”Œ CSV í¬ê¸°: 18084.73 KB (50,000í–‰)\n",
      "   í–‰ë‹¹ í‰ê·  í¬ê¸°: 370.4 bytes\n",
      "\n",
      "ğŸ¯ ì „ì²´ CSV ì˜ˆìƒ í¬ê¸°:\n",
      "   ì˜ˆìƒ í¬ê¸°: 3543.18 MB\n",
      "   ì˜ˆìƒ í¬ê¸°: 3.460 GB\n",
      "   ì˜ˆìƒ ë°”ì´íŠ¸: 3,715,290,129 bytes\n",
      "\n",
      "ğŸ“Š ì••ì¶•ë¥  ë¶„ì„:\n",
      "   Parquet vs CSV: 3.7x ì°¨ì´\n",
      "   Parquet ì••ì¶• íš¨ìœ¨: 72.6%\n",
      "   CSVê°€ Parquetë³´ë‹¤ 3.7ë°° ë” í¼\n",
      "\n",
      "ğŸ“‹ ì»¬ëŸ¼ë³„ í‰ê·  í¬ê¸° ë¶„ì„:\n",
      "   context: í‰ê·  114.9ì\n",
      "   event_properties: í‰ê·  60.4ì\n",
      "   event_id: í‰ê·  36.0ì\n",
      "   anonymous_id: í‰ê·  36.0ì\n",
      "   session_id: í‰ê·  36.0ì\n",
      "   timestamp: í‰ê·  27.0ì\n",
      "   event_name: í‰ê·  14.2ì\n",
      "   user_id: í‰ê·  4.6ì\n",
      "\n",
      "âš ï¸  ì£¼ì˜ì‚¬í•­:\n",
      "   - ì˜ˆìƒ CSV í¬ê¸°ê°€ 3.5 GBë¡œ ë§¤ìš° í½ë‹ˆë‹¤!\n",
      "   - ë©”ëª¨ë¦¬ ë¶€ì¡±ì´ë‚˜ ë¡œë”© ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
      "   - ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ê±°ë‚˜ Parquet ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤\n",
      "\n",
      "â±ï¸  ì˜ˆìƒ ë¡œë”© ì‹œê°„:\n",
      "   CSV íŒŒì¼ ì½ê¸°: ì•½ 35.4ì´ˆ (SSD ê¸°ì¤€)\n",
      "   Parquet íŒŒì¼ ì½ê¸°: ì•½ 4.9ì´ˆ (ë” ë¹ ë¦„)\n",
      "\n",
      "ğŸ”§ ì‹¤ì œ CSV ë³€í™˜:\n",
      "   ë³€í™˜ì„ ì›í•˜ë©´ ë‹¤ìŒ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”:\n",
      "   convert_to_csv_with_estimation('event_logs_10m.parquet')\n",
      "\n",
      "ğŸ“Š ìš”ì•½:\n",
      "   ğŸ“ Parquet: 970.72 MB\n",
      "   ğŸ“„ ì˜ˆìƒ CSV: 3543.18 MB\n",
      "   ğŸ—œï¸  ì••ì¶•ë¥ : 3.7x\n",
      "   ğŸ“ ì´ ë°ì´í„°: 10,031,152í–‰\n",
      "\n",
      "ğŸ’¡ ì°¸ê³ :\n",
      "   - Parquetì€ ì»¬ëŸ¼í˜• ì••ì¶•ìœ¼ë¡œ ì €ì¥ ê³µê°„ íš¨ìœ¨ì \n",
      "   - CSVëŠ” í…ìŠ¤íŠ¸ í˜•íƒœë¡œ í˜¸í™˜ì„±ì´ ì¢‹ì§€ë§Œ ìš©ëŸ‰ì´ í¼\n",
      "   - ë¶„ì„ìš©ë„ë¼ë©´ Parquet ì‚¬ìš© ê¶Œì¥\n",
      "   - ë‹¤ë¥¸ ì‹œìŠ¤í…œ ì—°ë™ì‹œì—ë§Œ CSV ë³€í™˜ ê³ ë ¤\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ“ event_logs_10m.parquet â†’ CSV í¬ê¸° ì¶”ì •\n",
    "# ===================================================================\n",
    "\n",
    "def estimate_csv_size_from_parquet(parquet_file_name='event_logs_10m.parquet'):\n",
    "    \"\"\"\n",
    "    Parquet íŒŒì¼ì„ CSVë¡œ ë³€í™˜í–ˆì„ ë•Œì˜ í¬ê¸°ë¥¼ ì¶”ì •\n",
    "    \n",
    "    Args:\n",
    "        parquet_file_name: ì¶”ì •í•  parquet íŒŒì¼ëª…\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸ“ Parquet â†’ CSV í¬ê¸° ì¶”ì • ì‹œì‘!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    parquet_file = os.path.join(OUTPUT_LOG_PATH, parquet_file_name)\n",
    "    \n",
    "    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "    if not os.path.exists(parquet_file):\n",
    "        print(f\"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {parquet_file}\")\n",
    "        return\n",
    "    \n",
    "    # Parquet íŒŒì¼ í¬ê¸°\n",
    "    parquet_size_bytes = os.path.getsize(parquet_file)\n",
    "    parquet_size_mb = parquet_size_bytes / (1024 * 1024)\n",
    "    parquet_size_gb = parquet_size_mb / 1024\n",
    "    \n",
    "    print(f\"ğŸ“ Parquet íŒŒì¼ ì •ë³´:\")\n",
    "    print(f\"   íŒŒì¼ëª…: {parquet_file_name}\")\n",
    "    print(f\"   í¬ê¸°: {parquet_size_mb:.2f} MB ({parquet_size_gb:.3f} GB)\")\n",
    "    print(f\"   ë°”ì´íŠ¸: {parquet_size_bytes:,} bytes\")\n",
    "    \n",
    "    try:\n",
    "        # ìƒ˜í”Œ ë°ì´í„°ë¡œ í¬ê¸° ì¶”ì •\n",
    "        print(f\"\\nğŸ“Š CSV í¬ê¸° ì¶”ì • ì¤‘...\")\n",
    "        \n",
    "        df = pd.read_parquet(parquet_file)\n",
    "        total_rows = len(df)\n",
    "        \n",
    "        print(f\"   ì´ ë°ì´í„°: {total_rows:,}í–‰ Ã— {len(df.columns)}ì—´\")\n",
    "        \n",
    "        # ìƒ˜í”Œ í¬ê¸° ê²°ì • (ìµœëŒ€ 50,000í–‰)\n",
    "        sample_size = min(50000, total_rows)\n",
    "        sample_df = df.sample(n=sample_size, random_state=42)\n",
    "        \n",
    "        print(f\"   ìƒ˜í”Œ í¬ê¸°: {sample_size:,}í–‰ìœ¼ë¡œ ì¶”ì •\")\n",
    "        \n",
    "        # ë©”ëª¨ë¦¬ ê¸°ë°˜ CSV í¬ê¸° ì¸¡ì •\n",
    "        import io\n",
    "        csv_buffer = io.StringIO()\n",
    "        sample_df.to_csv(csv_buffer, index=False)\n",
    "        csv_sample_content = csv_buffer.getvalue()\n",
    "        csv_sample_size_bytes = len(csv_sample_content.encode('utf-8'))\n",
    "        \n",
    "        # ì „ì²´ í¬ê¸° ì¶”ì •\n",
    "        estimated_csv_size_bytes = (csv_sample_size_bytes / sample_size) * total_rows\n",
    "        estimated_csv_size_mb = estimated_csv_size_bytes / (1024 * 1024)\n",
    "        estimated_csv_size_gb = estimated_csv_size_mb / 1024\n",
    "        \n",
    "        # ì••ì¶•ë¥  ê³„ì‚°\n",
    "        compression_ratio = estimated_csv_size_mb / parquet_size_mb\n",
    "        compression_efficiency = (1 - parquet_size_mb / estimated_csv_size_mb) * 100\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ í¬ê¸° ì¶”ì • ê²°ê³¼:\")\n",
    "        print(f\"   ìƒ˜í”Œ CSV í¬ê¸°: {csv_sample_size_bytes / 1024:.2f} KB ({sample_size:,}í–‰)\")\n",
    "        print(f\"   í–‰ë‹¹ í‰ê·  í¬ê¸°: {csv_sample_size_bytes / sample_size:.1f} bytes\")\n",
    "        \n",
    "        print(f\"\\nğŸ¯ ì „ì²´ CSV ì˜ˆìƒ í¬ê¸°:\")\n",
    "        print(f\"   ì˜ˆìƒ í¬ê¸°: {estimated_csv_size_mb:.2f} MB\")\n",
    "        print(f\"   ì˜ˆìƒ í¬ê¸°: {estimated_csv_size_gb:.3f} GB\")\n",
    "        print(f\"   ì˜ˆìƒ ë°”ì´íŠ¸: {estimated_csv_size_bytes:,.0f} bytes\")\n",
    "        \n",
    "        print(f\"\\nğŸ“Š ì••ì¶•ë¥  ë¶„ì„:\")\n",
    "        print(f\"   Parquet vs CSV: {compression_ratio:.1f}x ì°¨ì´\")\n",
    "        print(f\"   Parquet ì••ì¶• íš¨ìœ¨: {compression_efficiency:.1f}%\")\n",
    "        print(f\"   CSVê°€ Parquetë³´ë‹¤ {compression_ratio:.1f}ë°° ë” í¼\")\n",
    "        \n",
    "        # ì»¬ëŸ¼ë³„ í¬ê¸° ë¶„ì„\n",
    "        print(f\"\\nğŸ“‹ ì»¬ëŸ¼ë³„ í‰ê·  í¬ê¸° ë¶„ì„:\")\n",
    "        col_sizes = {}\n",
    "        for col in sample_df.columns:\n",
    "            col_series = sample_df[col].astype(str)\n",
    "            avg_char_count = col_series.str.len().mean()\n",
    "            col_sizes[col] = avg_char_count\n",
    "            \n",
    "        # í¬ê¸°ê°€ í° ì»¬ëŸ¼ ìˆœìœ¼ë¡œ ì •ë ¬\n",
    "        sorted_cols = sorted(col_sizes.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for col, avg_size in sorted_cols:\n",
    "            print(f\"   {col}: í‰ê·  {avg_size:.1f}ì\")\n",
    "        \n",
    "        # ê²½ê³  ë©”ì‹œì§€\n",
    "        if estimated_csv_size_gb > 2.0:\n",
    "            print(f\"\\nâš ï¸  ì£¼ì˜ì‚¬í•­:\")\n",
    "            print(f\"   - ì˜ˆìƒ CSV í¬ê¸°ê°€ {estimated_csv_size_gb:.1f} GBë¡œ ë§¤ìš° í½ë‹ˆë‹¤!\")\n",
    "            print(f\"   - ë©”ëª¨ë¦¬ ë¶€ì¡±ì´ë‚˜ ë¡œë”© ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "            print(f\"   - ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ê±°ë‚˜ Parquet ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤\")\n",
    "        elif estimated_csv_size_gb > 1.0:\n",
    "            print(f\"\\nğŸ’¡ ê¶Œì¥ì‚¬í•­:\")\n",
    "            print(f\"   - ì˜ˆìƒ CSV í¬ê¸°ê°€ {estimated_csv_size_gb:.1f} GBì…ë‹ˆë‹¤\")\n",
    "            print(f\"   - ëŒ€ìš©ëŸ‰ì´ë¯€ë¡œ pandas.read_csv()ì—ì„œ chunksize ì‚¬ìš© ê¶Œì¥\")\n",
    "        else:\n",
    "            print(f\"\\nâœ… ì ì • í¬ê¸°:\")\n",
    "            print(f\"   - ì˜ˆìƒ CSV í¬ê¸°ê°€ {estimated_csv_size_mb:.0f} MBë¡œ ì ë‹¹í•©ë‹ˆë‹¤\")\n",
    "            print(f\"   - ì¼ë°˜ì ì¸ ë°©ë²•ìœ¼ë¡œ ë¡œë”© ê°€ëŠ¥í•©ë‹ˆë‹¤\")\n",
    "        \n",
    "        # ë¡œë”© ì‹œê°„ ì¶”ì •\n",
    "        print(f\"\\nâ±ï¸  ì˜ˆìƒ ë¡œë”© ì‹œê°„:\")\n",
    "        # SSD ê¸°ì¤€ ëŒ€ëµì ì¸ ì½ê¸° ì†ë„ (100MB/së¡œ ê°€ì •)\n",
    "        estimated_read_time = estimated_csv_size_mb / 100\n",
    "        print(f\"   CSV íŒŒì¼ ì½ê¸°: ì•½ {estimated_read_time:.1f}ì´ˆ (SSD ê¸°ì¤€)\")\n",
    "        print(f\"   Parquet íŒŒì¼ ì½ê¸°: ì•½ {parquet_size_mb / 200:.1f}ì´ˆ (ë” ë¹ ë¦„)\")\n",
    "        \n",
    "        # ì‹¤ì œ ë³€í™˜ ì—¬ë¶€ ì„ íƒ\n",
    "        print(f\"\\nğŸ”§ ì‹¤ì œ CSV ë³€í™˜:\")\n",
    "        print(f\"   ë³€í™˜ì„ ì›í•˜ë©´ ë‹¤ìŒ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”:\")\n",
    "        print(f\"   convert_to_csv_with_estimation('{parquet_file_name}')\")\n",
    "        \n",
    "        return {\n",
    "            'parquet_size_mb': parquet_size_mb,\n",
    "            'estimated_csv_size_mb': estimated_csv_size_mb,\n",
    "            'compression_ratio': compression_ratio,\n",
    "            'total_rows': total_rows,\n",
    "            'estimated_read_time': estimated_read_time\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í¬ê¸° ì¶”ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None\n",
    "\n",
    "# event_logs_10m.parquet íŒŒì¼ í¬ê¸° ì¶”ì • ì‹¤í–‰\n",
    "print(\"ğŸ” ìƒì„±ëœ ì´ë²¤íŠ¸ ë¡œê·¸ íŒŒì¼ì˜ CSV ë³€í™˜ í¬ê¸°ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "size_estimation = estimate_csv_size_from_parquet('event_logs_10m.parquet')\n",
    "\n",
    "if size_estimation:\n",
    "    print(f\"\\nğŸ“Š ìš”ì•½:\")\n",
    "    print(f\"   ğŸ“ Parquet: {size_estimation['parquet_size_mb']:.2f} MB\")\n",
    "    print(f\"   ğŸ“„ ì˜ˆìƒ CSV: {size_estimation['estimated_csv_size_mb']:.2f} MB\")\n",
    "    print(f\"   ğŸ—œï¸  ì••ì¶•ë¥ : {size_estimation['compression_ratio']:.1f}x\")\n",
    "    print(f\"   ğŸ“ ì´ ë°ì´í„°: {size_estimation['total_rows']:,}í–‰\")\n",
    "    \n",
    "print(f\"\\nğŸ’¡ ì°¸ê³ :\")\n",
    "print(f\"   - Parquetì€ ì»¬ëŸ¼í˜• ì••ì¶•ìœ¼ë¡œ ì €ì¥ ê³µê°„ íš¨ìœ¨ì \")\n",
    "print(f\"   - CSVëŠ” í…ìŠ¤íŠ¸ í˜•íƒœë¡œ í˜¸í™˜ì„±ì´ ì¢‹ì§€ë§Œ ìš©ëŸ‰ì´ í¼\")\n",
    "print(f\"   - ë¶„ì„ìš©ë„ë¼ë©´ Parquet ì‚¬ìš© ê¶Œì¥\")\n",
    "print(f\"   - ë‹¤ë¥¸ ì‹œìŠ¤í…œ ì—°ë™ì‹œì—ë§Œ CSV ë³€í™˜ ê³ ë ¤\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-ER0ku5Vt-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
