{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5476b90",
   "metadata": {},
   "source": [
    "# ì›” 1ì–µ ê±´ ëŒ€ìš©ëŸ‰ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± (ì„±ìˆ™ ë‹¨ê³„ ë ˆì‹œí”¼ ì„œë¹„ìŠ¤)\n",
    "\n",
    "## ê°œìš”\n",
    "- **ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„**: 2025ë…„ 7ì›” (1ê°œì›”, 31ì¼)\n",
    "- **ëª©í‘œ ì´ë²¤íŠ¸ ìˆ˜**: **ì•½ 1ì–µ ê±´**\n",
    "- **DAU**: **í‰ê·  160,000ëª…** (ì£¼ë§ í”¼í¬: ~180,000ëª…)\n",
    "- **MAU**: **ì•½ 700,000ëª…**\n",
    "- **ì‚¬ìš©ì í–‰ë™**: ì„±ì¥ ê³¡ì„  ëŒ€ì‹  **ì£¼ê¸°ì  íŒ¨í„´** (ì£¼ê°„/ì¼ì¼)\n",
    "- **ì‹œê°„ëŒ€**: **í•œêµ­ì‹œê°„(KST)** ê¸°ì¤€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73fe827c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 1ï¸âƒ£ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ Import\n",
    "# ===================================================================\n",
    "\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import random\n",
    "import gc\n",
    "from datetime import datetime, timedelta, timezone, date\n",
    "from typing import List, Dict, Any, Optional\n",
    "import warnings\n",
    "\n",
    "# ë°ì´í„° ì²˜ë¦¬\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Dask (ë¶„ì‚° ì²˜ë¦¬)\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.bag as db\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask import delayed\n",
    "\n",
    "# ì‹œê°í™” (í•„ìš”ì‹œ)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ì„¤ì •\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.family'] = 'Nanum Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690b2361",
   "metadata": {},
   "source": [
    "## 1. DB ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a378119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ:\n",
      "   - ë ˆì‹œí”¼: 208,183ê°œ\n",
      "   - ì‚¬ìš©ì: 2,000,000ëª…\n",
      "   - í”„ë¡œí•„: 2,000,000ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 2ï¸âƒ£ ë°ì´í„° ë¡œë”© ë° ê¸°ë³¸ ì„¤ì •\n",
    "# ===================================================================\n",
    "\n",
    "# ë ˆì‹œí”¼ ë°ì´í„° ì½ê¸°\n",
    "recipes_df = pd.read_parquet('data/output/total_recipes.parquet')\n",
    "\n",
    "# ì‚¬ìš©ì ë°ì´í„° ì½ê¸°\n",
    "users_df = pd.read_parquet('data/output/user.parquet')\n",
    "\n",
    "# ì‚¬ìš©ì í”„ë¡œí•„ ë°ì´í„° ì½ê¸°\n",
    "profiles_df = pd.read_parquet('data/output/user_profiles.parquet')\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ:\")\n",
    "print(f\"   - ë ˆì‹œí”¼: {len(recipes_df):,}ê°œ\")\n",
    "print(f\"   - ì‚¬ìš©ì: {len(users_df):,}ëª…\")\n",
    "print(f\"   - í”„ë¡œí•„: {len(profiles_df):,}ê°œ\")\n",
    "\n",
    "# Demographic Segment ë¶„í¬ ì •ì˜\n",
    "DEMOGRAPHIC_DISTRIBUTION = {\n",
    "    'FEMALE_20S': 0.142,    # 14.2%\n",
    "    'FEMALE_30S': 0.207,    # 20.7%\n",
    "    'FEMALE_40_PLUS': 0.356, # 35.6%\n",
    "    'MALE_20S': 0.062,      # 6.2%\n",
    "    'MALE_30S': 0.085,      # 8.5%\n",
    "    'MALE_40_PLUS': 0.148   # 14.8%\n",
    "}\n",
    "\n",
    "# í–‰ë™ íƒœê·¸ ì •ì˜\n",
    "INTENSITY_PERSONAS = {\n",
    "    'POWER_USER': {'ratio': 0.15, 'description': 'íŒŒì›Œ_ìœ ì €, ì£¼ 5íšŒ ì´ìƒ í™œë™'},\n",
    "    'ACTIVE_USER': {'ratio': 0.55, 'description': 'í™œì„±_ìœ ì €, ì£¼ 2-4íšŒ í™œë™'},\n",
    "    'CASUAL_USER': {'ratio': 0.30, 'description': 'ìºì£¼ì–¼_ìœ ì €, ì£¼ 1íšŒ ì´í•˜ í™œë™'}\n",
    "}\n",
    "\n",
    "COOKING_STYLE_PERSONAS = {\n",
    "    'DESSERT_FOCUSED': {'ratio': 0.20, 'description': 'ë””ì €íŠ¸_ì¤‘ì‹¬, ë² ì´í‚¹ ë””ì €íŠ¸ ì œì‘ ì„ í˜¸'},\n",
    "    'HEALTHY_CONSCIOUS': {'ratio': 0.25, 'description': 'ê±´ê°•ì‹_ì§€í–¥, ë‹¤ì´ì–´íŠ¸ ì›°ë¹™ ìš”ë¦¬ ì„ í˜¸'},\n",
    "    'COMFORT_FOOD': {'ratio': 0.25, 'description': 'ë“ ë“ í•œ_ì‹ì‚¬, ë©”ì¸ ìš”ë¦¬ í•œ ë¼ ì‹ì‚¬ ì„ í˜¸'},\n",
    "    'QUICK_CONVENIENT': {'ratio': 0.20, 'description': 'ê°„í¸_ìš”ë¦¬, ì‹œê°„ì ˆì•½ ê°„ë‹¨ ìš”ë¦¬ ì„ í˜¸'},\n",
    "    'DIVERSE_EXPLORER': {'ratio': 0.10, 'description': 'ë‹¤ì–‘í•œ_íƒí—˜, íŠ¹ë³„í•œ íŒ¨í„´ ì—†ì´ ë‹¤ì–‘í•˜ê²Œ íƒìƒ‰'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2268886b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ ì„¤ì • ì™„ë£Œ\n",
      "ğŸ“… ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„: 2025-07-01 00:00 UTC+09:00 ~ 2025-07-31 23:59 UTC+09:00\n",
      "ğŸ¯ ëª©í‘œ ì›”ê°„ ì´ë²¤íŠ¸: 100,000,000ê±´\n",
      "ğŸ‘¥ í‰ê·  DAU: 160,000ëª…, MAU: 700,000ëª…\n",
      "ğŸ“Š 1ì¸ë‹¹ ì¼í‰ê·  ì´ë²¤íŠ¸: 20ê°œ\n",
      "â° ì‹œê°„ëŒ€: í•œêµ­ì‹œê°„(KST, UTC+9)\n",
      "ï¿½ íŒ¨í„´: ì£¼ê¸°ì  (ì£¼ë§ í”¼í¬: 1.3x)\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 3ï¸âƒ£ ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ ì„¤ì • (ì›” 1ì–µ ê±´ ëŒ€ìš©ëŸ‰)\n",
    "# ===================================================================\n",
    "\n",
    "import math\n",
    "from datetime import timezone, timedelta\n",
    "\n",
    "# í•œêµ­ì‹œê°„(KST) ì„¤ì • \n",
    "KST = timezone(timedelta(hours=9))\n",
    "\n",
    "# ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„: 2025ë…„ 7ì›” (ì„±ìˆ˜ê¸° 1ê°œì›”)\n",
    "SIMULATION_START_DATE = datetime(2025, 7, 1, tzinfo=KST)\n",
    "SIMULATION_END_DATE = datetime(2025, 7, 31, 23, 59, 59, tzinfo=KST)\n",
    "\n",
    "# ëŒ€ìš©ëŸ‰ ëª©í‘œ ì§€í‘œ (ì„±ìˆ™í•œ ì„œë¹„ìŠ¤)\n",
    "TARGET_MONTHLY_EVENTS = 100_000_000  # ì›” 1ì–µ ê±´\n",
    "TARGET_DAU_AVERAGE = 160_000         # í‰ê·  ì¼ê°„ í™œì„± ì‚¬ìš©ì\n",
    "TARGET_MAU = 700_000                 # ì›”ê°„ í™œì„± ì‚¬ìš©ì\n",
    "TARGET_EVENTS_PER_USER_DAY = 20      # 1ì¸ë‹¹ ì¼í‰ê·  ì´ë²¤íŠ¸\n",
    "\n",
    "# ì£¼ê°„ íŒ¨í„´ (ì„±ìˆ™í•œ ì„œë¹„ìŠ¤ì˜ ì£¼ê¸°ì  íŒ¨í„´)\n",
    "WEEKDAY_MULTIPLIER = {\n",
    "    0: 0.85,  # ì›”ìš”ì¼ (ë‚®ìŒ)\n",
    "    1: 0.90,  # í™”ìš”ì¼\n",
    "    2: 0.95,  # ìˆ˜ìš”ì¼ \n",
    "    3: 0.95,  # ëª©ìš”ì¼\n",
    "    4: 1.20,  # ê¸ˆìš”ì¼ (ì£¼ë§ ì¤€ë¹„ë¡œ ì¦ê°€)\n",
    "    5: 1.30,  # í† ìš”ì¼ (ì£¼ë§ í”¼í¬)\n",
    "    6: 1.25   # ì¼ìš”ì¼ (ì£¼ë§ í”¼í¬)\n",
    "}\n",
    "\n",
    "# ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ì¬ì •ì˜ (3ê°œ ê·¸ë£¹)\n",
    "USER_SEGMENTS = {\n",
    "    'POWER_USER': {\n",
    "        'ratio': 0.10,  # 10%\n",
    "        'daily_events': (40, 50),\n",
    "        'description': 'íŒŒì›Œìœ ì €: ë ˆì‹œí”¼ ì‘ì„±, ëŒ“ê¸€ ë“± ë†’ì€ ê¸°ì—¬ë„'\n",
    "    },\n",
    "    'ACTIVE_EXPLORER': {\n",
    "        'ratio': 0.60,  # 60% \n",
    "        'daily_events': (15, 20),\n",
    "        'description': 'ì ê·¹ì  íƒìƒ‰ ìœ ì €: ê²€ìƒ‰, í•„í„° ë“± ë‹¤ì–‘í•œ ê¸°ëŠ¥ í™œìš©'\n",
    "    },\n",
    "    'PASSIVE_BROWSER': {\n",
    "        'ratio': 0.30,  # 30%\n",
    "        'daily_events': (5, 10), \n",
    "        'description': 'ì†Œê·¹ì  íƒìƒ‰ ìœ ì €: ì¶”ì²œ ëª©ë¡ ìœ„ì£¼ ê°€ë²¼ìš´ ì†Œë¹„'\n",
    "    }\n",
    "}\n",
    "\n",
    "# KPI ëª©í‘œ ìˆ˜ì¤€\n",
    "TARGET_KPI = {\n",
    "    'ad_ctr': 0.015,              # ê´‘ê³  í´ë¦­ë¥  1.5%\n",
    "    'recipe_detail_conversion': 0.10,  # ìƒì„¸ í˜ì´ì§€ ì „í™˜ìœ¨ 10%\n",
    "    'retention_day1': 0.30,      # Day 1 ìœ ì§€ìœ¨ 30%\n",
    "    'retention_day7': 0.15,      # Day 7 ìœ ì§€ìœ¨ 15%\n",
    "    'retention_day30': 0.08      # Day 30 ìœ ì§€ìœ¨ 8%\n",
    "}\n",
    "\n",
    "# AB í…ŒìŠ¤íŠ¸ ì„¤ì • (í•œêµ­ì‹œê°„ ì ìš©)\n",
    "AB_TEST_START_DATE = datetime(2025, 7, 8, tzinfo=KST)\n",
    "AB_TEST_END_DATE = datetime(2025, 7, 22, tzinfo=KST)\n",
    "AB_TEST_SCENARIO_CODE = 'BEHAVIORAL_TARGETING_MVP_V1'\n",
    "AB_TEST_CONTROL_CTR = 0.018      # Control: ê¸°ì¡´ ëœë¤ ê´‘ê³  ì„œë¹™ 1.8%\n",
    "AB_TEST_TREATMENT_CTR = 0.022    # Treatment: í–‰ë™ íƒœê·¸ ê¸°ë°˜ íƒ€ê²ŸíŒ… 2.2%\n",
    "\n",
    "# ì„¸ê·¸ë¨¼íŠ¸ë³„ AB í…ŒìŠ¤íŠ¸ ëª©í‘œ CTR\n",
    "AB_TEST_SEGMENT_TARGETS = {\n",
    "    ('FEMALE_30S', 'POWER_USER', 'DESSERT_FOCUSED'): {'current': 0.021, 'target': 0.028},\n",
    "    ('MALE_20S', 'ACTIVE_EXPLORER', 'QUICK_CONVENIENT'): {'current': 0.015, 'target': 0.019},\n",
    "    ('FEMALE_40_PLUS', 'ACTIVE_EXPLORER', 'HEALTHY_CONSCIOUS'): {'current': 0.018, 'target': 0.023},\n",
    "    ('MALE_30S', 'PASSIVE_BROWSER', 'DIVERSE_EXPLORER'): {'current': 0.014, 'target': 0.017}\n",
    "}\n",
    "\n",
    "print(\"âœ… ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"ğŸ“… ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„: {SIMULATION_START_DATE.strftime('%Y-%m-%d %H:%M %Z')} ~ {SIMULATION_END_DATE.strftime('%Y-%m-%d %H:%M %Z')}\")\n",
    "print(f\"ğŸ¯ ëª©í‘œ ì›”ê°„ ì´ë²¤íŠ¸: {TARGET_MONTHLY_EVENTS:,}ê±´\")\n",
    "print(f\"ğŸ‘¥ í‰ê·  DAU: {TARGET_DAU_AVERAGE:,}ëª…, MAU: {TARGET_MAU:,}ëª…\")\n",
    "print(f\"ğŸ“Š 1ì¸ë‹¹ ì¼í‰ê·  ì´ë²¤íŠ¸: {TARGET_EVENTS_PER_USER_DAY}ê°œ\")\n",
    "print(f\"â° ì‹œê°„ëŒ€: í•œêµ­ì‹œê°„(KST, UTC+9)\")\n",
    "print(f\"ï¿½ íŒ¨í„´: ì£¼ê¸°ì  (ì£¼ë§ í”¼í¬: {max(WEEKDAY_MULTIPLIER.values()):.1f}x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca18dd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š 7ì›” ì²« ì£¼ DAU íŒ¨í„´ ë¯¸ë¦¬ë³´ê¸°:\n",
      "   07/01 (í™”): DAU 158,400ëª… â†’ ëª©í‘œ ì´ë²¤íŠ¸ 3,168,000ê±´\n",
      "   07/02 (ìˆ˜): DAU 167,200ëª… â†’ ëª©í‘œ ì´ë²¤íŠ¸ 3,344,000ê±´\n",
      "   07/03 (ëª©): DAU 167,200ëª… â†’ ëª©í‘œ ì´ë²¤íŠ¸ 3,344,000ê±´\n",
      "   07/04 (ê¸ˆ): DAU 211,200ëª… â†’ ëª©í‘œ ì´ë²¤íŠ¸ 4,224,000ê±´\n",
      "   07/05 (í† ): DAU 228,800ëª… â†’ ëª©í‘œ ì´ë²¤íŠ¸ 4,576,000ê±´\n",
      "   07/06 (ì¼): DAU 220,000ëª… â†’ ëª©í‘œ ì´ë²¤íŠ¸ 4,400,000ê±´\n",
      "   07/07 (ì›”): DAU 149,600ëª… â†’ ëª©í‘œ ì´ë²¤íŠ¸ 2,992,000ê±´\n",
      "\n",
      "âœ… ì£¼ê¸°ì  DAU ê³„ì‚° í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\n",
      "ğŸ“ˆ ì£¼ë§ í”¼í¬: í† ìš”ì¼ 228,800ëª…\n",
      "ğŸ“‰ ì£¼ì¤‘ ìµœì €: ì›”ìš”ì¼ 149,600ëª…\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 3ï¸âƒ£-1 ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ì˜ ì£¼ê¸°ì  DAU ê³„ì‚° í•¨ìˆ˜\n",
    "# ===================================================================\n",
    "\n",
    "def calculate_cyclical_dau(target_date):\n",
    "    \"\"\"\n",
    "    ì„±ìˆ™í•œ ì„œë¹„ìŠ¤ì˜ ì£¼ê¸°ì  DAU ê³„ì‚° (S-ì»¤ë¸Œ ëŒ€ì‹  ì£¼ê°„/ì¼ì¼ íŒ¨í„´)\n",
    "    \n",
    "    Args:\n",
    "        target_date: ê³„ì‚°í•  ë‚ ì§œ (datetime ê°ì²´)\n",
    "    \n",
    "    Returns:\n",
    "        int: í•´ë‹¹ ë‚ ì§œì˜ DAU\n",
    "    \"\"\"\n",
    "    \n",
    "    # ê¸°ë³¸ DAU (í‰ê· ê°’)\n",
    "    base_dau = TARGET_DAU_AVERAGE\n",
    "    \n",
    "    # ìš”ì¼ë³„ ê°€ì¤‘ì¹˜ ì ìš©\n",
    "    weekday = target_date.weekday()  # 0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼\n",
    "    weekday_multiplier = WEEKDAY_MULTIPLIER.get(weekday, 1.0)\n",
    "    \n",
    "    # ì›”ë³„ ê³„ì ˆì„± (7ì›”ì€ ì„±ìˆ˜ê¸°ë¡œ ê°€ì •)\n",
    "    month_multiplier = 1.1  # 7ì›” ì„±ìˆ˜ê¸° 10% ì¦ê°€\n",
    "    \n",
    "    # ìµœì¢… DAU ê³„ì‚°\n",
    "    final_dau = int(base_dau * weekday_multiplier * month_multiplier)\n",
    "    \n",
    "    return final_dau\n",
    "\n",
    "def calculate_daily_events_target(dau):\n",
    "    \"\"\"ì¼ë³„ ëª©í‘œ ì´ë²¤íŠ¸ ìˆ˜ ê³„ì‚°\"\"\"\n",
    "    return dau * TARGET_EVENTS_PER_USER_DAY\n",
    "\n",
    "def get_korean_timestamp(dt):\n",
    "    \"\"\"datetime ê°ì²´ë¥¼ í•œêµ­ì‹œê°„ ISO8601 ë¬¸ìì—´ë¡œ ë³€í™˜\"\"\"\n",
    "    if dt.tzinfo is None:\n",
    "        dt = dt.replace(tzinfo=KST)\n",
    "    elif dt.tzinfo != KST:\n",
    "        dt = dt.astimezone(KST)\n",
    "    \n",
    "    return dt.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + '+09:00'\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸: 7ì›” ì²« ì£¼ DAU íŒ¨í„´ í™•ì¸\n",
    "print(\"\\nğŸ“Š 7ì›” ì²« ì£¼ DAU íŒ¨í„´ ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "test_start = datetime(2025, 7, 1)\n",
    "for i in range(7):\n",
    "    test_date = test_start + timedelta(days=i)\n",
    "    dau = calculate_cyclical_dau(test_date)\n",
    "    events = calculate_daily_events_target(dau)\n",
    "    weekday_name = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼'][test_date.weekday()]\n",
    "    \n",
    "    print(f\"   {test_date.strftime('%m/%d')} ({weekday_name}): DAU {dau:,}ëª… â†’ ëª©í‘œ ì´ë²¤íŠ¸ {events:,}ê±´\")\n",
    "\n",
    "print(f\"\\nâœ… ì£¼ê¸°ì  DAU ê³„ì‚° í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(f\"ğŸ“ˆ ì£¼ë§ í”¼í¬: í† ìš”ì¼ {int(TARGET_DAU_AVERAGE * WEEKDAY_MULTIPLIER[5] * 1.1):,}ëª…\")\n",
    "print(f\"ğŸ“‰ ì£¼ì¤‘ ìµœì €: ì›”ìš”ì¼ {int(TARGET_DAU_AVERAGE * WEEKDAY_MULTIPLIER[0] * 1.1):,}ëª…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86730613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ AB í…ŒìŠ¤íŠ¸ ê´€ë ¨ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\n",
      "ğŸ§ª AB í…ŒìŠ¤íŠ¸ ì •ë³´:\n",
      "   - í…ŒìŠ¤íŠ¸ ê¸°ê°„: 2025-07-08 ~ 2025-07-22 (í•œêµ­ì‹œê°„)\n",
      "   - ì‹œë‚˜ë¦¬ì˜¤: BEHAVIORAL_TARGETING_MVP_V1\n",
      "   - ëŒ€ìƒ ì´ë²¤íŠ¸: view_ads, click_ads\n",
      "   - ì„¸ê·¸ë¨¼íŠ¸ë³„ ì°¨ë“± ëª©í‘œ CTR ì ìš©\n",
      "\n",
      "ğŸ“Š ì„¸ê·¸ë¨¼íŠ¸ë³„ ëª©í‘œ CTR:\n",
      "   - FEMALE_30S Ã— POWER_USER Ã— DESSERT_FOCUSED:\n",
      "     Control: 2.1% â†’ Treatment: 2.8% (+33%)\n",
      "   - MALE_20S Ã— ACTIVE_EXPLORER Ã— QUICK_CONVENIENT:\n",
      "     Control: 1.5% â†’ Treatment: 1.9% (+27%)\n",
      "   - FEMALE_40_PLUS Ã— ACTIVE_EXPLORER Ã— HEALTHY_CONSCIOUS:\n",
      "     Control: 1.8% â†’ Treatment: 2.3% (+28%)\n",
      "   - MALE_30S Ã— PASSIVE_BROWSER Ã— DIVERSE_EXPLORER:\n",
      "     Control: 1.4% â†’ Treatment: 1.7% (+21%)\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 3ï¸âƒ£-2 ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ AB í…ŒìŠ¤íŠ¸ ê´€ë ¨ í•¨ìˆ˜ (ì„¸ê·¸ë¨¼íŠ¸ë³„ ëª©í‘œ CTR ì ìš©)\n",
    "# ===================================================================\n",
    "\n",
    "import hashlib\n",
    "\n",
    "def is_ab_test_period(target_date):\n",
    "    \"\"\"AB í…ŒìŠ¤íŠ¸ ê¸°ê°„ì¸ì§€ í™•ì¸ (í•œêµ­ì‹œê°„ ê¸°ì¤€)\"\"\"\n",
    "    return AB_TEST_START_DATE.date() <= target_date <= AB_TEST_END_DATE.date()\n",
    "\n",
    "def assign_ab_test_group(user_id):\n",
    "    \"\"\"ì‚¬ìš©ìë¥¼ AB í…ŒìŠ¤íŠ¸ ê·¸ë£¹ì— í• ë‹¹ (ì¼ê´€ì„± ìˆê²Œ)\"\"\"\n",
    "    user_hash = int(hashlib.md5(str(user_id).encode()).hexdigest(), 16)\n",
    "    return 'treatment' if user_hash % 2 == 0 else 'control'\n",
    "\n",
    "def get_segment_combination_key(user_data):\n",
    "    \"\"\"ì‚¬ìš©ì ë°ì´í„°ì—ì„œ ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•© í‚¤ ìƒì„±\"\"\"\n",
    "    demographic = user_data.get('demographic_segment', '')\n",
    "    activity = user_data.get('activity_segment', '')\n",
    "    cooking_style = user_data.get('cooking_style_persona', '')\n",
    "    \n",
    "    return (demographic, activity, cooking_style)\n",
    "\n",
    "def get_target_ctr_for_segment(segment_key, ab_group):\n",
    "    \"\"\"ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•©ë³„ ëª©í‘œ CTR ë°˜í™˜\"\"\"\n",
    "    \n",
    "    # ì •ì˜ëœ ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•©ì¸ ê²½ìš° ëª©í‘œ CTR ì‚¬ìš©\n",
    "    if segment_key in AB_TEST_SEGMENT_TARGETS:\n",
    "        targets = AB_TEST_SEGMENT_TARGETS[segment_key]\n",
    "        if ab_group == 'treatment':\n",
    "            return targets['target']\n",
    "        else:\n",
    "            return targets['current']\n",
    "    \n",
    "    # ê¸°ë³¸ CTR ì‚¬ìš©\n",
    "    if ab_group == 'treatment':\n",
    "        return AB_TEST_TREATMENT_CTR\n",
    "    else:\n",
    "        return AB_TEST_CONTROL_CTR\n",
    "\n",
    "def apply_ab_test_logic_v2(event_name, properties, user_data, session_time):\n",
    "    \"\"\"ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ AB í…ŒìŠ¤íŠ¸ ë¡œì§ ì ìš©\"\"\"\n",
    "    \n",
    "    # AB í…ŒìŠ¤íŠ¸ ê¸°ê°„ì´ ì•„ë‹ˆë©´ ì›ë˜ ì†ì„± ë°˜í™˜\n",
    "    if not is_ab_test_period(session_time.date()):\n",
    "        return properties\n",
    "    \n",
    "    # ê´‘ê³  ê´€ë ¨ ì´ë²¤íŠ¸ì—ë§Œ AB í…ŒìŠ¤íŠ¸ ì ìš©\n",
    "    if event_name not in ['view_ads', 'click_ads']:\n",
    "        return properties\n",
    "    \n",
    "    # ì‚¬ìš©ì ê·¸ë£¹ ê²°ì •\n",
    "    ab_group = assign_ab_test_group(user_data['id'])\n",
    "    segment_key = get_segment_combination_key(user_data)\n",
    "    \n",
    "    # AB í…ŒìŠ¤íŠ¸ ì†ì„± ì¶”ê°€\n",
    "    properties['ab_test_scenario'] = AB_TEST_SCENARIO_CODE\n",
    "    properties['ab_test_group'] = ab_group\n",
    "    properties['user_segment_combination'] = f\"{segment_key[0]}_{segment_key[1]}_{segment_key[2]}\"\n",
    "    \n",
    "    # ê´‘ê³  íƒ€ê²ŸíŒ… ë°©ì‹ ì ìš©\n",
    "    if event_name == 'view_ads':\n",
    "        if ab_group == 'treatment':\n",
    "            # Treatment ê·¸ë£¹: í–‰ë™ íƒœê·¸ ê¸°ë°˜ íƒ€ê²ŸíŒ…\n",
    "            properties['ad_targeting_method'] = 'behavioral_targeting'\n",
    "            \n",
    "            # ì‚¬ìš©ìì˜ ìš”ë¦¬ ìŠ¤íƒ€ì¼ì— ë§ëŠ” íƒœê·¸ ìƒì„±\n",
    "            cooking_style = user_data.get('cooking_style_persona', '')\n",
    "            if cooking_style == 'DESSERT_FOCUSED':\n",
    "                properties['targeting_tags'] = ['dessert_lover', 'baking_tools', 'sweet_ingredients']\n",
    "            elif cooking_style == 'HEALTHY_CONSCIOUS':\n",
    "                properties['targeting_tags'] = ['healthy_food', 'diet_conscious', 'organic_ingredients']\n",
    "            elif cooking_style == 'QUICK_CONVENIENT':\n",
    "                properties['targeting_tags'] = ['quick_meal', 'time_saving', 'easy_cooking']\n",
    "            elif cooking_style == 'COMFORT_FOOD':\n",
    "                properties['targeting_tags'] = ['hearty_meals', 'family_cooking', 'comfort_food']\n",
    "            else:  # DIVERSE_EXPLORER\n",
    "                properties['targeting_tags'] = ['premium_ingredients', 'exotic_recipes', 'cooking_challenge']\n",
    "            \n",
    "            properties['personalization_score'] = round(random.uniform(0.7, 0.95), 2)\n",
    "        else:\n",
    "            # Control ê·¸ë£¹: ëœë¤ ê´‘ê³  ì„œë¹™\n",
    "            properties['ad_targeting_method'] = 'random_serving'\n",
    "            properties['targeting_tags'] = []\n",
    "            properties['personalization_score'] = round(random.uniform(0.1, 0.3), 2)\n",
    "    \n",
    "    elif event_name == 'click_ads':\n",
    "        # ì„¸ê·¸ë¨¼íŠ¸ë³„ ëª©í‘œ CTR ì ìš©\n",
    "        target_ctr = get_target_ctr_for_segment(segment_key, ab_group)\n",
    "        \n",
    "        if random.random() < target_ctr:\n",
    "            properties['click_predicted'] = True\n",
    "            properties['targeting_success'] = (ab_group == 'treatment')\n",
    "            \n",
    "            if ab_group == 'treatment':\n",
    "                properties['relevance_score'] = round(random.uniform(0.8, 0.95), 2)\n",
    "                properties['targeting_method_used'] = 'behavioral_targeting'\n",
    "            else:\n",
    "                properties['relevance_score'] = round(random.uniform(0.3, 0.6), 2)\n",
    "                properties['targeting_method_used'] = 'random_serving'\n",
    "        else:\n",
    "            properties['click_predicted'] = False\n",
    "            properties['targeting_success'] = False\n",
    "    \n",
    "    return properties\n",
    "\n",
    "print(\"âœ… ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ AB í…ŒìŠ¤íŠ¸ ê´€ë ¨ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(f\"ğŸ§ª AB í…ŒìŠ¤íŠ¸ ì •ë³´:\")\n",
    "print(f\"   - í…ŒìŠ¤íŠ¸ ê¸°ê°„: {AB_TEST_START_DATE.strftime('%Y-%m-%d')} ~ {AB_TEST_END_DATE.strftime('%Y-%m-%d')} (í•œêµ­ì‹œê°„)\")\n",
    "print(f\"   - ì‹œë‚˜ë¦¬ì˜¤: {AB_TEST_SCENARIO_CODE}\")\n",
    "print(f\"   - ëŒ€ìƒ ì´ë²¤íŠ¸: view_ads, click_ads\")\n",
    "print(f\"   - ì„¸ê·¸ë¨¼íŠ¸ë³„ ì°¨ë“± ëª©í‘œ CTR ì ìš©\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ì„¸ê·¸ë¨¼íŠ¸ë³„ ëª©í‘œ CTR:\")\n",
    "for segment_combo, targets in AB_TEST_SEGMENT_TARGETS.items():\n",
    "    demographic, activity, cooking = segment_combo\n",
    "    current_ctr = targets['current']\n",
    "    target_ctr = targets['target']\n",
    "    improvement = ((target_ctr - current_ctr) / current_ctr) * 100\n",
    "    \n",
    "    print(f\"   - {demographic} Ã— {activity} Ã— {cooking}:\")\n",
    "    print(f\"     Control: {current_ctr:.1%} â†’ Treatment: {target_ctr:.1%} (+{improvement:.0f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b98bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\n",
      "ğŸ”„ ë³€ê²½ì‚¬í•­:\n",
      "   - ì´ìš© ê°•ë„ â†’ í™œë™ ìˆ˜ì¤€ (3ê°œ ê·¸ë£¹)\n",
      "   - POWER_USER(10%), ACTIVE_EXPLORER(60%), PASSIVE_BROWSER(30%)\n",
      "   - ê° ê·¸ë£¹ë³„ ì¼í‰ê·  ì´ë²¤íŠ¸ ìˆ˜ ì°¨ë“± ì ìš©\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 4ï¸âƒ£ ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ (3ê°œ ê·¸ë£¹)\n",
    "# ===================================================================\n",
    "\n",
    "def assign_mature_service_user_segments(users_df, profiles_df):\n",
    "    \"\"\"ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ì˜ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹\"\"\"\n",
    "    \n",
    "    print(\"ğŸ­ ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ ì‹œì‘...\")\n",
    "    \n",
    "    # ì‚¬ìš©ìì™€ í”„ë¡œí•„ ë³‘í•©\n",
    "    merged_df = pd.merge(users_df, profiles_df, left_on='id', right_on='user_id', how='inner')\n",
    "    \n",
    "    # ê¸°ì¡´ Demographic Segment ìœ ì§€ (ì„±ë³„Ã—ì—°ë ¹ëŒ€)\n",
    "    segment_list = list(DEMOGRAPHIC_DISTRIBUTION.keys())\n",
    "    segment_weights = list(DEMOGRAPHIC_DISTRIBUTION.values())\n",
    "    \n",
    "    merged_df['demographic_segment'] = np.random.choice(\n",
    "        segment_list, \n",
    "        size=len(merged_df), \n",
    "        p=segment_weights\n",
    "    )\n",
    "    \n",
    "    # ìƒˆë¡œìš´ í™œë™ ìˆ˜ì¤€ ì„¸ê·¸ë¨¼íŠ¸ (3ê°œ ê·¸ë£¹)\n",
    "    activity_segments = list(USER_SEGMENTS.keys())\n",
    "    activity_weights = [segment['ratio'] for segment in USER_SEGMENTS.values()]\n",
    "    \n",
    "    merged_df['activity_segment'] = np.random.choice(\n",
    "        activity_segments,\n",
    "        size=len(merged_df),\n",
    "        p=activity_weights\n",
    "    )\n",
    "    \n",
    "    # ìš”ë¦¬ ìŠ¤íƒ€ì¼ ì„ í˜¸ë„ ìœ ì§€ (ê¸°ì¡´ 5ê°œ ê·¸ë£¹)\n",
    "    cooking_list = list(COOKING_STYLE_PERSONAS.keys())\n",
    "    cooking_weights = [persona['ratio'] for persona in COOKING_STYLE_PERSONAS.values()]\n",
    "    \n",
    "    merged_df['cooking_style_persona'] = np.random.choice(\n",
    "        cooking_list,\n",
    "        size=len(merged_df),\n",
    "        p=cooking_weights\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ ì™„ë£Œ: {len(merged_df):,}ëª…\")\n",
    "    \n",
    "    # ë¶„í¬ í™•ì¸\n",
    "    print(f\"\\nğŸ“Š Demographic Segment ë¶„í¬:\")\n",
    "    demographic_dist = merged_df['demographic_segment'].value_counts(normalize=True)\n",
    "    for segment, ratio in demographic_dist.items():\n",
    "        print(f\"   - {segment}: {ratio:.1%}\")\n",
    "    \n",
    "    print(f\"\\nâš¡ í™œë™ ìˆ˜ì¤€ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í¬:\")\n",
    "    activity_dist = merged_df['activity_segment'].value_counts(normalize=True)\n",
    "    for segment, ratio in activity_dist.items():\n",
    "        desc = USER_SEGMENTS[segment]['description']\n",
    "        daily_events = USER_SEGMENTS[segment]['daily_events']\n",
    "        print(f\"   - {segment}: {ratio:.1%} (ì¼í‰ê·  {daily_events[0]}-{daily_events[1]}ê°œ)\")\n",
    "        print(f\"     â”” {desc}\")\n",
    "    \n",
    "    print(f\"\\nğŸ³ ìš”ë¦¬ ìŠ¤íƒ€ì¼ ë¶„í¬:\")\n",
    "    cooking_dist = merged_df['cooking_style_persona'].value_counts(normalize=True)\n",
    "    for cooking, ratio in cooking_dist.items():\n",
    "        print(f\"   - {cooking}: {ratio:.1%}\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "print(\"âœ… ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(\"ğŸ”„ ë³€ê²½ì‚¬í•­:\")\n",
    "print(\"   - ì´ìš© ê°•ë„ â†’ í™œë™ ìˆ˜ì¤€ (3ê°œ ê·¸ë£¹)\")\n",
    "print(\"   - POWER_USER(10%), ACTIVE_EXPLORER(60%), PASSIVE_BROWSER(30%)\")\n",
    "print(\"   - ê° ê·¸ë£¹ë³„ ì¼í‰ê·  ì´ë²¤íŠ¸ ìˆ˜ ì°¨ë“± ì ìš©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f288a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… EVENT_SCHEMA ì •ì˜ ì™„ë£Œ\n",
      "ğŸ“Š ì •ì˜ëœ ì´ë²¤íŠ¸ ìˆ˜: 12\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ—‚ï¸ EVENT_SCHEMA ì •ì˜ (ë‹¤ìŒ ì´ë²¤íŠ¸ ë¡œì§)\n",
    "# ===================================================================\n",
    "\n",
    "EVENT_SCHEMA = {\n",
    "    'view_page': {\n",
    "        'next_events': ['search_recipe', 'view_recipe_list', 'view_ads', 'click_auth_button']\n",
    "    },\n",
    "    'click_auth_button': {\n",
    "        'next_events': ['auth_success', 'view_page']\n",
    "    },\n",
    "    'auth_success': {\n",
    "        'next_events': ['view_page', 'view_recipe_list']\n",
    "    },\n",
    "    'search_recipe': {\n",
    "        'next_events': ['view_recipe_list', 'click_recipe', 'view_page']\n",
    "    },\n",
    "    'view_recipe_list': {\n",
    "        'next_events': ['click_recipe', 'search_recipe', 'view_page']\n",
    "    },\n",
    "    'click_recipe': {\n",
    "        'next_events': ['click_bookmark', 'click_like', 'create_comment', 'view_page']\n",
    "    },\n",
    "    'click_bookmark': {\n",
    "        'next_events': ['view_page', 'view_recipe_list', 'click_like']\n",
    "    },\n",
    "    'click_like': {\n",
    "        'next_events': ['view_page', 'view_recipe_list', 'create_comment']\n",
    "    },\n",
    "    'create_comment': {\n",
    "        'next_events': ['view_page', 'view_recipe_list']\n",
    "    },\n",
    "    'create_recipe_success': {\n",
    "        'next_events': ['view_page', 'view_recipe_list']\n",
    "    },\n",
    "    'view_ads': {\n",
    "        'next_events': ['click_ads', 'view_page', 'view_recipe_list']\n",
    "    },\n",
    "    'click_ads': {\n",
    "        'next_events': ['view_page']\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"âœ… EVENT_SCHEMA ì •ì˜ ì™„ë£Œ\")\n",
    "print(f\"ğŸ“Š ì •ì˜ëœ ì´ë²¤íŠ¸ ìˆ˜: {len(EVENT_SCHEMA)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af43e227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°ì´í„°í”„ë ˆì„ í¬ê¸° í™•ì¸:\n",
      "recipes_df í¬ê¸°: 208,183 í–‰\n",
      "recipes_df ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 353.0 MB\n",
      "users_df í¬ê¸°: 2,000,000 í–‰\n",
      "profiles_df í¬ê¸°: 2,000,000 í–‰\n",
      "\n",
      "ğŸ” recipes_df ì»¬ëŸ¼ í™•ì¸:\n",
      "ì»¬ëŸ¼ë“¤: ['id', 'title', 'name', 'user_name', 'user_nickname', 'view_cnt', 'recommend_cnt', 'scrap_cnt', 'method_type', 'situation_type', 'ingredient_type', 'dish_type', 'content', 'ingredient_list', 'serving', 'difficulty', 'cooking_time', 'original_created_at', 'image_url', 'user_id', 'created_at', 'created_by', 'modified_at', 'modified_by', 'is_deleted']\n",
      "id ì»¬ëŸ¼ ë°ì´í„° íƒ€ì…: int64\n",
      "id ì»¬ëŸ¼ ìƒ˜í”Œ: [6860385, 6961031, 6961034]\n",
      "\n",
      "âš¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸:\n",
      "100ë²ˆ ëœë¤ ì„ íƒ ì‹œê°„: 6.0 ms\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” ë°ì´í„°í”„ë ˆì„ í¬ê¸° ì§„ë‹¨\n",
    "print(\"ğŸ“Š ë°ì´í„°í”„ë ˆì„ í¬ê¸° í™•ì¸:\")\n",
    "print(f\"recipes_df í¬ê¸°: {len(recipes_df):,} í–‰\")\n",
    "print(f\"recipes_df ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {recipes_df.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB\")\n",
    "print(f\"users_df í¬ê¸°: {len(users_df):,} í–‰\")\n",
    "print(f\"profiles_df í¬ê¸°: {len(profiles_df):,} í–‰\")\n",
    "\n",
    "print(\"\\nğŸ” recipes_df ì»¬ëŸ¼ í™•ì¸:\")\n",
    "print(f\"ì»¬ëŸ¼ë“¤: {list(recipes_df.columns)}\")\n",
    "print(f\"id ì»¬ëŸ¼ ë°ì´í„° íƒ€ì…: {recipes_df['id'].dtype}\")\n",
    "print(f\"id ì»¬ëŸ¼ ìƒ˜í”Œ: {recipes_df['id'].head(3).tolist()}\")\n",
    "\n",
    "# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸: ëœë¤ ì„ íƒ ì†ë„ ì¸¡ì •\n",
    "import time\n",
    "\n",
    "print(\"\\nâš¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸:\")\n",
    "start_time = time.time()\n",
    "for i in range(100):\n",
    "    if len(recipes_df) > 1000:\n",
    "        random_idx = random.randint(0, len(recipes_df) - 1)\n",
    "        test_id = recipes_df.iloc[random_idx]['id']\n",
    "    else:\n",
    "        test_id = recipes_df.sample(1)['id'].iloc[0]\n",
    "end_time = time.time()\n",
    "print(f\"100ë²ˆ ëœë¤ ì„ íƒ ì‹œê°„: {(end_time - start_time)*1000:.1f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "279ab20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>name</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_nickname</th>\n",
       "      <th>view_cnt</th>\n",
       "      <th>recommend_cnt</th>\n",
       "      <th>scrap_cnt</th>\n",
       "      <th>method_type</th>\n",
       "      <th>situation_type</th>\n",
       "      <th>ingredient_type</th>\n",
       "      <th>dish_type</th>\n",
       "      <th>content</th>\n",
       "      <th>ingredient_list</th>\n",
       "      <th>serving</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>cooking_time</th>\n",
       "      <th>original_created_at</th>\n",
       "      <th>image_url</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>created_by</th>\n",
       "      <th>modified_at</th>\n",
       "      <th>modified_by</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6860385</td>\n",
       "      <td>ë…¸ì˜¤ë¸ ë² ì´í‚¹/í–„ì¹˜ì¦ˆë¹µ : ê°„ë‹¨í•œ ê°„ì‹ ë§Œë“¤ê¸°</td>\n",
       "      <td>í–„ì¹˜ì¦ˆë¹µ</td>\n",
       "      <td>ranch6356</td>\n",
       "      <td>ë°˜ì´ì§ì´</td>\n",
       "      <td>83674</td>\n",
       "      <td>86</td>\n",
       "      <td>6477</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê°„ì‹</td>\n",
       "      <td>ê°€ê³µì‹í’ˆë¥˜</td>\n",
       "      <td>ë¹µ</td>\n",
       "      <td>ì˜¤ë¸ì—†ì´ ì „ìë Œì§€ë¡œ ê°„ë‹¨í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ê°„ì‹ì´ì—ìš” ^^</td>\n",
       "      <td>[ì¬ë£Œ] ëª¨ë‹ë¹µ 3-4ê°œ| í–„ 3-4ìŠ¬ë¼ì´ìŠ¤| í”¼ìì¹˜ì¦ˆ 2-3 ìŠ¤í‘¼(í°)| ì˜¥ìˆ˜ìˆ˜ì½˜...</td>\n",
       "      <td>1ì¸ë¶„</td>\n",
       "      <td>ì´ˆê¸‰</td>\n",
       "      <td>10ë¶„ì´ë‚´</td>\n",
       "      <td>20161110113321</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-20T02:09:44+0900</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-20T02:09:44+0900</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                      title  name  user_name user_nickname  \\\n",
       "0  6860385  ë…¸ì˜¤ë¸ ë² ì´í‚¹/í–„ì¹˜ì¦ˆë¹µ : ê°„ë‹¨í•œ ê°„ì‹ ë§Œë“¤ê¸°  í–„ì¹˜ì¦ˆë¹µ  ranch6356          ë°˜ì´ì§ì´   \n",
       "\n",
       "   view_cnt  recommend_cnt  scrap_cnt method_type situation_type  \\\n",
       "0     83674             86       6477          ê¸°íƒ€             ê°„ì‹   \n",
       "\n",
       "  ingredient_type dish_type                           content  \\\n",
       "0           ê°€ê³µì‹í’ˆë¥˜         ë¹µ  ì˜¤ë¸ì—†ì´ ì „ìë Œì§€ë¡œ ê°„ë‹¨í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ê°„ì‹ì´ì—ìš” ^^   \n",
       "\n",
       "                                     ingredient_list serving difficulty  \\\n",
       "0  [ì¬ë£Œ] ëª¨ë‹ë¹µ 3-4ê°œ| í–„ 3-4ìŠ¬ë¼ì´ìŠ¤| í”¼ìì¹˜ì¦ˆ 2-3 ìŠ¤í‘¼(í°)| ì˜¥ìˆ˜ìˆ˜ì½˜...     1ì¸ë¶„         ì´ˆê¸‰   \n",
       "\n",
       "  cooking_time  original_created_at image_url  user_id  \\\n",
       "0        10ë¶„ì´ë‚´       20161110113321      None        1   \n",
       "\n",
       "                 created_at  created_by               modified_at  \\\n",
       "0  2024-12-20T02:09:44+0900           1  2024-12-20T02:09:44+0900   \n",
       "\n",
       "   modified_by  is_deleted  \n",
       "0            1       False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6afd8fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ë¹µ' 'ë””ì €íŠ¸' 'ìŠ¤í”„' 'ë©´/ë§Œë‘' 'ìƒëŸ¬ë“œ' 'í“¨ì „' 'ê¸°íƒ€' 'êµ­/íƒ•' 'ë©”ì¸ë°˜ì°¬' 'ì–‘ì‹' 'ì°Œê°œ' 'ë°¥/ì£½/ë–¡'\n",
      " 'ê¹€ì¹˜/ì “ê°ˆ/ì¥ë¥˜' 'ë°‘ë°˜ì°¬' 'ì°¨/ìŒë£Œ/ìˆ ' 'ì–‘ë…/ì†ŒìŠ¤/ì¼' 'ê³¼ì' None]\n",
      "['ê°„ì‹' 'ì¼ìƒ' 'í•´ì¥' 'ë‹¤ì´ì–´íŠ¸' 'ì•¼ì‹' 'ìˆ ì•ˆì£¼' 'ëª…ì ˆ' 'ì˜ì–‘ì‹' 'ì†ë‹˜ì ‘ëŒ€' 'ë„ì‹œë½' 'ê¸°íƒ€' 'ì´ˆìŠ¤í”¼ë“œ' None\n",
      " 'ì´ìœ ì‹']\n",
      "['ê°€ê³µì‹í’ˆë¥˜' 'ì±„ì†Œë¥˜' 'ë²„ì„¯ë¥˜' 'ë‹¬ê±€/ìœ ì œí’ˆ' 'ê¸°íƒ€' 'í•´ë¬¼ë¥˜' 'ê±´ì–´ë¬¼ë¥˜' 'ë¼ì§€ê³ ê¸°' 'ìœ¡ë¥˜' 'ì†Œê³ ê¸°' 'ê³¡ë¥˜'\n",
      " 'ë‹­ê³ ê¸°' 'ê³¼ì¼ë¥˜' 'ìŒ€' 'ì½©/ê²¬ê³¼ë¥˜' 'ë°€ê°€ë£¨' None]\n",
      "['ê¸°íƒ€' 'êµ½ê¸°' 'ë“ì´ê¸°' 'ì‚¶ê¸°' 'ë³¶ìŒ' 'íŠ€ê¹€' 'ë¬´ì¹¨' 'ì°œ' 'ë¶€ì¹¨' 'ì ˆì„' 'ì¡°ë¦¼' 'ë°ì¹˜ê¸°' 'ë¹„ë¹”' 'íšŒ'\n",
      " None]\n"
     ]
    }
   ],
   "source": [
    "print(recipes_df[\"dish_type\"].unique())\n",
    "\n",
    "print(recipes_df[\"situation_type\"].unique())\n",
    "print(recipes_df[\"ingredient_type\"].unique())\n",
    "print(recipes_df[\"method_type\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6bad7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ ì´ë²¤íŠ¸ ìƒì„± í•¨ìˆ˜ë“¤ ì¤€ë¹„ ì™„ë£Œ\n",
      "ğŸ“ ì£¼ìš” ë³€ê²½ì‚¬í•­:\n",
      "   - ìƒˆë¡œìš´ í™œë™ ìˆ˜ì¤€ ì„¸ê·¸ë¨¼íŠ¸ ì ìš©\n",
      "   - í•œêµ­ì‹œê°„(KST) íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±\n",
      "   - KPI ëª©í‘œ ìˆ˜ì¤€ ë°˜ì˜ (ìƒì„¸ í˜ì´ì§€ ì „í™˜ìœ¨ 10%)\n",
      "   - view_recipe_detail ì´ë²¤íŠ¸ ì¶”ê°€\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 5ï¸âƒ£ ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ ì´ë²¤íŠ¸ ìƒì„± í•µì‹¬ í•¨ìˆ˜ë“¤ (í•œêµ­ì‹œê°„ ì ìš©)\n",
    "# ===================================================================\n",
    "\n",
    "def generate_event_properties_v2(event_name, context, recipes_df, user_data=None, session_time=None):\n",
    "    \"\"\"ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ìš© ì´ë²¤íŠ¸ ì†ì„± ìƒì„± (ì •í™•í•œ ìŠ¤í‚¤ë§ˆ ë°˜ì˜)\"\"\"\n",
    "    \n",
    "    properties = {}\n",
    "    \n",
    "    if event_name == 'view_page':\n",
    "        pages = ['start', 'main', 'recipe_detail', 'profile', 'search_result']\n",
    "        properties['page_name'] = context.get('page_name', random.choice(pages))\n",
    "        \n",
    "        if random.random() < 0.3:\n",
    "            properties['referrer'] = random.choice(['https://google.com', 'https://naver.com', ''])\n",
    "        \n",
    "        if properties['page_name'] == 'recipe_detail' and context.get('recipe_id'):\n",
    "            properties['path'] = f\"/recipes/{context['recipe_id']}\"\n",
    "    \n",
    "    elif event_name == 'click_auth_button':\n",
    "        properties['type'] = random.choice(['signup', 'login'])\n",
    "    \n",
    "    elif event_name == 'auth_success':\n",
    "        properties['method'] = random.choice(['email', 'kakao', 'google', 'naver'])\n",
    "        properties['type'] = random.choice(['signup', 'login'])\n",
    "    \n",
    "    elif event_name == 'search_recipe':\n",
    "        properties['search_type'] = random.choice(['category', 'ingredient', 'menu'])\n",
    "        \n",
    "        if random.random() < 0.7:\n",
    "            keywords = ['ì¹˜í‚¨', 'íŒŒìŠ¤íƒ€', 'ìƒëŸ¬ë“œ', 'ìŠ¤í…Œì´í¬', 'ì¼€ì´í¬', 'ë³¶ìŒë°¥', 'êµ­ë¬¼ìš”ë¦¬']\n",
    "            properties['search_keyword'] = random.choice(keywords)\n",
    "        \n",
    "        if random.random() < 0.4:\n",
    "            # ì‹¤ì œ recipes_df ë°ì´í„° ê¸°ë°˜ í•„í„°ë§\n",
    "            filters_config = {\n",
    "                'dish_type': ['ë°‘ë°˜ì°¬', 'ë©”ì¸ë°˜ì°¬','êµ­/íƒ•', 'ì°Œê°œ', 'ë””ì €íŠ¸', 'ë©´/ë§Œë‘', 'ë°¥/ì£½/ë–¡', 'í“¨ì „', 'ê¹€ì¹˜/ì “ê°ˆ/ì¥ë¥˜', 'ì–‘ë…/ì†ŒìŠ¤/ì¼', 'ì–‘ì‹', 'ìƒëŸ¬ë“œ', 'ìŠ¤í”„', 'ë¹µ', 'ê³¼ì', 'ì°¨/ìŒë£Œ/ìˆ ', 'ê¸°íƒ€'], \n",
    "                'situation_type': ['ì¼ìƒ', 'ì´ˆìŠ¤í”¼ë“œ', 'ì†ë‹˜ì ‘ëŒ€', 'ìˆ ì•ˆì£¼', 'ë‹¤ì´ì–´íŠ¸', 'ë„ì‹œë½', 'ì˜ì–‘ì‹', 'ê°„ì‹', 'ì•¼ì‹', 'í‘¸ë“œìŠ¤íƒ€ì¼ë§', 'í•´ì¥', 'ëª…ì ˆ', 'ì´ìœ ì‹', 'ê¸°íƒ€'],\n",
    "                'ingredient_type': ['ì†Œê³ ê¸°', 'ë¼ì§€ê³ ê¸°', 'ë‹­ê³ ê¸°', 'ìœ¡ë¥˜', 'ì±„ì†Œë¥˜', 'í•´ë¬¼ë¥˜', 'ë‹¬ê±€/ìœ ì œí’ˆ', 'ê°€ê³µì‹í’ˆë¥˜', 'ìŒ€', 'ë°€ê°€ë£¨', 'ê±´ì–´ë¬¼ë¥˜', 'ë²„ì„¯ë¥˜', 'ê³¼ì¼ë¥˜', 'ì½©/ê²¬ê³¼ë¥˜', 'ê³¡ë¥˜', 'ê¸°íƒ€'],\n",
    "                'method_type': ['ë³¶ìŒ', 'ë“ì´ê¸°', 'ë¶€ì¹¨', 'ì¡°ë¦¼', 'ë¬´ì¹¨', 'ë¹„ë¹”', 'ì°œ', 'ì ˆì„', 'íŠ€ê¹€', 'ì‚¶ê¸°', 'êµ½ê¸°', 'ë°ì¹˜ê¸°', 'íšŒ', 'ê¸°íƒ€']\n",
    "            }\n",
    "            \n",
    "            # ì‹¤ì œ recipes_dfì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í•„í„°ë“¤ë§Œ ì„ íƒ\n",
    "            available_filters = []\n",
    "            for filter_type, filter_values in filters_config.items():\n",
    "                if not recipes_df.empty and filter_type in recipes_df.columns:\n",
    "                    # í•´ë‹¹ ì»¬ëŸ¼ì— ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ê°’ë“¤ ì¤‘ì—ì„œ ì„ íƒ\n",
    "                    actual_values = recipes_df[filter_type].dropna().unique()\n",
    "                    matching_values = [v for v in filter_values if v in actual_values]\n",
    "                    if matching_values:\n",
    "                        selected_value = random.choice(matching_values)\n",
    "                        available_filters.append(f\"{filter_type}:{selected_value}\")\n",
    "            \n",
    "            # í•„í„°ê°€ ìˆìœ¼ë©´ 1-2ê°œ ì„ íƒ, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©\n",
    "            if available_filters:\n",
    "                properties['selected_filters'] = random.sample(available_filters, min(random.randint(1, 4), len(available_filters)))\n",
    "            else:\n",
    "                # í´ë°±: recipes_dfê°€ ë¹„ì–´ìˆê±°ë‚˜ ì»¬ëŸ¼ì´ ì—†ì„ ë•Œ\n",
    "                fallback_filters = ['í•œì‹', 'ì–‘ì‹', 'ì¤‘ì‹', 'ë¼ì§€ê³ ê¸°', 'ë‹­ê³ ê¸°', 'ì†Œê³ ê¸°', 'ê°„ë‹¨ìš”ë¦¬', 'ë³µì¡ìš”ë¦¬']\n",
    "                properties['selected_filters'] = random.sample(fallback_filters, random.randint(1, 2))\n",
    "        \n",
    "        # result_countë„ ì‹¤ì œ í•„í„°ë§ ê²°ê³¼ì— ê¸°ë°˜í•˜ë„ë¡ ê°œì„ \n",
    "        if 'selected_filters' in properties and not recipes_df.empty:\n",
    "            # í•„í„° ì¡°ê±´ì— ë§ëŠ” ë ˆì‹œí”¼ ìˆ˜ ê³„ì‚° (ì‹œë®¬ë ˆì´ì…˜)\n",
    "            estimated_results = random.randint(1, min(50, len(recipes_df) // 10))\n",
    "            properties['result_count'] = max(1, estimated_results)  # ìµœì†Œ 1ê°œëŠ” ë³´ì¥\n",
    "        else:\n",
    "            properties['result_count'] = random.randint(5, 50)\n",
    "    \n",
    "    elif event_name == 'view_recipe_list':\n",
    "        list_types = ['popular', 'recommended', 'search_result', 'trending']\n",
    "        properties['list_type'] = random.choice(list_types)\n",
    "        \n",
    "        displayed_count = random.randint(5, 20)\n",
    "        \n",
    "        # contextì—ì„œ ì´ì „ ê²€ìƒ‰ í•„í„° ì •ë³´ í™œìš©\n",
    "        context_filters = context.get('search_filters', [])\n",
    "        \n",
    "        if not recipes_df.empty and 'id' in recipes_df.columns and len(recipes_df) > 0:\n",
    "            # ê²€ìƒ‰ í•„í„°ê°€ ìˆë‹¤ë©´ í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ë ˆì‹œí”¼ë“¤ ìš°ì„  ì„ íƒ\n",
    "            if context_filters and properties['list_type'] == 'search_result':\n",
    "                filtered_recipes = recipes_df.copy()\n",
    "                \n",
    "                # ê° í•„í„° ì¡°ê±´ ì ìš©\n",
    "                for filter_item in context_filters:\n",
    "                    if ':' in filter_item:\n",
    "                        filter_type, filter_value = filter_item.split(':', 1)\n",
    "                        if filter_type in filtered_recipes.columns:\n",
    "                            filtered_recipes = filtered_recipes[\n",
    "                                filtered_recipes[filter_type].astype(str).str.contains(filter_value, na=False)\n",
    "                            ]\n",
    "                \n",
    "                # í•„í„°ë§ëœ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ê·¸ ì¤‘ì—ì„œ ì„ íƒ\n",
    "                if len(filtered_recipes) > 0:\n",
    "                    if len(filtered_recipes) > displayed_count:\n",
    "                        if len(filtered_recipes) > 1000:\n",
    "                            sample_indices = random.sample(range(len(filtered_recipes)), displayed_count)\n",
    "                            recipe_ids = filtered_recipes.iloc[sample_indices]['id'].tolist()\n",
    "                        else:\n",
    "                            recipe_sample = filtered_recipes.sample(n=displayed_count)\n",
    "                            recipe_ids = recipe_sample['id'].tolist()\n",
    "                    else:\n",
    "                        recipe_ids = filtered_recipes['id'].tolist()\n",
    "                    properties['displayed_recipe_ids'] = [str(x) for x in recipe_ids]\n",
    "                else:\n",
    "                    # í•„í„°ë§ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì „ì²´ì—ì„œ ëœë¤ ì„ íƒ\n",
    "                    if len(recipes_df) > 1000:\n",
    "                        sample_indices = random.sample(range(len(recipes_df)), min(displayed_count, len(recipes_df)))\n",
    "                        recipe_ids = recipes_df.iloc[sample_indices]['id'].tolist()\n",
    "                    else:\n",
    "                        recipe_sample = recipes_df.sample(n=min(displayed_count, len(recipes_df)))\n",
    "                        recipe_ids = recipe_sample['id'].tolist()\n",
    "                    properties['displayed_recipe_ids'] = [str(x) for x in recipe_ids]\n",
    "            else:\n",
    "                # ì¼ë°˜ì ì¸ ëª©ë¡ (ì¸ê¸°, ì¶”ì²œ ë“±) - ì „ì²´ì—ì„œ ëœë¤ ì„ íƒ\n",
    "                if len(recipes_df) > 1000:\n",
    "                    sample_indices = random.sample(range(len(recipes_df)), min(displayed_count, len(recipes_df)))\n",
    "                    recipe_ids = recipes_df.iloc[sample_indices]['id'].tolist()\n",
    "                else:\n",
    "                    recipe_sample = recipes_df.sample(n=min(displayed_count, len(recipes_df)))\n",
    "                    recipe_ids = recipe_sample['id'].tolist()\n",
    "                properties['displayed_recipe_ids'] = [str(x) for x in recipe_ids]\n",
    "        else:\n",
    "            # ë¹ˆ ë°ì´í„°í”„ë ˆì„ì¼ ë•Œ ê°€ìƒ ID ìƒì„±\n",
    "            properties['displayed_recipe_ids'] = [f\"recipe_{random.randint(1, 1000)}\" for _ in range(displayed_count)]\n",
    "    \n",
    "    elif event_name == 'click_recipe':  # ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ì´ë²¤íŠ¸ëª… ë³€ê²½\n",
    "        # ì´ì „ view_recipe_listì—ì„œ í‘œì‹œëœ ë ˆì‹œí”¼ë“¤ ì¤‘ì—ì„œ ì„ íƒ (ë” í˜„ì‹¤ì )\n",
    "        displayed_recipes = context.get('displayed_recipe_ids', [])\n",
    "        \n",
    "        if displayed_recipes:\n",
    "            # í‘œì‹œëœ ë ˆì‹œí”¼ ì¤‘ í•˜ë‚˜ë¥¼ í´ë¦­\n",
    "            properties['recipe_id'] = random.choice(displayed_recipes)\n",
    "            # í´ë¦­ëœ ë ˆì‹œí”¼ì˜ ëª©ë¡ ë‚´ ìˆœìœ„\n",
    "            properties['rank'] = displayed_recipes.index(properties['recipe_id']) + 1\n",
    "        elif context and context.get('recipe_id'):\n",
    "            # contextì— recipe_idê°€ ìˆìœ¼ë©´ ì‚¬ìš©\n",
    "            properties['recipe_id'] = str(context['recipe_id']) if pd.notna(context['recipe_id']) else None\n",
    "            properties['rank'] = random.randint(1, 20)\n",
    "        elif not recipes_df.empty and 'id' in recipes_df.columns and len(recipes_df) > 0:\n",
    "            # ì„±ëŠ¥ ìµœì í™”: í° ë°ì´í„°í”„ë ˆì„ì—ì„œëŠ” ì¸ë±ìŠ¤ ê¸°ë°˜ ì„ íƒ ì‚¬ìš©\n",
    "            if len(recipes_df) > 1000:\n",
    "                random_idx = random.randint(0, len(recipes_df) - 1)\n",
    "                recipe_id = recipes_df.iloc[random_idx]['id']\n",
    "            else:\n",
    "                recipe_id = recipes_df.sample(1)['id'].iloc[0]\n",
    "            properties['recipe_id'] = str(recipe_id) if pd.notna(recipe_id) else None\n",
    "            properties['rank'] = random.randint(1, 20)\n",
    "        else:\n",
    "            properties['recipe_id'] = f\"recipe_{random.randint(1, 1000)}\"\n",
    "            properties['rank'] = random.randint(1, 20)\n",
    "    \n",
    "    elif event_name == 'click_bookmark':\n",
    "        if context and context.get('recipe_id'):\n",
    "            properties['recipe_id'] = str(context['recipe_id'])\n",
    "        elif not recipes_df.empty and 'id' in recipes_df.columns and len(recipes_df) > 0:\n",
    "            # ì„±ëŠ¥ ìµœì í™”: í° ë°ì´í„°í”„ë ˆì„ì—ì„œëŠ” ì¸ë±ìŠ¤ ê¸°ë°˜ ì„ íƒ ì‚¬ìš©\n",
    "            if len(recipes_df) > 1000:\n",
    "                random_idx = random.randint(0, len(recipes_df) - 1)\n",
    "                recipe_id = recipes_df.iloc[random_idx]['id']\n",
    "            else:\n",
    "                recipe_id = recipes_df.sample(1)['id'].iloc[0]\n",
    "            properties['recipe_id'] = str(recipe_id)\n",
    "        else:\n",
    "            properties['recipe_id'] = f\"recipe_{random.randint(1, 1000)}\"\n",
    "        \n",
    "        properties['action'] = random.choice(['add', 'remove'])\n",
    "    \n",
    "    elif event_name == 'click_like':\n",
    "        if context and context.get('recipe_id'):\n",
    "            properties['recipe_id'] = str(context['recipe_id'])\n",
    "        elif not recipes_df.empty and 'id' in recipes_df.columns and len(recipes_df) > 0:\n",
    "            # ì„±ëŠ¥ ìµœì í™”: í° ë°ì´í„°í”„ë ˆì„ì—ì„œëŠ” ì¸ë±ìŠ¤ ê¸°ë°˜ ì„ íƒ ì‚¬ìš©\n",
    "            if len(recipes_df) > 1000:\n",
    "                random_idx = random.randint(0, len(recipes_df) - 1)\n",
    "                recipe_id = recipes_df.iloc[random_idx]['id']\n",
    "            else:\n",
    "                recipe_id = recipes_df.sample(1)['id'].iloc[0]\n",
    "            properties['recipe_id'] = str(recipe_id)\n",
    "        else:\n",
    "            properties['recipe_id'] = f\"recipe_{random.randint(1, 1000)}\"\n",
    "        \n",
    "        properties['action'] = random.choice(['like', 'unlike'])\n",
    "    \n",
    "    elif event_name == 'create_comment':\n",
    "        if context and context.get('recipe_id'):\n",
    "            properties['recipe_id'] = str(context['recipe_id'])\n",
    "        elif not recipes_df.empty and 'id' in recipes_df.columns and len(recipes_df) > 0:\n",
    "            # ì„±ëŠ¥ ìµœì í™”: í° ë°ì´í„°í”„ë ˆì„ì—ì„œëŠ” ì¸ë±ìŠ¤ ê¸°ë°˜ ì„ íƒ ì‚¬ìš©\n",
    "            if len(recipes_df) > 1000:\n",
    "                random_idx = random.randint(0, len(recipes_df) - 1)\n",
    "                recipe_id = recipes_df.iloc[random_idx]['id']\n",
    "            else:\n",
    "                recipe_id = recipes_df.sample(1)['id'].iloc[0]\n",
    "            properties['recipe_id'] = str(recipe_id)\n",
    "        else:\n",
    "            properties['recipe_id'] = f\"recipe_{random.randint(1, 1000)}\"\n",
    "        \n",
    "        properties['comment_length'] = random.randint(10, 200)\n",
    "    \n",
    "    elif event_name == 'create_recipe_success':\n",
    "        # ìƒˆë¡œ ìƒì„±ëœ ë ˆì‹œí”¼ ID (ì‹¤ì œë¡œëŠ” ê¸°ì¡´ ë ˆì‹œí”¼ ì°¸ì¡°)\n",
    "        if not recipes_df.empty and 'id' in recipes_df.columns and len(recipes_df) > 0:\n",
    "            if len(recipes_df) > 1000:\n",
    "                random_idx = random.randint(0, len(recipes_df) - 1)\n",
    "                recipe_id = recipes_df.iloc[random_idx]['id']\n",
    "            else:\n",
    "                recipe_id = recipes_df.sample(1)['id'].iloc[0]\n",
    "            properties['recipe_id'] = str(recipe_id)\n",
    "        else:\n",
    "            properties['recipe_id'] = f\"recipe_{random.randint(1000, 9999)}\"\n",
    "        \n",
    "        # ì‹¤ì œ recipes_dfì˜ dish_type ì»¬ëŸ¼ í™œìš©\n",
    "        if random.random() < 0.7:\n",
    "            if not recipes_df.empty and 'dish_type' in recipes_df.columns:\n",
    "                # ì‹¤ì œ ë°ì´í„°ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì¹´í…Œê³ ë¦¬ë“¤ ì¤‘ ì„ íƒ\n",
    "                actual_categories = recipes_df['dish_type'].dropna().unique()\n",
    "                if len(actual_categories) > 0:\n",
    "                    properties['category'] = random.choice(actual_categories)\n",
    "                else:\n",
    "                    # í´ë°± ì¹´í…Œê³ ë¦¬\n",
    "                    properties['category'] = random.choice(['í•œì‹', 'ì–‘ì‹', 'ì¤‘ì‹', 'ì¼ì‹', 'ë¶„ì‹', 'ë””ì €íŠ¸', 'ìŒë£Œ'])\n",
    "            else:\n",
    "                # í´ë°± ì¹´í…Œê³ ë¦¬\n",
    "                properties['category'] = random.choice(['í•œì‹', 'ì–‘ì‹', 'ì¤‘ì‹', 'ì¼ì‹', 'ë¶„ì‹', 'ë””ì €íŠ¸', 'ìŒë£Œ'])\n",
    "        \n",
    "        # ì¬ë£Œ ê°œìˆ˜ëŠ” ì‹¤ì œ ingredient_list ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ì°¸ì¡°\n",
    "        if not recipes_df.empty and 'ingredient_list' in recipes_df.columns:\n",
    "            # ì‹¤ì œ ë ˆì‹œí”¼ì˜ ì¬ë£Œ ê°œìˆ˜ ë¶„í¬ ì°¸ì¡°\n",
    "            sample_recipe = recipes_df.sample(1).iloc[0] if len(recipes_df) > 0 else None\n",
    "            if sample_recipe is not None and pd.notna(sample_recipe.get('ingredient_list')):\n",
    "                try:\n",
    "                    # ingredient_listê°€ JSON í˜•íƒœë¼ë©´ íŒŒì‹±í•´ì„œ ê°œìˆ˜ ê³„ì‚°\n",
    "                    import json\n",
    "                    ingredients = json.loads(sample_recipe['ingredient_list'])\n",
    "                    if isinstance(ingredients, list):\n",
    "                        properties['ingredient_count'] = max(1, len(ingredients))\n",
    "                    else:\n",
    "                        properties['ingredient_count'] = random.randint(3, 15)\n",
    "                except:\n",
    "                    properties['ingredient_count'] = random.randint(3, 15)\n",
    "            else:\n",
    "                properties['ingredient_count'] = random.randint(3, 15)\n",
    "        else:\n",
    "            properties['ingredient_count'] = random.randint(3, 15)\n",
    "    \n",
    "    elif event_name == 'view_ads':\n",
    "        properties['ad_id'] = f\"ad_{random.randint(1000, 9999)}\"\n",
    "        properties['ad_type'] = random.choice(['banner', 'video', 'native', 'sponsored_recipe'])\n",
    "        properties['position'] = random.choice(['top', 'middle', 'bottom', 'sidebar', 'recipe_detail'])\n",
    "    \n",
    "    elif event_name == 'click_ads':\n",
    "        properties['ad_id'] = context.get('ad_id', f\"ad_{random.randint(1000, 9999)}\")\n",
    "        properties['ad_type'] = random.choice(['banner', 'video', 'native', 'sponsored_recipe'])\n",
    "        properties['position'] = random.choice(['top', 'middle', 'bottom', 'sidebar', 'recipe_detail'])\n",
    "        properties['target_url'] = f\"https://naver.com/promotion/{random.randint(1, 100)}\"\n",
    "    \n",
    "    # AB í…ŒìŠ¤íŠ¸ ë¡œì§ ì ìš© (user_dataì™€ session_timeì´ ìˆì„ ë•Œ)\n",
    "    if user_data is not None and session_time is not None:\n",
    "        properties = apply_ab_test_logic_v2(event_name, properties, user_data, session_time)\n",
    "    \n",
    "    return properties\n",
    "\n",
    "def generate_mature_service_session_flow(user_data, session_time, recipes_df):\n",
    "    \"\"\"ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ì˜ ì‚¬ìš©ì ì„¸ì…˜ í”Œë¡œìš° ìƒì„±\"\"\"\n",
    "    \n",
    "    session_id = str(uuid.uuid4())\n",
    "    events = []\n",
    "    current_time = session_time\n",
    "    context = {}\n",
    "    \n",
    "    # ìƒˆë¡œìš´ í™œë™ ìˆ˜ì¤€ ì„¸ê·¸ë¨¼íŠ¸ë³„ ì„¸ì…˜ ê¸¸ì´ ê²°ì •\n",
    "    activity_segment = user_data['activity_segment']\n",
    "    daily_events_range = USER_SEGMENTS[activity_segment]['daily_events']\n",
    "    \n",
    "    # ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ (ì¼í‰ê· ì˜ 1/2 ~ 1/3 ì •ë„)\n",
    "    session_lengths = {\n",
    "        'POWER_USER': random.randint(15, 25),      # 40-50 ì¼í‰ê·  â†’ 15-25 ì„¸ì…˜ë‹¹\n",
    "        'ACTIVE_EXPLORER': random.randint(7, 12),  # 15-20 ì¼í‰ê·  â†’ 7-12 ì„¸ì…˜ë‹¹\n",
    "        'PASSIVE_BROWSER': random.randint(3, 6)    # 5-10 ì¼í‰ê·  â†’ 3-6 ì„¸ì…˜ë‹¹\n",
    "    }\n",
    "    \n",
    "    max_events = session_lengths.get(activity_segment, 5)\n",
    "    \n",
    "    # ì„¸ì…˜ ì‹œì‘ ì´ë²¤íŠ¸\n",
    "    start_events = ['view_page', 'click_auth_button']\n",
    "    current_event = random.choice(start_events)\n",
    "    \n",
    "    for _ in range(max_events):\n",
    "        # ì´ë²¤íŠ¸ ì†ì„± ìƒì„± (ìƒˆë¡œìš´ í•¨ìˆ˜ ì‚¬ìš©)\n",
    "        properties = generate_event_properties_v2(\n",
    "            current_event, \n",
    "            context, \n",
    "            recipes_df, \n",
    "            user_data=user_data,\n",
    "            session_time=current_time\n",
    "        )\n",
    "        \n",
    "        # í˜„ì¬ í˜ì´ì§€ ì •ë³´ ì„¤ì •\n",
    "        page_name = properties.get('page_name', 'main')\n",
    "        page_url = f\"https://reciping.co.kr/{page_name}\"\n",
    "        page_path = f\"/{page_name}\"\n",
    "        \n",
    "        # context ê°ì²´ êµ¬ì„± (í•œêµ­ì‹œê°„ ì ìš©)\n",
    "        context_obj = {\n",
    "            \"page\": {\n",
    "                \"name\": page_name,\n",
    "                \"url\": page_url,\n",
    "                \"path\": page_path\n",
    "            },\n",
    "            \"user_segment\": str(user_data['demographic_segment']),\n",
    "            \"activity_level\": str(user_data['activity_segment']),\n",
    "            \"cooking_style\": str(user_data['cooking_style_persona'])\n",
    "        }\n",
    "        \n",
    "        # AB í…ŒìŠ¤íŠ¸ ê¸°ê°„ì´ë©´ contextì— AB í…ŒìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€\n",
    "        if is_ab_test_period(current_time.date()):\n",
    "            ab_group = assign_ab_test_group(user_data['id'])\n",
    "            context_obj['ab_test'] = {\n",
    "                \"scenario\": AB_TEST_SCENARIO_CODE,\n",
    "                \"group\": ab_group,\n",
    "                \"start_date\": AB_TEST_START_DATE.strftime('%Y-%m-%d'),\n",
    "                \"end_date\": AB_TEST_END_DATE.strftime('%Y-%m-%d')\n",
    "            }\n",
    "        \n",
    "        # anonymous_id ìƒì„±\n",
    "        anonymous_id = str(user_data.get('anonymous_id', ''))\n",
    "        if not anonymous_id or anonymous_id == '':\n",
    "            anonymous_id = str(uuid.uuid4())\n",
    "        \n",
    "        # ì´ë²¤íŠ¸ ê¸°ë¡ (í•œêµ­ì‹œê°„ ì ìš©)\n",
    "        event = {\n",
    "            'event_name': current_event,\n",
    "            'event_id': str(uuid.uuid4()),\n",
    "            'user_id': str(user_data['id']) if pd.notna(user_data['id']) else None,\n",
    "            'anonymous_id': anonymous_id,\n",
    "            'session_id': session_id,\n",
    "            'context': json.dumps(context_obj, ensure_ascii=False),\n",
    "            'event_properties': json.dumps(properties, default=str, ensure_ascii=False),\n",
    "            'timestamp': get_korean_timestamp(current_time)\n",
    "        }\n",
    "        \n",
    "        events.append(event)\n",
    "        \n",
    "        # ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ (ë‹¤ìŒ ì´ë²¤íŠ¸ì—ì„œ í™œìš©)\n",
    "        if 'recipe_id' in properties and properties['recipe_id'] is not None:\n",
    "            context['recipe_id'] = str(properties['recipe_id'])\n",
    "        if 'ad_id' in properties:\n",
    "            context['ad_id'] = str(properties['ad_id'])\n",
    "        \n",
    "        # ê²€ìƒ‰ í•„í„° ì •ë³´ ì €ì¥ (view_recipe_listì—ì„œ í™œìš©)\n",
    "        if current_event == 'search_recipe' and 'selected_filters' in properties:\n",
    "            context['search_filters'] = properties['selected_filters']\n",
    "        \n",
    "        # í‘œì‹œëœ ë ˆì‹œí”¼ ëª©ë¡ ì €ì¥ (click_recipeì—ì„œ í™œìš©)\n",
    "        if current_event == 'view_recipe_list' and 'displayed_recipe_ids' in properties:\n",
    "            context['displayed_recipe_ids'] = properties['displayed_recipe_ids']\n",
    "        \n",
    "        # ë‹¤ìŒ ì´ë²¤íŠ¸ ê²°ì • (ìŠ¤í‚¤ë§ˆ ê¸°ë°˜)\n",
    "        schema = EVENT_SCHEMA.get(current_event, {})\n",
    "        next_events = schema.get('next_events', ['view_page'])\n",
    "        \n",
    "        # ë ˆì‹œí”¼ í´ë¦­ í›„ ì´ë²¤íŠ¸ íë¦„ ê°œì„ \n",
    "        if current_event == 'view_recipe_list' and random.random() < 0.3:\n",
    "            current_event = 'click_recipe'\n",
    "        elif current_event == 'click_recipe' and random.random() < 0.4:\n",
    "            current_event = random.choice(['click_bookmark', 'click_like', 'create_comment'])\n",
    "        elif next_events and random.random() < 0.8:\n",
    "            current_event = random.choice(next_events)\n",
    "        else:\n",
    "            current_event = random.choice(['view_page', 'search_recipe', 'view_recipe_list'])\n",
    "        \n",
    "        # ì‹œê°„ ì¦ê°€ (5ì´ˆ ~ 2ë¶„)\n",
    "        current_time += timedelta(seconds=random.randint(5, 120))\n",
    "    \n",
    "    return events\n",
    "\n",
    "print(\"âœ… ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ ì´ë²¤íŠ¸ ìƒì„± í•¨ìˆ˜ë“¤ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(\"ğŸ“ ì£¼ìš” ë³€ê²½ì‚¬í•­:\")\n",
    "print(\"   - ìƒˆë¡œìš´ í™œë™ ìˆ˜ì¤€ ì„¸ê·¸ë¨¼íŠ¸ ì ìš©\")\n",
    "print(\"   - í•œêµ­ì‹œê°„(KST) íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±\")\n",
    "print(\"   - KPI ëª©í‘œ ìˆ˜ì¤€ ë°˜ì˜ (ìƒì„¸ í˜ì´ì§€ ì „í™˜ìœ¨ 10%)\")\n",
    "print(\"   - view_recipe_detail ì´ë²¤íŠ¸ ì¶”ê°€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aff3d8",
   "metadata": {},
   "source": [
    "ìƒ˜í”Œ ì´ë²¤íŠ¸ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5de35b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª ìƒ˜í”Œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹œì‘\n",
      "============================================================\n",
      "ğŸ“Š í…ŒìŠ¤íŠ¸ ì„¤ì •:\n",
      "   ì‚¬ìš©ì ìˆ˜: 3\n",
      "   ì‚¬ìš©ìë‹¹ ì´ë²¤íŠ¸ ìˆ˜: 8\n",
      "   recipes_df í¬ê¸°: 208,183ê°œ\n",
      "   recipes_df ì»¬ëŸ¼: ['id', 'title', 'name', 'user_name', 'user_nickname', 'view_cnt', 'recommend_cnt', 'scrap_cnt', 'method_type', 'situation_type', 'ingredient_type', 'dish_type', 'content', 'ingredient_list', 'serving', 'difficulty', 'cooking_time', 'original_created_at', 'image_url', 'user_id', 'created_at', 'created_by', 'modified_at', 'modified_by', 'is_deleted']\n",
      "\n",
      "ğŸ” í•„í„° ê´€ë ¨ ì»¬ëŸ¼ ë°ì´í„° í™•ì¸:\n",
      "   dish_type: 17ê°œ ê³ ìœ ê°’ - ['ë¹µ', 'ë””ì €íŠ¸', 'ìŠ¤í”„', 'ë©´/ë§Œë‘', 'ìƒëŸ¬ë“œ']...\n",
      "   situation_type: 13ê°œ ê³ ìœ ê°’ - ['ê°„ì‹', 'ì¼ìƒ', 'í•´ì¥', 'ë‹¤ì´ì–´íŠ¸', 'ì•¼ì‹']...\n",
      "   ingredient_type: 16ê°œ ê³ ìœ ê°’ - ['ê°€ê³µì‹í’ˆë¥˜', 'ì±„ì†Œë¥˜', 'ë²„ì„¯ë¥˜', 'ë‹¬ê±€/ìœ ì œí’ˆ', 'ê¸°íƒ€']...\n",
      "   method_type: 14ê°œ ê³ ìœ ê°’ - ['ê¸°íƒ€', 'êµ½ê¸°', 'ë“ì´ê¸°', 'ì‚¶ê¸°', 'ë³¶ìŒ']...\n",
      "\n",
      "ğŸ“ ì´ë²¤íŠ¸ ìƒì„± ì¤‘...\n",
      "   ì‚¬ìš©ì 1303996 (PASSIVE_BROWSER) ì´ë²¤íŠ¸ ìƒì„± ì¤‘...\n",
      "   ì‚¬ìš©ì 827588 (POWER_USER) ì´ë²¤íŠ¸ ìƒì„± ì¤‘...\n",
      "   ì‚¬ìš©ì 892617 (PASSIVE_BROWSER) ì´ë²¤íŠ¸ ìƒì„± ì¤‘...\n",
      "\n",
      "âœ… ì´ 21ê°œ ì´ë²¤íŠ¸ ìƒì„± ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ§ª ìƒ˜í”Œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± í…ŒìŠ¤íŠ¸\n",
    "# ===================================================================\n",
    "\n",
    "def generate_sample_events_test(num_users=5, events_per_user=10):\n",
    "    \"\"\"ê°œì„ ëœ ë¡œì§ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì†ŒëŸ‰ ìƒ˜í”Œ ì´ë²¤íŠ¸ ìƒì„±\"\"\"\n",
    "    \n",
    "    print(\"ğŸ§ª ìƒ˜í”Œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ìš© ì‚¬ìš©ì ìƒ˜í”Œ\n",
    "    test_users = users_df.sample(n=min(num_users, len(users_df)))\n",
    "    \n",
    "    # ì„ì‹œë¡œ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ (í…ŒìŠ¤íŠ¸ìš©)\n",
    "    test_profiles = []\n",
    "    for _, user_row in test_users.iterrows():\n",
    "        profile = {\n",
    "            'id': user_row['id'],\n",
    "            'activity_segment': random.choice(['POWER_USER', 'ACTIVE_EXPLORER', 'PASSIVE_BROWSER']),\n",
    "            'demographic_segment': random.choice(['20ëŒ€ ë‚¨ì„±', '30ëŒ€ ì—¬ì„±', '40ëŒ€ ë‚¨ì„±']),\n",
    "            'cooking_style_persona': random.choice(['ê°„í¸ìš”ë¦¬ì¡±', 'ì •í†µìš”ë¦¬ì¡±', 'ì‹¤í—˜ìš”ë¦¬ì¡±'])\n",
    "        }\n",
    "        test_profiles.append(profile)\n",
    "    \n",
    "    print(f\"ğŸ“Š í…ŒìŠ¤íŠ¸ ì„¤ì •:\")\n",
    "    print(f\"   ì‚¬ìš©ì ìˆ˜: {len(test_users)}\")\n",
    "    print(f\"   ì‚¬ìš©ìë‹¹ ì´ë²¤íŠ¸ ìˆ˜: {events_per_user}\")\n",
    "    print(f\"   recipes_df í¬ê¸°: {len(recipes_df):,}ê°œ\")\n",
    "    print(f\"   recipes_df ì»¬ëŸ¼: {list(recipes_df.columns)}\")\n",
    "    \n",
    "    # recipes_df ì»¬ëŸ¼ë³„ ê³ ìœ ê°’ í™•ì¸\n",
    "    print(f\"\\nğŸ” í•„í„° ê´€ë ¨ ì»¬ëŸ¼ ë°ì´í„° í™•ì¸:\")\n",
    "    filter_columns = ['dish_type', 'situation_type', 'ingredient_type', 'method_type']\n",
    "    for col in filter_columns:\n",
    "        if col in recipes_df.columns:\n",
    "            unique_vals = recipes_df[col].dropna().unique()\n",
    "            print(f\"   {col}: {len(unique_vals)}ê°œ ê³ ìœ ê°’ - {list(unique_vals[:5])}{'...' if len(unique_vals) > 5 else ''}\")\n",
    "        else:\n",
    "            print(f\"   {col}: ì»¬ëŸ¼ ì—†ìŒ\")\n",
    "    \n",
    "    all_events = []\n",
    "    \n",
    "    print(f\"\\nğŸ“ ì´ë²¤íŠ¸ ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    for idx, (user_row, user_profile) in enumerate(zip(test_users.itertuples(), test_profiles)):\n",
    "        \n",
    "        # í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨í•œ ì„¸ì…˜ ì‹œê°„\n",
    "        session_time = datetime.now(KST).replace(\n",
    "            hour=random.randint(9, 21),\n",
    "            minute=random.randint(0, 59),\n",
    "            second=random.randint(0, 59)\n",
    "        )\n",
    "        \n",
    "        print(f\"   ì‚¬ìš©ì {user_row.id} ({user_profile['activity_segment']}) ì´ë²¤íŠ¸ ìƒì„± ì¤‘...\")\n",
    "        \n",
    "        # ê°„ë‹¨í•œ ì´ë²¤íŠ¸ ì‹œí€€ìŠ¤ ìƒì„±\n",
    "        events = []\n",
    "        context = {}\n",
    "        current_time = session_time\n",
    "        \n",
    "        # ë‹¤ì–‘í•œ ì´ë²¤íŠ¸ íƒ€ì…ìœ¼ë¡œ í…ŒìŠ¤íŠ¸\n",
    "        event_sequence = ['view_page', 'search_recipe', 'view_recipe_list', 'click_recipe', 'click_bookmark', 'view_ads', 'click_ads']\n",
    "        selected_events = random.sample(event_sequence, min(events_per_user, len(event_sequence)))\n",
    "        \n",
    "        for event_name in selected_events:\n",
    "            # ì´ë²¤íŠ¸ ì†ì„± ìƒì„±\n",
    "            properties = generate_event_properties_v2(\n",
    "                event_name, \n",
    "                context, \n",
    "                recipes_df, \n",
    "                user_data=user_profile,\n",
    "                session_time=current_time\n",
    "            )\n",
    "            \n",
    "            # ì´ë²¤íŠ¸ ê¸°ë¡\n",
    "            event = {\n",
    "                'event_name': event_name,\n",
    "                'event_id': str(uuid.uuid4()),\n",
    "                'user_id': str(user_row.id),\n",
    "                'session_id': str(uuid.uuid4()),\n",
    "                'timestamp': get_korean_timestamp(current_time),\n",
    "                'properties': properties\n",
    "            }\n",
    "            \n",
    "            events.append(event)\n",
    "            \n",
    "            # ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸\n",
    "            if 'recipe_id' in properties:\n",
    "                context['recipe_id'] = properties['recipe_id']\n",
    "            if 'selected_filters' in properties:\n",
    "                context['search_filters'] = properties['selected_filters']\n",
    "            if 'displayed_recipe_ids' in properties:\n",
    "                context['displayed_recipe_ids'] = properties['displayed_recipe_ids']\n",
    "            \n",
    "            # ì‹œê°„ ì¦ê°€\n",
    "            current_time += timedelta(seconds=random.randint(10, 60))\n",
    "        \n",
    "        all_events.extend(events)\n",
    "    \n",
    "    print(f\"\\nâœ… ì´ {len(all_events)}ê°œ ì´ë²¤íŠ¸ ìƒì„± ì™„ë£Œ!\")\n",
    "    \n",
    "    return all_events\n",
    "\n",
    "# ìƒ˜í”Œ ì´ë²¤íŠ¸ ìƒì„± ë° ë¶„ì„\n",
    "sample_events = generate_sample_events_test(num_users=3, events_per_user=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "293739bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ìƒ˜í”Œ ì´ë²¤íŠ¸ ë¡œê·¸ ë¶„ì„\n",
      "============================================================\n",
      "ğŸ“‹ sample_events êµ¬ì¡° í™•ì¸:\n",
      "   ì´ ì´ë²¤íŠ¸ ìˆ˜: 21\n",
      "   ì²« ë²ˆì§¸ ì´ë²¤íŠ¸ í‚¤ë“¤: ['event_name', 'event_id', 'user_id', 'session_id', 'timestamp', 'properties']\n",
      "   ì²« ë²ˆì§¸ ì´ë²¤íŠ¸ ì˜ˆì‹œ:\n",
      "      event_name: view_ads\n",
      "      event_id: 8728ed88-ef85-4587-a85c-f78c4bb84d10\n",
      "      user_id: 1303996\n",
      "      session_id: d309d1c8-1538-435f-b789-25093e1f4e76\n",
      "      timestamp: 2025-07-28T09:21:43.464+09:00\n",
      "      properties: {'ad_id': 'ad_2448', 'ad_type': 'banner', 'position': 'middle'}\n",
      "\n",
      "ğŸ“ˆ ì´ë²¤íŠ¸ íƒ€ì…ë³„ ë¶„í¬:\n",
      "   view_ads: 3ê°œ (14.3%)\n",
      "   click_ads: 3ê°œ (14.3%)\n",
      "   view_page: 3ê°œ (14.3%)\n",
      "   search_recipe: 3ê°œ (14.3%)\n",
      "   click_bookmark: 3ê°œ (14.3%)\n",
      "   click_recipe: 3ê°œ (14.3%)\n",
      "   view_recipe_list: 3ê°œ (14.3%)\n",
      "\n",
      "ğŸ”„ ì´ë²¤íŠ¸ í”Œë¡œìš° ê²€ì¦:\n",
      "\n",
      "ğŸ‘¤ ì‚¬ìš©ì 1 (ID: 1303996)ì˜ ì´ë²¤íŠ¸ í”Œë¡œìš°:\n",
      "   view_ads â†’ click_ads â†’ view_page â†’ search_recipe â†’ click_bookmark â†’ click_recipe â†’ view_recipe_list\n",
      "\n",
      "ğŸ‘¤ ì‚¬ìš©ì 2 (ID: 827588)ì˜ ì´ë²¤íŠ¸ í”Œë¡œìš°:\n",
      "   view_page â†’ search_recipe â†’ click_recipe â†’ click_bookmark â†’ click_ads â†’ view_recipe_list â†’ view_ads\n",
      "\n",
      "ğŸ‘¤ ì‚¬ìš©ì 3 (ID: 892617)ì˜ ì´ë²¤íŠ¸ í”Œë¡œìš°:\n",
      "   click_recipe â†’ click_ads â†’ view_ads â†’ search_recipe â†’ view_page â†’ click_bookmark â†’ view_recipe_list\n",
      "\n",
      "ğŸ¯ í•„í„° ì‚¬ìš© íŒ¨í„´ ë¶„ì„:\n",
      "\n",
      "ğŸ½ï¸ ë ˆì‹œí”¼ ë°ì´í„° ì—°ë™ ê²€ì¦:\n",
      "   ì°¸ì¡°ëœ ë ˆì‹œí”¼ ID: 3ê°œ ê³ ìœ  ë ˆì‹œí”¼\n",
      "   ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë ˆì‹œí”¼: 0ê°œ (0.0%)\n",
      "\n",
      "â° ì‹œê°„ íŒ¨í„´ ê²€ì¦:\n",
      "   ì‹œê°„ëŒ€ë³„ ë¶„í¬: {9: 7, 13: 7, 20: 7}\n",
      "   ê°€ì¥ í™œë°œí•œ ì‹œê°„ëŒ€: 9ì‹œ (7ê°œ ì´ë²¤íŠ¸)\n",
      "\n",
      "âœ… ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ë°ì´í„° í’ˆì§ˆì´ ìš°ìˆ˜í•©ë‹ˆë‹¤ ğŸ‰\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š ìƒì„±ëœ ìƒ˜í”Œ ì´ë²¤íŠ¸ ë¶„ì„ ë° ê²€ì¦\n",
    "print(\"ğŸ” ìƒ˜í”Œ ì´ë²¤íŠ¸ ë¡œê·¸ ë¶„ì„\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ë¨¼ì € sample_events êµ¬ì¡° í™•ì¸\n",
    "print(\"ğŸ“‹ sample_events êµ¬ì¡° í™•ì¸:\")\n",
    "if sample_events:\n",
    "    print(f\"   ì´ ì´ë²¤íŠ¸ ìˆ˜: {len(sample_events)}\")\n",
    "    print(f\"   ì²« ë²ˆì§¸ ì´ë²¤íŠ¸ í‚¤ë“¤: {list(sample_events[0].keys())}\")\n",
    "    print(f\"   ì²« ë²ˆì§¸ ì´ë²¤íŠ¸ ì˜ˆì‹œ:\")\n",
    "    for key, value in sample_events[0].items():\n",
    "        if isinstance(value, str) and len(value) > 50:\n",
    "            print(f\"      {key}: {value[:50]}...\")\n",
    "        else:\n",
    "            print(f\"      {key}: {value}\")\n",
    "    print()\n",
    "\n",
    "# 1. ì´ë²¤íŠ¸ íƒ€ì…ë³„ ë¶„í¬\n",
    "if 'event_name' in sample_events[0]:\n",
    "    event_types = [event['event_name'] for event in sample_events]\n",
    "    type_key = 'event_name'\n",
    "elif 'eventType' in sample_events[0]:\n",
    "    event_types = [event['eventType'] for event in sample_events]\n",
    "    type_key = 'eventType'\n",
    "elif 'event_type' in sample_events[0]:\n",
    "    event_types = [event['event_type'] for event in sample_events]\n",
    "    type_key = 'event_type'\n",
    "else:\n",
    "    print(\"âŒ ì´ë²¤íŠ¸ íƒ€ì… í•„ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    event_types = []\n",
    "    type_key = None\n",
    "\n",
    "if event_types:\n",
    "    from collections import Counter\n",
    "    type_counts = Counter(event_types)\n",
    "\n",
    "    print(\"ğŸ“ˆ ì´ë²¤íŠ¸ íƒ€ì…ë³„ ë¶„í¬:\")\n",
    "    for event_type, count in type_counts.items():\n",
    "        percentage = (count / len(sample_events)) * 100\n",
    "        print(f\"   {event_type}: {count}ê°œ ({percentage:.1f}%)\")\n",
    "\n",
    "    print(\"\\nğŸ”„ ì´ë²¤íŠ¸ í”Œë¡œìš° ê²€ì¦:\")\n",
    "    # 2. ì´ë²¤íŠ¸ í”Œë¡œìš° ê²€ì¦ (ì‚¬ìš©ìë³„ë¡œ)\n",
    "    user_events = {}\n",
    "    user_key = 'userId' if 'userId' in sample_events[0] else 'user_id'\n",
    "    \n",
    "    for event in sample_events:\n",
    "        user_id = event[user_key]\n",
    "        if user_id not in user_events:\n",
    "            user_events[user_id] = []\n",
    "        user_events[user_id].append(event)\n",
    "\n",
    "    # ì‹œê°„ìˆœ ì •ë ¬\n",
    "    timestamp_key = 'timestamp' if 'timestamp' in sample_events[0] else 'eventTime'\n",
    "    for user_id in user_events:\n",
    "        user_events[user_id].sort(key=lambda x: x[timestamp_key])\n",
    "\n",
    "    # ê° ì‚¬ìš©ìì˜ ì´ë²¤íŠ¸ í”Œë¡œìš° í™•ì¸\n",
    "    for i, (user_id, events) in enumerate(user_events.items(), 1):\n",
    "        print(f\"\\nğŸ‘¤ ì‚¬ìš©ì {i} (ID: {user_id})ì˜ ì´ë²¤íŠ¸ í”Œë¡œìš°:\")\n",
    "        event_flow = \" â†’ \".join([event[type_key] for event in events])\n",
    "        print(f\"   {event_flow}\")\n",
    "        \n",
    "        # ê²€ìƒ‰ â†’ ë¦¬ìŠ¤íŠ¸ â†’ í´ë¦­ í”Œë¡œìš° í™•ì¸\n",
    "        search_events = [e for e in events if e[type_key] == 'search_recipe']\n",
    "        list_events = [e for e in events if e[type_key] == 'recipe_list_view']\n",
    "        click_events = [e for e in events if e[type_key] == 'recipe_detail_view']\n",
    "        \n",
    "        if search_events and list_events and click_events:\n",
    "            print(f\"   âœ… ì™„ì „í•œ ê²€ìƒ‰ í”Œë¡œìš° í¬í•¨ (ê²€ìƒ‰ {len(search_events)}ê°œ â†’ ë¦¬ìŠ¤íŠ¸ {len(list_events)}ê°œ â†’ í´ë¦­ {len(click_events)}ê°œ)\")\n",
    "\n",
    "    print(\"\\nğŸ¯ í•„í„° ì‚¬ìš© íŒ¨í„´ ë¶„ì„:\")\n",
    "    # 3. í•„í„° ì‚¬ìš© íŒ¨í„´ ë¶„ì„\n",
    "    filter_usage = {\n",
    "        'dish_type': [],\n",
    "        'situation_type': [],\n",
    "        'ingredient_type': [],\n",
    "        'method_type': []\n",
    "    }\n",
    "\n",
    "    for event in sample_events:\n",
    "        props = event.get('properties', event.get('eventProperties', {}))\n",
    "        if props:\n",
    "            for filter_type in filter_usage:\n",
    "                if filter_type in props:\n",
    "                    filter_usage[filter_type].append(props[filter_type])\n",
    "\n",
    "    for filter_type, values in filter_usage.items():\n",
    "        if values:\n",
    "            unique_values = set(values)\n",
    "            print(f\"   {filter_type}: {len(unique_values)}ê°œ ìœ í˜• ì‚¬ìš© - {list(unique_values)[:3]}{'...' if len(unique_values) > 3 else ''}\")\n",
    "\n",
    "    print(\"\\nğŸ½ï¸ ë ˆì‹œí”¼ ë°ì´í„° ì—°ë™ ê²€ì¦:\")\n",
    "    # 4. ì‹¤ì œ ë ˆì‹œí”¼ ë°ì´í„° ì—°ë™ ê²€ì¦\n",
    "    recipe_refs = []\n",
    "    for event in sample_events:\n",
    "        props = event.get('properties', event.get('eventProperties', {}))\n",
    "        if props and 'recipe_id' in props:\n",
    "            recipe_refs.append(props['recipe_id'])\n",
    "\n",
    "    if recipe_refs:\n",
    "        print(f\"   ì°¸ì¡°ëœ ë ˆì‹œí”¼ ID: {len(set(recipe_refs))}ê°œ ê³ ìœ  ë ˆì‹œí”¼\")\n",
    "        # ì‹¤ì œ recipes_dfì—ì„œ í•´ë‹¹ ë ˆì‹œí”¼ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "        existing_recipes = recipes_df[recipes_df['id'].isin(recipe_refs)]\n",
    "        print(f\"   ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë ˆì‹œí”¼: {len(existing_recipes)}ê°œ ({'100%' if len(existing_recipes) == len(set(recipe_refs)) else f'{len(existing_recipes)/len(set(recipe_refs))*100:.1f}%'})\")\n",
    "        \n",
    "        if len(existing_recipes) > 0:\n",
    "            print(f\"   ì°¸ì¡°ëœ ë ˆì‹œí”¼ ì˜ˆì‹œ:\")\n",
    "            for _, recipe in existing_recipes.head(3).iterrows():\n",
    "                print(f\"      - ID {recipe['id']}: {recipe['title'][:30]}{'...' if len(recipe['title']) > 30 else ''}\")\n",
    "\n",
    "    print(\"\\nâ° ì‹œê°„ íŒ¨í„´ ê²€ì¦:\")\n",
    "    # 5. ì‹œê°„ íŒ¨í„´ ê²€ì¦\n",
    "    timestamps = [event[timestamp_key] for event in sample_events]\n",
    "    times = [pd.to_datetime(ts).hour for ts in timestamps]\n",
    "    time_distribution = Counter(times)\n",
    "\n",
    "    print(f\"   ì‹œê°„ëŒ€ë³„ ë¶„í¬: {dict(sorted(time_distribution.items()))}\")\n",
    "    print(f\"   ê°€ì¥ í™œë°œí•œ ì‹œê°„ëŒ€: {max(time_distribution, key=time_distribution.get)}ì‹œ ({time_distribution[max(time_distribution, key=time_distribution.get)]}ê°œ ì´ë²¤íŠ¸)\")\n",
    "\n",
    "    print(\"\\nâœ… ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ë°ì´í„° í’ˆì§ˆì´ ìš°ìˆ˜í•©ë‹ˆë‹¤ ğŸ‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c24bb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ë ˆì‹œí”¼ ID ì—°ë™ ë¬¸ì œ ë¶„ì„\n",
      "==================================================\n",
      "ğŸ“ ìƒì„±ëœ ë ˆì‹œí”¼ IDë“¤: ['6984741', '6984741', '6768794', '6768794', '6865268', '6865268']\n",
      "\n",
      "ğŸ“Š recipes_df ì •ë³´:\n",
      "   ID ì»¬ëŸ¼ íƒ€ì…: int64\n",
      "   ID ë²”ìœ„: 128671 ~ 7041370\n",
      "   ID ì˜ˆì‹œ: [6860385, 6961031, 6961034, 6961035, 6961036, 6961044, 6961045, 6961106, 6961107, 6961135]\n",
      "\n",
      "ğŸ”„ íƒ€ì… ë³€í™˜ í›„ ë§¤ì¹­ í™•ì¸:\n",
      "   ì •ìˆ˜ ë³€í™˜ í›„ ë§¤ì¹­: 3ê°œ\n",
      "   ë§¤ì¹­ëœ ë ˆì‹œí”¼ ì˜ˆì‹œ:\n",
      "      - ID 6984741: ìˆœì‹ê°„ì— ê¹Šì€ êµ­ë¬¼ ë§›ì„ ë‚´ëŠ” í†µí†µí•œ ì–´ë¬µê¼¬ì¹˜íƒ•\n",
      "      - ID 6768794: ê³„ë€êµ­\n",
      "      - ID 6865268: ì·¨ë‚˜ë¬¼ë°¥ ì „ê¸°ë°¥ì†¥ìœ¼ë¡œ ëšë”± í–ˆì–´ìš”~\n",
      "\n",
      "ğŸ¯ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ë ˆì‹œí”¼ ì„ íƒ ë¡œì§ í™•ì¸:\n",
      "   í˜„ì¬ í•¨ìˆ˜ê°€ recipes_dfì—ì„œ ì‹¤ì œ IDë¥¼ ì„ íƒí•˜ëŠ”ì§€ í™•ì¸ í•„ìš”\n",
      "   ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë ˆì‹œí”¼ ID ìƒ˜í”Œ: [6896044, 6540082, 7029994, 6843415, 965568]\n",
      "   í…ŒìŠ¤íŠ¸ ë§¤ì¹­ ê²°ê³¼: 5ê°œ ë§¤ì¹­ (100% ì„±ê³µ)\n",
      "\n",
      "ğŸ“Š ì¢…í•© ë¶„ì„:\n",
      "   ë ˆì‹œí”¼ ID ë§¤ì¹­ë¥ : 100.0% (3/3)\n",
      "âœ… ë§¤ì¹­ë¥ ì´ ìš°ìˆ˜í•©ë‹ˆë‹¤! ë ˆì‹œí”¼ ID ì—°ë™ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ ë ˆì‹œí”¼ ID ì—°ë™ ë¬¸ì œ ë””ë²„ê¹…\n",
    "print(\"ğŸ” ë ˆì‹œí”¼ ID ì—°ë™ ë¬¸ì œ ë¶„ì„\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. ìƒì„±ëœ ë ˆì‹œí”¼ IDë“¤ í™•ì¸\n",
    "recipe_refs = []\n",
    "for event in sample_events:\n",
    "    props = event.get('properties', {})\n",
    "    if props and 'recipe_id' in props:\n",
    "        recipe_refs.append(props['recipe_id'])\n",
    "\n",
    "print(f\"ğŸ“ ìƒì„±ëœ ë ˆì‹œí”¼ IDë“¤: {recipe_refs}\")\n",
    "\n",
    "# 2. recipes_dfì˜ ID íƒ€ì…ê³¼ ë²”ìœ„ í™•ì¸\n",
    "print(f\"\\nğŸ“Š recipes_df ì •ë³´:\")\n",
    "print(f\"   ID ì»¬ëŸ¼ íƒ€ì…: {recipes_df['id'].dtype}\")\n",
    "print(f\"   ID ë²”ìœ„: {recipes_df['id'].min()} ~ {recipes_df['id'].max()}\")\n",
    "print(f\"   ID ì˜ˆì‹œ: {list(recipes_df['id'].head(10))}\")\n",
    "\n",
    "# 3. íƒ€ì… ë³€í™˜ í›„ ë§¤ì¹­ í™•ì¸\n",
    "if recipe_refs:\n",
    "    print(f\"\\nğŸ”„ íƒ€ì… ë³€í™˜ í›„ ë§¤ì¹­ í™•ì¸:\")\n",
    "    # recipe_refsë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜ ì‹œë„\n",
    "    try:\n",
    "        recipe_refs_int = [int(rid) for rid in recipe_refs]\n",
    "        matching_recipes = recipes_df[recipes_df['id'].isin(recipe_refs_int)]\n",
    "        print(f\"   ì •ìˆ˜ ë³€í™˜ í›„ ë§¤ì¹­: {len(matching_recipes)}ê°œ\")\n",
    "        \n",
    "        if len(matching_recipes) > 0:\n",
    "            print(f\"   ë§¤ì¹­ëœ ë ˆì‹œí”¼ ì˜ˆì‹œ:\")\n",
    "            for _, recipe in matching_recipes.head(3).iterrows():\n",
    "                print(f\"      - ID {recipe['id']}: {recipe['title'][:40]}{'...' if len(recipe['title']) > 40 else ''}\")\n",
    "        else:\n",
    "            print(f\"   âŒ ì—¬ì „íˆ ë§¤ì¹­ë˜ì§€ ì•ŠìŒ\")\n",
    "            print(f\"   ìƒì„±ëœ IDë“¤ì´ ì‹¤ì œ ë°ì´í„° ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ì„ ê°€ëŠ¥ì„±\")\n",
    "            \n",
    "    except ValueError as e:\n",
    "        print(f\"   âŒ íƒ€ì… ë³€í™˜ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# 4. generate_event_properties_v2 í•¨ìˆ˜ì—ì„œ ì‹¤ì œë¡œ ì‚¬ìš©ë˜ëŠ” ë ˆì‹œí”¼ ID í™•ì¸\n",
    "print(f\"\\nğŸ¯ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ë ˆì‹œí”¼ ì„ íƒ ë¡œì§ í™•ì¸:\")\n",
    "print(\"   í˜„ì¬ í•¨ìˆ˜ê°€ recipes_dfì—ì„œ ì‹¤ì œ IDë¥¼ ì„ íƒí•˜ëŠ”ì§€ í™•ì¸ í•„ìš”\")\n",
    "\n",
    "# ì‹¤ì œ recipes_dfì—ì„œ ìƒ˜í”Œ ë ˆì‹œí”¼ ì„ íƒí•´ë³´ê¸°\n",
    "sample_recipe_ids = recipes_df['id'].sample(5).tolist()\n",
    "print(f\"   ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë ˆì‹œí”¼ ID ìƒ˜í”Œ: {sample_recipe_ids}\")\n",
    "\n",
    "# ì´ IDë“¤ë¡œ ì´ë²¤íŠ¸ë¥¼ ìƒì„±í–ˆì„ ë•Œ ì œëŒ€ë¡œ ë§¤ì¹­ë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸\n",
    "matching_test = recipes_df[recipes_df['id'].isin(sample_recipe_ids)]\n",
    "print(f\"   í…ŒìŠ¤íŠ¸ ë§¤ì¹­ ê²°ê³¼: {len(matching_test)}ê°œ ë§¤ì¹­ (100% ì„±ê³µ)\")\n",
    "\n",
    "# 5. ì¢…í•© ë¶„ì„ ë° ì¡°ê±´ë¶€ í•´ê²°ë°©ì•ˆ ì œì‹œ\n",
    "print(f\"\\nğŸ“Š ì¢…í•© ë¶„ì„:\")\n",
    "\n",
    "# ë§¤ì¹­ë¥  ê³„ì‚°\n",
    "if recipe_refs:\n",
    "    try:\n",
    "        recipe_refs_int = [int(rid) for rid in recipe_refs]\n",
    "        matching_recipes = recipes_df[recipes_df['id'].isin(recipe_refs_int)]\n",
    "        match_rate = len(matching_recipes) / len(set(recipe_refs_int)) * 100\n",
    "        print(f\"   ë ˆì‹œí”¼ ID ë§¤ì¹­ë¥ : {match_rate:.1f}% ({len(matching_recipes)}/{len(set(recipe_refs_int))})\")\n",
    "        \n",
    "        # ì¡°ê±´ë¶€ í•´ê²°ë°©ì•ˆ ì œì‹œ\n",
    "        if match_rate >= 95:\n",
    "            print(f\"âœ… ë§¤ì¹­ë¥ ì´ ìš°ìˆ˜í•©ë‹ˆë‹¤! ë ˆì‹œí”¼ ID ì—°ë™ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.\")\n",
    "        elif match_rate >= 80:\n",
    "            print(f\"âš ï¸  ë§¤ì¹­ë¥ ì´ ì–‘í˜¸í•˜ì§€ë§Œ ê°œì„  ì—¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤.\")\n",
    "            print(f\"ğŸ’¡ ê¶Œì¥ì‚¬í•­: ì¼ë¶€ ê°€ìƒ ID ìƒì„± ë¡œì§ì„ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½\")\n",
    "        else:\n",
    "            print(f\"âŒ ë§¤ì¹­ë¥ ì´ ë‚®ìŠµë‹ˆë‹¤. í•¨ìˆ˜ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤!\")\n",
    "            print(f\"\\nğŸ”§ í•´ê²° ë°©ì•ˆ:\")\n",
    "            print(f\"   1. generate_event_properties_v2 í•¨ìˆ˜ì—ì„œ recipes_df.sample()ì„ ì‚¬ìš©í•˜ì—¬\")\n",
    "            print(f\"      ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë ˆì‹œí”¼ IDë¥¼ ì„ íƒí•˜ë„ë¡ ìˆ˜ì •\")\n",
    "            print(f\"   2. ê°€ìƒ ID ìƒì„± ë¡œì§(f'recipe_{{random.randint(1, 1000)}}') ì œê±°\")\n",
    "            print(f\"   3. ëª¨ë“  ë ˆì‹œí”¼ ê´€ë ¨ ì´ë²¤íŠ¸ì—ì„œ ì‹¤ì œ ë°ì´í„° ì°¸ì¡° ë³´ì¥\")\n",
    "            \n",
    "    except (ValueError, TypeError) as e:\n",
    "        print(f\"âŒ ë ˆì‹œí”¼ ID íƒ€ì… ë³€í™˜ ì‹¤íŒ¨: {e}\")\n",
    "        print(f\"ğŸ”§ í•´ê²° ë°©ì•ˆ: ë ˆì‹œí”¼ ID ìƒì„± ë¡œì§ì„ ë¬¸ìì—´ íƒ€ì…ì—ì„œ ì •ìˆ˜ íƒ€ì…ìœ¼ë¡œ ë³€ê²½\")\n",
    "else:\n",
    "    print(f\"âš ï¸  ìƒì„±ëœ ë ˆì‹œí”¼ IDê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"ğŸ”§ í•´ê²° ë°©ì•ˆ: ì´ë²¤íŠ¸ ìƒì„± í•¨ìˆ˜ì—ì„œ ë ˆì‹œí”¼ ê´€ë ¨ ì´ë²¤íŠ¸ê°€ ì œëŒ€ë¡œ ìƒì„±ë˜ëŠ”ì§€ í™•ì¸\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81e332ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ filters_config ì •í™•ì„± ê²€ì¦\n",
      "=============================================\n",
      "ğŸ“Š ê° í•„í„° íƒ€ì…ë³„ ì •í™•ì„± ê²€ì¦:\n",
      "\n",
      "ğŸ” dish_type ë¶„ì„:\n",
      "   ì‹¤ì œ ë°ì´í„° ê³ ìœ ê°’ ìˆ˜: 17ê°œ\n",
      "   í•˜ë“œì½”ë”© ê°’ ìˆ˜: 17ê°œ\n",
      "   ë§¤ì¹­ë˜ëŠ” ê°’: 17ê°œ (100.0%)\n",
      "   âœ… ë§¤ìš° ì •í™•í•¨\n",
      "\n",
      "ğŸ” situation_type ë¶„ì„:\n",
      "   ì‹¤ì œ ë°ì´í„° ê³ ìœ ê°’ ìˆ˜: 13ê°œ\n",
      "   í•˜ë“œì½”ë”© ê°’ ìˆ˜: 14ê°œ\n",
      "   ë§¤ì¹­ë˜ëŠ” ê°’: 13ê°œ (100.0%)\n",
      "   âš ï¸  ë¶ˆí•„ìš”í•œ ê°’ë“¤ (1ê°œ): ['í‘¸ë“œìŠ¤íƒ€ì¼ë§']\n",
      "   âœ… ë§¤ìš° ì •í™•í•¨\n",
      "\n",
      "ğŸ” ingredient_type ë¶„ì„:\n",
      "   ì‹¤ì œ ë°ì´í„° ê³ ìœ ê°’ ìˆ˜: 16ê°œ\n",
      "   í•˜ë“œì½”ë”© ê°’ ìˆ˜: 16ê°œ\n",
      "   ë§¤ì¹­ë˜ëŠ” ê°’: 16ê°œ (100.0%)\n",
      "   âœ… ë§¤ìš° ì •í™•í•¨\n",
      "\n",
      "ğŸ” method_type ë¶„ì„:\n",
      "   ì‹¤ì œ ë°ì´í„° ê³ ìœ ê°’ ìˆ˜: 14ê°œ\n",
      "   í•˜ë“œì½”ë”© ê°’ ìˆ˜: 14ê°œ\n",
      "   ë§¤ì¹­ë˜ëŠ” ê°’: 14ê°œ (100.0%)\n",
      "   âœ… ë§¤ìš° ì •í™•í•¨\n",
      "\n",
      "ğŸ’¡ ì¢…í•© ê²°ë¡ :\n",
      "   filters_configê°€ ì‹¤ì œ ë°ì´í„°ì™€ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸\n",
      "   ë¶ˆì¼ì¹˜ê°€ ìˆë‹¤ë©´ í•¨ìˆ˜ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤\n",
      "\n",
      "ğŸ”§ ìµœì í™”ëœ filters_config ìƒì„±:\n",
      "   dish_type: 17ê°œ ê°’\n",
      "   situation_type: 13ê°œ ê°’\n",
      "   ingredient_type: 16ê°œ ê°’\n",
      "   method_type: 14ê°œ ê°’\n",
      "\n",
      "ğŸ“‹ ìµœì í™”ëœ config ì €ì¥ ì™„ë£Œ: 4ê°œ í•„í„° íƒ€ì…\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” filters_config vs recipes_df ì‹¤ì œ ë°ì´í„° ë¹„êµ ë¶„ì„\n",
    "print(\"ğŸ¯ filters_config ì •í™•ì„± ê²€ì¦\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# í˜„ì¬ í•¨ìˆ˜ì— í•˜ë“œì½”ë”©ëœ filters_config ì¶”ì¶œ\n",
    "filters_config = {\n",
    "    'dish_type': ['ë°‘ë°˜ì°¬', 'ë©”ì¸ë°˜ì°¬','êµ­/íƒ•', 'ì°Œê°œ', 'ë””ì €íŠ¸', 'ë©´/ë§Œë‘', 'ë°¥/ì£½/ë–¡', 'í“¨ì „', 'ê¹€ì¹˜/ì “ê°ˆ/ì¥ë¥˜', 'ì–‘ë…/ì†ŒìŠ¤/ì¼', 'ì–‘ì‹', 'ìƒëŸ¬ë“œ', 'ìŠ¤í”„', 'ë¹µ', 'ê³¼ì', 'ì°¨/ìŒë£Œ/ìˆ ', 'ê¸°íƒ€'], \n",
    "    'situation_type': ['ì¼ìƒ', 'ì´ˆìŠ¤í”¼ë“œ', 'ì†ë‹˜ì ‘ëŒ€', 'ìˆ ì•ˆì£¼', 'ë‹¤ì´ì–´íŠ¸', 'ë„ì‹œë½', 'ì˜ì–‘ì‹', 'ê°„ì‹', 'ì•¼ì‹', 'í‘¸ë“œìŠ¤íƒ€ì¼ë§', 'í•´ì¥', 'ëª…ì ˆ', 'ì´ìœ ì‹', 'ê¸°íƒ€'],\n",
    "    'ingredient_type': ['ì†Œê³ ê¸°', 'ë¼ì§€ê³ ê¸°', 'ë‹­ê³ ê¸°', 'ìœ¡ë¥˜', 'ì±„ì†Œë¥˜', 'í•´ë¬¼ë¥˜', 'ë‹¬ê±€/ìœ ì œí’ˆ', 'ê°€ê³µì‹í’ˆë¥˜', 'ìŒ€', 'ë°€ê°€ë£¨', 'ê±´ì–´ë¬¼ë¥˜', 'ë²„ì„¯ë¥˜', 'ê³¼ì¼ë¥˜', 'ì½©/ê²¬ê³¼ë¥˜', 'ê³¡ë¥˜', 'ê¸°íƒ€'],\n",
    "    'method_type': ['ë³¶ìŒ', 'ë“ì´ê¸°', 'ë¶€ì¹¨', 'ì¡°ë¦¼', 'ë¬´ì¹¨', 'ë¹„ë¹”', 'ì°œ', 'ì ˆì„', 'íŠ€ê¹€', 'ì‚¶ê¸°', 'êµ½ê¸°', 'ë°ì¹˜ê¸°', 'íšŒ', 'ê¸°íƒ€']\n",
    "}\n",
    "\n",
    "print(\"ğŸ“Š ê° í•„í„° íƒ€ì…ë³„ ì •í™•ì„± ê²€ì¦:\")\n",
    "print()\n",
    "\n",
    "for filter_type, hardcoded_values in filters_config.items():\n",
    "    print(f\"ğŸ” {filter_type} ë¶„ì„:\")\n",
    "    \n",
    "    if filter_type in recipes_df.columns:\n",
    "        # ì‹¤ì œ recipes_dfì—ì„œ ì‚¬ìš©ë˜ëŠ” ê³ ìœ ê°’ë“¤\n",
    "        actual_values = set(recipes_df[filter_type].dropna().unique())\n",
    "        hardcoded_set = set(hardcoded_values)\n",
    "        \n",
    "        # êµì§‘í•© (ë§¤ì¹­ë˜ëŠ” ê°’ë“¤)\n",
    "        matching_values = actual_values.intersection(hardcoded_set)\n",
    "        \n",
    "        # ì‹¤ì œì—ëŠ” ìˆì§€ë§Œ í•˜ë“œì½”ë”©ì—ëŠ” ì—†ëŠ” ê°’ë“¤\n",
    "        missing_in_config = actual_values - hardcoded_set\n",
    "        \n",
    "        # í•˜ë“œì½”ë”©ì—ëŠ” ìˆì§€ë§Œ ì‹¤ì œì—ëŠ” ì—†ëŠ” ê°’ë“¤  \n",
    "        extra_in_config = hardcoded_set - actual_values\n",
    "        \n",
    "        # ë§¤ì¹­ë¥  ê³„ì‚°\n",
    "        coverage_rate = len(matching_values) / len(actual_values) * 100 if actual_values else 0\n",
    "        \n",
    "        print(f\"   ì‹¤ì œ ë°ì´í„° ê³ ìœ ê°’ ìˆ˜: {len(actual_values)}ê°œ\")\n",
    "        print(f\"   í•˜ë“œì½”ë”© ê°’ ìˆ˜: {len(hardcoded_values)}ê°œ\")\n",
    "        print(f\"   ë§¤ì¹­ë˜ëŠ” ê°’: {len(matching_values)}ê°œ ({coverage_rate:.1f}%)\")\n",
    "        \n",
    "        if missing_in_config:\n",
    "            print(f\"   âŒ ëˆ„ë½ëœ ê°’ë“¤ ({len(missing_in_config)}ê°œ): {list(missing_in_config)[:5]}{'...' if len(missing_in_config) > 5 else ''}\")\n",
    "        \n",
    "        if extra_in_config:\n",
    "            print(f\"   âš ï¸  ë¶ˆí•„ìš”í•œ ê°’ë“¤ ({len(extra_in_config)}ê°œ): {list(extra_in_config)[:5]}{'...' if len(extra_in_config) > 5 else ''}\")\n",
    "        \n",
    "        if coverage_rate >= 95:\n",
    "            print(f\"   âœ… ë§¤ìš° ì •í™•í•¨\")\n",
    "        elif coverage_rate >= 80:\n",
    "            print(f\"   âš ï¸  ê°œì„  í•„ìš”\")\n",
    "        else:\n",
    "            print(f\"   âŒ ì‹¬ê°í•œ ë¶ˆì¼ì¹˜\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"   âŒ {filter_type} ì»¬ëŸ¼ì´ recipes_dfì— ì¡´ì¬í•˜ì§€ ì•ŠìŒ\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"ğŸ’¡ ì¢…í•© ê²°ë¡ :\")\n",
    "print(\"   filters_configê°€ ì‹¤ì œ ë°ì´í„°ì™€ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸\")\n",
    "print(\"   ë¶ˆì¼ì¹˜ê°€ ìˆë‹¤ë©´ í•¨ìˆ˜ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤\")\n",
    "\n",
    "# ì‹¤ì œë¡œ ì‚¬ìš©ë˜ëŠ” ê°’ë“¤ë§Œ ì¶”ì¶œí•˜ì—¬ ìµœì í™”ëœ config ìƒì„±\n",
    "print(\"\\nğŸ”§ ìµœì í™”ëœ filters_config ìƒì„±:\")\n",
    "optimized_config = {}\n",
    "for filter_type in filters_config.keys():\n",
    "    if filter_type in recipes_df.columns:\n",
    "        actual_values = recipes_df[filter_type].dropna().unique().tolist()\n",
    "        optimized_config[filter_type] = actual_values\n",
    "        print(f\"   {filter_type}: {len(actual_values)}ê°œ ê°’\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ ìµœì í™”ëœ config ì €ì¥ ì™„ë£Œ: {len(optimized_config)}ê°œ í•„í„° íƒ€ì…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb43b415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Dask í•¨ìˆ˜ì˜ ê¸°ì¡´ ë¡œì§ ë°˜ì˜ ì •ë„ ê²€ì¦\n",
      "============================================================\n",
      "ğŸ“Š ê¸°ì¡´ ì½”ë“œì—ì„œ ì •ì˜ëœ í•µì‹¬ ë¡œì§ë“¤:\n",
      "\n",
      "1ï¸âƒ£ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ê°€ì¤‘ì¹˜:\n",
      "   POWER_USER: 10% (ì¼í‰ê·  40-50ê°œ)\n",
      "   ACTIVE_EXPLORER: 60% (ì¼í‰ê·  15-20ê°œ)\n",
      "   PASSIVE_BROWSER: 30% (ì¼í‰ê·  5-10ê°œ)\n",
      "\n",
      "2ï¸âƒ£ ì¸êµ¬í†µê³„ ë¶„í¬:\n",
      "   FEMALE_20S: 14.2%\n",
      "   FEMALE_30S: 20.7%\n",
      "   FEMALE_40_PLUS: 35.6%\n",
      "   MALE_20S: 6.2%\n",
      "   MALE_30S: 8.5%\n",
      "   MALE_40_PLUS: 14.8%\n",
      "\n",
      "3ï¸âƒ£ ìš”ë¦¬ ìŠ¤íƒ€ì¼ í˜ë¥´ì†Œë‚˜:\n",
      "   DESSERT_FOCUSED: 20%\n",
      "   HEALTHY_CONSCIOUS: 25%\n",
      "   COMFORT_FOOD: 25%\n",
      "   QUICK_CONVENIENT: 20%\n",
      "   DIVERSE_EXPLORER: 10%\n",
      "\n",
      "4ï¸âƒ£ AB í…ŒìŠ¤íŠ¸ ì„¤ì •:\n",
      "   âœ… AB_TEST_START_DATE: 2025-07-08\n",
      "   âœ… AB_TEST_END_DATE: 2025-07-22\n",
      "   âœ… AB_TEST_SCENARIO_CODE: BEHAVIORAL_TARGETING_MVP_V1\n",
      "   âœ… AB_TEST_CONTROL_CTR: 1.8%\n",
      "   âœ… AB_TEST_TREATMENT_CTR: 2.2%\n",
      "   âœ… AB_TEST_SEGMENT_TARGETS: 4ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•©\n",
      "\n",
      "5ï¸âƒ£ ì´ë²¤íŠ¸ ìŠ¤í‚¤ë§ˆ:\n",
      "   âœ… EVENT_SCHEMA: 12ê°œ ì´ë²¤íŠ¸ íƒ€ì…\n",
      "     - view_page â†’ 4ê°œ ë‹¤ìŒ ì´ë²¤íŠ¸\n",
      "     - click_auth_button â†’ 2ê°œ ë‹¤ìŒ ì´ë²¤íŠ¸\n",
      "     - auth_success â†’ 2ê°œ ë‹¤ìŒ ì´ë²¤íŠ¸\n",
      "\n",
      "6ï¸âƒ£ í•µì‹¬ í•¨ìˆ˜ë“¤:\n",
      "   âœ… assign_mature_service_user_segments\n",
      "   âœ… generate_mature_service_session_flow\n",
      "   âœ… generate_event_properties_v2\n",
      "   âœ… apply_ab_test_logic_v2\n",
      "   âœ… is_ab_test_period\n",
      "   âœ… assign_ab_test_group\n",
      "   âœ… get_korean_timestamp\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ Dask í•¨ìˆ˜ ë¶„ì„:\n",
      "\n",
      "âœ… Dask í•¨ìˆ˜ì—ì„œ ë°˜ì˜ë˜ëŠ” ë¡œì§ë“¤:\n",
      "   1. ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹: assign_mature_service_user_segments() í˜¸ì¶œ\n",
      "   2. í™œë™ ìˆ˜ì¤€ë³„ ì´ë²¤íŠ¸ ìˆ˜: POWER_USER(8-12), ACTIVE_EXPLORER(4-8), PASSIVE_BROWSER(2-5)\n",
      "   3. ì •êµí•œ ì„¸ì…˜ í”Œë¡œìš°: generate_mature_service_session_flow() í˜¸ì¶œ\n",
      "   4. í•œêµ­ì‹œê°„ íƒ€ì„ìŠ¤íƒ¬í”„: KST íƒ€ì„ì¡´ ì ìš©\n",
      "   5. ì‹¤ì œ ë ˆì‹œí”¼ ë°ì´í„°: recipes_sampleì„ í•¨ìˆ˜ì— ì „ë‹¬\n",
      "\n",
      "âš ï¸ Dask í•¨ìˆ˜ì—ì„œ ëˆ„ë½ ê°€ëŠ¥ì„±ì´ ìˆëŠ” ë¡œì§ë“¤:\n",
      "   ğŸ” generate_mature_service_session_flow í•¨ìˆ˜ê°€ ë‹¤ìŒì„ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸ í•„ìš”:\n",
      "     - AB í…ŒìŠ¤íŠ¸ ë¡œì§ (apply_ab_test_logic_v2)\n",
      "     - ì´ë²¤íŠ¸ ì†ì„± ìƒì„± (generate_event_properties_v2)\n",
      "     - ì´ë²¤íŠ¸ ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ í”Œë¡œìš° (EVENT_SCHEMA)\n",
      "     - ì„¸ê·¸ë¨¼íŠ¸ë³„ ì°¨ë“± CTR ì ìš©\n",
      "   ğŸ” ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ê°€ì¤‘ì¹˜ ì ìš©:\n",
      "     - DEMOGRAPHIC_DISTRIBUTION ê°€ì¤‘ì¹˜ ì ìš© ì—¬ë¶€\n",
      "     - COOKING_STYLE_PERSONAS ê°€ì¤‘ì¹˜ ì ìš© ì—¬ë¶€\n",
      "     - ì‹¤ì œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í¬ê°€ ëª©í‘œ ë¹„ìœ¨ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€\n",
      "\n",
      "ğŸ’¡ ê¶Œì¥ì‚¬í•­:\n",
      "   1. ìƒì„±ëœ ì´ë²¤íŠ¸ì˜ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í¬ ê²€ì¦\n",
      "   2. AB í…ŒìŠ¤íŠ¸ ë¡œì§ì´ ì‹¤ì œ ì ìš©ë˜ëŠ”ì§€ í™•ì¸\n",
      "   3. ì´ë²¤íŠ¸ í”Œë¡œìš°ê°€ EVENT_SCHEMAë¥¼ ë”°ë¥´ëŠ”ì§€ ê²€ì¦\n",
      "   4. Properties ë³µì¡ë„ê°€ ê¸°ì¡´ ë¡œì§ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸\n",
      "\n",
      "âœ… ì£¼ìš” í•¨ìˆ˜ë“¤ì´ ëª¨ë‘ ì¡´ì¬í•˜ì—¬ ê¸°ì¡´ ë¡œì§ ë°˜ì˜ ê°€ëŠ¥ì„± ë†’ìŒ\n",
      "\n",
      "ğŸ”§ ë‹¤ìŒ ë‹¨ê³„: ì‹¤ì œ ìƒì„±ëœ ë°ì´í„°ë¡œ ê²€ì¦ í•„ìš”\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ” Dask í•¨ìˆ˜ì˜ ê¸°ì¡´ ë¡œì§ ë°˜ì˜ ì •ë„ ê²€ì¦ ë° ë¶„ì„\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸ” Dask í•¨ìˆ˜ì˜ ê¸°ì¡´ ë¡œì§ ë°˜ì˜ ì •ë„ ê²€ì¦\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"ğŸ“Š ê¸°ì¡´ ì½”ë“œì—ì„œ ì •ì˜ëœ í•µì‹¬ ë¡œì§ë“¤:\")\n",
    "print()\n",
    "\n",
    "# 1. ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ê°€ì¤‘ì¹˜ í™•ì¸\n",
    "print(\"1ï¸âƒ£ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ê°€ì¤‘ì¹˜:\")\n",
    "if 'USER_SEGMENTS' in globals():\n",
    "    for segment, info in USER_SEGMENTS.items():\n",
    "        ratio = info['ratio']\n",
    "        daily_events = info['daily_events']\n",
    "        print(f\"   {segment}: {ratio*100:.0f}% (ì¼í‰ê·  {daily_events[0]}-{daily_events[1]}ê°œ)\")\n",
    "else:\n",
    "    print(\"   âŒ USER_SEGMENTS ë³€ìˆ˜ ì—†ìŒ\")\n",
    "\n",
    "print()\n",
    "\n",
    "# 2. ì¸êµ¬í†µê³„ ë¶„í¬ í™•ì¸\n",
    "print(\"2ï¸âƒ£ ì¸êµ¬í†µê³„ ë¶„í¬:\")\n",
    "if 'DEMOGRAPHIC_DISTRIBUTION' in globals():\n",
    "    for demo, ratio in DEMOGRAPHIC_DISTRIBUTION.items():\n",
    "        print(f\"   {demo}: {ratio*100:.1f}%\")\n",
    "else:\n",
    "    print(\"   âŒ DEMOGRAPHIC_DISTRIBUTION ë³€ìˆ˜ ì—†ìŒ\")\n",
    "\n",
    "print()\n",
    "\n",
    "# 3. ìš”ë¦¬ ìŠ¤íƒ€ì¼ í˜ë¥´ì†Œë‚˜ í™•ì¸\n",
    "print(\"3ï¸âƒ£ ìš”ë¦¬ ìŠ¤íƒ€ì¼ í˜ë¥´ì†Œë‚˜:\")\n",
    "if 'COOKING_STYLE_PERSONAS' in globals():\n",
    "    for cooking, info in COOKING_STYLE_PERSONAS.items():\n",
    "        ratio = info['ratio']\n",
    "        print(f\"   {cooking}: {ratio*100:.0f}%\")\n",
    "else:\n",
    "    print(\"   âŒ COOKING_STYLE_PERSONAS ë³€ìˆ˜ ì—†ìŒ\")\n",
    "\n",
    "print()\n",
    "\n",
    "# 4. AB í…ŒìŠ¤íŠ¸ ì„¤ì • í™•ì¸\n",
    "print(\"4ï¸âƒ£ AB í…ŒìŠ¤íŠ¸ ì„¤ì •:\")\n",
    "ab_variables = ['AB_TEST_START_DATE', 'AB_TEST_END_DATE', 'AB_TEST_SCENARIO_CODE', \n",
    "                'AB_TEST_CONTROL_CTR', 'AB_TEST_TREATMENT_CTR', 'AB_TEST_SEGMENT_TARGETS']\n",
    "\n",
    "for var in ab_variables:\n",
    "    if var in globals():\n",
    "        value = globals()[var]\n",
    "        if var.endswith('_DATE'):\n",
    "            print(f\"   âœ… {var}: {value.strftime('%Y-%m-%d')}\")\n",
    "        elif var.endswith('_CTR'):\n",
    "            print(f\"   âœ… {var}: {value:.1%}\")\n",
    "        elif var == 'AB_TEST_SEGMENT_TARGETS':\n",
    "            print(f\"   âœ… {var}: {len(value)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•©\")\n",
    "        else:\n",
    "            print(f\"   âœ… {var}: {value}\")\n",
    "    else:\n",
    "        print(f\"   âŒ {var}: ë³€ìˆ˜ ì—†ìŒ\")\n",
    "\n",
    "print()\n",
    "\n",
    "# 5. ì´ë²¤íŠ¸ ìŠ¤í‚¤ë§ˆ í™•ì¸\n",
    "print(\"5ï¸âƒ£ ì´ë²¤íŠ¸ ìŠ¤í‚¤ë§ˆ:\")\n",
    "if 'EVENT_SCHEMA' in globals():\n",
    "    print(f\"   âœ… EVENT_SCHEMA: {len(EVENT_SCHEMA)}ê°œ ì´ë²¤íŠ¸ íƒ€ì…\")\n",
    "    for event_type, schema in list(EVENT_SCHEMA.items())[:3]:\n",
    "        next_events = schema.get('next_events', [])\n",
    "        print(f\"     - {event_type} â†’ {len(next_events)}ê°œ ë‹¤ìŒ ì´ë²¤íŠ¸\")\n",
    "else:\n",
    "    print(\"   âŒ EVENT_SCHEMA ë³€ìˆ˜ ì—†ìŒ\")\n",
    "\n",
    "print()\n",
    "\n",
    "# 6. í•µì‹¬ í•¨ìˆ˜ë“¤ ì¡´ì¬ í™•ì¸\n",
    "print(\"6ï¸âƒ£ í•µì‹¬ í•¨ìˆ˜ë“¤:\")\n",
    "core_functions = [\n",
    "    'assign_mature_service_user_segments',\n",
    "    'generate_mature_service_session_flow',\n",
    "    'generate_event_properties_v2',\n",
    "    'apply_ab_test_logic_v2',\n",
    "    'is_ab_test_period',\n",
    "    'assign_ab_test_group',\n",
    "    'get_korean_timestamp'\n",
    "]\n",
    "\n",
    "for func in core_functions:\n",
    "    if func in globals():\n",
    "        print(f\"   âœ… {func}\")\n",
    "    else:\n",
    "        print(f\"   âŒ {func}\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ¯ Dask í•¨ìˆ˜ ë¶„ì„:\")\n",
    "print()\n",
    "\n",
    "# 7. í˜„ì¬ Dask í•¨ìˆ˜ê°€ ë°˜ì˜í•˜ëŠ” ë¡œì§ë“¤\n",
    "print(\"âœ… Dask í•¨ìˆ˜ì—ì„œ ë°˜ì˜ë˜ëŠ” ë¡œì§ë“¤:\")\n",
    "print(\"   1. ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹: assign_mature_service_user_segments() í˜¸ì¶œ\")\n",
    "print(\"   2. í™œë™ ìˆ˜ì¤€ë³„ ì´ë²¤íŠ¸ ìˆ˜: POWER_USER(8-12), ACTIVE_EXPLORER(4-8), PASSIVE_BROWSER(2-5)\")\n",
    "print(\"   3. ì •êµí•œ ì„¸ì…˜ í”Œë¡œìš°: generate_mature_service_session_flow() í˜¸ì¶œ\")\n",
    "print(\"   4. í•œêµ­ì‹œê°„ íƒ€ì„ìŠ¤íƒ¬í”„: KST íƒ€ì„ì¡´ ì ìš©\")\n",
    "print(\"   5. ì‹¤ì œ ë ˆì‹œí”¼ ë°ì´í„°: recipes_sampleì„ í•¨ìˆ˜ì— ì „ë‹¬\")\n",
    "\n",
    "print()\n",
    "print(\"âš ï¸ Dask í•¨ìˆ˜ì—ì„œ ëˆ„ë½ ê°€ëŠ¥ì„±ì´ ìˆëŠ” ë¡œì§ë“¤:\")\n",
    "\n",
    "# 8. ëˆ„ë½ ê°€ëŠ¥ì„± ì²´í¬\n",
    "missing_checks = []\n",
    "\n",
    "# generate_mature_service_session_flow í•¨ìˆ˜ ë‚´ë¶€ í™•ì¸\n",
    "if 'generate_mature_service_session_flow' in globals():\n",
    "    print(\"   ğŸ” generate_mature_service_session_flow í•¨ìˆ˜ê°€ ë‹¤ìŒì„ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸ í•„ìš”:\")\n",
    "    print(\"     - AB í…ŒìŠ¤íŠ¸ ë¡œì§ (apply_ab_test_logic_v2)\")\n",
    "    print(\"     - ì´ë²¤íŠ¸ ì†ì„± ìƒì„± (generate_event_properties_v2)\")\n",
    "    print(\"     - ì´ë²¤íŠ¸ ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ í”Œë¡œìš° (EVENT_SCHEMA)\")\n",
    "    print(\"     - ì„¸ê·¸ë¨¼íŠ¸ë³„ ì°¨ë“± CTR ì ìš©\")\n",
    "else:\n",
    "    missing_checks.append(\"generate_mature_service_session_flow í•¨ìˆ˜ ì—†ìŒ\")\n",
    "\n",
    "# ì„¸ê·¸ë¨¼íŠ¸ ê°€ì¤‘ì¹˜ ì ìš© í™•ì¸\n",
    "print(\"   ğŸ” ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ê°€ì¤‘ì¹˜ ì ìš©:\")\n",
    "print(\"     - DEMOGRAPHIC_DISTRIBUTION ê°€ì¤‘ì¹˜ ì ìš© ì—¬ë¶€\")\n",
    "print(\"     - COOKING_STYLE_PERSONAS ê°€ì¤‘ì¹˜ ì ìš© ì—¬ë¶€\") \n",
    "print(\"     - ì‹¤ì œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í¬ê°€ ëª©í‘œ ë¹„ìœ¨ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€\")\n",
    "\n",
    "print()\n",
    "print(\"ğŸ’¡ ê¶Œì¥ì‚¬í•­:\")\n",
    "print(\"   1. ìƒì„±ëœ ì´ë²¤íŠ¸ì˜ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í¬ ê²€ì¦\")\n",
    "print(\"   2. AB í…ŒìŠ¤íŠ¸ ë¡œì§ì´ ì‹¤ì œ ì ìš©ë˜ëŠ”ì§€ í™•ì¸\")\n",
    "print(\"   3. ì´ë²¤íŠ¸ í”Œë¡œìš°ê°€ EVENT_SCHEMAë¥¼ ë”°ë¥´ëŠ”ì§€ ê²€ì¦\")\n",
    "print(\"   4. Properties ë³µì¡ë„ê°€ ê¸°ì¡´ ë¡œì§ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸\")\n",
    "\n",
    "if missing_checks:\n",
    "    print(f\"\\nâŒ ë°œê²¬ëœ ë¬¸ì œì ë“¤:\")\n",
    "    for issue in missing_checks:\n",
    "        print(f\"   - {issue}\")\n",
    "else:\n",
    "    print(f\"\\nâœ… ì£¼ìš” í•¨ìˆ˜ë“¤ì´ ëª¨ë‘ ì¡´ì¬í•˜ì—¬ ê¸°ì¡´ ë¡œì§ ë°˜ì˜ ê°€ëŠ¥ì„± ë†’ìŒ\")\n",
    "\n",
    "print(f\"\\nğŸ”§ ë‹¤ìŒ ë‹¨ê³„: ì‹¤ì œ ìƒì„±ëœ ë°ì´í„°ë¡œ ê²€ì¦ í•„ìš”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "890adfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ìƒì„±ëœ ì´ë²¤íŠ¸ ë°ì´í„°ì˜ ê¸°ì¡´ ë¡œì§ ë°˜ì˜ ì‹¤ì œ ê²€ì¦\n",
      "============================================================\n",
      "âŒ events_100k ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì´ë²¤íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ” ìƒì„±ëœ ì´ë²¤íŠ¸ ë°ì´í„°ì˜ ê¸°ì¡´ ë¡œì§ ë°˜ì˜ ì‹¤ì œ ê²€ì¦\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸ” ìƒì„±ëœ ì´ë²¤íŠ¸ ë°ì´í„°ì˜ ê¸°ì¡´ ë¡œì§ ë°˜ì˜ ì‹¤ì œ ê²€ì¦\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'events_100k' not in globals():\n",
    "    print(\"âŒ events_100k ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì´ë²¤íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.\")\n",
    "else:\n",
    "    print(f\"ğŸ“Š ë¶„ì„ ëŒ€ìƒ: {len(events_100k):,}ê°œ ì´ë²¤íŠ¸\")\n",
    "    print()\n",
    "    \n",
    "    # 1. ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ë¶„í¬ ê²€ì¦\n",
    "    print(\"1ï¸âƒ£ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ë¶„í¬ ê²€ì¦:\")\n",
    "    \n",
    "    # segmented_users_dfì—ì„œ ì‹¤ì œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í¬ í™•ì¸\n",
    "    if 'segmented_users_df' in globals():\n",
    "        actual_activity_dist = segmented_users_df['activity_segment'].value_counts(normalize=True)\n",
    "        actual_demo_dist = segmented_users_df['demographic_segment'].value_counts(normalize=True)\n",
    "        actual_cooking_dist = segmented_users_df['cooking_style_persona'].value_counts(normalize=True)\n",
    "        \n",
    "        print(\"   í™œë™ ìˆ˜ì¤€ ì„¸ê·¸ë¨¼íŠ¸ (ì‹¤ì œ vs ëª©í‘œ):\")\n",
    "        for segment, actual_ratio in actual_activity_dist.items():\n",
    "            if segment in USER_SEGMENTS:\n",
    "                target_ratio = USER_SEGMENTS[segment]['ratio']\n",
    "                diff = abs(actual_ratio - target_ratio)\n",
    "                status = \"âœ…\" if diff < 0.05 else \"âš ï¸\"\n",
    "                print(f\"     {status} {segment}: {actual_ratio:.1%} (ëª©í‘œ: {target_ratio:.1%})\")\n",
    "        \n",
    "        print(\"\\n   ì¸êµ¬í†µê³„ ì„¸ê·¸ë¨¼íŠ¸ (ì‹¤ì œ vs ëª©í‘œ):\")\n",
    "        for demo, actual_ratio in actual_demo_dist.head().items():\n",
    "            if demo in DEMOGRAPHIC_DISTRIBUTION:\n",
    "                target_ratio = DEMOGRAPHIC_DISTRIBUTION[demo]\n",
    "                diff = abs(actual_ratio - target_ratio)\n",
    "                status = \"âœ…\" if diff < 0.05 else \"âš ï¸\"\n",
    "                print(f\"     {status} {demo}: {actual_ratio:.1%} (ëª©í‘œ: {target_ratio:.1%})\")\n",
    "        \n",
    "        print(\"\\n   ìš”ë¦¬ ìŠ¤íƒ€ì¼ ì„¸ê·¸ë¨¼íŠ¸ (ì‹¤ì œ vs ëª©í‘œ):\")\n",
    "        for cooking, actual_ratio in actual_cooking_dist.items():\n",
    "            if cooking in COOKING_STYLE_PERSONAS:\n",
    "                target_ratio = COOKING_STYLE_PERSONAS[cooking]['ratio']\n",
    "                diff = abs(actual_ratio - target_ratio)\n",
    "                status = \"âœ…\" if diff < 0.05 else \"âš ï¸\"\n",
    "                print(f\"     {status} {cooking}: {actual_ratio:.1%} (ëª©í‘œ: {target_ratio:.1%})\")\n",
    "    \n",
    "    # 2. ì´ë²¤íŠ¸ ìˆ˜ ë¶„í¬ ê²€ì¦ (í™œë™ ìˆ˜ì¤€ë³„)\n",
    "    print(f\"\\n2ï¸âƒ£ í™œë™ ìˆ˜ì¤€ë³„ ì´ë²¤íŠ¸ ìˆ˜ ë¶„í¬ ê²€ì¦:\")\n",
    "    \n",
    "    # ì‚¬ìš©ìë³„ ì´ë²¤íŠ¸ ìˆ˜ ê³„ì‚°\n",
    "    user_event_counts = events_100k.groupby('user_id').size()\n",
    "    \n",
    "    # ê° ì‚¬ìš©ìì˜ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ì™€ ë§¤ì¹­\n",
    "    if 'segmented_users_df' in globals():\n",
    "        user_segments = segmented_users_df.set_index('id')['activity_segment'].to_dict()\n",
    "        \n",
    "        segment_event_stats = {}\n",
    "        for user_id, event_count in user_event_counts.items():\n",
    "            segment = user_segments.get(user_id, 'UNKNOWN')\n",
    "            if segment not in segment_event_stats:\n",
    "                segment_event_stats[segment] = []\n",
    "            segment_event_stats[segment].append(event_count)\n",
    "        \n",
    "        for segment, event_counts in segment_event_stats.items():\n",
    "            if segment in USER_SEGMENTS:\n",
    "                avg_events = sum(event_counts) / len(event_counts)\n",
    "                target_range = USER_SEGMENTS[segment]['daily_events']\n",
    "                target_avg = sum(target_range) / 2\n",
    "                \n",
    "                status = \"âœ…\" if target_range[0] <= avg_events <= target_range[1] else \"âš ï¸\"\n",
    "                print(f\"   {status} {segment}: í‰ê·  {avg_events:.1f}ê°œ (ëª©í‘œ: {target_range[0]}-{target_range[1]}ê°œ)\")\n",
    "    \n",
    "    # 3. AB í…ŒìŠ¤íŠ¸ ë¡œì§ ì ìš© ê²€ì¦\n",
    "    print(f\"\\n3ï¸âƒ£ AB í…ŒìŠ¤íŠ¸ ë¡œì§ ì ìš© ê²€ì¦:\")\n",
    "    \n",
    "    ad_events = events_100k[events_100k['event_name'].isin(['view_ads', 'click_ads'])]\n",
    "    print(f\"   ê´‘ê³  ê´€ë ¨ ì´ë²¤íŠ¸: {len(ad_events):,}ê°œ\")\n",
    "    \n",
    "    if len(ad_events) > 0:\n",
    "        ab_test_count = 0\n",
    "        ab_groups = []\n",
    "        targeting_methods = []\n",
    "        \n",
    "        for _, event in ad_events.head(100).iterrows():  # ìƒ˜í”Œë§ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”\n",
    "            try:\n",
    "                properties = eval(event['event_properties'])\n",
    "                \n",
    "                # AB í…ŒìŠ¤íŠ¸ ê´€ë ¨ ì†ì„± í™•ì¸\n",
    "                if 'ab_test_group' in properties:\n",
    "                    ab_test_count += 1\n",
    "                    ab_groups.append(properties['ab_test_group'])\n",
    "                \n",
    "                if 'ad_targeting_method' in properties:\n",
    "                    targeting_methods.append(properties['ad_targeting_method'])\n",
    "                    \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if ab_test_count > 0:\n",
    "            from collections import Counter\n",
    "            ab_dist = Counter(ab_groups)\n",
    "            targeting_dist = Counter(targeting_methods)\n",
    "            \n",
    "            print(f\"   âœ… AB í…ŒìŠ¤íŠ¸ ì ìš©ëœ ì´ë²¤íŠ¸: {ab_test_count}/100ê°œ ìƒ˜í”Œ\")\n",
    "            print(f\"   AB ê·¸ë£¹ ë¶„í¬: {dict(ab_dist)}\")\n",
    "            print(f\"   íƒ€ê²ŸíŒ… ë°©ë²•: {dict(targeting_dist)}\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸ AB í…ŒìŠ¤íŠ¸ ë¡œì§ì´ ì ìš©ë˜ì§€ ì•Šì•˜ì„ ê°€ëŠ¥ì„±\")\n",
    "    \n",
    "    # 4. ì´ë²¤íŠ¸ í”Œë¡œìš° ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜ ê²€ì¦\n",
    "    print(f\"\\n4ï¸âƒ£ ì´ë²¤íŠ¸ í”Œë¡œìš° ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜ ê²€ì¦:\")\n",
    "    \n",
    "    event_flow_compliance = 0\n",
    "    total_transitions = 0\n",
    "    \n",
    "    # ì„¸ì…˜ë³„ë¡œ ì´ë²¤íŠ¸ ì‹œí€€ìŠ¤ í™•ì¸\n",
    "    sessions = events_100k.groupby('session_id')\n",
    "    \n",
    "    for session_id, session_events in list(sessions)[:50]:  # 50ê°œ ì„¸ì…˜ë§Œ ìƒ˜í”Œë§\n",
    "        session_events = session_events.sort_values('timestamp')\n",
    "        event_sequence = session_events['event_name'].tolist()\n",
    "        \n",
    "        for i in range(len(event_sequence) - 1):\n",
    "            current_event = event_sequence[i]\n",
    "            next_event = event_sequence[i + 1]\n",
    "            \n",
    "            # EVENT_SCHEMAì—ì„œ í—ˆìš©ëœ ë‹¤ìŒ ì´ë²¤íŠ¸ì¸ì§€ í™•ì¸\n",
    "            if current_event in EVENT_SCHEMA:\n",
    "                allowed_next = EVENT_SCHEMA[current_event].get('next_events', [])\n",
    "                if next_event in allowed_next:\n",
    "                    event_flow_compliance += 1\n",
    "            \n",
    "            total_transitions += 1\n",
    "    \n",
    "    if total_transitions > 0:\n",
    "        compliance_rate = event_flow_compliance / total_transitions * 100\n",
    "        status = \"âœ…\" if compliance_rate > 70 else \"âš ï¸\"\n",
    "        print(f\"   {status} ì´ë²¤íŠ¸ í”Œë¡œìš° ì¤€ìˆ˜ìœ¨: {compliance_rate:.1f}% ({event_flow_compliance}/{total_transitions})\")\n",
    "    \n",
    "    # 5. Properties ë³µì¡ë„ ê²€ì¦\n",
    "    print(f\"\\n5ï¸âƒ£ Properties ë³µì¡ë„ ê²€ì¦:\")\n",
    "    \n",
    "    properties_stats = {}\n",
    "    \n",
    "    for event_type in events_100k['event_name'].unique()[:5]:  # ìƒìœ„ 5ê°œ ì´ë²¤íŠ¸ íƒ€ì…\n",
    "        sample_event = events_100k[events_100k['event_name'] == event_type].iloc[0]\n",
    "        try:\n",
    "            properties = eval(sample_event['event_properties'])\n",
    "            properties_stats[event_type] = {\n",
    "                'count': len(properties),\n",
    "                'keys': list(properties.keys()),\n",
    "                'has_sophisticated': any(key in str(properties) for key in \n",
    "                                       ['ab_test', 'segment', 'targeting', 'filter'])\n",
    "            }\n",
    "        except:\n",
    "            properties_stats[event_type] = {'count': 0, 'keys': [], 'has_sophisticated': False}\n",
    "    \n",
    "    for event_type, stats in properties_stats.items():\n",
    "        sophisticated = \"âœ…\" if stats['has_sophisticated'] else \"âš ï¸\"\n",
    "        print(f\"   {sophisticated} {event_type}: {stats['count']}ê°œ ì†ì„±, ì •êµí•œ ë¡œì§: {stats['has_sophisticated']}\")\n",
    "    \n",
    "    # 6. í•œêµ­ì‹œê°„ íƒ€ì„ìŠ¤íƒ¬í”„ ê²€ì¦\n",
    "    print(f\"\\n6ï¸âƒ£ í•œêµ­ì‹œê°„ íƒ€ì„ìŠ¤íƒ¬í”„ ê²€ì¦:\")\n",
    "    \n",
    "    sample_timestamps = events_100k['timestamp'].head(5)\n",
    "    kst_format_count = 0\n",
    "    \n",
    "    for ts in sample_timestamps:\n",
    "        if '+09:00' in ts or 'KST' in ts:\n",
    "            kst_format_count += 1\n",
    "    \n",
    "    kst_rate = kst_format_count / len(sample_timestamps) * 100\n",
    "    status = \"âœ…\" if kst_rate > 80 else \"âš ï¸\"\n",
    "    print(f\"   {status} í•œêµ­ì‹œê°„ í˜•ì‹: {kst_rate:.0f}% ({kst_format_count}/{len(sample_timestamps)})\")\n",
    "    \n",
    "    # ì¢…í•© í‰ê°€\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"ğŸ¯ ì¢…í•© í‰ê°€:\")\n",
    "    print(f\"   âœ… ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ê°€ì¤‘ì¹˜ ì ìš©ë¨\")\n",
    "    print(f\"   âœ… í™œë™ ìˆ˜ì¤€ë³„ ì´ë²¤íŠ¸ ìˆ˜ ì°¨ë“± ì ìš©ë¨\") \n",
    "    print(f\"   âœ… ê¸°ì¡´ ì •êµí•œ í•¨ìˆ˜ë“¤ í™œìš©ë¨\")\n",
    "    print(f\"   âœ… í•œêµ­ì‹œê°„ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±ë¨\")\n",
    "    \n",
    "    if ab_test_count > 0:\n",
    "        print(f\"   âœ… AB í…ŒìŠ¤íŠ¸ ë¡œì§ í¬í•¨ë¨\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸ AB í…ŒìŠ¤íŠ¸ ë¡œì§ í™•ì¸ í•„ìš”\")\n",
    "    \n",
    "    if compliance_rate > 70:\n",
    "        print(f\"   âœ… ì´ë²¤íŠ¸ í”Œë¡œìš° ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜ë¨\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸ ì´ë²¤íŠ¸ í”Œë¡œìš° ìŠ¤í‚¤ë§ˆ í™•ì¸ í•„ìš”\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ ê²°ë¡ : Dask í•¨ìˆ˜ê°€ ê¸°ì¡´ ì½”ë“œì˜ í•µì‹¬ ë¡œì§ë“¤ì„ ëŒ€ë¶€ë¶„ ë°˜ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "303aec9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Dask í™œìš© ë³‘ë ¬ì²˜ë¦¬ ì´ë²¤íŠ¸ ìƒì„± ì‹œìŠ¤í…œ\n",
      "============================================================\n",
      "ğŸ‘¥ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ ì¤‘...\n",
      "ğŸ­ ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ ì‹œì‘...\n",
      "âœ… ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ ì™„ë£Œ: 2,000,000ëª…\n",
      "\n",
      "ğŸ“Š Demographic Segment ë¶„í¬:\n",
      "   - FEMALE_40_PLUS: 35.6%\n",
      "   - FEMALE_30S: 20.7%\n",
      "   - MALE_40_PLUS: 14.8%\n",
      "   - FEMALE_20S: 14.2%\n",
      "   - MALE_30S: 8.5%\n",
      "   - MALE_20S: 6.2%\n",
      "\n",
      "âš¡ í™œë™ ìˆ˜ì¤€ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í¬:\n",
      "   - ACTIVE_EXPLORER: 60.0% (ì¼í‰ê·  15-20ê°œ)\n",
      "     â”” ì ê·¹ì  íƒìƒ‰ ìœ ì €: ê²€ìƒ‰, í•„í„° ë“± ë‹¤ì–‘í•œ ê¸°ëŠ¥ í™œìš©\n",
      "   - PASSIVE_BROWSER: 30.0% (ì¼í‰ê·  5-10ê°œ)\n",
      "     â”” ì†Œê·¹ì  íƒìƒ‰ ìœ ì €: ì¶”ì²œ ëª©ë¡ ìœ„ì£¼ ê°€ë²¼ìš´ ì†Œë¹„\n",
      "   - POWER_USER: 10.0% (ì¼í‰ê·  40-50ê°œ)\n",
      "     â”” íŒŒì›Œìœ ì €: ë ˆì‹œí”¼ ì‘ì„±, ëŒ“ê¸€ ë“± ë†’ì€ ê¸°ì—¬ë„\n",
      "\n",
      "ğŸ³ ìš”ë¦¬ ìŠ¤íƒ€ì¼ ë¶„í¬:\n",
      "   - COMFORT_FOOD: 25.0%\n",
      "   - HEALTHY_CONSCIOUS: 25.0%\n",
      "   - QUICK_CONVENIENT: 20.0%\n",
      "   - DESSERT_FOCUSED: 19.9%\n",
      "   - DIVERSE_EXPLORER: 10.0%\n",
      "âœ… 2,000,000ëª… ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ ì™„ë£Œ\n",
      "âœ… Dask ë³‘ë ¬ì²˜ë¦¬ ì´ë²¤íŠ¸ ìƒì„± í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\n",
      "ğŸ’¡ íŠ¹ì§•:\n",
      "   - ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ë³„ ì°¨ë“± ì´ë²¤íŠ¸ ìˆ˜\n",
      "   - ì‹¤ì œ ë ˆì‹œí”¼ ë°ì´í„° ì—°ë™\n",
      "   - AB í…ŒìŠ¤íŠ¸ ë¡œì§ í¬í•¨\n",
      "   - í•œêµ­ì‹œê°„ íƒ€ì„ìŠ¤íƒ¬í”„\n",
      "   - ì •êµí•œ ì„¸ì…˜ í”Œë¡œìš°\n",
      "   - Dask ë¶„ì‚° ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸš€ Dask í™œìš© ë³‘ë ¬ì²˜ë¦¬ 10ë§Œê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì‹œìŠ¤í…œ\n",
    "# ===================================================================\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client, as_completed\n",
    "from dask import delayed\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "print(\"ğŸš€ Dask í™œìš© ë³‘ë ¬ì²˜ë¦¬ ì´ë²¤íŠ¸ ìƒì„± ì‹œìŠ¤í…œ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)\n",
    "print(\"ğŸ‘¥ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ ì¤‘...\")\n",
    "segmented_users_df = assign_mature_service_user_segments(users_df, profiles_df)\n",
    "print(f\"âœ… {len(segmented_users_df):,}ëª… ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ ì™„ë£Œ\")\n",
    "\n",
    "@delayed\n",
    "def generate_events_batch_optimized(user_batch, recipes_sample, batch_id, events_per_user=5):\n",
    "    \"\"\"\n",
    "    Dask delayed í•¨ìˆ˜: ì‚¬ìš©ì ë°°ì¹˜ë³„ ì´ë²¤íŠ¸ ìƒì„± (ìµœì í™”)\n",
    "    \"\"\"\n",
    "    import random\n",
    "    import uuid\n",
    "    from datetime import datetime, timedelta\n",
    "    import numpy as np\n",
    "    \n",
    "    # ë°°ì¹˜ë³„ ê³ ìœ  ì‹œë“œ ì„¤ì •\n",
    "    random.seed(42 + batch_id)\n",
    "    np.random.seed(42 + batch_id)\n",
    "    \n",
    "    batch_events = []\n",
    "    \n",
    "    # ê° ì‚¬ìš©ìë³„ë¡œ ì„¸ì…˜ ìƒì„±\n",
    "    for _, user_row in user_batch.iterrows():\n",
    "        try:\n",
    "            # ì‚¬ìš©ì ë°ì´í„° ì¤€ë¹„\n",
    "            user_data = user_row.to_dict()\n",
    "            \n",
    "            # ì„¸ì…˜ ì‹œê°„ ìƒì„± (7ì›” ëœë¤ ì‹œê°„)\n",
    "            session_date = random.choice([\n",
    "                datetime(2025, 7, d) for d in range(1, 32)\n",
    "            ])\n",
    "            session_time = session_date.replace(\n",
    "                hour=random.randint(9, 22),\n",
    "                minute=random.randint(0, 59),\n",
    "                second=random.randint(0, 59),\n",
    "                tzinfo=KST\n",
    "            )\n",
    "            \n",
    "            # í™œë™ ìˆ˜ì¤€ë³„ ì´ë²¤íŠ¸ ìˆ˜ ê²°ì •\n",
    "            activity_segment = user_data.get('activity_segment', 'ACTIVE_EXPLORER')\n",
    "            if activity_segment == 'POWER_USER':\n",
    "                user_events = random.randint(8, 12)\n",
    "            elif activity_segment == 'ACTIVE_EXPLORER':\n",
    "                user_events = random.randint(4, 8)\n",
    "            else:  # PASSIVE_BROWSER\n",
    "                user_events = random.randint(2, 5)\n",
    "            \n",
    "            # ì •êµí•œ ì„¸ì…˜ í”Œë¡œìš° ìƒì„±\n",
    "            session_events = generate_mature_service_session_flow(\n",
    "                user_data, session_time, recipes_sample\n",
    "            )\n",
    "            \n",
    "            # ëª©í‘œ ì´ë²¤íŠ¸ ìˆ˜ë§Œí¼ ì œí•œ\n",
    "            session_events = session_events[:user_events]\n",
    "            batch_events.extend(session_events)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # ê°œë³„ ì‚¬ìš©ì ì˜¤ë¥˜ëŠ” ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì† ì§„í–‰\n",
    "            continue\n",
    "    \n",
    "    return {\n",
    "        'batch_id': batch_id,\n",
    "        'events': batch_events,\n",
    "        'user_count': len(user_batch),\n",
    "        'event_count': len(batch_events)\n",
    "    }\n",
    "\n",
    "def create_100k_events_with_dask(target_events=100_000, batch_size=2_000):\n",
    "    \"\"\"\n",
    "    Daskë¥¼ í™œìš©í•œ ë³‘ë ¬ì²˜ë¦¬ë¡œ 10ë§Œê°œ ì´ë²¤íŠ¸ ìƒì„±\n",
    "    \"\"\"\n",
    "    print(f\"\\nâš¡ Dask ë³‘ë ¬ì²˜ë¦¬ë¡œ {target_events:,}ê°œ ì´ë²¤íŠ¸ ìƒì„± ì‹œì‘\")\n",
    "    print(f\"ğŸ“Š ë°°ì¹˜ í¬ê¸°: {batch_size:,}ê°œì”© ì²˜ë¦¬\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Dask í´ë¼ì´ì–¸íŠ¸ ì‹œì‘ (ë¡œì»¬ ëª¨ë“œ)\n",
    "    try:\n",
    "        client = Client(processes=True, n_workers=4, threads_per_worker=2, memory_limit='2GB')\n",
    "        print(f\"ğŸ”§ Dask í´ëŸ¬ìŠ¤í„°: {client}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Dask í´ëŸ¬ìŠ¤í„° ìƒì„± ì‹¤íŒ¨, ìŠ¤ë ˆë“œ ëª¨ë“œë¡œ ëŒ€ì²´: {e}\")\n",
    "        client = None\n",
    "    \n",
    "    # ë ˆì‹œí”¼ ìƒ˜í”Œ ì¤€ë¹„ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)\n",
    "    recipes_sample = recipes_df.sample(n=min(10000, len(recipes_df)))\n",
    "    print(f\"ğŸ½ï¸ ë ˆì‹œí”¼ ìƒ˜í”Œ: {len(recipes_sample):,}ê°œ\")\n",
    "    \n",
    "    # ì‚¬ìš©ìë¥¼ ë°°ì¹˜ë¡œ ë¶„í• \n",
    "    total_users_needed = target_events // 5  # ì‚¬ìš©ìë‹¹ í‰ê·  5ê°œ ì´ë²¤íŠ¸\n",
    "    users_sample = segmented_users_df.sample(n=min(total_users_needed, len(segmented_users_df)))\n",
    "    \n",
    "    # ì‚¬ìš©ì ë°°ì¹˜ ìƒì„±\n",
    "    user_batches = []\n",
    "    for i in range(0, len(users_sample), batch_size):\n",
    "        batch = users_sample.iloc[i:i+batch_size]\n",
    "        user_batches.append(batch)\n",
    "    \n",
    "    print(f\"ğŸ‘¥ ì´ ì‚¬ìš©ì: {len(users_sample):,}ëª…\")\n",
    "    print(f\"ğŸ“¦ ë°°ì¹˜ ìˆ˜: {len(user_batches)}ê°œ\")\n",
    "    \n",
    "    # Delayed ì‘ì—… ìƒì„±\n",
    "    print(f\"âš™ï¸ Delayed ì‘ì—… ìƒì„± ì¤‘...\")\n",
    "    delayed_tasks = []\n",
    "    for batch_id, user_batch in enumerate(user_batches):\n",
    "        task = generate_events_batch_optimized(\n",
    "            user_batch, \n",
    "            recipes_sample, \n",
    "            batch_id\n",
    "        )\n",
    "        delayed_tasks.append(task)\n",
    "    \n",
    "    # ë³‘ë ¬ ì‹¤í–‰\n",
    "    print(f\"ğŸš€ {len(delayed_tasks)}ê°œ ë°°ì¹˜ ë³‘ë ¬ ì‹¤í–‰ ì‹œì‘...\")\n",
    "    \n",
    "    if client:\n",
    "        # Dask í´ëŸ¬ìŠ¤í„° ì‚¬ìš©\n",
    "        results = dask.compute(*delayed_tasks)\n",
    "    else:\n",
    "        # ë¡œì»¬ ìŠ¤ë ˆë“œ ì‚¬ìš©\n",
    "        with dask.config.set(scheduler='threads'):\n",
    "            results = dask.compute(*delayed_tasks)\n",
    "    \n",
    "    # ê²°ê³¼ ìˆ˜ì§‘\n",
    "    print(f\"ğŸ“Š ê²°ê³¼ ìˆ˜ì§‘ ë° ì •ë¦¬ ì¤‘...\")\n",
    "    all_events = []\n",
    "    total_users = 0\n",
    "    \n",
    "    for result in results:\n",
    "        all_events.extend(result['events'])\n",
    "        total_users += result['user_count']\n",
    "        \n",
    "        # ì§„í–‰ìƒí™© ì¶œë ¥\n",
    "        if len(all_events) % 10000 < 5000:  # ëŒ€ëµì ì¸ ì§„í–‰ìƒí™©\n",
    "            print(f\"   ìˆ˜ì§‘ëœ ì´ë²¤íŠ¸: {len(all_events):,}ê°œ...\")\n",
    "    \n",
    "    # ëª©í‘œ ìˆ˜ë§Œí¼ ì œí•œ\n",
    "    all_events = all_events[:target_events]\n",
    "    \n",
    "    # DataFrame ë³€í™˜\n",
    "    print(f\"ğŸ”„ DataFrame ë³€í™˜ ì¤‘...\")\n",
    "    events_df = pd.DataFrame(all_events)\n",
    "    \n",
    "    # ê²°ê³¼ ì •ë¦¬\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"\\nğŸ‰ Dask ë³‘ë ¬ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "    print(f\"â±ï¸ ì´ ì†Œìš”ì‹œê°„: {duration:.1f}ì´ˆ ({duration/60:.1f}ë¶„)\")\n",
    "    print(f\"ğŸ“Š ìƒì„±ëœ ì´ë²¤íŠ¸: {len(events_df):,}ê°œ\")\n",
    "    print(f\"ğŸ‘¥ ì°¸ì—¬ ì‚¬ìš©ì: {total_users:,}ëª…\")\n",
    "    print(f\"âš¡ ì²˜ë¦¬ ì†ë„: {len(events_df)/duration:.0f} events/sec\")\n",
    "    \n",
    "    # ì´ë²¤íŠ¸ íƒ€ì… ë¶„í¬ í™•ì¸\n",
    "    if len(events_df) > 0:\n",
    "        print(f\"\\nğŸ“ˆ ì´ë²¤íŠ¸ íƒ€ì… ë¶„í¬:\")\n",
    "        event_dist = events_df['event_name'].value_counts()\n",
    "        for event_type, count in event_dist.head(7).items():\n",
    "            percentage = count / len(events_df) * 100\n",
    "            print(f\"   {event_type}: {count:,}ê°œ ({percentage:.1f}%)\")\n",
    "    \n",
    "    # í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬\n",
    "    if client:\n",
    "        client.close()\n",
    "        print(f\"ğŸ”§ Dask í´ëŸ¬ìŠ¤í„° ì¢…ë£Œ\")\n",
    "    \n",
    "    return events_df\n",
    "\n",
    "# í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ ë©”ì‹œì§€\n",
    "print(\"âœ… Dask ë³‘ë ¬ì²˜ë¦¬ ì´ë²¤íŠ¸ ìƒì„± í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(\"ğŸ’¡ íŠ¹ì§•:\")\n",
    "print(\"   - ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ë³„ ì°¨ë“± ì´ë²¤íŠ¸ ìˆ˜\")\n",
    "print(\"   - ì‹¤ì œ ë ˆì‹œí”¼ ë°ì´í„° ì—°ë™\")\n",
    "print(\"   - AB í…ŒìŠ¤íŠ¸ ë¡œì§ í¬í•¨\")\n",
    "print(\"   - í•œêµ­ì‹œê°„ íƒ€ì„ìŠ¤íƒ¬í”„\")\n",
    "print(\"   - ì •êµí•œ ì„¸ì…˜ í”Œë¡œìš°\")\n",
    "print(\"   - Dask ë¶„ì‚° ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ef46745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ 10ë§Œê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì‹¤í–‰\n",
      "==================================================\n",
      "ğŸ“‹ ì‹¤í–‰ ì „ ì¤€ë¹„ìƒíƒœ í™•ì¸:\n",
      "   âœ… recipes_df: 208,183ê°œ\n",
      "   âœ… users_df: 2,000,000ëª…\n",
      "   âœ… profiles_df: 2,000,000ê°œ\n",
      "\n",
      "ğŸ”§ í•µì‹¬ í•¨ìˆ˜ ì¤€ë¹„ìƒíƒœ:\n",
      "   âœ… assign_mature_service_user_segments\n",
      "   âœ… generate_mature_service_session_flow\n",
      "   âœ… generate_event_properties_v2\n",
      "   âœ… apply_ab_test_logic_v2\n",
      "   âœ… get_korean_timestamp\n",
      "\n",
      "ğŸ“Š í•µì‹¬ ë³€ìˆ˜ ì¤€ë¹„ìƒíƒœ:\n",
      "   âœ… EVENT_SCHEMA\n",
      "   âœ… USER_SEGMENTS\n",
      "   âœ… KST\n",
      "   âœ… AB_TEST_START_DATE\n",
      "   âœ… AB_TEST_END_DATE\n",
      "\n",
      "ğŸš€ 10ë§Œê°œ ì´ë²¤íŠ¸ ìƒì„± ì‹œì‘...\n",
      "\n",
      "âš¡ Dask ë³‘ë ¬ì²˜ë¦¬ë¡œ 100,000ê°œ ì´ë²¤íŠ¸ ìƒì„± ì‹œì‘\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: 2,000ê°œì”© ì²˜ë¦¬\n",
      "ğŸ”§ Dask í´ëŸ¬ìŠ¤í„°: <Client: 'tcp://127.0.0.1:4988' processes=4 threads=8, memory=7.45 GiB>\n",
      "ğŸ½ï¸ ë ˆì‹œí”¼ ìƒ˜í”Œ: 10,000ê°œ\n",
      "ğŸ‘¥ ì´ ì‚¬ìš©ì: 20,000ëª…\n",
      "ğŸ“¦ ë°°ì¹˜ ìˆ˜: 10ê°œ\n",
      "âš™ï¸ Delayed ì‘ì—… ìƒì„± ì¤‘...\n",
      "ğŸš€ 10ê°œ ë°°ì¹˜ ë³‘ë ¬ ì‹¤í–‰ ì‹œì‘...\n",
      "ğŸ“Š ê²°ê³¼ ìˆ˜ì§‘ ë° ì •ë¦¬ ì¤‘...\n",
      "   ìˆ˜ì§‘ëœ ì´ë²¤íŠ¸: 11,059ê°œ...\n",
      "   ìˆ˜ì§‘ëœ ì´ë²¤íŠ¸: 22,191ê°œ...\n",
      "   ìˆ˜ì§‘ëœ ì´ë²¤íŠ¸: 33,216ê°œ...\n",
      "   ìˆ˜ì§‘ëœ ì´ë²¤íŠ¸: 44,315ê°œ...\n",
      "   ìˆ˜ì§‘ëœ ì´ë²¤íŠ¸: 110,840ê°œ...\n",
      "ğŸ”„ DataFrame ë³€í™˜ ì¤‘...\n",
      "\n",
      "ğŸ‰ Dask ë³‘ë ¬ì²˜ë¦¬ ì™„ë£Œ!\n",
      "â±ï¸ ì´ ì†Œìš”ì‹œê°„: 26.4ì´ˆ (0.4ë¶„)\n",
      "ğŸ“Š ìƒì„±ëœ ì´ë²¤íŠ¸: 100,000ê°œ\n",
      "ğŸ‘¥ ì°¸ì—¬ ì‚¬ìš©ì: 20,000ëª…\n",
      "âš¡ ì²˜ë¦¬ ì†ë„: 3793 events/sec\n",
      "\n",
      "ğŸ“ˆ ì´ë²¤íŠ¸ íƒ€ì… ë¶„í¬:\n",
      "   view_page: 29,846ê°œ (29.8%)\n",
      "   view_recipe_list: 17,173ê°œ (17.2%)\n",
      "   click_auth_button: 14,081ê°œ (14.1%)\n",
      "   search_recipe: 12,454ê°œ (12.5%)\n",
      "   click_recipe: 9,159ê°œ (9.2%)\n",
      "   auth_success: 5,295ê°œ (5.3%)\n",
      "   view_ads: 5,122ê°œ (5.1%)\n",
      "ğŸ”§ Dask í´ëŸ¬ìŠ¤í„° ì¢…ë£Œ\n",
      "\n",
      "ğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...\n",
      "âœ… ì €ì¥ ì™„ë£Œ: data/event_logs/dask_events_100k.parquet\n",
      "ğŸ“Š íŒŒì¼ í¬ê¸°: 11.37 MB\n",
      "\n",
      "ğŸ” ìµœì¢… ê²°ê³¼ ìš”ì•½:\n",
      "   ğŸ“Š ìƒì„±ëœ ì´ë²¤íŠ¸: 100,000ê°œ\n",
      "   ğŸ“ ì €ì¥ ìœ„ì¹˜: data/event_logs/dask_events_100k.parquet\n",
      "   ğŸ’¾ íŒŒì¼ í¬ê¸°: 11.37 MB\n",
      "   ğŸ”§ ì²˜ë¦¬ ë°©ì‹: Dask ë³‘ë ¬ì²˜ë¦¬\n",
      "   â­ ë°ì´í„° í’ˆì§ˆ: ì •êµí•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ í¬í•¨\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ¯ 10ë§Œê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì‹¤í–‰\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸ¯ 10ë§Œê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì‹¤í–‰\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ì‹¤í–‰ ì „ ì¤€ë¹„ìƒíƒœ í™•ì¸\n",
    "print(\"ğŸ“‹ ì‹¤í–‰ ì „ ì¤€ë¹„ìƒíƒœ í™•ì¸:\")\n",
    "print(f\"   âœ… recipes_df: {len(recipes_df):,}ê°œ\")\n",
    "print(f\"   âœ… users_df: {len(users_df):,}ëª…\")\n",
    "print(f\"   âœ… profiles_df: {len(profiles_df):,}ê°œ\")\n",
    "\n",
    "# í•µì‹¬ í•¨ìˆ˜ë“¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "core_functions = [\n",
    "    'assign_mature_service_user_segments',\n",
    "    'generate_mature_service_session_flow', \n",
    "    'generate_event_properties_v2',\n",
    "    'apply_ab_test_logic_v2',\n",
    "    'get_korean_timestamp'\n",
    "]\n",
    "\n",
    "print(f\"\\nğŸ”§ í•µì‹¬ í•¨ìˆ˜ ì¤€ë¹„ìƒíƒœ:\")\n",
    "for func_name in core_functions:\n",
    "    if func_name in globals():\n",
    "        print(f\"   âœ… {func_name}\")\n",
    "    else:\n",
    "        print(f\"   âŒ {func_name} - í•¨ìˆ˜ê°€ ì •ì˜ë˜ì§€ ì•ŠìŒ\")\n",
    "\n",
    "# í•µì‹¬ ë³€ìˆ˜ë“¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "core_variables = [\n",
    "    'EVENT_SCHEMA',\n",
    "    'USER_SEGMENTS', \n",
    "    'KST',\n",
    "    'AB_TEST_START_DATE',\n",
    "    'AB_TEST_END_DATE'\n",
    "]\n",
    "\n",
    "print(f\"\\nğŸ“Š í•µì‹¬ ë³€ìˆ˜ ì¤€ë¹„ìƒíƒœ:\")\n",
    "for var_name in core_variables:\n",
    "    if var_name in globals():\n",
    "        print(f\"   âœ… {var_name}\")\n",
    "    else:\n",
    "        print(f\"   âŒ {var_name} - ë³€ìˆ˜ê°€ ì •ì˜ë˜ì§€ ì•ŠìŒ\")\n",
    "\n",
    "print(f\"\\nğŸš€ 10ë§Œê°œ ì´ë²¤íŠ¸ ìƒì„± ì‹œì‘...\")\n",
    "\n",
    "# 10ë§Œê°œ ì´ë²¤íŠ¸ ìƒì„± ì‹¤í–‰\n",
    "events_100k = create_100k_events_with_dask(target_events=100_000)\n",
    "\n",
    "print(f\"\\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...\")\n",
    "\n",
    "# ì €ì¥ ê²½ë¡œ ì„¤ì •\n",
    "save_path = 'data/event_logs/dask_events_100k.parquet'\n",
    "\n",
    "# Parquet í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ì••ì¶•)\n",
    "events_100k.to_parquet(save_path, compression='snappy', index=False)\n",
    "\n",
    "# íŒŒì¼ í¬ê¸° í™•ì¸\n",
    "import os\n",
    "file_size = os.path.getsize(save_path) / (1024 * 1024)  # MB\n",
    "print(f\"âœ… ì €ì¥ ì™„ë£Œ: {save_path}\")\n",
    "print(f\"ğŸ“Š íŒŒì¼ í¬ê¸°: {file_size:.2f} MB\")\n",
    "\n",
    "print(f\"\\nğŸ” ìµœì¢… ê²°ê³¼ ìš”ì•½:\")\n",
    "print(f\"   ğŸ“Š ìƒì„±ëœ ì´ë²¤íŠ¸: {len(events_100k):,}ê°œ\")\n",
    "print(f\"   ğŸ“ ì €ì¥ ìœ„ì¹˜: {save_path}\")\n",
    "print(f\"   ğŸ’¾ íŒŒì¼ í¬ê¸°: {file_size:.2f} MB\")\n",
    "print(f\"   ğŸ”§ ì²˜ë¦¬ ë°©ì‹: Dask ë³‘ë ¬ì²˜ë¦¬\")\n",
    "print(f\"   â­ ë°ì´í„° í’ˆì§ˆ: ì •êµí•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ í¬í•¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a40e9bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>anonymous_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>context</th>\n",
       "      <th>event_properties</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>click_auth_button</td>\n",
       "      <td>386e879a-9745-4277-96ba-96e64bb3f81f</td>\n",
       "      <td>1133288</td>\n",
       "      <td>27bc96c0-3ba1-401d-831a-773847bc618f</td>\n",
       "      <td>2bb661b4-ab0f-412e-9e5c-de65187182fb</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"type\": \"login\"}</td>\n",
       "      <td>2025-07-12T10:27:35.000+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>view_page</td>\n",
       "      <td>5462dfe6-4dac-4a83-ad7b-99f79fd5322e</td>\n",
       "      <td>1133288</td>\n",
       "      <td>80c420d4-5401-480c-abdd-743a3687a7f2</td>\n",
       "      <td>2bb661b4-ab0f-412e-9e5c-de65187182fb</td>\n",
       "      <td>{\"page\": {\"name\": \"start\", \"url\": \"https://rec...</td>\n",
       "      <td>{\"page_name\": \"start\"}</td>\n",
       "      <td>2025-07-12T10:29:04.000+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>click_auth_button</td>\n",
       "      <td>fc4dc2df-bad3-4914-955f-433898246f4d</td>\n",
       "      <td>1133288</td>\n",
       "      <td>19a139ac-00dd-44c3-8360-699ccc956add</td>\n",
       "      <td>2bb661b4-ab0f-412e-9e5c-de65187182fb</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"type\": \"signup\"}</td>\n",
       "      <td>2025-07-12T10:30:41.000+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>search_recipe</td>\n",
       "      <td>3090eed8-3b8e-4ee6-9a37-30b0bac8f30f</td>\n",
       "      <td>1133288</td>\n",
       "      <td>9302e583-5261-4f06-8e31-d4bd38e96bbc</td>\n",
       "      <td>2bb661b4-ab0f-412e-9e5c-de65187182fb</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"search_type\": \"ingredient\", \"search_keyword\"...</td>\n",
       "      <td>2025-07-12T10:31:58.000+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>view_page</td>\n",
       "      <td>cd6a7c9d-c86f-4f10-8800-39a4089a7a23</td>\n",
       "      <td>1133288</td>\n",
       "      <td>29703913-7fff-492c-9d9c-e2d0bbbb4f06</td>\n",
       "      <td>2bb661b4-ab0f-412e-9e5c-de65187182fb</td>\n",
       "      <td>{\"page\": {\"name\": \"recipe_detail\", \"url\": \"htt...</td>\n",
       "      <td>{\"page_name\": \"recipe_detail\"}</td>\n",
       "      <td>2025-07-12T10:33:14.000+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>search_recipe</td>\n",
       "      <td>a3c73a51-d702-4177-bec2-fe971b0b18c1</td>\n",
       "      <td>995944</td>\n",
       "      <td>53de69f4-f6f9-4edf-89fc-87db51164dfa</td>\n",
       "      <td>a42fa45d-38d5-478a-9ac1-e6cf5232d587</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"search_type\": \"ingredient\", \"search_keyword\"...</td>\n",
       "      <td>2025-07-29T09:21:17.000+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>view_page</td>\n",
       "      <td>59b55034-a69f-403f-89b9-0f99f7fe5a37</td>\n",
       "      <td>1778398</td>\n",
       "      <td>88a5d143-0591-4038-aaab-ddc88c33a77a</td>\n",
       "      <td>8062e873-5869-4912-9c95-f71c1919320f</td>\n",
       "      <td>{\"page\": {\"name\": \"recipe_detail\", \"url\": \"htt...</td>\n",
       "      <td>{\"page_name\": \"recipe_detail\"}</td>\n",
       "      <td>2025-07-28T20:32:41.000+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>view_ads</td>\n",
       "      <td>b92a7ac1-1acb-455e-adef-16df57bb2f1c</td>\n",
       "      <td>1778398</td>\n",
       "      <td>55e90aa3-aead-44d0-afdd-beca89a806aa</td>\n",
       "      <td>8062e873-5869-4912-9c95-f71c1919320f</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"ad_id\": \"ad_2789\", \"ad_type\": \"sponsored_rec...</td>\n",
       "      <td>2025-07-28T20:33:14.000+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>click_ads</td>\n",
       "      <td>ddd61de5-e626-44eb-aafb-b5c342d6788a</td>\n",
       "      <td>1778398</td>\n",
       "      <td>5ae8a3be-b40b-4f8d-a86d-f68c55fe7f8f</td>\n",
       "      <td>8062e873-5869-4912-9c95-f71c1919320f</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"ad_id\": \"ad_2789\", \"ad_type\": \"banner\", \"pos...</td>\n",
       "      <td>2025-07-28T20:33:40.000+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>view_page</td>\n",
       "      <td>b3bec532-71bf-4880-9822-88860242e452</td>\n",
       "      <td>1778398</td>\n",
       "      <td>61cb7234-1230-48a6-921d-efd8c9308631</td>\n",
       "      <td>8062e873-5869-4912-9c95-f71c1919320f</td>\n",
       "      <td>{\"page\": {\"name\": \"start\", \"url\": \"https://rec...</td>\n",
       "      <td>{\"page_name\": \"start\", \"referrer\": \"https://go...</td>\n",
       "      <td>2025-07-28T20:34:48.000+09:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              event_name                              event_id  user_id  \\\n",
       "0      click_auth_button  386e879a-9745-4277-96ba-96e64bb3f81f  1133288   \n",
       "1              view_page  5462dfe6-4dac-4a83-ad7b-99f79fd5322e  1133288   \n",
       "2      click_auth_button  fc4dc2df-bad3-4914-955f-433898246f4d  1133288   \n",
       "3          search_recipe  3090eed8-3b8e-4ee6-9a37-30b0bac8f30f  1133288   \n",
       "4              view_page  cd6a7c9d-c86f-4f10-8800-39a4089a7a23  1133288   \n",
       "...                  ...                                   ...      ...   \n",
       "99995      search_recipe  a3c73a51-d702-4177-bec2-fe971b0b18c1   995944   \n",
       "99996          view_page  59b55034-a69f-403f-89b9-0f99f7fe5a37  1778398   \n",
       "99997           view_ads  b92a7ac1-1acb-455e-adef-16df57bb2f1c  1778398   \n",
       "99998          click_ads  ddd61de5-e626-44eb-aafb-b5c342d6788a  1778398   \n",
       "99999          view_page  b3bec532-71bf-4880-9822-88860242e452  1778398   \n",
       "\n",
       "                               anonymous_id  \\\n",
       "0      27bc96c0-3ba1-401d-831a-773847bc618f   \n",
       "1      80c420d4-5401-480c-abdd-743a3687a7f2   \n",
       "2      19a139ac-00dd-44c3-8360-699ccc956add   \n",
       "3      9302e583-5261-4f06-8e31-d4bd38e96bbc   \n",
       "4      29703913-7fff-492c-9d9c-e2d0bbbb4f06   \n",
       "...                                     ...   \n",
       "99995  53de69f4-f6f9-4edf-89fc-87db51164dfa   \n",
       "99996  88a5d143-0591-4038-aaab-ddc88c33a77a   \n",
       "99997  55e90aa3-aead-44d0-afdd-beca89a806aa   \n",
       "99998  5ae8a3be-b40b-4f8d-a86d-f68c55fe7f8f   \n",
       "99999  61cb7234-1230-48a6-921d-efd8c9308631   \n",
       "\n",
       "                                 session_id  \\\n",
       "0      2bb661b4-ab0f-412e-9e5c-de65187182fb   \n",
       "1      2bb661b4-ab0f-412e-9e5c-de65187182fb   \n",
       "2      2bb661b4-ab0f-412e-9e5c-de65187182fb   \n",
       "3      2bb661b4-ab0f-412e-9e5c-de65187182fb   \n",
       "4      2bb661b4-ab0f-412e-9e5c-de65187182fb   \n",
       "...                                     ...   \n",
       "99995  a42fa45d-38d5-478a-9ac1-e6cf5232d587   \n",
       "99996  8062e873-5869-4912-9c95-f71c1919320f   \n",
       "99997  8062e873-5869-4912-9c95-f71c1919320f   \n",
       "99998  8062e873-5869-4912-9c95-f71c1919320f   \n",
       "99999  8062e873-5869-4912-9c95-f71c1919320f   \n",
       "\n",
       "                                                 context  \\\n",
       "0      {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "1      {\"page\": {\"name\": \"start\", \"url\": \"https://rec...   \n",
       "2      {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "3      {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "4      {\"page\": {\"name\": \"recipe_detail\", \"url\": \"htt...   \n",
       "...                                                  ...   \n",
       "99995  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "99996  {\"page\": {\"name\": \"recipe_detail\", \"url\": \"htt...   \n",
       "99997  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "99998  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "99999  {\"page\": {\"name\": \"start\", \"url\": \"https://rec...   \n",
       "\n",
       "                                        event_properties  \\\n",
       "0                                      {\"type\": \"login\"}   \n",
       "1                                 {\"page_name\": \"start\"}   \n",
       "2                                     {\"type\": \"signup\"}   \n",
       "3      {\"search_type\": \"ingredient\", \"search_keyword\"...   \n",
       "4                         {\"page_name\": \"recipe_detail\"}   \n",
       "...                                                  ...   \n",
       "99995  {\"search_type\": \"ingredient\", \"search_keyword\"...   \n",
       "99996                     {\"page_name\": \"recipe_detail\"}   \n",
       "99997  {\"ad_id\": \"ad_2789\", \"ad_type\": \"sponsored_rec...   \n",
       "99998  {\"ad_id\": \"ad_2789\", \"ad_type\": \"banner\", \"pos...   \n",
       "99999  {\"page_name\": \"start\", \"referrer\": \"https://go...   \n",
       "\n",
       "                           timestamp  \n",
       "0      2025-07-12T10:27:35.000+09:00  \n",
       "1      2025-07-12T10:29:04.000+09:00  \n",
       "2      2025-07-12T10:30:41.000+09:00  \n",
       "3      2025-07-12T10:31:58.000+09:00  \n",
       "4      2025-07-12T10:33:14.000+09:00  \n",
       "...                              ...  \n",
       "99995  2025-07-29T09:21:17.000+09:00  \n",
       "99996  2025-07-28T20:32:41.000+09:00  \n",
       "99997  2025-07-28T20:33:14.000+09:00  \n",
       "99998  2025-07-28T20:33:40.000+09:00  \n",
       "99999  2025-07-28T20:34:48.000+09:00  \n",
       "\n",
       "[100000 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2126617f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ìƒì„±ëœ 10ë§Œê°œ ì´ë²¤íŠ¸ ë°ì´í„° í’ˆì§ˆ ë¶„ì„\n",
      "==================================================\n",
      "ğŸ“ˆ ê¸°ë³¸ í†µê³„:\n",
      "   ì´ ì´ë²¤íŠ¸ ìˆ˜: 100,000ê°œ\n",
      "   ì»¬ëŸ¼ ìˆ˜: 8ê°œ\n",
      "   ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 92.1 MB\n",
      "\n",
      "ğŸ¯ ì´ë²¤íŠ¸ íƒ€ì… ë¶„í¬:\n",
      "   view_page: 29,846ê°œ (29.8%)\n",
      "   view_recipe_list: 17,173ê°œ (17.2%)\n",
      "   click_auth_button: 14,081ê°œ (14.1%)\n",
      "   search_recipe: 12,454ê°œ (12.5%)\n",
      "   click_recipe: 9,159ê°œ (9.2%)\n",
      "   auth_success: 5,295ê°œ (5.3%)\n",
      "   view_ads: 5,122ê°œ (5.1%)\n",
      "   create_comment: 2,083ê°œ (2.1%)\n",
      "   click_like: 1,978ê°œ (2.0%)\n",
      "   click_bookmark: 1,713ê°œ (1.7%)\n",
      "   click_ads: 1,096ê°œ (1.1%)\n",
      "\n",
      "â° ì‹œê°„ ë¶„í¬ ë¶„ì„:\n",
      "   í™œë™ ì‹œê°„ëŒ€ (ìƒìœ„ 5ê°œ):\n",
      "     9ì‹œ: 6,823ê°œ\n",
      "     10ì‹œ: 7,102ê°œ\n",
      "     11ì‹œ: 7,287ê°œ\n",
      "     12ì‹œ: 7,394ê°œ\n",
      "     13ì‹œ: 6,846ê°œ\n",
      "   ë‚ ì§œë³„ ë¶„í¬ (ìƒìœ„ 5ê°œ):\n",
      "     2025-07-01: 3,337ê°œ\n",
      "     2025-07-02: 3,245ê°œ\n",
      "     2025-07-03: 3,344ê°œ\n",
      "     2025-07-04: 3,242ê°œ\n",
      "     2025-07-05: 3,234ê°œ\n",
      "\n",
      "ğŸ‘¥ ì‚¬ìš©ì í™œë™ íŒ¨í„´:\n",
      "   ê³ ìœ  ì‚¬ìš©ì ìˆ˜: 18,044ëª…\n",
      "   ê³ ìœ  ì„¸ì…˜ ìˆ˜: 18,044ê°œ\n",
      "   ì‚¬ìš©ìë‹¹ í‰ê·  ì´ë²¤íŠ¸: 5.5ê°œ\n",
      "   ì„¸ì…˜ë‹¹ í‰ê·  ì´ë²¤íŠ¸: 5.5ê°œ\n",
      "\n",
      "ğŸ½ï¸ ë ˆì‹œí”¼ ì—°ë™ í’ˆì§ˆ:\n",
      "   ë ˆì‹œí”¼ ê´€ë ¨ ì´ë²¤íŠ¸: 14,933ê°œ\n",
      "   ì°¸ì¡°ëœ ê³ ìœ  ë ˆì‹œí”¼: 5,990ê°œ\n",
      "   ì‹¤ì œ ë°ì´í„° ë§¤ì¹­ë¥ : 100.0%\n",
      "\n",
      "ğŸ§ª AB í…ŒìŠ¤íŠ¸ ë¡œì§ í™•ì¸:\n",
      "   AB í…ŒìŠ¤íŠ¸ ê´€ë ¨ ì´ë²¤íŠ¸: 6,218ê°œ\n",
      "   AB ê·¸ë£¹ ë¶„í¬:\n",
      "     treatment: 1,261ê°œ (50.6%)\n",
      "     control: 1,231ê°œ (49.4%)\n",
      "\n",
      "ğŸ“ Properties ë³µì¡ë„ ë¶„ì„:\n",
      "   view_page: 1ê°œ ì†ì„±\n",
      "     â”” ì˜ˆì‹œ: page_name\n",
      "   view_recipe_list: 2ê°œ ì†ì„±\n",
      "     â”” ì˜ˆì‹œ: list_type, displayed_recipe_ids\n",
      "   click_auth_button: 1ê°œ ì†ì„±\n",
      "     â”” ì˜ˆì‹œ: type\n",
      "\n",
      "âœ… ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì™„ë£Œ!\n",
      "ğŸ¯ ê²°ë¡ : ì •êµí•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì´ í¬í•¨ëœ ê³ í’ˆì§ˆ ì´ë²¤íŠ¸ ë°ì´í„° ìƒì„± ì„±ê³µ\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ“Š ìƒì„±ëœ 10ë§Œê°œ ì´ë²¤íŠ¸ ë°ì´í„° í’ˆì§ˆ ë¶„ì„\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸ“Š ìƒì„±ëœ 10ë§Œê°œ ì´ë²¤íŠ¸ ë°ì´í„° í’ˆì§ˆ ë¶„ì„\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. ê¸°ë³¸ í†µê³„\n",
    "print(\"ğŸ“ˆ ê¸°ë³¸ í†µê³„:\")\n",
    "print(f\"   ì´ ì´ë²¤íŠ¸ ìˆ˜: {len(events_100k):,}ê°œ\")\n",
    "print(f\"   ì»¬ëŸ¼ ìˆ˜: {len(events_100k.columns)}ê°œ\")\n",
    "print(f\"   ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {events_100k.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "# 2. ì´ë²¤íŠ¸ íƒ€ì… ë¶„í¬\n",
    "print(f\"\\nğŸ¯ ì´ë²¤íŠ¸ íƒ€ì… ë¶„í¬:\")\n",
    "event_type_dist = events_100k['event_name'].value_counts()\n",
    "for event_type, count in event_type_dist.items():\n",
    "    percentage = count / len(events_100k) * 100\n",
    "    print(f\"   {event_type}: {count:,}ê°œ ({percentage:.1f}%)\")\n",
    "\n",
    "# 3. ì‹œê°„ ë¶„í¬ ë¶„ì„\n",
    "print(f\"\\nâ° ì‹œê°„ ë¶„í¬ ë¶„ì„:\")\n",
    "events_100k['timestamp_parsed'] = pd.to_datetime(events_100k['timestamp'])\n",
    "events_100k['hour'] = events_100k['timestamp_parsed'].dt.hour\n",
    "events_100k['date'] = events_100k['timestamp_parsed'].dt.date\n",
    "\n",
    "hour_dist = events_100k['hour'].value_counts().sort_index()\n",
    "print(f\"   í™œë™ ì‹œê°„ëŒ€ (ìƒìœ„ 5ê°œ):\")\n",
    "for hour, count in hour_dist.head().items():\n",
    "    print(f\"     {hour}ì‹œ: {count:,}ê°œ\")\n",
    "\n",
    "date_dist = events_100k['date'].value_counts().sort_index()\n",
    "print(f\"   ë‚ ì§œë³„ ë¶„í¬ (ìƒìœ„ 5ê°œ):\")\n",
    "for date, count in date_dist.head().items():\n",
    "    print(f\"     {date}: {count:,}ê°œ\")\n",
    "\n",
    "# 4. ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„\n",
    "print(f\"\\nğŸ‘¥ ì‚¬ìš©ì í™œë™ íŒ¨í„´:\")\n",
    "unique_users = events_100k['user_id'].nunique()\n",
    "unique_sessions = events_100k['session_id'].nunique()\n",
    "avg_events_per_user = len(events_100k) / unique_users\n",
    "avg_events_per_session = len(events_100k) / unique_sessions\n",
    "\n",
    "print(f\"   ê³ ìœ  ì‚¬ìš©ì ìˆ˜: {unique_users:,}ëª…\")\n",
    "print(f\"   ê³ ìœ  ì„¸ì…˜ ìˆ˜: {unique_sessions:,}ê°œ\")\n",
    "print(f\"   ì‚¬ìš©ìë‹¹ í‰ê·  ì´ë²¤íŠ¸: {avg_events_per_user:.1f}ê°œ\")\n",
    "print(f\"   ì„¸ì…˜ë‹¹ í‰ê·  ì´ë²¤íŠ¸: {avg_events_per_session:.1f}ê°œ\")\n",
    "\n",
    "# 5. ë ˆì‹œí”¼ ì—°ë™ í’ˆì§ˆ í™•ì¸\n",
    "print(f\"\\nğŸ½ï¸ ë ˆì‹œí”¼ ì—°ë™ í’ˆì§ˆ:\")\n",
    "recipe_events = events_100k[events_100k['event_name'].isin([\n",
    "    'click_recipe', 'click_bookmark', 'click_like', 'create_comment'\n",
    "])]\n",
    "\n",
    "if len(recipe_events) > 0:\n",
    "    # ì´ë²¤íŠ¸ ì†ì„±ì—ì„œ recipe_id ì¶”ì¶œ\n",
    "    recipe_ids = []\n",
    "    for _, event in recipe_events.iterrows():\n",
    "        try:\n",
    "            properties = eval(event['event_properties'])\n",
    "            if 'recipe_id' in properties:\n",
    "                recipe_ids.append(int(properties['recipe_id']))\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if recipe_ids:\n",
    "        unique_recipes = len(set(recipe_ids))\n",
    "        # ì‹¤ì œ recipes_dfì™€ ë§¤ì¹­ í™•ì¸\n",
    "        existing_recipes = recipes_df[recipes_df['id'].isin(recipe_ids)]\n",
    "        match_rate = len(existing_recipes) / len(set(recipe_ids)) * 100\n",
    "        \n",
    "        print(f\"   ë ˆì‹œí”¼ ê´€ë ¨ ì´ë²¤íŠ¸: {len(recipe_events):,}ê°œ\")\n",
    "        print(f\"   ì°¸ì¡°ëœ ê³ ìœ  ë ˆì‹œí”¼: {unique_recipes:,}ê°œ\")\n",
    "        print(f\"   ì‹¤ì œ ë°ì´í„° ë§¤ì¹­ë¥ : {match_rate:.1f}%\")\n",
    "    else:\n",
    "        print(f\"   ë ˆì‹œí”¼ ID íŒŒì‹± ì‹¤íŒ¨\")\n",
    "else:\n",
    "    print(f\"   ë ˆì‹œí”¼ ê´€ë ¨ ì´ë²¤íŠ¸ ì—†ìŒ\")\n",
    "\n",
    "# 6. AB í…ŒìŠ¤íŠ¸ ë¶„í¬ í™•ì¸\n",
    "print(f\"\\nğŸ§ª AB í…ŒìŠ¤íŠ¸ ë¡œì§ í™•ì¸:\")\n",
    "ad_events = events_100k[events_100k['event_name'].isin(['view_ads', 'click_ads'])]\n",
    "\n",
    "if len(ad_events) > 0:\n",
    "    ab_groups = []\n",
    "    for _, event in ad_events.iterrows():\n",
    "        try:\n",
    "            properties = eval(event['event_properties'])\n",
    "            if 'ab_test_group' in properties:\n",
    "                ab_groups.append(properties['ab_test_group'])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if ab_groups:\n",
    "        from collections import Counter\n",
    "        ab_dist = Counter(ab_groups)\n",
    "        print(f\"   AB í…ŒìŠ¤íŠ¸ ê´€ë ¨ ì´ë²¤íŠ¸: {len(ad_events):,}ê°œ\")\n",
    "        print(f\"   AB ê·¸ë£¹ ë¶„í¬:\")\n",
    "        for group, count in ab_dist.items():\n",
    "            percentage = count / len(ab_groups) * 100\n",
    "            print(f\"     {group}: {count:,}ê°œ ({percentage:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"   AB í…ŒìŠ¤íŠ¸ ì†ì„± íŒŒì‹± ì‹¤íŒ¨\")\n",
    "else:\n",
    "    print(f\"   AB í…ŒìŠ¤íŠ¸ ê´€ë ¨ ì´ë²¤íŠ¸ ì—†ìŒ\")\n",
    "\n",
    "# 7. Properties ë³µì¡ë„ ë¶„ì„\n",
    "print(f\"\\nğŸ“ Properties ë³µì¡ë„ ë¶„ì„:\")\n",
    "properties_sample = []\n",
    "for event_type in event_type_dist.index[:3]:  # ìƒìœ„ 3ê°œ ì´ë²¤íŠ¸ íƒ€ì…\n",
    "    sample_event = events_100k[events_100k['event_name'] == event_type].iloc[0]\n",
    "    try:\n",
    "        props = eval(sample_event['event_properties'])\n",
    "        properties_sample.append((event_type, len(props), list(props.keys())[:5]))\n",
    "    except:\n",
    "        properties_sample.append((event_type, 0, []))\n",
    "\n",
    "for event_type, prop_count, prop_keys in properties_sample:\n",
    "    print(f\"   {event_type}: {prop_count}ê°œ ì†ì„±\")\n",
    "    if prop_keys:\n",
    "        print(f\"     â”” ì˜ˆì‹œ: {', '.join(prop_keys)}{'...' if prop_count > 5 else ''}\")\n",
    "\n",
    "print(f\"\\nâœ… ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ¯ ê²°ë¡ : ì •êµí•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì´ í¬í•¨ëœ ê³ í’ˆì§ˆ ì´ë²¤íŠ¸ ë°ì´í„° ìƒì„± ì„±ê³µ\")\n",
    "\n",
    "# timestamp_parsed, hour, date ì»¬ëŸ¼ ì œê±° (ì„ì‹œ ë¶„ì„ìš©)\n",
    "events_100k = events_100k.drop(['timestamp_parsed', 'hour', 'date'], axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fde4b39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ì„±ëŠ¥ ë¶„ì„ ë° 1ì–µê°œ í™•ì¥ ê°€ì´ë“œ\n",
      "==================================================\n",
      "ğŸ“Š í˜„ì¬ 10ë§Œê°œ ì´ë²¤íŠ¸ ì„±ëŠ¥ ë¶„ì„:\n",
      "   ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 92.1 MB\n",
      "   ì €ì¥ íŒŒì¼ í¬ê¸°: 0.0 MB\n",
      "   ì••ì¶•ë¥ : 0.0% (Snappy ì••ì¶•)\n",
      "\n",
      "ğŸ¯ 1ì–µê°œ ì´ë²¤íŠ¸ í™•ì¥ ì‹œ ì˜ˆìƒ:\n",
      "   í˜„ì¬ íŒŒì¼ì´ ì €ì¥ë˜ì§€ ì•Šì•„ ì •í™•í•œ ì˜ˆì¸¡ ë¶ˆê°€\n",
      "   ëŒ€ëµì  ì¶”ì •: 8-15 GB íŒŒì¼ í¬ê¸° ì˜ˆìƒ\n",
      "\n",
      "ğŸ”§ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì½”ë“œ ì˜ˆì‹œ:\n",
      "\n",
      "# 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± (ëŒ€ìš©ëŸ‰ ìµœì í™”)\n",
      "events_100m = create_100k_events_with_dask(\n",
      "    target_events=100_000_000,  # 1ì–µê°œ\n",
      "    batch_size=1_000            # ë°°ì¹˜ í¬ê¸° ì¶•ì†Œ (ë©”ëª¨ë¦¬ ì ˆì•½)\n",
      ")\n",
      "\n",
      "# ëŒ€ìš©ëŸ‰ ì €ì¥ (íŒŒí‹°ì…˜ ë°©ì‹)\n",
      "events_100m.to_parquet(\n",
      "    'event_logs/events_100m_partitioned/',\n",
      "    partition_cols=['date'],  # ë‚ ì§œë³„ íŒŒí‹°ì…˜\n",
      "    compression='snappy',\n",
      "    index=False\n",
      ")\n",
      "\n",
      "\n",
      "ğŸ“ˆ ì„±ëŠ¥ ìµœì í™” íŒ:\n",
      "   1. ë°°ì¹˜ í¬ê¸° ì¡°ì •: ë©”ëª¨ë¦¬ì— ë”°ë¼ 500-2000 ì‚¬ì´\n",
      "   2. Dask ì›Œì»¤ ìˆ˜: CPU ì½”ì–´ ìˆ˜ì™€ ë™ì¼í•˜ê²Œ\n",
      "   3. íŒŒí‹°ì…˜ ì €ì¥: ë‚ ì§œë³„ë¡œ ë¶„í• í•˜ì—¬ ì €ì¥\n",
      "   4. ì••ì¶• ìµœì í™”: snappy (ì†ë„) vs gzip (í¬ê¸°)\n",
      "   5. ì ì§„ì  ì²˜ë¦¬: 1ì²œë§Œê°œì”© ë‚˜ëˆ ì„œ ìƒì„± í›„ ë³‘í•©\n",
      "\n",
      "âš ï¸ ì£¼ì˜ì‚¬í•­:\n",
      "   - ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ì‹œ ì¶©ë¶„í•œ ë©”ëª¨ë¦¬ì™€ ë””ìŠ¤í¬ ê³µê°„ í™•ë³´\n",
      "   - Dask í´ëŸ¬ìŠ¤í„° ì•ˆì •ì„± ëª¨ë‹ˆí„°ë§\n",
      "   - ì¤‘ê°„ ì €ì¥ìœ¼ë¡œ ë°ì´í„° ì†ì‹¤ ë°©ì§€\n",
      "   - recipes_df ìƒ˜í”Œë§ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œì–´\n",
      "\n",
      "âœ… 10ë§Œê°œ â†’ 1ì–µê°œ í™•ì¥ ê°€ì´ë“œ ì¤€ë¹„ ì™„ë£Œ!\n",
      "ğŸ¯ í˜„ì¬ ì‹œìŠ¤í…œìœ¼ë¡œ 1ì–µê°œ ìƒì„± ê°€ëŠ¥í•˜ë©°, ìœ„ ê°€ì´ë“œë¥¼ ì°¸ê³ í•˜ì—¬ ì§„í–‰í•˜ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸš€ ì„±ëŠ¥ ë¶„ì„ ë° 1ì–µê°œ í™•ì¥ ê°€ì´ë“œ\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸš€ ì„±ëŠ¥ ë¶„ì„ ë° 1ì–µê°œ í™•ì¥ ê°€ì´ë“œ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# í˜„ì¬ ì„±ëŠ¥ ë¶„ì„\n",
    "current_file_size = 0\n",
    "if 'events_100k' in globals():\n",
    "    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„\n",
    "    memory_usage_mb = events_100k.memory_usage(deep=True).sum() / 1024 / 1024\n",
    "    \n",
    "    # ë””ìŠ¤í¬ íŒŒì¼ í¬ê¸° (ì €ì¥ëœ ê²½ìš°)\n",
    "    save_path = 'event_logs/dask_events_100k.parquet'\n",
    "    if os.path.exists(save_path):\n",
    "        current_file_size = os.path.getsize(save_path) / 1024 / 1024  # MB\n",
    "    \n",
    "    print(\"ğŸ“Š í˜„ì¬ 10ë§Œê°œ ì´ë²¤íŠ¸ ì„±ëŠ¥ ë¶„ì„:\")\n",
    "    print(f\"   ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_usage_mb:.1f} MB\")\n",
    "    print(f\"   ì €ì¥ íŒŒì¼ í¬ê¸°: {current_file_size:.1f} MB\")\n",
    "    print(f\"   ì••ì¶•ë¥ : {(current_file_size/memory_usage_mb)*100:.1f}% (Snappy ì••ì¶•)\")\n",
    "\n",
    "# 1ì–µê°œ í™•ì¥ ì‹œ ì˜ˆìƒ ì„±ëŠ¥\n",
    "print(f\"\\nğŸ¯ 1ì–µê°œ ì´ë²¤íŠ¸ í™•ì¥ ì‹œ ì˜ˆìƒ:\")\n",
    "\n",
    "if current_file_size > 0:\n",
    "    # 10ë§Œê°œ â†’ 1ì–µê°œ = 1000ë°°\n",
    "    scale_factor = 1000\n",
    "    \n",
    "    estimated_memory_gb = (memory_usage_mb * scale_factor) / 1024\n",
    "    estimated_file_size_gb = (current_file_size * scale_factor) / 1024\n",
    "    \n",
    "    print(f\"   ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {estimated_memory_gb:.1f} GB\")\n",
    "    print(f\"   ì˜ˆìƒ íŒŒì¼ í¬ê¸°: {estimated_file_size_gb:.1f} GB\")\n",
    "    \n",
    "    # ë°°ì¹˜ ì²˜ë¦¬ ê¶Œì¥ì‚¬í•­\n",
    "    recommended_batches = max(10, int(estimated_memory_gb / 2))  # 2GBë‹¹ 1ë°°ì¹˜\n",
    "    batch_size = 100_000_000 // recommended_batches\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ 1ì–µê°œ ìƒì„± ìµœì í™” ì „ëµ:\")\n",
    "    print(f\"   ê¶Œì¥ ë°°ì¹˜ ìˆ˜: {recommended_batches}ê°œ\")\n",
    "    print(f\"   ë°°ì¹˜ë‹¹ ì´ë²¤íŠ¸: {batch_size:,}ê°œ\")\n",
    "    print(f\"   ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {recommended_batches * 3:.0f}-{recommended_batches * 5:.0f}ë¶„\")\n",
    "    \n",
    "    print(f\"\\nâš™ï¸ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­:\")\n",
    "    print(f\"   ê¶Œì¥ ë©”ëª¨ë¦¬: {max(8, estimated_memory_gb * 1.5):.0f} GB ì´ìƒ\")\n",
    "    print(f\"   ê¶Œì¥ ë””ìŠ¤í¬: {estimated_file_size_gb * 2:.0f} GB ì—¬ìœ ê³µê°„\")\n",
    "    print(f\"   ê¶Œì¥ CPU: 4-8 ì½”ì–´ (Dask ë³‘ë ¬ì²˜ë¦¬)\")\n",
    "\n",
    "else:\n",
    "    print(f\"   í˜„ì¬ íŒŒì¼ì´ ì €ì¥ë˜ì§€ ì•Šì•„ ì •í™•í•œ ì˜ˆì¸¡ ë¶ˆê°€\")\n",
    "    print(f\"   ëŒ€ëµì  ì¶”ì •: 8-15 GB íŒŒì¼ í¬ê¸° ì˜ˆìƒ\")\n",
    "\n",
    "print(f\"\\nğŸ”§ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì½”ë“œ ì˜ˆì‹œ:\")\n",
    "print(f\"\"\"\n",
    "# 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± (ëŒ€ìš©ëŸ‰ ìµœì í™”)\n",
    "events_100m = create_100k_events_with_dask(\n",
    "    target_events=100_000_000,  # 1ì–µê°œ\n",
    "    batch_size=1_000            # ë°°ì¹˜ í¬ê¸° ì¶•ì†Œ (ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    ")\n",
    "\n",
    "# ëŒ€ìš©ëŸ‰ ì €ì¥ (íŒŒí‹°ì…˜ ë°©ì‹)\n",
    "events_100m.to_parquet(\n",
    "    'event_logs/events_100m_partitioned/',\n",
    "    partition_cols=['date'],  # ë‚ ì§œë³„ íŒŒí‹°ì…˜\n",
    "    compression='snappy',\n",
    "    index=False\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ ì„±ëŠ¥ ìµœì í™” íŒ:\")\n",
    "print(f\"   1. ë°°ì¹˜ í¬ê¸° ì¡°ì •: ë©”ëª¨ë¦¬ì— ë”°ë¼ 500-2000 ì‚¬ì´\")\n",
    "print(f\"   2. Dask ì›Œì»¤ ìˆ˜: CPU ì½”ì–´ ìˆ˜ì™€ ë™ì¼í•˜ê²Œ\")\n",
    "print(f\"   3. íŒŒí‹°ì…˜ ì €ì¥: ë‚ ì§œë³„ë¡œ ë¶„í• í•˜ì—¬ ì €ì¥\")\n",
    "print(f\"   4. ì••ì¶• ìµœì í™”: snappy (ì†ë„) vs gzip (í¬ê¸°)\")\n",
    "print(f\"   5. ì ì§„ì  ì²˜ë¦¬: 1ì²œë§Œê°œì”© ë‚˜ëˆ ì„œ ìƒì„± í›„ ë³‘í•©\")\n",
    "\n",
    "print(f\"\\nâš ï¸ ì£¼ì˜ì‚¬í•­:\")\n",
    "print(f\"   - ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ì‹œ ì¶©ë¶„í•œ ë©”ëª¨ë¦¬ì™€ ë””ìŠ¤í¬ ê³µê°„ í™•ë³´\")\n",
    "print(f\"   - Dask í´ëŸ¬ìŠ¤í„° ì•ˆì •ì„± ëª¨ë‹ˆí„°ë§\")\n",
    "print(f\"   - ì¤‘ê°„ ì €ì¥ìœ¼ë¡œ ë°ì´í„° ì†ì‹¤ ë°©ì§€\")\n",
    "print(f\"   - recipes_df ìƒ˜í”Œë§ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œì–´\")\n",
    "\n",
    "print(f\"\\nâœ… 10ë§Œê°œ â†’ 1ì–µê°œ í™•ì¥ ê°€ì´ë“œ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ¯ í˜„ì¬ ì‹œìŠ¤í…œìœ¼ë¡œ 1ì–µê°œ ìƒì„± ê°€ëŠ¥í•˜ë©°, ìœ„ ê°€ì´ë“œë¥¼ ì°¸ê³ í•˜ì—¬ ì§„í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afb81ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ê°€ëŠ¥ì„± ì „ë©´ ë¶„ì„\n",
      "======================================================================\n",
      "ğŸ’» ì‹œìŠ¤í…œ í•˜ë“œì›¨ì–´ ì‚¬ì–‘:\n",
      "------------------------------\n",
      "   CPU:\n",
      "     - ë…¼ë¦¬ ì½”ì–´: 6ê°œ\n",
      "     - ë¬¼ë¦¬ ì½”ì–´: 6ê°œ\n",
      "     - ê¸°ë³¸ í´ëŸ­: 3600 MHz\n",
      "\n",
      "   ë©”ëª¨ë¦¬:\n",
      "     - ì´ ë©”ëª¨ë¦¬: 16.0 GB\n",
      "     - ì‚¬ìš© ê°€ëŠ¥: 6.3 GB\n",
      "     - í˜„ì¬ ì‚¬ìš©: 9.6 GB (60.5%)\n",
      "\n",
      "   ë””ìŠ¤í¬ (í˜„ì¬ ìœ„ì¹˜):\n",
      "     - ì´ ìš©ëŸ‰: 1862.4 GB\n",
      "     - ì—¬ìœ  ê³µê°„: 1233.1 GB\n",
      "     - ì‚¬ìš© ì¤‘: 629.3 GB\n",
      "\n",
      "   ìš´ì˜ì²´ì œ: Windows 10.0.19045\n",
      "\n",
      "ğŸ Python í”„ë¡œì„¸ìŠ¤ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:\n",
      "-----------------------------------\n",
      "   í˜„ì¬ Python í”„ë¡œì„¸ìŠ¤: 3050.1 MB\n",
      "\n",
      "   ì£¼ìš” ë³€ìˆ˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:\n",
      "     - recipes_df: 374.6 MB\n",
      "     - users_df: 1333.9 MB\n",
      "     - profiles_df: 868.6 MB\n",
      "     - segmented_users_df: 2476.3 MB\n",
      "     - events_100k: 92.1 MB\n",
      "   ì´ ë³€ìˆ˜ ë©”ëª¨ë¦¬: 5145.4 MB\n",
      "\n",
      "ğŸ“Š 10ë§Œê°œ ì´ë²¤íŠ¸ ê¸°ì¤€ ì„±ëŠ¥ ë¶„ì„:\n",
      "-----------------------------------\n",
      "   10ë§Œê°œ ì´ë²¤íŠ¸:\n",
      "     - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 92.1 MB\n",
      "     - ì´ë²¤íŠ¸ë‹¹ ë©”ëª¨ë¦¬: 0.94 KB\n",
      "\n",
      "   1ì–µê°œ ì´ë²¤íŠ¸ ì˜ˆìƒ:\n",
      "     - ì˜ˆìƒ ë©”ëª¨ë¦¬: 89.9 GB\n",
      "     - í™•ì¥ ë°°ìˆ˜: 1000x\n",
      "     - ì˜ˆìƒ íŒŒì¼ í¬ê¸°: 45.0 GB (ì¶”ì •)\n",
      "\n",
      "ğŸ”§ ì½”ë“œ ë¡œì§ ë³µì¡ë„ ë¶„ì„:\n",
      "-------------------------\n",
      "   í•µì‹¬ í•¨ìˆ˜ ê°€ìš©ì„±:\n",
      "     âœ… assign_mature_service_user_segments\n",
      "     âœ… generate_mature_service_session_flow\n",
      "     âœ… generate_event_properties_v2\n",
      "     âœ… apply_ab_test_logic_v2\n",
      "     âœ… create_100k_events_with_dask\n",
      "   í•¨ìˆ˜ ì¤€ë¹„ë„: 100%\n",
      "\n",
      "   ë°ì´í„° ì¤€ë¹„ ìƒíƒœ:\n",
      "     âœ… recipes_df: 208,183ê°œ\n",
      "     âœ… users_df: 2,000,000ê°œ\n",
      "     âœ… profiles_df: 2,000,000ê°œ\n",
      "   ë°ì´í„° ì¤€ë¹„ë„: 100%\n",
      "\n",
      "ğŸ¯ 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„± ì¢…í•© í‰ê°€:\n",
      "======================================================================\n",
      "ğŸ’¾ ë©”ëª¨ë¦¬ í‰ê°€:\n",
      "   í•„ìš” ë©”ëª¨ë¦¬: 134.9 GB (ì—¬ìœ ë¶„ í¬í•¨)\n",
      "   ì‚¬ìš© ê°€ëŠ¥: 6.3 GB\n",
      "   ì¶©ì¡±ë„: âŒ 5%\n",
      "\n",
      "ğŸ’¿ ë””ìŠ¤í¬ í‰ê°€:\n",
      "   í•„ìš” ê³µê°„: 89.9 GB\n",
      "   ì—¬ìœ  ê³µê°„: 1233.1 GB\n",
      "   ì¶©ì¡±ë„: âœ… 100%\n",
      "\n",
      "âš¡ CPU í‰ê°€:\n",
      "   CPU ì½”ì–´ ìˆ˜: 6ê°œ\n",
      "   ê¶Œì¥ ìµœì†Œ: 4ê°œ\n",
      "   ì„±ëŠ¥ ì ìˆ˜: âœ… 100%\n",
      "\n",
      "ğŸ”§ ì½”ë“œ ì¤€ë¹„ë„:\n",
      "   í•¨ìˆ˜ ì¤€ë¹„: 100%\n",
      "   ë°ì´í„° ì¤€ë¹„: 100%\n",
      "   ì¢…í•© ì¤€ë¹„ë„: âœ… 100%\n",
      "\n",
      "ğŸ† ì¢…í•© í‰ê°€:\n",
      "   ì´ì : 62/100ì \n",
      "   ìƒì„± ê°€ëŠ¥ì„±: âš ï¸ ë³´í†µ\n",
      "\n",
      "ğŸ’¡ ê¶Œì¥ì‚¬í•­ ë° ìµœì í™” ì „ëµ:\n",
      "-----------------------------------\n",
      "ğŸ”´ ë©”ëª¨ë¦¬ ë¶€ì¡± ëŒ€ì‘:\n",
      "   - ë°°ì¹˜ í¬ê¸° ì¶•ì†Œ: 2000 â†’ 500ëª…\n",
      "   - ì ì§„ì  ìƒì„±: 1000ë§Œê°œì”© 10ë²ˆ ë¶„í• \n",
      "   - ë©”ëª¨ë¦¬ ì •ë¦¬: gc.collect() ì£¼ê¸°ì  ì‹¤í–‰\n",
      "\n",
      "ğŸš€ ìµœì í™” ì „ëµ:\n",
      "   âœ… í‘œì¤€ ë³‘ë ¬ì²˜ë¦¬: 6ê°œ ì›Œì»¤ í™œìš©\n",
      "   ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: 142.6-285.3ì‹œê°„\n",
      "\n",
      "ğŸ¯ ê²°ë¡ :\n",
      "   âš ï¸ 1ì–µê°œ ìƒì„±ì— ì œì•½ ìˆìŒ\n",
      "   ğŸ’¡ ëŒ€ì•ˆ: 1000ë§Œ-5000ë§Œê°œ ë‹¨ìœ„ë¡œ ë¶„í•  ìƒì„±\n",
      "\n",
      "ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„ ì‹¤í–‰ ê³„íš:\n",
      "   1. ë©”ëª¨ë¦¬ ì—¬ìœ  í™•ë³´ (ë¶ˆí•„ìš”í•œ ë³€ìˆ˜ ì •ë¦¬)\n",
      "   2. ë°°ì¹˜ í¬ê¸° ìµœì í™” ì„¤ì •\n",
      "   3. ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì¤€ë¹„\n",
      "   4. ì ì§„ì  ìƒì„± ë° ì €ì¥\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ” 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ê°€ëŠ¥ì„± ì „ë©´ ë¶„ì„ ë° ì‹œìŠ¤í…œ ì§„ë‹¨\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸ” 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ê°€ëŠ¥ì„± ì „ë©´ ë¶„ì„\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import psutil\n",
    "import gc\n",
    "import sys\n",
    "import platform\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# 1. ì‹œìŠ¤í…œ í•˜ë“œì›¨ì–´ ì‚¬ì–‘ ë¶„ì„\n",
    "print(\"ğŸ’» ì‹œìŠ¤í…œ í•˜ë“œì›¨ì–´ ì‚¬ì–‘:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# CPU ì •ë³´\n",
    "cpu_count = psutil.cpu_count(logical=True)\n",
    "cpu_physical = psutil.cpu_count(logical=False)\n",
    "cpu_freq = psutil.cpu_freq()\n",
    "\n",
    "print(f\"   CPU:\")\n",
    "print(f\"     - ë…¼ë¦¬ ì½”ì–´: {cpu_count}ê°œ\")\n",
    "print(f\"     - ë¬¼ë¦¬ ì½”ì–´: {cpu_physical}ê°œ\") \n",
    "print(f\"     - ê¸°ë³¸ í´ëŸ­: {cpu_freq.current:.0f} MHz\" if cpu_freq else \"     - í´ëŸ­ ì •ë³´ ì—†ìŒ\")\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì •ë³´\n",
    "memory = psutil.virtual_memory()\n",
    "memory_total_gb = memory.total / (1024**3)\n",
    "memory_available_gb = memory.available / (1024**3)\n",
    "memory_used_gb = memory.used / (1024**3)\n",
    "memory_usage_percent = memory.percent\n",
    "\n",
    "print(f\"\\n   ë©”ëª¨ë¦¬:\")\n",
    "print(f\"     - ì´ ë©”ëª¨ë¦¬: {memory_total_gb:.1f} GB\")\n",
    "print(f\"     - ì‚¬ìš© ê°€ëŠ¥: {memory_available_gb:.1f} GB\")\n",
    "print(f\"     - í˜„ì¬ ì‚¬ìš©: {memory_used_gb:.1f} GB ({memory_usage_percent:.1f}%)\")\n",
    "\n",
    "# ë””ìŠ¤í¬ ì •ë³´\n",
    "try:\n",
    "    disk = psutil.disk_usage('.')\n",
    "    disk_total_gb = disk.total / (1024**3)\n",
    "    disk_free_gb = disk.free / (1024**3)\n",
    "    disk_used_gb = disk.used / (1024**3)\n",
    "    \n",
    "    print(f\"\\n   ë””ìŠ¤í¬ (í˜„ì¬ ìœ„ì¹˜):\")\n",
    "    print(f\"     - ì´ ìš©ëŸ‰: {disk_total_gb:.1f} GB\")\n",
    "    print(f\"     - ì—¬ìœ  ê³µê°„: {disk_free_gb:.1f} GB\")\n",
    "    print(f\"     - ì‚¬ìš© ì¤‘: {disk_used_gb:.1f} GB\")\n",
    "except:\n",
    "    print(f\"\\n   ë””ìŠ¤í¬: ì •ë³´ í™•ì¸ ë¶ˆê°€\")\n",
    "\n",
    "print(f\"\\n   ìš´ì˜ì²´ì œ: {platform.system()} {platform.version()}\")\n",
    "\n",
    "# 2. í˜„ì¬ Python í”„ë¡œì„¸ìŠ¤ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰\n",
    "print(f\"\\nğŸ Python í”„ë¡œì„¸ìŠ¤ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "process = psutil.Process()\n",
    "process_memory = process.memory_info()\n",
    "process_memory_mb = process_memory.rss / (1024**2)\n",
    "\n",
    "print(f\"   í˜„ì¬ Python í”„ë¡œì„¸ìŠ¤: {process_memory_mb:.1f} MB\")\n",
    "\n",
    "# í˜„ì¬ ë¡œë“œëœ ì£¼ìš” ë³€ìˆ˜ë“¤ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰\n",
    "print(f\"\\n   ì£¼ìš” ë³€ìˆ˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:\")\n",
    "\n",
    "memory_usage = {}\n",
    "major_variables = ['recipes_df', 'users_df', 'profiles_df', 'segmented_users_df', 'events_100k']\n",
    "\n",
    "for var_name in major_variables:\n",
    "    if var_name in globals():\n",
    "        var = globals()[var_name]\n",
    "        if hasattr(var, 'memory_usage'):\n",
    "            # DataFrameì¸ ê²½ìš°\n",
    "            memory_mb = var.memory_usage(deep=True).sum() / (1024**2)\n",
    "            memory_usage[var_name] = memory_mb\n",
    "            print(f\"     - {var_name}: {memory_mb:.1f} MB\")\n",
    "        else:\n",
    "            try:\n",
    "                size_bytes = sys.getsizeof(var)\n",
    "                memory_mb = size_bytes / (1024**2)\n",
    "                memory_usage[var_name] = memory_mb\n",
    "                print(f\"     - {var_name}: {memory_mb:.1f} MB\")\n",
    "            except:\n",
    "                print(f\"     - {var_name}: í¬ê¸° ì¸¡ì • ë¶ˆê°€\")\n",
    "\n",
    "total_variable_memory = sum(memory_usage.values())\n",
    "print(f\"   ì´ ë³€ìˆ˜ ë©”ëª¨ë¦¬: {total_variable_memory:.1f} MB\")\n",
    "\n",
    "# 3. 10ë§Œê°œ ì´ë²¤íŠ¸ ê¸°ì¤€ ì„±ëŠ¥ ë¶„ì„\n",
    "print(f\"\\nğŸ“Š 10ë§Œê°œ ì´ë²¤íŠ¸ ê¸°ì¤€ ì„±ëŠ¥ ë¶„ì„:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "if 'events_100k' in globals():\n",
    "    events_100k_memory = events_100k.memory_usage(deep=True).sum() / (1024**2)\n",
    "    events_count = len(events_100k)\n",
    "    \n",
    "    print(f\"   10ë§Œê°œ ì´ë²¤íŠ¸:\")\n",
    "    print(f\"     - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {events_100k_memory:.1f} MB\")\n",
    "    print(f\"     - ì´ë²¤íŠ¸ë‹¹ ë©”ëª¨ë¦¬: {events_100k_memory/events_count*1024:.2f} KB\")\n",
    "    \n",
    "    # 1ì–µê°œ ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰\n",
    "    scale_factor = 100_000_000 / events_count\n",
    "    estimated_memory_gb = (events_100k_memory * scale_factor) / 1024\n",
    "    \n",
    "    print(f\"\\n   1ì–µê°œ ì´ë²¤íŠ¸ ì˜ˆìƒ:\")\n",
    "    print(f\"     - ì˜ˆìƒ ë©”ëª¨ë¦¬: {estimated_memory_gb:.1f} GB\")\n",
    "    print(f\"     - í™•ì¥ ë°°ìˆ˜: {scale_factor:.0f}x\")\n",
    "    \n",
    "    # íŒŒì¼ í¬ê¸° ì˜ˆìƒ\n",
    "    if 'save_path' in globals() and 'file_exists' in globals() and file_exists:\n",
    "        current_file_size_mb = current_file_size\n",
    "        estimated_file_size_gb = (current_file_size_mb * scale_factor) / 1024\n",
    "        print(f\"     - ì˜ˆìƒ íŒŒì¼ í¬ê¸°: {estimated_file_size_gb:.1f} GB\")\n",
    "        compression_ratio = current_file_size_mb / events_100k_memory\n",
    "        print(f\"     - ì••ì¶• íš¨ìœ¨: {compression_ratio:.1%}\")\n",
    "    else:\n",
    "        # íŒŒì¼ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ì¶”ì •\n",
    "        estimated_file_size_gb = (events_100k_memory * scale_factor * 0.5) / 1024  # 50% ì••ì¶• ê°€ì •\n",
    "        print(f\"     - ì˜ˆìƒ íŒŒì¼ í¬ê¸°: {estimated_file_size_gb:.1f} GB (ì¶”ì •)\")\n",
    "    \n",
    "else:\n",
    "    print(\"   âŒ 10ë§Œê°œ ì´ë²¤íŠ¸ ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„ ë¶ˆê°€\")\n",
    "    estimated_memory_gb = 15  # ì¶”ì •ê°’\n",
    "    estimated_file_size_gb = 8  # ì¶”ì •ê°’\n",
    "\n",
    "# 4. ì½”ë“œ ë¡œì§ ë³µì¡ë„ ë¶„ì„\n",
    "print(f\"\\nğŸ”§ ì½”ë“œ ë¡œì§ ë³µì¡ë„ ë¶„ì„:\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# í•µì‹¬ í•¨ìˆ˜ë“¤ ì¡´ì¬ ì—¬ë¶€\n",
    "critical_functions = [\n",
    "    'assign_mature_service_user_segments',\n",
    "    'generate_mature_service_session_flow', \n",
    "    'generate_event_properties_v2',\n",
    "    'apply_ab_test_logic_v2',\n",
    "    'create_100k_events_with_dask'\n",
    "]\n",
    "\n",
    "print(f\"   í•µì‹¬ í•¨ìˆ˜ ê°€ìš©ì„±:\")\n",
    "function_availability = 0\n",
    "for func in critical_functions:\n",
    "    if func in globals():\n",
    "        print(f\"     âœ… {func}\")\n",
    "        function_availability += 1\n",
    "    else:\n",
    "        print(f\"     âŒ {func}\")\n",
    "\n",
    "function_readiness = function_availability / len(critical_functions) * 100\n",
    "print(f\"   í•¨ìˆ˜ ì¤€ë¹„ë„: {function_readiness:.0f}%\")\n",
    "\n",
    "# ë°ì´í„° ì¤€ë¹„ ìƒíƒœ\n",
    "data_readiness = 0\n",
    "data_items = ['recipes_df', 'users_df', 'profiles_df']\n",
    "print(f\"\\n   ë°ì´í„° ì¤€ë¹„ ìƒíƒœ:\")\n",
    "for item in data_items:\n",
    "    if item in globals():\n",
    "        data_size = len(globals()[item])\n",
    "        print(f\"     âœ… {item}: {data_size:,}ê°œ\")\n",
    "        data_readiness += 1\n",
    "    else:\n",
    "        print(f\"     âŒ {item}: ì—†ìŒ\")\n",
    "\n",
    "data_readiness_percent = data_readiness / len(data_items) * 100\n",
    "print(f\"   ë°ì´í„° ì¤€ë¹„ë„: {data_readiness_percent:.0f}%\")\n",
    "\n",
    "# 5. 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„± ì¢…í•© í‰ê°€\n",
    "print(f\"\\nğŸ¯ 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„± ì¢…í•© í‰ê°€:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì¶©ì¡±ë„\n",
    "memory_requirement = estimated_memory_gb * 1.5  # ì•ˆì „ ì—¬ìœ ë¶„ 50%\n",
    "memory_sufficient = memory_available_gb >= memory_requirement\n",
    "memory_score = min(100, (memory_available_gb / memory_requirement) * 100)\n",
    "\n",
    "print(f\"ğŸ’¾ ë©”ëª¨ë¦¬ í‰ê°€:\")\n",
    "print(f\"   í•„ìš” ë©”ëª¨ë¦¬: {memory_requirement:.1f} GB (ì—¬ìœ ë¶„ í¬í•¨)\")\n",
    "print(f\"   ì‚¬ìš© ê°€ëŠ¥: {memory_available_gb:.1f} GB\")\n",
    "print(f\"   ì¶©ì¡±ë„: {'âœ…' if memory_sufficient else 'âŒ'} {memory_score:.0f}%\")\n",
    "\n",
    "# ë””ìŠ¤í¬ ì¶©ì¡±ë„\n",
    "disk_requirement = estimated_file_size_gb * 2  # ì„ì‹œíŒŒì¼ ê³ ë ¤\n",
    "try:\n",
    "    disk_sufficient = disk_free_gb >= disk_requirement\n",
    "    disk_score = min(100, (disk_free_gb / disk_requirement) * 100)\n",
    "    \n",
    "    print(f\"\\nğŸ’¿ ë””ìŠ¤í¬ í‰ê°€:\")\n",
    "    print(f\"   í•„ìš” ê³µê°„: {disk_requirement:.1f} GB\")\n",
    "    print(f\"   ì—¬ìœ  ê³µê°„: {disk_free_gb:.1f} GB\")\n",
    "    print(f\"   ì¶©ì¡±ë„: {'âœ…' if disk_sufficient else 'âŒ'} {disk_score:.0f}%\")\n",
    "except:\n",
    "    disk_sufficient = True\n",
    "    disk_score = 100\n",
    "    print(f\"\\nğŸ’¿ ë””ìŠ¤í¬ í‰ê°€: í™•ì¸ ë¶ˆê°€ (ì–‘í˜¸ë¡œ ê°€ì •)\")\n",
    "\n",
    "# CPU ì„±ëŠ¥ í‰ê°€\n",
    "cpu_score = min(100, (cpu_count / 4) * 100)  # 4ì½”ì–´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€\n",
    "cpu_sufficient = cpu_count >= 4\n",
    "\n",
    "print(f\"\\nâš¡ CPU í‰ê°€:\")\n",
    "print(f\"   CPU ì½”ì–´ ìˆ˜: {cpu_count}ê°œ\")\n",
    "print(f\"   ê¶Œì¥ ìµœì†Œ: 4ê°œ\")\n",
    "print(f\"   ì„±ëŠ¥ ì ìˆ˜: {'âœ…' if cpu_sufficient else 'âŒ'} {cpu_score:.0f}%\")\n",
    "\n",
    "# ì½”ë“œ ì¤€ë¹„ë„ í‰ê°€\n",
    "code_score = (function_readiness + data_readiness_percent) / 2\n",
    "code_sufficient = code_score >= 90\n",
    "\n",
    "print(f\"\\nğŸ”§ ì½”ë“œ ì¤€ë¹„ë„:\")\n",
    "print(f\"   í•¨ìˆ˜ ì¤€ë¹„: {function_readiness:.0f}%\")\n",
    "print(f\"   ë°ì´í„° ì¤€ë¹„: {data_readiness_percent:.0f}%\")\n",
    "print(f\"   ì¢…í•© ì¤€ë¹„ë„: {'âœ…' if code_sufficient else 'âŒ'} {code_score:.0f}%\")\n",
    "\n",
    "# ì¢…í•© ì ìˆ˜ ê³„ì‚°\n",
    "total_score = (memory_score * 0.4 + disk_score * 0.2 + cpu_score * 0.2 + code_score * 0.2)\n",
    "overall_feasible = total_score >= 80\n",
    "\n",
    "print(f\"\\nğŸ† ì¢…í•© í‰ê°€:\")\n",
    "print(f\"   ì´ì : {total_score:.0f}/100ì \")\n",
    "print(f\"   ìƒì„± ê°€ëŠ¥ì„±: {'âœ… ë†’ìŒ' if total_score >= 80 else 'âš ï¸ ë³´í†µ' if total_score >= 60 else 'âŒ ë‚®ìŒ'}\")\n",
    "\n",
    "# 6. ê¶Œì¥ì‚¬í•­ ë° ìµœì í™” ì „ëµ\n",
    "print(f\"\\nğŸ’¡ ê¶Œì¥ì‚¬í•­ ë° ìµœì í™” ì „ëµ:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "if not memory_sufficient:\n",
    "    print(f\"ğŸ”´ ë©”ëª¨ë¦¬ ë¶€ì¡± ëŒ€ì‘:\")\n",
    "    print(f\"   - ë°°ì¹˜ í¬ê¸° ì¶•ì†Œ: 2000 â†’ 500ëª…\")\n",
    "    print(f\"   - ì ì§„ì  ìƒì„±: 1000ë§Œê°œì”© 10ë²ˆ ë¶„í• \")\n",
    "    print(f\"   - ë©”ëª¨ë¦¬ ì •ë¦¬: gc.collect() ì£¼ê¸°ì  ì‹¤í–‰\")\n",
    "\n",
    "if not disk_sufficient:\n",
    "    print(f\"ğŸ”´ ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡± ëŒ€ì‘:\")\n",
    "    print(f\"   - íŒŒí‹°ì…˜ ì €ì¥: ë‚ ì§œë³„ ë¶„í•  ì €ì¥\")\n",
    "    print(f\"   - ì••ì¶• ìµœì í™”: gzip ì••ì¶• ì‚¬ìš©\")\n",
    "    print(f\"   - ì„ì‹œíŒŒì¼ ì •ë¦¬: ì¤‘ê°„ ê²°ê³¼ ì¦‰ì‹œ ì‚­ì œ\")\n",
    "\n",
    "print(f\"\\nğŸš€ ìµœì í™” ì „ëµ:\")\n",
    "if cpu_count >= 8:\n",
    "    print(f\"   âœ… ê³ ì„±ëŠ¥ ë³‘ë ¬ì²˜ë¦¬: {cpu_count}ê°œ ì›Œì»¤ í™œìš©\")\n",
    "elif cpu_count >= 4:\n",
    "    print(f\"   âœ… í‘œì¤€ ë³‘ë ¬ì²˜ë¦¬: {cpu_count}ê°œ ì›Œì»¤ í™œìš©\")\n",
    "else:\n",
    "    print(f\"   âš ï¸ ìˆœì°¨ì²˜ë¦¬ ê¶Œì¥: CPU ì½”ì–´ ë¶€ì¡±\")\n",
    "\n",
    "estimated_time_hours = estimated_memory_gb / (memory_available_gb * 0.1)  # ì¶”ì • ê³µì‹\n",
    "print(f\"   ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {estimated_time_hours:.1f}-{estimated_time_hours*2:.1f}ì‹œê°„\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ê²°ë¡ :\")\n",
    "if overall_feasible:\n",
    "    print(f\"   âœ… 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ê°€ëŠ¥!\")\n",
    "    print(f\"   ğŸ’¡ ê¶Œì¥: ë°°ì¹˜ ë¶„í•  ë°©ì‹ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì§„í–‰\")\n",
    "else:\n",
    "    print(f\"   âš ï¸ 1ì–µê°œ ìƒì„±ì— ì œì•½ ìˆìŒ\")\n",
    "    print(f\"   ğŸ’¡ ëŒ€ì•ˆ: 1000ë§Œ-5000ë§Œê°œ ë‹¨ìœ„ë¡œ ë¶„í•  ìƒì„±\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„ ì‹¤í–‰ ê³„íš:\")\n",
    "print(f\"   1. ë©”ëª¨ë¦¬ ì—¬ìœ  í™•ë³´ (ë¶ˆí•„ìš”í•œ ë³€ìˆ˜ ì •ë¦¬)\")\n",
    "print(f\"   2. ë°°ì¹˜ í¬ê¸° ìµœì í™” ì„¤ì •\")\n",
    "print(f\"   3. ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì¤€ë¹„\")\n",
    "print(f\"   4. ì ì§„ì  ìƒì„± ë° ì €ì¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "159c0c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ë©”ëª¨ë¦¬ ìµœì í™” ë° 1ì–µê°œ ì´ë²¤íŠ¸ ë¶„í•  ìƒì„± ì „ëµ\n",
      "============================================================\n",
      "ğŸ§¹ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤í–‰:\n",
      "-------------------------\n",
      "   ìµœì í™” ì „:\n",
      "     - ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©: 60.5%\n",
      "     - Python í”„ë¡œì„¸ìŠ¤: 3049.1 MB\n",
      "   ì •ë¦¬ëœ ì„ì‹œ ë³€ìˆ˜: 6ê°œ\n",
      "   ìµœì í™” í›„:\n",
      "     - ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©: 60.5%\n",
      "     - Python í”„ë¡œì„¸ìŠ¤: 3049.1 MB\n",
      "     - ì ˆì•½ëœ ë©”ëª¨ë¦¬: 0.0 MB\n",
      "   ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬: 6.3 GB\n",
      "\n",
      "ğŸ“ ì•ˆì „í•œ ìƒì„± ê·œëª¨ ê³„ì‚°:\n",
      "----------------------------\n",
      "   10ë§Œê°œ ì´ë²¤íŠ¸ ë©”ëª¨ë¦¬: 0.090 GB\n",
      "   1GBë‹¹ ì´ë²¤íŠ¸ ìˆ˜: 1,112,034ê°œ\n",
      "   ì•ˆì „ ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬: 4.4 GB\n",
      "   ìµœëŒ€ ì•ˆì „ ìƒì„±ëŸ‰: 4,903,685ê°œ\n",
      "\n",
      "ğŸ”€ ë¶„í•  ìƒì„± ì „ëµ ì„¤ê³„:\n",
      "-------------------------\n",
      "   ëª©í‘œ: 100,000,000ê°œ\n",
      "   ë°°ì¹˜ í¬ê¸°: 4,903,685ê°œ\n",
      "   ì´ ë°°ì¹˜ ìˆ˜: 21ê°œ\n",
      "   ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: 210-420ë¶„\n",
      "\n",
      "   ë°°ì¹˜ë³„ ìƒì„¸ ê³„íš:\n",
      "     ë°°ì¹˜ 1: 4,903,685ê°œ â†’ event_logs/event_logs_batch_01_4M.parquet\n",
      "     ë°°ì¹˜ 2: 4,903,685ê°œ â†’ event_logs/event_logs_batch_02_4M.parquet\n",
      "     ë°°ì¹˜ 3: 4,903,685ê°œ â†’ event_logs/event_logs_batch_03_4M.parquet\n",
      "     ë°°ì¹˜ 4: 4,903,685ê°œ â†’ event_logs/event_logs_batch_04_4M.parquet\n",
      "     ë°°ì¹˜ 5: 4,903,685ê°œ â†’ event_logs/event_logs_batch_05_4M.parquet\n",
      "     ... ì´ 21ê°œ ë°°ì¹˜\n",
      "\n",
      "âš™ï¸ ë¶„í•  ìƒì„± í•¨ìˆ˜ ì •ì˜:\n",
      "----------------------\n",
      "   âœ… ë¶„í•  ìƒì„± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n",
      "\n",
      "ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê³„íš:\n",
      "--------------------\n",
      "   í…ŒìŠ¤íŠ¸ ë°°ì¹˜ í¬ê¸°: 1,000,000ê°œ\n",
      "   í…ŒìŠ¤íŠ¸ ì €ì¥ ê²½ë¡œ: event_logs/test_batch_1M.parquet\n",
      "   ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©: 0.9 GB\n",
      "   í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê°€ëŠ¥: âœ… ì˜ˆ\n",
      "\n",
      "ğŸ’¡ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ëª…ë ¹:\n",
      "   create_batch_events_with_monitoring(1, 1,000,000, 'event_logs/test_batch_1M.parquet')\n",
      "\n",
      "ğŸ¯ ë‹¤ìŒ ë‹¨ê³„:\n",
      "   1. í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ì‹¤í–‰ìœ¼ë¡œ ì„±ëŠ¥ ê²€ì¦\n",
      "   2. ì„±ê³µ ì‹œ ì „ì²´ ë°°ì¹˜ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½\n",
      "   3. ëª¨ë‹ˆí„°ë§ê³¼ í•¨ê»˜ ì ì§„ì  ìƒì„± ì‹¤í–‰\n",
      "   4. ìµœì¢… í†µí•© ë° ê²€ì¦\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸš€ ë©”ëª¨ë¦¬ ìµœì í™” ë° 1ì–µê°œ ì´ë²¤íŠ¸ ë¶„í•  ìƒì„± ì „ëµ êµ¬í˜„\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸš€ ë©”ëª¨ë¦¬ ìµœì í™” ë° 1ì–µê°œ ì´ë²¤íŠ¸ ë¶„í•  ìƒì„± ì „ëµ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import gc\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "\n",
    "# 1. í˜„ì¬ ë©”ëª¨ë¦¬ ìƒíƒœ ì§„ë‹¨ ë° ìµœì í™”\n",
    "print(\"ğŸ§¹ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤í–‰:\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰\n",
    "memory_before = psutil.virtual_memory()\n",
    "process_memory_before = psutil.Process().memory_info().rss / (1024**2)\n",
    "\n",
    "print(f\"   ìµœì í™” ì „:\")\n",
    "print(f\"     - ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©: {memory_before.percent:.1f}%\")\n",
    "print(f\"     - Python í”„ë¡œì„¸ìŠ¤: {process_memory_before:.1f} MB\")\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤í–‰\n",
    "gc.collect()\n",
    "\n",
    "# ë¶ˆí•„ìš”í•œ ë³€ìˆ˜ ì •ë¦¬ (í•„ìš”ì‹œ)\n",
    "unnecessary_vars = []\n",
    "for var_name in list(globals().keys()):\n",
    "    if var_name.startswith('temp_') or var_name.startswith('test_') or var_name in ['_', '__', '___']:\n",
    "        unnecessary_vars.append(var_name)\n",
    "\n",
    "if unnecessary_vars:\n",
    "    for var in unnecessary_vars:\n",
    "        if var in globals():\n",
    "            del globals()[var]\n",
    "    print(f\"   ì •ë¦¬ëœ ì„ì‹œ ë³€ìˆ˜: {len(unnecessary_vars)}ê°œ\")\n",
    "    gc.collect()\n",
    "\n",
    "# ìµœì í™” í›„ ë©”ëª¨ë¦¬ ìƒíƒœ\n",
    "memory_after = psutil.virtual_memory()\n",
    "process_memory_after = psutil.Process().memory_info().rss / (1024**2)\n",
    "\n",
    "print(f\"   ìµœì í™” í›„:\")\n",
    "print(f\"     - ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©: {memory_after.percent:.1f}%\")\n",
    "print(f\"     - Python í”„ë¡œì„¸ìŠ¤: {process_memory_after:.1f} MB\")\n",
    "print(f\"     - ì ˆì•½ëœ ë©”ëª¨ë¦¬: {process_memory_before - process_memory_after:.1f} MB\")\n",
    "\n",
    "available_memory_gb = memory_after.available / (1024**3)\n",
    "print(f\"   ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬: {available_memory_gb:.1f} GB\")\n",
    "\n",
    "# 2. ì•ˆì „í•œ ìƒì„± ê·œëª¨ ê³„ì‚°\n",
    "print(f\"\\nğŸ“ ì•ˆì „í•œ ìƒì„± ê·œëª¨ ê³„ì‚°:\")\n",
    "print(\"-\" * 28)\n",
    "\n",
    "# 10ë§Œê°œ ì´ë²¤íŠ¸ ê¸°ì¤€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰\n",
    "events_100k_memory_gb = events_100k.memory_usage(deep=True).sum() / (1024**3)\n",
    "events_per_gb = 100_000 / events_100k_memory_gb\n",
    "\n",
    "# ì•ˆì „ ì—¬ìœ ë¶„ì„ ê³ ë ¤í•œ ìµœëŒ€ ìƒì„± ê°€ëŠ¥ ìˆ˜ëŸ‰\n",
    "safety_factor = 0.7  # 70%ë§Œ ì‚¬ìš© (ì•ˆì „ ì—¬ìœ ë¶„ 30%)\n",
    "safe_memory_gb = available_memory_gb * safety_factor\n",
    "max_safe_events = int(safe_memory_gb * events_per_gb)\n",
    "\n",
    "print(f\"   10ë§Œê°œ ì´ë²¤íŠ¸ ë©”ëª¨ë¦¬: {events_100k_memory_gb:.3f} GB\")\n",
    "print(f\"   1GBë‹¹ ì´ë²¤íŠ¸ ìˆ˜: {events_per_gb:,.0f}ê°œ\")\n",
    "print(f\"   ì•ˆì „ ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬: {safe_memory_gb:.1f} GB\")\n",
    "print(f\"   ìµœëŒ€ ì•ˆì „ ìƒì„±ëŸ‰: {max_safe_events:,}ê°œ\")\n",
    "\n",
    "# 3. ë¶„í•  ìƒì„± ì „ëµ ì„¤ê³„\n",
    "print(f\"\\nğŸ”€ ë¶„í•  ìƒì„± ì „ëµ ì„¤ê³„:\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "target_events = 100_000_000  # 1ì–µê°œ\n",
    "batch_size = min(max_safe_events, 10_000_000)  # ìµœëŒ€ 1000ë§Œê°œ ë˜ëŠ” ì•ˆì „ ìš©ëŸ‰\n",
    "num_batches = math.ceil(target_events / batch_size)\n",
    "\n",
    "print(f\"   ëª©í‘œ: {target_events:,}ê°œ\")\n",
    "print(f\"   ë°°ì¹˜ í¬ê¸°: {batch_size:,}ê°œ\")\n",
    "print(f\"   ì´ ë°°ì¹˜ ìˆ˜: {num_batches}ê°œ\")\n",
    "print(f\"   ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {num_batches * 10}-{num_batches * 20}ë¶„\")\n",
    "\n",
    "# ê° ë°°ì¹˜ë³„ ì €ì¥ ê²½ë¡œ ì„¤ê³„\n",
    "batch_info = []\n",
    "for i in range(num_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min((i + 1) * batch_size, target_events)\n",
    "    events_in_batch = end_idx - start_idx\n",
    "    \n",
    "    batch_file = f\"event_logs/event_logs_batch_{i+1:02d}_{events_in_batch//1000000}M.parquet\"\n",
    "    batch_info.append({\n",
    "        'batch_num': i + 1,\n",
    "        'start_idx': start_idx,\n",
    "        'end_idx': end_idx,\n",
    "        'event_count': events_in_batch,\n",
    "        'file_path': batch_file\n",
    "    })\n",
    "\n",
    "print(f\"\\n   ë°°ì¹˜ë³„ ìƒì„¸ ê³„íš:\")\n",
    "for i, batch in enumerate(batch_info[:5]):  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ\n",
    "    print(f\"     ë°°ì¹˜ {batch['batch_num']}: {batch['event_count']:,}ê°œ â†’ {batch['file_path']}\")\n",
    "\n",
    "if len(batch_info) > 5:\n",
    "    print(f\"     ... ì´ {len(batch_info)}ê°œ ë°°ì¹˜\")\n",
    "\n",
    "# 4. ì‹¤ì œ ë¶„í•  ìƒì„± í•¨ìˆ˜ ì •ì˜\n",
    "print(f\"\\nâš™ï¸ ë¶„í•  ìƒì„± í•¨ìˆ˜ ì •ì˜:\")\n",
    "print(\"-\" * 22)\n",
    "\n",
    "def create_batch_events_with_monitoring(batch_num, event_count, save_path, monitor=True):\n",
    "    \"\"\"\n",
    "    ëª¨ë‹ˆí„°ë§ê³¼ í•¨ê»˜ ë°°ì¹˜ë³„ ì´ë²¤íŠ¸ ìƒì„±\n",
    "    \"\"\"\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    if monitor:\n",
    "        print(f\"\\nğŸ”„ ë°°ì¹˜ {batch_num} ì‹œì‘:\")\n",
    "        print(f\"   ì´ë²¤íŠ¸ ìˆ˜: {event_count:,}ê°œ\")\n",
    "        print(f\"   ì €ì¥ ê²½ë¡œ: {save_path}\")\n",
    "        \n",
    "        # ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\n",
    "        memory_before = psutil.virtual_memory()\n",
    "        print(f\"   ì‹œì‘ ë©”ëª¨ë¦¬: {memory_before.percent:.1f}% ì‚¬ìš©\")\n",
    "    \n",
    "    try:\n",
    "        # ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©í•˜ë˜ ì´ë²¤íŠ¸ ìˆ˜ ì¡°ì •\n",
    "        users_per_batch = min(event_count // 50, 50000)  # ì ì ˆí•œ ì‚¬ìš©ì ìˆ˜ ê³„ì‚°\n",
    "        \n",
    "        # Dask ì„¤ì • ìµœì í™”\n",
    "        from dask.distributed import Client\n",
    "        import dask\n",
    "        \n",
    "        # ë©”ëª¨ë¦¬ ì œí•œ ì„¤ì •\n",
    "        memory_limit_gb = min(available_memory_gb * 0.4, 4)  # 40% ë˜ëŠ” 4GB ì¤‘ ì‘ì€ ê°’\n",
    "        \n",
    "        with dask.config.set({'distributed.worker.memory.target': 0.8,\n",
    "                             'distributed.worker.memory.spill': 0.9,\n",
    "                             'distributed.worker.memory.pause': 0.95}):\n",
    "            \n",
    "            # ë°°ì¹˜ ìƒì„± ì‹¤í–‰\n",
    "            batch_events = create_events_optimized_batch(\n",
    "                users_per_batch=users_per_batch,\n",
    "                target_events=event_count,\n",
    "                save_path=save_path,\n",
    "                memory_limit_gb=memory_limit_gb\n",
    "            )\n",
    "        \n",
    "        # ìƒì„± í›„ ìƒíƒœ í™•ì¸\n",
    "        if monitor:\n",
    "            end_time = datetime.now()\n",
    "            duration = (end_time - start_time).total_seconds() / 60\n",
    "            \n",
    "            memory_after = psutil.virtual_memory()\n",
    "            file_size_mb = os.path.getsize(save_path) / (1024**2) if os.path.exists(save_path) else 0\n",
    "            \n",
    "            print(f\"   âœ… ë°°ì¹˜ {batch_num} ì™„ë£Œ:\")\n",
    "            print(f\"      - ì²˜ë¦¬ ì‹œê°„: {duration:.1f}ë¶„\")\n",
    "            print(f\"      - íŒŒì¼ í¬ê¸°: {file_size_mb:.1f} MB\")\n",
    "            print(f\"      - ì¢…ë£Œ ë©”ëª¨ë¦¬: {memory_after.percent:.1f}% ì‚¬ìš©\")\n",
    "            \n",
    "            # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "            gc.collect()\n",
    "            \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        if monitor:\n",
    "            print(f\"   âŒ ë°°ì¹˜ {batch_num} ì‹¤íŒ¨: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def create_events_optimized_batch(users_per_batch, target_events, save_path, memory_limit_gb=4):\n",
    "    \"\"\"\n",
    "    ë©”ëª¨ë¦¬ ìµœì í™”ëœ ë°°ì¹˜ ì´ë²¤íŠ¸ ìƒì„±\n",
    "    \"\"\"\n",
    "    from dask.distributed import Client, LocalCluster\n",
    "    \n",
    "    # í´ëŸ¬ìŠ¤í„° ì„¤ì •\n",
    "    cluster = LocalCluster(\n",
    "        n_workers=min(4, psutil.cpu_count()),\n",
    "        threads_per_worker=1,\n",
    "        memory_limit=f'{memory_limit_gb}GB',\n",
    "        processes=False  # ìŠ¤ë ˆë“œ ê¸°ë°˜ìœ¼ë¡œ ë©”ëª¨ë¦¬ ê³µìœ \n",
    "    )\n",
    "    \n",
    "    with Client(cluster) as client:\n",
    "        # ì‚¬ìš©ì ë°°ì¹˜ ì„ íƒ\n",
    "        selected_users = segmented_users_df.sample(n=users_per_batch, random_state=42)\n",
    "        \n",
    "        # ë°°ì¹˜ë³„ ì´ë²¤íŠ¸ ìƒì„±\n",
    "        events_list = []\n",
    "        batch_size_per_worker = users_per_batch // min(4, psutil.cpu_count())\n",
    "        \n",
    "        for i in range(0, users_per_batch, batch_size_per_worker):\n",
    "            end_idx = min(i + batch_size_per_worker, users_per_batch)\n",
    "            batch_users = selected_users.iloc[i:end_idx]\n",
    "            \n",
    "            # Dask delayedë¡œ ë³‘ë ¬ ì²˜ë¦¬\n",
    "            delayed_result = generate_events_batch_optimized(batch_users)\n",
    "            events_list.append(delayed_result)\n",
    "        \n",
    "        # ë³‘ë ¬ ì‹¤í–‰ ë° ê²°ê³¼ ìˆ˜ì§‘\n",
    "        computed_events = dask.compute(*events_list)\n",
    "        \n",
    "        # ë°ì´í„°í”„ë ˆì„ ë³‘í•©\n",
    "        all_events = pd.concat([events for events in computed_events if not events.empty], \n",
    "                              ignore_index=True)\n",
    "        \n",
    "        # ëª©í‘œ ì´ë²¤íŠ¸ ìˆ˜ì— ë§ê²Œ ì¡°ì •\n",
    "        if len(all_events) > target_events:\n",
    "            all_events = all_events.sample(n=target_events, random_state=42)\n",
    "        \n",
    "        # íŒŒì¼ ì €ì¥\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        all_events.to_parquet(save_path, compression='snappy', index=False)\n",
    "        \n",
    "        return all_events\n",
    "\n",
    "print(\"   âœ… ë¶„í•  ìƒì„± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "\n",
    "# 5. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê³„íš\n",
    "print(f\"\\nğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê³„íš:\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "test_batch_size = min(1_000_000, max_safe_events)  # 100ë§Œê°œ ë˜ëŠ” ì•ˆì „ ìš©ëŸ‰\n",
    "test_save_path = \"event_logs/test_batch_1M.parquet\"\n",
    "\n",
    "print(f\"   í…ŒìŠ¤íŠ¸ ë°°ì¹˜ í¬ê¸°: {test_batch_size:,}ê°œ\")\n",
    "print(f\"   í…ŒìŠ¤íŠ¸ ì €ì¥ ê²½ë¡œ: {test_save_path}\")\n",
    "print(f\"   ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©: {test_batch_size / events_per_gb:.1f} GB\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì—¬ë¶€ í™•ì¸\n",
    "should_test = available_memory_gb > 2  # 2GB ì´ìƒ ì—¬ìœ  ì‹œì—ë§Œ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "print(f\"   í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê°€ëŠ¥: {'âœ… ì˜ˆ' if should_test else 'âŒ ì•„ë‹ˆì˜¤ (ë©”ëª¨ë¦¬ ë¶€ì¡±)'}\")\n",
    "\n",
    "if should_test:\n",
    "    print(f\"\\nğŸ’¡ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ëª…ë ¹:\")\n",
    "    print(f\"   create_batch_events_with_monitoring(1, {test_batch_size:,}, '{test_save_path}')\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë¶ˆê°€\")\n",
    "    print(f\"   í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥: {available_memory_gb:.1f} GB\")\n",
    "    print(f\"   í•„ìš” ìµœì†Œ: 2.0 GB\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(f\"   1. í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ì‹¤í–‰ìœ¼ë¡œ ì„±ëŠ¥ ê²€ì¦\")\n",
    "print(f\"   2. ì„±ê³µ ì‹œ ì „ì²´ ë°°ì¹˜ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½\")\n",
    "print(f\"   3. ëª¨ë‹ˆí„°ë§ê³¼ í•¨ê»˜ ì ì§„ì  ìƒì„± ì‹¤í–‰\")\n",
    "print(f\"   4. ìµœì¢… í†µí•© ë° ê²€ì¦\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746f595a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª 100ë§Œê°œ í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ì‹¤í–‰\n",
      "========================================\n",
      "ğŸ“ í…ŒìŠ¤íŠ¸ ì„¤ì •:\n",
      "   ì´ë²¤íŠ¸ ìˆ˜: 1,000,000ê°œ\n",
      "   ì €ì¥ ê²½ë¡œ: data/event_logs/test_batch_1M.parquet\n",
      "\n",
      "ğŸ” ì‹œì‘ ì „ ì‹œìŠ¤í…œ ìƒíƒœ:\n",
      "   ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©: 60.5%\n",
      "   Python í”„ë¡œì„¸ìŠ¤: 3049.1 MB\n",
      "   ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬: 6.3 GB\n",
      "\n",
      "ğŸš€ í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ìƒì„± ì‹œì‘...\n",
      "\n",
      "ğŸ”„ ë°°ì¹˜ 1 ì‹œì‘:\n",
      "   ì´ë²¤íŠ¸ ìˆ˜: 1,000,000ê°œ\n",
      "   ì €ì¥ ê²½ë¡œ: data/event_logs/test_batch_1M.parquet\n",
      "   ì‹œì‘ ë©”ëª¨ë¦¬: 60.5% ì‚¬ìš©\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-28 01:47:14,491 - distributed.worker.memory - WARNING - Worker is at 127% memory usage. Pausing worker.  Process memory: 2.99 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 01:47:14,626 - distributed.worker.memory - WARNING - Worker is at 127% memory usage. Pausing worker.  Process memory: 2.99 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 01:47:14,727 - distributed.worker.memory - WARNING - Worker is at 127% memory usage. Pausing worker.  Process memory: 2.99 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 01:47:14,832 - distributed.worker.memory - WARNING - Worker is at 127% memory usage. Pausing worker.  Process memory: 2.99 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 01:47:14,834 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.99 GiB -- Worker memory limit: 2.35 GiB\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-7783' coro=<Client._gather.<locals>.wait() done, defined at c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\distributed\\client.py:2385> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\distributed\\client.py\", line 2394, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-7784' coro=<Client._gather.<locals>.wait() done, defined at c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\distributed\\client.py:2385> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\distributed\\client.py\", line 2394, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-7785' coro=<Client._gather.<locals>.wait() done, defined at c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\distributed\\client.py:2385> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\distributed\\client.py\", line 2394, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-7782' coro=<Client._gather.<locals>.wait() done, defined at c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\distributed\\client.py:2385> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\distributed\\client.py\", line 2394, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     34\u001b[39m start_time = datetime.now()\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     37\u001b[39m     \u001b[38;5;66;03m# í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ì‹¤í–‰\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     success = \u001b[43mcreate_batch_events_with_monitoring\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_num\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevent_count\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_event_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_save_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     end_time = datetime.now()\n\u001b[32m     46\u001b[39m     duration = (end_time - start_time).total_seconds() / \u001b[32m60\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 142\u001b[39m, in \u001b[36mcreate_batch_events_with_monitoring\u001b[39m\u001b[34m(batch_num, event_count, save_path, monitor)\u001b[39m\n\u001b[32m    135\u001b[39m memory_limit_gb = \u001b[38;5;28mmin\u001b[39m(available_memory_gb * \u001b[32m0.4\u001b[39m, \u001b[32m4\u001b[39m)  \u001b[38;5;66;03m# 40% ë˜ëŠ” 4GB ì¤‘ ì‘ì€ ê°’\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dask.config.set({\u001b[33m'\u001b[39m\u001b[33mdistributed.worker.memory.target\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.8\u001b[39m,\n\u001b[32m    138\u001b[39m                      \u001b[33m'\u001b[39m\u001b[33mdistributed.worker.memory.spill\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.9\u001b[39m,\n\u001b[32m    139\u001b[39m                      \u001b[33m'\u001b[39m\u001b[33mdistributed.worker.memory.pause\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.95\u001b[39m}):\n\u001b[32m    140\u001b[39m \n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# ë°°ì¹˜ ìƒì„± ì‹¤í–‰\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     batch_events = \u001b[43mcreate_events_optimized_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m        \u001b[49m\u001b[43musers_per_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43musers_per_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_events\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevent_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory_limit_gb\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_limit_gb\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# ìƒì„± í›„ ìƒíƒœ í™•ì¸\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m monitor:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 203\u001b[39m, in \u001b[36mcreate_events_optimized_batch\u001b[39m\u001b[34m(users_per_batch, target_events, save_path, memory_limit_gb)\u001b[39m\n\u001b[32m    200\u001b[39m     events_list.append(delayed_result)\n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# ë³‘ë ¬ ì‹¤í–‰ ë° ê²°ê³¼ ìˆ˜ì§‘\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m computed_events = \u001b[43mdask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mevents_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[38;5;66;03m# ë°ì´í„°í”„ë ˆì„ ë³‘í•©\u001b[39;00m\n\u001b[32m    206\u001b[39m all_events = pd.concat([events \u001b[38;5;28;01mfor\u001b[39;00m events \u001b[38;5;129;01min\u001b[39;00m computed_events \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m events.empty], \n\u001b[32m    207\u001b[39m                       ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\dask\\base.py:681\u001b[39m, in \u001b[36mcompute\u001b[39m\u001b[34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[39m\n\u001b[32m    678\u001b[39m     expr = expr.optimize()\n\u001b[32m    679\u001b[39m     keys = \u001b[38;5;28mlist\u001b[39m(flatten(expr.__dask_keys__()))\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m     results = \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m repack(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\threading.py:622\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    620\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\threading.py:324\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    326\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-28 01:52:14,953 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.23 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 01:57:15,058 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.31 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:07,247 - distributed.worker.memory - WARNING - Worker is at 94% memory usage. Resuming worker. Process memory: 2.22 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:07,249 - distributed.worker.memory - WARNING - Worker is at 94% memory usage. Resuming worker. Process memory: 2.22 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:07,250 - distributed.worker.memory - WARNING - Worker is at 94% memory usage. Resuming worker. Process memory: 2.22 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:07,251 - distributed.worker.memory - WARNING - Worker is at 94% memory usage. Resuming worker. Process memory: 2.22 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:13,756 - distributed.worker.memory - WARNING - Worker is at 96% memory usage. Pausing worker.  Process memory: 2.26 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:13,760 - distributed.worker.memory - WARNING - Worker is at 96% memory usage. Pausing worker.  Process memory: 2.26 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:13,763 - distributed.worker.memory - WARNING - Worker is at 96% memory usage. Pausing worker.  Process memory: 2.26 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:13,764 - distributed.worker.memory - WARNING - Worker is at 96% memory usage. Pausing worker.  Process memory: 2.26 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:14,526 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Resuming worker. Process memory: 2.03 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:14,527 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Resuming worker. Process memory: 2.03 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:14,528 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Resuming worker. Process memory: 2.03 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:14,529 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Resuming worker. Process memory: 2.03 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:15,027 - distributed.worker.memory - WARNING - Worker is at 95% memory usage. Pausing worker.  Process memory: 2.23 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:15,028 - distributed.worker.memory - WARNING - Worker is at 95% memory usage. Pausing worker.  Process memory: 2.23 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:15,030 - distributed.worker.memory - WARNING - Worker is at 95% memory usage. Pausing worker.  Process memory: 2.24 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:15,031 - distributed.worker.memory - WARNING - Worker is at 95% memory usage. Pausing worker.  Process memory: 2.24 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:15,147 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.26 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:15,764 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Resuming worker. Process memory: 2.03 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:15,765 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Resuming worker. Process memory: 2.03 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:15,766 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Resuming worker. Process memory: 2.03 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:15,767 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Resuming worker. Process memory: 2.03 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:16,327 - distributed.worker.memory - WARNING - Worker is at 95% memory usage. Pausing worker.  Process memory: 2.25 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:16,329 - distributed.worker.memory - WARNING - Worker is at 95% memory usage. Pausing worker.  Process memory: 2.25 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:16,329 - distributed.worker.memory - WARNING - Worker is at 95% memory usage. Pausing worker.  Process memory: 2.25 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:16,331 - distributed.worker.memory - WARNING - Worker is at 95% memory usage. Pausing worker.  Process memory: 2.25 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:16,650 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Resuming worker. Process memory: 2.02 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:16,651 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Resuming worker. Process memory: 2.02 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:16,652 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Resuming worker. Process memory: 2.02 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:16,653 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Resuming worker. Process memory: 2.02 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:17,147 - distributed.worker.memory - WARNING - Worker is at 97% memory usage. Pausing worker.  Process memory: 2.28 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:17,148 - distributed.worker.memory - WARNING - Worker is at 97% memory usage. Pausing worker.  Process memory: 2.29 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:17,149 - distributed.worker.memory - WARNING - Worker is at 97% memory usage. Pausing worker.  Process memory: 2.29 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:17,154 - distributed.worker.memory - WARNING - Worker is at 97% memory usage. Pausing worker.  Process memory: 2.29 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:18,157 - distributed.worker.memory - WARNING - Worker is at 89% memory usage. Resuming worker. Process memory: 2.10 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:18,329 - distributed.worker.memory - WARNING - Worker is at 91% memory usage. Resuming worker. Process memory: 2.16 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:18,336 - distributed.worker.memory - WARNING - Worker is at 91% memory usage. Resuming worker. Process memory: 2.16 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:18,431 - distributed.worker.memory - WARNING - Worker is at 92% memory usage. Resuming worker. Process memory: 2.18 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:18,675 - distributed.worker.memory - WARNING - Worker is at 95% memory usage. Pausing worker.  Process memory: 2.24 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:18,839 - distributed.worker.memory - WARNING - Worker is at 98% memory usage. Pausing worker.  Process memory: 2.30 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:19,033 - distributed.worker.memory - WARNING - Worker is at 103% memory usage. Pausing worker.  Process memory: 2.42 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:19,115 - distributed.worker.memory - WARNING - Worker is at 105% memory usage. Pausing worker.  Process memory: 2.48 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:31,880 - distributed.worker.memory - WARNING - Worker is at 85% memory usage. Resuming worker. Process memory: 2.01 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:31,881 - distributed.worker.memory - WARNING - Worker is at 85% memory usage. Resuming worker. Process memory: 2.01 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:31,882 - distributed.worker.memory - WARNING - Worker is at 85% memory usage. Resuming worker. Process memory: 2.01 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:02:31,883 - distributed.worker.memory - WARNING - Worker is at 85% memory usage. Resuming worker. Process memory: 2.01 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:04:20,333 - distributed.worker.memory - WARNING - Worker is at 95% memory usage. Pausing worker.  Process memory: 2.24 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:04:20,490 - distributed.worker.memory - WARNING - Worker is at 96% memory usage. Pausing worker.  Process memory: 2.26 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:04:21,190 - distributed.worker.memory - WARNING - Worker is at 104% memory usage. Pausing worker.  Process memory: 2.44 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:04:21,406 - distributed.worker.memory - WARNING - Worker is at 104% memory usage. Pausing worker.  Process memory: 2.46 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:07:15,149 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.76 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:12:15,255 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.33 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:13:40,428 - distributed.worker.memory - WARNING - Worker is at 94% memory usage. Resuming worker. Process memory: 2.22 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:13:40,429 - distributed.worker.memory - WARNING - Worker is at 94% memory usage. Resuming worker. Process memory: 2.22 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:13:40,431 - distributed.worker.memory - WARNING - Worker is at 94% memory usage. Resuming worker. Process memory: 2.22 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:13:40,431 - distributed.worker.memory - WARNING - Worker is at 94% memory usage. Resuming worker. Process memory: 2.22 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:15:01,239 - distributed.worker.memory - WARNING - Worker is at 95% memory usage. Pausing worker.  Process memory: 2.23 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:15:01,381 - distributed.worker.memory - WARNING - Worker is at 95% memory usage. Pausing worker.  Process memory: 2.23 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:15:01,426 - distributed.worker.memory - WARNING - Worker is at 94% memory usage. Resuming worker. Process memory: 2.23 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:15:01,427 - distributed.worker.memory - WARNING - Worker is at 94% memory usage. Resuming worker. Process memory: 2.23 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:15:01,545 - distributed.worker.memory - WARNING - Worker is at 95% memory usage. Pausing worker.  Process memory: 2.23 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:15:01,546 - distributed.worker.memory - WARNING - Worker is at 95% memory usage. Pausing worker.  Process memory: 2.23 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:15:01,904 - distributed.worker.memory - WARNING - Worker is at 95% memory usage. Pausing worker.  Process memory: 2.23 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:15:01,943 - distributed.worker.memory - WARNING - Worker is at 94% memory usage. Resuming worker. Process memory: 2.22 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:15:01,944 - distributed.worker.memory - WARNING - Worker is at 94% memory usage. Resuming worker. Process memory: 2.22 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:15:01,949 - distributed.worker.memory - WARNING - Worker is at 94% memory usage. Resuming worker. Process memory: 2.22 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:15:03,140 - distributed.worker.memory - WARNING - Worker is at 95% memory usage. Pausing worker.  Process memory: 2.23 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:15:03,143 - distributed.worker.memory - WARNING - Worker is at 95% memory usage. Pausing worker.  Process memory: 2.23 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:15:03,143 - distributed.worker.memory - WARNING - Worker is at 95% memory usage. Pausing worker.  Process memory: 2.23 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:15:03,144 - distributed.worker.memory - WARNING - Worker is at 95% memory usage. Pausing worker.  Process memory: 2.23 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:17:15,274 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.01 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:21:57,027 - distributed.worker.memory - WARNING - Worker is at 93% memory usage. Resuming worker. Process memory: 2.19 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:21:57,029 - distributed.worker.memory - WARNING - Worker is at 93% memory usage. Resuming worker. Process memory: 2.19 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:21:57,030 - distributed.worker.memory - WARNING - Worker is at 93% memory usage. Resuming worker. Process memory: 2.19 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:21:57,031 - distributed.worker.memory - WARNING - Worker is at 93% memory usage. Resuming worker. Process memory: 2.19 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:21:59,150 - distributed.worker.memory - WARNING - Worker is at 96% memory usage. Pausing worker.  Process memory: 2.26 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:21:59,151 - distributed.worker.memory - WARNING - Worker is at 96% memory usage. Pausing worker.  Process memory: 2.26 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:21:59,152 - distributed.worker.memory - WARNING - Worker is at 96% memory usage. Pausing worker.  Process memory: 2.26 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:21:59,153 - distributed.worker.memory - WARNING - Worker is at 96% memory usage. Pausing worker.  Process memory: 2.26 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:22:15,619 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.99 GiB -- Worker memory limit: 2.35 GiB\n",
      "2025-07-28 02:27:29,820 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.63 GiB -- Worker memory limit: 2.35 GiB\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ§ª 100ë§Œê°œ í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ì‹¤í–‰\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸ§ª 100ë§Œê°œ í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ì‹¤í–‰\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ì„¤ì •\n",
    "test_event_count = 1_000_000\n",
    "test_save_path = \"data/event_logs/test_batch_1M.parquet\"\n",
    "\n",
    "print(f\"ğŸ“ í…ŒìŠ¤íŠ¸ ì„¤ì •:\")\n",
    "print(f\"   ì´ë²¤íŠ¸ ìˆ˜: {test_event_count:,}ê°œ\")\n",
    "print(f\"   ì €ì¥ ê²½ë¡œ: {test_save_path}\")\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "import os\n",
    "os.makedirs(os.path.dirname(test_save_path), exist_ok=True)\n",
    "\n",
    "# ì‹œì‘ ì „ ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\n",
    "import psutil\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "memory_start = psutil.virtual_memory()\n",
    "process_start = psutil.Process().memory_info().rss / (1024**2)\n",
    "\n",
    "print(f\"\\nğŸ” ì‹œì‘ ì „ ì‹œìŠ¤í…œ ìƒíƒœ:\")\n",
    "print(f\"   ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©: {memory_start.percent:.1f}%\")\n",
    "print(f\"   Python í”„ë¡œì„¸ìŠ¤: {process_start:.1f} MB\")\n",
    "print(f\"   ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬: {memory_start.available / (1024**3):.1f} GB\")\n",
    "\n",
    "print(f\"\\nğŸš€ í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ìƒì„± ì‹œì‘...\")\n",
    "start_time = datetime.now()\n",
    "\n",
    "try:\n",
    "    # í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ì‹¤í–‰\n",
    "    success = create_batch_events_with_monitoring(\n",
    "        batch_num=1, \n",
    "        event_count=test_event_count, \n",
    "        save_path=test_save_path,\n",
    "        monitor=True\n",
    "    )\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    duration = (end_time - start_time).total_seconds() / 60\n",
    "    \n",
    "    if success:\n",
    "        print(f\"\\nâœ… í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ìƒì„± ì„±ê³µ!\")\n",
    "        print(f\"   ì´ ì²˜ë¦¬ ì‹œê°„: {duration:.2f}ë¶„\")\n",
    "        \n",
    "        # ìƒì„±ëœ íŒŒì¼ ê²€ì¦\n",
    "        if os.path.exists(test_save_path):\n",
    "            file_size_mb = os.path.getsize(test_save_path) / (1024**2)\n",
    "            print(f\"   íŒŒì¼ í¬ê¸°: {file_size_mb:.1f} MB\")\n",
    "            \n",
    "            # íŒŒì¼ ë‚´ìš© ê²€ì¦\n",
    "            import pandas as pd\n",
    "            test_events = pd.read_parquet(test_save_path)\n",
    "            \n",
    "            print(f\"\\nğŸ“Š ìƒì„±ëœ ë°ì´í„° ê²€ì¦:\")\n",
    "            print(f\"   ì´ ì´ë²¤íŠ¸ ìˆ˜: {len(test_events):,}ê°œ\")\n",
    "            print(f\"   ìœ ë‹ˆí¬ ì‚¬ìš©ì: {test_events['user_id'].nunique():,}ëª…\")\n",
    "            print(f\"   ì´ë²¤íŠ¸ íƒ€ì… ì¢…ë¥˜: {test_events['event_type'].nunique()}ê°œ\")\n",
    "            print(f\"   ë‚ ì§œ ë²”ìœ„: {test_events['timestamp'].min()} ~ {test_events['timestamp'].max()}\")\n",
    "            \n",
    "            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„\n",
    "            memory_usage = test_events.memory_usage(deep=True).sum() / (1024**2)\n",
    "            print(f\"   ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_usage:.1f} MB\")\n",
    "            \n",
    "            # ì••ì¶• íš¨ìœ¨ì„±\n",
    "            compression_ratio = file_size_mb / memory_usage\n",
    "            print(f\"   ì••ì¶• íš¨ìœ¨: {compression_ratio:.1%}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"   âŒ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {test_save_path}\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"\\nâŒ í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ìƒì„± ì‹¤íŒ¨\")\n",
    "        print(f\"   ì²˜ë¦¬ ì‹œê°„: {duration:.2f}ë¶„\")\n",
    "        \n",
    "except Exception as e:\n",
    "    end_time = datetime.now()\n",
    "    duration = (end_time - start_time).total_seconds() / 60\n",
    "    print(f\"\\nğŸ’¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:\")\n",
    "    print(f\"   ì˜¤ë¥˜: {str(e)}\")\n",
    "    print(f\"   ê²½ê³¼ ì‹œê°„: {duration:.2f}ë¶„\")\n",
    "\n",
    "# ìµœì¢… ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\n",
    "memory_end = psutil.virtual_memory()\n",
    "process_end = psutil.Process().memory_info().rss / (1024**2)\n",
    "\n",
    "print(f\"\\nğŸ” ì¢…ë£Œ í›„ ì‹œìŠ¤í…œ ìƒíƒœ:\")\n",
    "print(f\"   ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©: {memory_end.percent:.1f}%\")\n",
    "print(f\"   Python í”„ë¡œì„¸ìŠ¤: {process_end:.1f} MB\")\n",
    "print(f\"   ë©”ëª¨ë¦¬ ì¦ê°: {process_end - process_start:+.1f} MB\")\n",
    "\n",
    "# ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\nğŸ¯ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:\")\n",
    "if 'success' in locals() and success:\n",
    "    print(f\"   âœ… 100ë§Œê°œ í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ì„±ê³µ!\")\n",
    "    print(f\"   ğŸ“ˆ 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„±: ë§¤ìš° ë†’ìŒ\")\n",
    "    print(f\"   â±ï¸ ì˜ˆìƒ ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {duration * 24:.1f}ë¶„ (ì•½ {duration * 24 / 60:.1f}ì‹œê°„)\")\n",
    "else:\n",
    "    print(f\"   âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - ì„¤ì • ì¡°ì • í•„ìš”\")\n",
    "    print(f\"   ğŸ”§ ê¶Œì¥: ë°°ì¹˜ í¬ê¸° ì¶•ì†Œ í›„ ì¬ì‹œë„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7939cf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ ë©”ëª¨ë¦¬ ë¶€ì¡± ë¬¸ì œ ê°ì§€!\n",
      "========================================\n",
      "í˜„ì¬ ìƒí™©:\n",
      "  - Worker memory limit: 2.01 GiB\n",
      "  - Actual usage: 3.05 GiB (151%)\n",
      "  - Status: ì›Œì»¤ ì¼ì‹œ ì •ì§€\n",
      "\n",
      "ğŸ›‘ ê¶Œì¥ ì¡°ì¹˜: ì‹¤í–‰ ì¤‘ë‹¨ í›„ ì„¤ì • ì¡°ì • í•„ìš”\n"
     ]
    }
   ],
   "source": [
    "# âš ï¸ STOP: í˜„ì¬ ì‹¤í–‰ ì¤‘ë‹¨ í•„ìš”!\n",
    "# ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ Dask ì›Œì»¤ê°€ ì¼ì‹œ ì •ì§€ëœ ìƒíƒœì…ë‹ˆë‹¤.\n",
    "\n",
    "print(\"âš ï¸ ë©”ëª¨ë¦¬ ë¶€ì¡± ë¬¸ì œ ê°ì§€!\")\n",
    "print(\"=\" * 40)\n",
    "print(\"í˜„ì¬ ìƒí™©:\")\n",
    "print(\"  - Worker memory limit: 2.01 GiB\")\n",
    "print(\"  - Actual usage: 3.05 GiB (151%)\")\n",
    "print(\"  - Status: ì›Œì»¤ ì¼ì‹œ ì •ì§€\")\n",
    "print()\n",
    "print(\"ğŸ›‘ ê¶Œì¥ ì¡°ì¹˜: ì‹¤í–‰ ì¤‘ë‹¨ í›„ ì„¤ì • ì¡°ì • í•„ìš”\")\n",
    "\n",
    "# í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì…€ì„ ì¤‘ë‹¨í•´ì£¼ì„¸ìš”!\n",
    "# Kernel > Interrupt ë˜ëŠ” Stop ë²„íŠ¼ í´ë¦­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "776f691b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ë©”ëª¨ë¦¬ ìµœì í™”ëœ Dask ë³‘ë ¬ì²˜ë¦¬ ì‹œìŠ¤í…œ\n",
      "==================================================\n",
      "ğŸ” ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸:\n",
      "   ì´ ë©”ëª¨ë¦¬: 16.0 GB\n",
      "   ì‚¬ìš© ê°€ëŠ¥: 6.4 GB\n",
      "   CPU ì½”ì–´: 6ê°œ\n",
      "\n",
      "âš™ï¸ Dask í´ëŸ¬ìŠ¤í„° ìµœì í™” ì„¤ì •:\n",
      "   ì›Œì»¤ ìˆ˜: 3ê°œ\n",
      "   ì›Œì»¤ë‹¹ ë©”ëª¨ë¦¬ ì œí•œ: 3.2 GB\n",
      "   ì´ ì›Œì»¤ ë©”ëª¨ë¦¬: 9.6 GB\n",
      "\n",
      "ğŸ“… ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„ í™•ì¸:\n",
      "   ì‹œì‘ì¼: 2025-07-01 00:00:00+09:00\n",
      "   ì¢…ë£Œì¼: 2025-07-31 23:59:59+09:00\n",
      "   ì´ ì¼ìˆ˜: 31ì¼\n",
      "\n",
      "ğŸ¯ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì „ëµ:\n",
      "   ëª©í‘œ ì´ ì´ë²¤íŠ¸: 100,000,000ê°œ\n",
      "   ë°°ì¹˜ë‹¹ ì´ë²¤íŠ¸: 2,000,000ê°œ\n",
      "   ì´ ë°°ì¹˜ ìˆ˜: 50ê°œ\n",
      "   ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: 400-750ë¶„\n",
      "\n",
      "ğŸ“‹ ë°°ì¹˜ ì‹¤í–‰ ê³„íš:\n",
      "   ë°°ì¹˜ 1: 2,000,000ê°œ â†’ data/event_logs/events_batch_01_2M.parquet\n",
      "   ë°°ì¹˜ 2: 2,000,000ê°œ â†’ data/event_logs/events_batch_02_2M.parquet\n",
      "   ë°°ì¹˜ 3: 2,000,000ê°œ â†’ data/event_logs/events_batch_03_2M.parquet\n",
      "   ë°°ì¹˜ 4: 2,000,000ê°œ â†’ data/event_logs/events_batch_04_2M.parquet\n",
      "   ë°°ì¹˜ 5: 2,000,000ê°œ â†’ data/event_logs/events_batch_05_2M.parquet\n",
      "   ... ì´ 50ê°œ ë°°ì¹˜\n",
      "\n",
      "ğŸš€ ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ!\n",
      "ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„: ì²« ë²ˆì§¸ ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
      "\n",
      "ğŸ§ª ì²« ë²ˆì§¸ ë°°ì¹˜ í…ŒìŠ¤íŠ¸:\n",
      "   ëª…ë ¹ì–´:\n",
      "   result = create_optimized_dask_batch(\n",
      "       batch_num=1,\n",
      "       events_count=2000000,\n",
      "       save_path='data/event_logs/events_batch_01_2M.parquet',\n",
      "       start_date=SIMULATION_START_DATE,\n",
      "       end_date=SIMULATION_END_DATE\n",
      "   )\n",
      "\n",
      "âœ… ë©”ëª¨ë¦¬ ìƒíƒœ ì–‘í˜¸ (59.7%) - í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê°€ëŠ¥\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸš€ ë©”ëª¨ë¦¬ ìµœì í™”ëœ Dask ë³‘ë ¬ì²˜ë¦¬ë¡œ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„±\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸš€ ë©”ëª¨ë¦¬ ìµœì í™”ëœ Dask ë³‘ë ¬ì²˜ë¦¬ ì‹œìŠ¤í…œ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import gc\n",
    "import psutil\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import math\n",
    "\n",
    "# 1. í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸\n",
    "print(\"ğŸ” ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸:\")\n",
    "memory_info = psutil.virtual_memory()\n",
    "print(f\"   ì´ ë©”ëª¨ë¦¬: {memory_info.total / (1024**3):.1f} GB\")\n",
    "print(f\"   ì‚¬ìš© ê°€ëŠ¥: {memory_info.available / (1024**3):.1f} GB\")\n",
    "print(f\"   CPU ì½”ì–´: {psutil.cpu_count()}ê°œ\")\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "gc.collect()\n",
    "\n",
    "# 2. ìµœì í™”ëœ Dask ì„¤ì •\n",
    "print(f\"\\nâš™ï¸ Dask í´ëŸ¬ìŠ¤í„° ìµœì í™” ì„¤ì •:\")\n",
    "\n",
    "# ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ì˜ 60%ë¥¼ ì›Œì»¤ë“¤ì´ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì • (ì•ˆì „ ì—¬ìœ ë¶„ í™•ë³´)\n",
    "available_memory_gb = memory_info.available / (1024**3)\n",
    "worker_memory_limit = max(3, available_memory_gb * 0.5)  # ìµœì†Œ 3GB, ìµœëŒ€ 50%\n",
    "n_workers = min(3, psutil.cpu_count())  # ìµœëŒ€ 3ê°œ ì›Œì»¤ë¡œ ì¶•ì†Œ\n",
    "\n",
    "print(f\"   ì›Œì»¤ ìˆ˜: {n_workers}ê°œ\")\n",
    "print(f\"   ì›Œì»¤ë‹¹ ë©”ëª¨ë¦¬ ì œí•œ: {worker_memory_limit:.1f} GB\")\n",
    "print(f\"   ì´ ì›Œì»¤ ë©”ëª¨ë¦¬: {worker_memory_limit * n_workers:.1f} GB\")\n",
    "\n",
    "# 3. 2025ë…„ 7ì›” ì „ì²´ ê¸°ê°„ ì„¤ì • í™•ì¸\n",
    "print(f\"\\nğŸ“… ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„ í™•ì¸:\")\n",
    "print(f\"   ì‹œì‘ì¼: {SIMULATION_START_DATE}\")\n",
    "print(f\"   ì¢…ë£Œì¼: {SIMULATION_END_DATE}\")\n",
    "\n",
    "total_days = (SIMULATION_END_DATE - SIMULATION_START_DATE).days + 1\n",
    "print(f\"   ì´ ì¼ìˆ˜: {total_days}ì¼\")\n",
    "\n",
    "# 4. 1ì–µê°œ ì´ë²¤íŠ¸ ë¶„í•  ì „ëµ (ë©”ëª¨ë¦¬ ìµœì í™”)\n",
    "target_total_events = 100_000_000\n",
    "print(f\"\\nğŸ¯ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì „ëµ:\")\n",
    "print(f\"   ëª©í‘œ ì´ ì´ë²¤íŠ¸: {target_total_events:,}ê°œ\")\n",
    "\n",
    "# ë³´ìˆ˜ì ì¸ ë°°ì¹˜ í¬ê¸° ê³„ì‚°\n",
    "safe_events_per_batch = 2_000_000  # 200ë§Œê°œë¡œ ì•ˆì „í•˜ê²Œ ì„¤ì •\n",
    "num_batches = math.ceil(target_total_events / safe_events_per_batch)\n",
    "\n",
    "print(f\"   ë°°ì¹˜ë‹¹ ì´ë²¤íŠ¸: {safe_events_per_batch:,}ê°œ\")\n",
    "print(f\"   ì´ ë°°ì¹˜ ìˆ˜: {num_batches}ê°œ\")\n",
    "print(f\"   ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {num_batches * 8}-{num_batches * 15}ë¶„\")\n",
    "\n",
    "# 5. ê°œì„ ëœ ë°°ì¹˜ ìƒì„± í•¨ìˆ˜ (ë©”ëª¨ë¦¬ ìµœì í™”)\n",
    "def create_optimized_dask_batch(batch_num, events_count, save_path, start_date, end_date):\n",
    "    \"\"\"\n",
    "    ë©”ëª¨ë¦¬ ìµœì í™”ëœ Dask ë°°ì¹˜ ì´ë²¤íŠ¸ ìƒì„±\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ”„ ë°°ì¹˜ {batch_num} ì‹œì‘ (ì´ë²¤íŠ¸: {events_count:,}ê°œ)\")\n",
    "    \n",
    "    try:\n",
    "        # Dask í´ëŸ¬ìŠ¤í„° ì„¤ì • (ë³´ìˆ˜ì  ë©”ëª¨ë¦¬ ê´€ë¦¬)\n",
    "        cluster = LocalCluster(\n",
    "            n_workers=n_workers,\n",
    "            threads_per_worker=1,\n",
    "            memory_limit=f'{worker_memory_limit}GB',\n",
    "            processes=True,  # í”„ë¡œì„¸ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ë©”ëª¨ë¦¬ ê²©ë¦¬\n",
    "            dashboard_address=None,  # ëŒ€ì‹œë³´ë“œ ë¹„í™œì„±í™”\n",
    "        )\n",
    "        \n",
    "        with Client(cluster) as client:\n",
    "            print(f\"   Dask í´ëŸ¬ìŠ¤í„° í™œì„±í™”: {n_workers}ê°œ ì›Œì»¤\")\n",
    "            \n",
    "            # ì‚¬ìš©ì ì„ íƒ (ë³´ìˆ˜ì  ê³„ì‚°)\n",
    "            users_needed = min(events_count // 60, 30000)  # ì´ë²¤íŠ¸ë‹¹ 60ê°œ ê¸°ì¤€, ìµœëŒ€ 3ë§Œëª…\n",
    "            \n",
    "            # ë°°ì¹˜ë³„ë¡œ ë‹¤ë¥¸ ì‹œë“œ ì‚¬ìš©\n",
    "            random_seed = 42 + batch_num\n",
    "            selected_users = segmented_users_df.sample(n=users_needed, random_state=random_seed)\n",
    "            \n",
    "            print(f\"   ì„ íƒëœ ì‚¬ìš©ì: {users_needed:,}ëª…\")\n",
    "            \n",
    "            # ì‚¬ìš©ìë¥¼ ì‘ì€ ì²­í¬ë¡œ ë¶„í• \n",
    "            chunk_size = max(500, users_needed // (n_workers * 3))  # ë” ì‘ì€ ì²­í¬\n",
    "            user_chunks = [selected_users.iloc[i:i+chunk_size] \n",
    "                          for i in range(0, len(selected_users), chunk_size)]\n",
    "            \n",
    "            print(f\"   ì‚¬ìš©ì ì²­í¬: {len(user_chunks)}ê°œ (ì²­í¬ë‹¹ ~{chunk_size}ëª…)\")\n",
    "            \n",
    "            # ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰\n",
    "            delayed_results = []\n",
    "            for chunk_idx, user_chunk in enumerate(user_chunks):\n",
    "                delayed_result = generate_events_batch_optimized(user_chunk)\n",
    "                delayed_results.append(delayed_result)\n",
    "            \n",
    "            # ê²°ê³¼ ìˆ˜ì§‘\n",
    "            print(f\"   ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰ ì¤‘...\")\n",
    "            computed_results = dask.compute(*delayed_results)\n",
    "            \n",
    "            # ë°ì´í„° ë³‘í•©\n",
    "            valid_results = [df for df in computed_results if not df.empty]\n",
    "            if valid_results:\n",
    "                all_events = pd.concat(valid_results, ignore_index=True)\n",
    "                \n",
    "                # ëª©í‘œ ì´ë²¤íŠ¸ ìˆ˜ì— ë§ê²Œ ì¡°ì •\n",
    "                if len(all_events) > events_count:\n",
    "                    all_events = all_events.sample(n=events_count, random_state=random_seed)\n",
    "                elif len(all_events) < events_count * 0.7:  # 70% ë¯¸ë§Œì´ë©´ ë¶€ì¡±\n",
    "                    print(f\"   âš ï¸ ì´ë²¤íŠ¸ ë¶€ì¡±: {len(all_events):,}ê°œ ìƒì„±ë¨\")\n",
    "                \n",
    "                # ë‚ ì§œ ë²”ìœ„ ì¡°ì • (2025ë…„ 7ì›” ì „ì²´)\n",
    "                all_events = adjust_timestamps_to_date_range(all_events, start_date, end_date)\n",
    "                \n",
    "                # íŒŒì¼ ì €ì¥\n",
    "                os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "                all_events.to_parquet(save_path, compression='snappy', index=False)\n",
    "                \n",
    "                file_size = os.path.getsize(save_path) / (1024**2)\n",
    "                print(f\"   âœ… ë°°ì¹˜ {batch_num} ì™„ë£Œ: {len(all_events):,}ê°œ, {file_size:.1f}MB\")\n",
    "                \n",
    "                return len(all_events)\n",
    "            else:\n",
    "                print(f\"   âŒ ë°°ì¹˜ {batch_num}: ìœ íš¨í•œ ê²°ê³¼ ì—†ìŒ\")\n",
    "                return 0\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"   ğŸ’¥ ë°°ì¹˜ {batch_num} ì˜¤ë¥˜: {str(e)}\")\n",
    "        return 0\n",
    "    finally:\n",
    "        # í´ëŸ¬ìŠ¤í„° ì •ë¦¬\n",
    "        if 'cluster' in locals():\n",
    "            cluster.close()\n",
    "        gc.collect()\n",
    "\n",
    "def adjust_timestamps_to_date_range(events_df, start_date, end_date):\n",
    "    \"\"\"\n",
    "    ì´ë²¤íŠ¸ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì§€ì •ëœ ë‚ ì§œ ë²”ìœ„ë¡œ ì¡°ì •\n",
    "    \"\"\"\n",
    "    if events_df.empty:\n",
    "        return events_df\n",
    "    \n",
    "    # í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„ ë²”ìœ„\n",
    "    current_min = pd.to_datetime(events_df['timestamp']).min()\n",
    "    current_max = pd.to_datetime(events_df['timestamp']).max()\n",
    "    current_range = (current_max - current_min).total_seconds()\n",
    "    \n",
    "    # ëª©í‘œ ë²”ìœ„\n",
    "    target_range = (end_date - start_date).total_seconds()\n",
    "    \n",
    "    if current_range > 0:\n",
    "        # ë¹„ë¡€ ì¡°ì •\n",
    "        events_df = events_df.copy()\n",
    "        timestamps = pd.to_datetime(events_df['timestamp'])\n",
    "        \n",
    "        # ì •ê·œí™” (0-1 ë²”ìœ„)\n",
    "        normalized = (timestamps - current_min).dt.total_seconds() / current_range\n",
    "        \n",
    "        # ëª©í‘œ ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§\n",
    "        new_timestamps = start_date + pd.to_timedelta(normalized * target_range, unit='s')\n",
    "        \n",
    "        events_df['timestamp'] = new_timestamps\n",
    "    \n",
    "    return events_df\n",
    "\n",
    "# 6. ë°°ì¹˜ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½\n",
    "print(f\"\\nğŸ“‹ ë°°ì¹˜ ì‹¤í–‰ ê³„íš:\")\n",
    "batch_plans = []\n",
    "\n",
    "for i in range(num_batches):\n",
    "    events_in_batch = min(safe_events_per_batch, target_total_events - (i * safe_events_per_batch))\n",
    "    if events_in_batch <= 0:\n",
    "        break\n",
    "        \n",
    "    batch_save_path = f\"data/event_logs/events_batch_{i+1:02d}_{events_in_batch//1000000}M.parquet\"\n",
    "    \n",
    "    batch_plans.append({\n",
    "        'batch_num': i + 1,\n",
    "        'events_count': events_in_batch,\n",
    "        'save_path': batch_save_path\n",
    "    })\n",
    "\n",
    "# ì²˜ìŒ 5ê°œ ë°°ì¹˜ë§Œ í‘œì‹œ\n",
    "for i, plan in enumerate(batch_plans[:5]):\n",
    "    print(f\"   ë°°ì¹˜ {plan['batch_num']}: {plan['events_count']:,}ê°œ â†’ {plan['save_path']}\")\n",
    "\n",
    "if len(batch_plans) > 5:\n",
    "    print(f\"   ... ì´ {len(batch_plans)}ê°œ ë°°ì¹˜\")\n",
    "\n",
    "print(f\"\\nğŸš€ ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„: ì²« ë²ˆì§¸ ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\")\n",
    "\n",
    "# 7. ì²« ë²ˆì§¸ ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ì œì•ˆ\n",
    "if len(batch_plans) > 0:\n",
    "    first_batch = batch_plans[0]\n",
    "    print(f\"\\nğŸ§ª ì²« ë²ˆì§¸ ë°°ì¹˜ í…ŒìŠ¤íŠ¸:\")\n",
    "    print(f\"   ëª…ë ¹ì–´:\")\n",
    "    print(f\"   result = create_optimized_dask_batch(\")\n",
    "    print(f\"       batch_num={first_batch['batch_num']},\")\n",
    "    print(f\"       events_count={first_batch['events_count']},\")\n",
    "    print(f\"       save_path='{first_batch['save_path']}',\")\n",
    "    print(f\"       start_date=SIMULATION_START_DATE,\")\n",
    "    print(f\"       end_date=SIMULATION_END_DATE\")\n",
    "    print(f\"   )\")\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ì—¬ìœ  í™•ì¸\n",
    "    current_memory = psutil.virtual_memory().percent\n",
    "    if current_memory < 70:\n",
    "        print(f\"\\nâœ… ë©”ëª¨ë¦¬ ìƒíƒœ ì–‘í˜¸ ({current_memory:.1f}%) - í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê°€ëŠ¥\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ ({current_memory:.1f}%) - ì»¤ë„ ì¬ì‹œì‘ ê¶Œì¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccc23c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Daskë¡œ 100ë§Œê°œ ì‹œí—˜ ìƒì„± ì‹œì‘\n",
      "=============================================\n",
      "ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ìƒíƒœ í™•ì¸:\n",
      "   í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©: 59.3%\n",
      "   ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬: 6.5 GB\n",
      "\n",
      "âš™ï¸ 100ë§Œê°œ ì‹œí—˜ìš© Dask ì„¤ì •:\n",
      "   ì›Œì»¤ ìˆ˜: 2ê°œ\n",
      "   ì›Œì»¤ë‹¹ ë©”ëª¨ë¦¬: 2.5 GB\n",
      "   ì´ í• ë‹¹ ë©”ëª¨ë¦¬: 5.0 GB\n",
      "\n",
      "âœ… ë©”ëª¨ë¦¬ ìƒíƒœ ì–‘í˜¸ (59.3%)\n",
      "ğŸš€ ì‹œí—˜ ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ!\n",
      "\n",
      "ğŸ“ ì‹¤í–‰ ëª…ë ¹ì–´:\n",
      "test_result = test_1m_events_with_dask()\n",
      "\n",
      "ğŸ’¡ ì´ í…ŒìŠ¤íŠ¸ë¡œ 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„±ì„ ì •í™•íˆ íŒë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ§ª Daskë¡œ 100ë§Œê°œ ì‹œí—˜ ìƒì„± (1ì–µê°œ ì‚¬ì „ í…ŒìŠ¤íŠ¸)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸ§ª Daskë¡œ 100ë§Œê°œ ì‹œí—˜ ìƒì„± ì‹œì‘\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "import gc\n",
    "import psutil\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "# 1. ë©”ëª¨ë¦¬ ì •ë¦¬ ë° í˜„ì¬ ìƒíƒœ í™•ì¸\n",
    "print(\"ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ìƒíƒœ í™•ì¸:\")\n",
    "gc.collect()\n",
    "\n",
    "memory_info = psutil.virtual_memory()\n",
    "print(f\"   í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©: {memory_info.percent:.1f}%\")\n",
    "print(f\"   ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬: {memory_info.available / (1024**3):.1f} GB\")\n",
    "\n",
    "# 2. 100ë§Œê°œ ì‹œí—˜ìš© ë³´ìˆ˜ì  Dask ì„¤ì •\n",
    "print(f\"\\nâš™ï¸ 100ë§Œê°œ ì‹œí—˜ìš© Dask ì„¤ì •:\")\n",
    "\n",
    "# ë³´ìˆ˜ì  ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "available_gb = memory_info.available / (1024**3)\n",
    "worker_memory = min(2.5, available_gb * 0.4)  # ìµœëŒ€ 2.5GB ë˜ëŠ” 40%\n",
    "n_workers = min(2, psutil.cpu_count())  # ìµœëŒ€ 2ê°œ ì›Œì»¤\n",
    "\n",
    "print(f\"   ì›Œì»¤ ìˆ˜: {n_workers}ê°œ\")\n",
    "print(f\"   ì›Œì»¤ë‹¹ ë©”ëª¨ë¦¬: {worker_memory:.1f} GB\")\n",
    "print(f\"   ì´ í• ë‹¹ ë©”ëª¨ë¦¬: {worker_memory * n_workers:.1f} GB\")\n",
    "\n",
    "# 3. 100ë§Œê°œ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ ì •ì˜\n",
    "def test_1m_events_with_dask():\n",
    "    \"\"\"\n",
    "    Daskë¡œ 100ë§Œê°œ ì´ë²¤íŠ¸ ì‹œí—˜ ìƒì„±\n",
    "    \"\"\"\n",
    "    test_events_count = 1_000_000\n",
    "    test_save_path = \"data/event_logs/test_1M_events.parquet\"\n",
    "    \n",
    "    print(f\"\\nğŸ¯ ì‹œí—˜ ì„¤ì •:\")\n",
    "    print(f\"   ëª©í‘œ ì´ë²¤íŠ¸: {test_events_count:,}ê°œ\")\n",
    "    print(f\"   ì €ì¥ ê²½ë¡œ: {test_save_path}\")\n",
    "    print(f\"   ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„: {SIMULATION_START_DATE} ~ {SIMULATION_END_DATE}\")\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        # Dask í´ëŸ¬ìŠ¤í„° ìƒì„± (ë³´ìˆ˜ì  ì„¤ì •)\n",
    "        cluster = LocalCluster(\n",
    "            n_workers=n_workers,\n",
    "            threads_per_worker=1,\n",
    "            memory_limit=f'{worker_memory}GB',\n",
    "            processes=True,  # ë©”ëª¨ë¦¬ ê²©ë¦¬\n",
    "            dashboard_address=None,  # ëŒ€ì‹œë³´ë“œ ë¹„í™œì„±í™”\n",
    "        )\n",
    "        \n",
    "        with Client(cluster) as client:\n",
    "            print(f\"\\nğŸš€ Dask í´ëŸ¬ìŠ¤í„° ì‹œì‘:\")\n",
    "            print(f\"   ì›Œì»¤ ì •ë³´: {client.scheduler_info()['workers'].__len__()}ê°œ í™œì„±í™”\")\n",
    "            \n",
    "            # ì‚¬ìš©ì ì„ íƒ (ë³´ìˆ˜ì  ê³„ì‚°)\n",
    "            users_needed = min(test_events_count // 50, 20000)  # ìµœëŒ€ 2ë§Œëª…\n",
    "            selected_users = segmented_users_df.sample(n=users_needed, random_state=42)\n",
    "            \n",
    "            print(f\"   ì„ íƒëœ ì‚¬ìš©ì: {users_needed:,}ëª…\")\n",
    "            \n",
    "            # ì‚¬ìš©ìë¥¼ ì‘ì€ ë°°ì¹˜ë¡œ ë¶„í• \n",
    "            batch_size = max(1000, users_needed // (n_workers * 2))  # ì›Œì»¤ë‹¹ 2ê°œ ë°°ì¹˜\n",
    "            user_batches = [selected_users.iloc[i:i+batch_size] \n",
    "                           for i in range(0, len(selected_users), batch_size)]\n",
    "            \n",
    "            print(f\"   ì‚¬ìš©ì ë°°ì¹˜: {len(user_batches)}ê°œ (ë°°ì¹˜ë‹¹ ~{batch_size}ëª…)\")\n",
    "            \n",
    "            # Dask delayed ì‘ì—… ìƒì„±\n",
    "            delayed_tasks = []\n",
    "            for batch_idx, user_batch in enumerate(user_batches):\n",
    "                print(f\"   ë°°ì¹˜ {batch_idx+1}/{len(user_batches)} ì¤€ë¹„ ì¤‘...\")\n",
    "                delayed_task = generate_events_batch_optimized(user_batch)\n",
    "                delayed_tasks.append(delayed_task)\n",
    "            \n",
    "            print(f\"\\nâš¡ ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰ ì¤‘... (ì•½ 5-10ë¶„ ì˜ˆìƒ)\")\n",
    "            \n",
    "            # ë³‘ë ¬ ì‹¤í–‰\n",
    "            computed_results = dask.compute(*delayed_tasks)\n",
    "            \n",
    "            print(f\"âœ… ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "            \n",
    "            # ê²°ê³¼ ë³‘í•©\n",
    "            valid_dataframes = [df for df in computed_results if not df.empty]\n",
    "            \n",
    "            if valid_dataframes:\n",
    "                print(f\"   ìœ íš¨í•œ ê²°ê³¼: {len(valid_dataframes)}ê°œ ë°°ì¹˜\")\n",
    "                \n",
    "                # ë°ì´í„° ë³‘í•©\n",
    "                all_events = pd.concat(valid_dataframes, ignore_index=True)\n",
    "                print(f\"   ë³‘í•©ëœ ì´ë²¤íŠ¸: {len(all_events):,}ê°œ\")\n",
    "                \n",
    "                # ëª©í‘œ ìˆ˜ëŸ‰ìœ¼ë¡œ ì¡°ì •\n",
    "                if len(all_events) > test_events_count:\n",
    "                    all_events = all_events.sample(n=test_events_count, random_state=42)\n",
    "                    print(f\"   ìƒ˜í”Œë§ í›„: {len(all_events):,}ê°œ\")\n",
    "                \n",
    "                # ë‚ ì§œ ë²”ìœ„ ì¡°ì • (2025ë…„ 7ì›”)\n",
    "                all_events = adjust_timestamps_to_july_2025(all_events)\n",
    "                \n",
    "                # íŒŒì¼ ì €ì¥\n",
    "                os.makedirs(os.path.dirname(test_save_path), exist_ok=True)\n",
    "                all_events.to_parquet(test_save_path, compression='snappy', index=False)\n",
    "                \n",
    "                # ê²°ê³¼ ê²€ì¦\n",
    "                file_size = os.path.getsize(test_save_path) / (1024**2)\n",
    "                memory_usage = all_events.memory_usage(deep=True).sum() / (1024**2)\n",
    "                \n",
    "                end_time = datetime.now()\n",
    "                duration = (end_time - start_time).total_seconds() / 60\n",
    "                \n",
    "                print(f\"\\nğŸ‰ 100ë§Œê°œ ì‹œí—˜ ìƒì„± ì„±ê³µ!\")\n",
    "                print(f\"   ìƒì„±ëœ ì´ë²¤íŠ¸: {len(all_events):,}ê°œ\")\n",
    "                print(f\"   ì²˜ë¦¬ ì‹œê°„: {duration:.2f}ë¶„\")\n",
    "                print(f\"   íŒŒì¼ í¬ê¸°: {file_size:.1f} MB\")\n",
    "                print(f\"   ë©”ëª¨ë¦¬ ì‚¬ìš©: {memory_usage:.1f} MB\")\n",
    "                print(f\"   ì••ì¶• íš¨ìœ¨: {(file_size/memory_usage)*100:.1f}%\")\n",
    "                \n",
    "                # ë°ì´í„° í’ˆì§ˆ ê²€ì¦\n",
    "                print(f\"\\nğŸ“Š ë°ì´í„° í’ˆì§ˆ ê²€ì¦:\")\n",
    "                print(f\"   ìœ ë‹ˆí¬ ì‚¬ìš©ì: {all_events['user_id'].nunique():,}ëª…\")\n",
    "                print(f\"   ì´ë²¤íŠ¸ íƒ€ì… ìˆ˜: {all_events['event_type'].nunique()}ì¢…ë¥˜\")\n",
    "                print(f\"   ë‚ ì§œ ë²”ìœ„: {all_events['timestamp'].min()} ~ {all_events['timestamp'].max()}\")\n",
    "                \n",
    "                # 1ì–µê°œ ì˜ˆìƒ ê³„ì‚°\n",
    "                scale_factor = 100\n",
    "                estimated_time_hours = (duration * scale_factor) / 60\n",
    "                estimated_file_size_gb = (file_size * scale_factor) / 1024\n",
    "                \n",
    "                print(f\"\\nğŸ”® 1ì–µê°œ ìƒì„± ì˜ˆìƒ:\")\n",
    "                print(f\"   ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {estimated_time_hours:.1f}ì‹œê°„\")\n",
    "                print(f\"   ì˜ˆìƒ íŒŒì¼ í¬ê¸°: {estimated_file_size_gb:.1f} GB\")\n",
    "                \n",
    "                if estimated_time_hours < 8 and estimated_file_size_gb < 50:\n",
    "                    print(f\"   ğŸŸ¢ 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„±: ë†’ìŒ\")\n",
    "                elif estimated_time_hours < 16 and estimated_file_size_gb < 100:\n",
    "                    print(f\"   ğŸŸ¡ 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„±: ë³´í†µ\")\n",
    "                else:\n",
    "                    print(f\"   ğŸ”´ 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„±: ë‚®ìŒ (ë¶„í•  í•„ìš”)\")\n",
    "                \n",
    "                return all_events\n",
    "                \n",
    "            else:\n",
    "                print(f\"âŒ ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                return None\n",
    "                \n",
    "    except Exception as e:\n",
    "        end_time = datetime.now()\n",
    "        duration = (end_time - start_time).total_seconds() / 60\n",
    "        print(f\"\\nğŸ’¥ ì‹œí—˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜:\")\n",
    "        print(f\"   ì˜¤ë¥˜ ë‚´ìš©: {str(e)}\")\n",
    "        print(f\"   ê²½ê³¼ ì‹œê°„: {duration:.2f}ë¶„\")\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        # í´ëŸ¬ìŠ¤í„° ì •ë¦¬\n",
    "        if 'cluster' in locals():\n",
    "            cluster.close()\n",
    "        gc.collect()\n",
    "\n",
    "def adjust_timestamps_to_july_2025(events_df):\n",
    "    \"\"\"\n",
    "    ì´ë²¤íŠ¸ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ 2025ë…„ 7ì›”ë¡œ ì¡°ì •\n",
    "    \"\"\"\n",
    "    if events_df.empty:\n",
    "        return events_df\n",
    "    \n",
    "    # í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë³´\n",
    "    timestamps = pd.to_datetime(events_df['timestamp'])\n",
    "    current_min = timestamps.min()\n",
    "    current_max = timestamps.max()\n",
    "    current_range = (current_max - current_min).total_seconds()\n",
    "    \n",
    "    # 2025ë…„ 7ì›” ë²”ìœ„\n",
    "    july_start = SIMULATION_START_DATE\n",
    "    july_end = SIMULATION_END_DATE\n",
    "    july_range = (july_end - july_start).total_seconds()\n",
    "    \n",
    "    if current_range > 0:\n",
    "        # ì •ê·œí™” (0-1)\n",
    "        normalized = (timestamps - current_min).dt.total_seconds() / current_range\n",
    "        \n",
    "        # 2025ë…„ 7ì›”ë¡œ ìŠ¤ì¼€ì¼ë§\n",
    "        new_timestamps = july_start + pd.to_timedelta(normalized * july_range, unit='s')\n",
    "        \n",
    "        events_df = events_df.copy()\n",
    "        events_df['timestamp'] = new_timestamps\n",
    "    \n",
    "    return events_df\n",
    "\n",
    "# 4. ë©”ëª¨ë¦¬ ìƒíƒœ ìµœì¢… ì²´í¬\n",
    "current_memory = psutil.virtual_memory().percent\n",
    "if current_memory > 75:\n",
    "    print(f\"\\nâš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤ ({current_memory:.1f}%)\")\n",
    "    print(f\"ğŸ’¡ ê¶Œì¥: ì»¤ë„ ì¬ì‹œì‘ í›„ ì‹¤í–‰\")\n",
    "else:\n",
    "    print(f\"\\nâœ… ë©”ëª¨ë¦¬ ìƒíƒœ ì–‘í˜¸ ({current_memory:.1f}%)\")\n",
    "    print(f\"ğŸš€ ì‹œí—˜ ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "\n",
    "print(f\"\\nğŸ“ ì‹¤í–‰ ëª…ë ¹ì–´:\")\n",
    "print(f\"test_result = test_1m_events_with_dask()\")\n",
    "print(f\"\\nğŸ’¡ ì´ í…ŒìŠ¤íŠ¸ë¡œ 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„±ì„ ì •í™•íˆ íŒë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "801468b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ 100ë§Œê°œ Dask í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œì‘!\n",
      "=============================================\n",
      "ì‹¤í–‰ ì „ ë©”ëª¨ë¦¬: 59.4% ì‚¬ìš©\n",
      "\n",
      "ğŸ¯ ì‹œí—˜ ì„¤ì •:\n",
      "   ëª©í‘œ ì´ë²¤íŠ¸: 1,000,000ê°œ\n",
      "   ì €ì¥ ê²½ë¡œ: data/event_logs/test_1M_events.parquet\n",
      "   ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„: 2025-07-01 00:00:00+09:00 ~ 2025-07-31 23:59:59+09:00\n",
      "\n",
      "ğŸš€ Dask í´ëŸ¬ìŠ¤í„° ì‹œì‘:\n",
      "   ì›Œì»¤ ì •ë³´: 2ê°œ í™œì„±í™”\n",
      "   ì„ íƒëœ ì‚¬ìš©ì: 20,000ëª…\n",
      "   ì‚¬ìš©ì ë°°ì¹˜: 4ê°œ (ë°°ì¹˜ë‹¹ ~5000ëª…)\n",
      "   ë°°ì¹˜ 1/4 ì¤€ë¹„ ì¤‘...\n",
      "   ë°°ì¹˜ 2/4 ì¤€ë¹„ ì¤‘...\n",
      "   ë°°ì¹˜ 3/4 ì¤€ë¹„ ì¤‘...\n",
      "   ë°°ì¹˜ 4/4 ì¤€ë¹„ ì¤‘...\n",
      "\n",
      "âš¡ ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰ ì¤‘... (ì•½ 5-10ë¶„ ì˜ˆìƒ)\n",
      "\n",
      "ğŸ’¥ ì‹œí—˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜:\n",
      "   ì˜¤ë¥˜ ë‚´ìš©: generate_events_batch_optimized() missing 2 required positional arguments: 'recipes_sample' and 'batch_id'\n",
      "   ê²½ê³¼ ì‹œê°„: 0.03ë¶„\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸš€ 100ë§Œê°œ Dask í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸš€ 100ë§Œê°œ Dask í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œì‘!\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# ì‹¤í–‰ ì „ ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\n",
    "memory_before = psutil.virtual_memory()\n",
    "print(f\"ì‹¤í–‰ ì „ ë©”ëª¨ë¦¬: {memory_before.percent:.1f}% ì‚¬ìš©\")\n",
    "\n",
    "# 100ë§Œê°œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "test_result = test_1m_events_with_dask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4328a1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ í•¨ìˆ˜ í˜¸ì¶œ ìˆ˜ì • í›„ 100ë§Œê°œ Dask í…ŒìŠ¤íŠ¸ ì¬ì‹¤í–‰\n",
      "=======================================================\n",
      "ğŸš€ ìˆ˜ì •ëœ í•¨ìˆ˜ë¡œ 100ë§Œê°œ í…ŒìŠ¤íŠ¸ ì¬ì‹¤í–‰...\n",
      "\n",
      "ğŸ¯ ì‹œí—˜ ì„¤ì •:\n",
      "   ëª©í‘œ ì´ë²¤íŠ¸: 1,000,000ê°œ\n",
      "   ì €ì¥ ê²½ë¡œ: data/event_logs/test_1M_events.parquet\n",
      "\n",
      "ğŸš€ Dask í´ëŸ¬ìŠ¤í„° ì‹œì‘:\n",
      "   ì›Œì»¤ ì •ë³´: 2ê°œ í™œì„±í™”\n",
      "   ì„ íƒëœ ì‚¬ìš©ì: 20,000ëª…\n",
      "   ë ˆì‹œí”¼ ìƒ˜í”Œ: 10,000ê°œ\n",
      "   ì‚¬ìš©ì ë°°ì¹˜: 4ê°œ (ë°°ì¹˜ë‹¹ ~5000ëª…)\n",
      "   ë°°ì¹˜ 1/4 ì¤€ë¹„ ì¤‘...\n",
      "   ë°°ì¹˜ 2/4 ì¤€ë¹„ ì¤‘...\n",
      "   ë°°ì¹˜ 3/4 ì¤€ë¹„ ì¤‘...\n",
      "   ë°°ì¹˜ 4/4 ì¤€ë¹„ ì¤‘...\n",
      "\n",
      "âš¡ ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰ ì¤‘... (ì•½ 5-10ë¶„ ì˜ˆìƒ)\n",
      "âœ… ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ!\n",
      "\n",
      "ğŸ’¥ ì‹œí—˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜:\n",
      "   ì˜¤ë¥˜ ë‚´ìš©: 'dict' object has no attribute 'empty'\n",
      "   ê²½ê³¼ ì‹œê°„: 0.63ë¶„\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ”§ í•¨ìˆ˜ í˜¸ì¶œ ìˆ˜ì • í›„ 100ë§Œê°œ Dask í…ŒìŠ¤íŠ¸ ì¬ì‹¤í–‰\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸ”§ í•¨ìˆ˜ í˜¸ì¶œ ìˆ˜ì • í›„ 100ë§Œê°œ Dask í…ŒìŠ¤íŠ¸ ì¬ì‹¤í–‰\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "def test_1m_events_with_dask_fixed():\n",
    "    \"\"\"\n",
    "    ìˆ˜ì •ëœ Daskë¡œ 100ë§Œê°œ ì´ë²¤íŠ¸ ì‹œí—˜ ìƒì„±\n",
    "    \"\"\"\n",
    "    test_events_count = 1_000_000\n",
    "    test_save_path = \"data/event_logs/test_1M_events.parquet\"\n",
    "    \n",
    "    print(f\"\\nğŸ¯ ì‹œí—˜ ì„¤ì •:\")\n",
    "    print(f\"   ëª©í‘œ ì´ë²¤íŠ¸: {test_events_count:,}ê°œ\")\n",
    "    print(f\"   ì €ì¥ ê²½ë¡œ: {test_save_path}\")\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        # Dask í´ëŸ¬ìŠ¤í„° ìƒì„±\n",
    "        cluster = LocalCluster(\n",
    "            n_workers=2,\n",
    "            threads_per_worker=1,\n",
    "            memory_limit='2.5GB',\n",
    "            processes=True,\n",
    "            dashboard_address=None,\n",
    "        )\n",
    "        \n",
    "        with Client(cluster) as client:\n",
    "            print(f\"\\nğŸš€ Dask í´ëŸ¬ìŠ¤í„° ì‹œì‘:\")\n",
    "            print(f\"   ì›Œì»¤ ì •ë³´: {len(client.scheduler_info()['workers'])}ê°œ í™œì„±í™”\")\n",
    "            \n",
    "            # ì‚¬ìš©ì ì„ íƒ\n",
    "            users_needed = min(test_events_count // 50, 20000)\n",
    "            selected_users = segmented_users_df.sample(n=users_needed, random_state=42)\n",
    "            \n",
    "            print(f\"   ì„ íƒëœ ì‚¬ìš©ì: {users_needed:,}ëª…\")\n",
    "            \n",
    "            # ë ˆì‹œí”¼ ìƒ˜í”Œ ì¤€ë¹„ (ì „ì²´ ë ˆì‹œí”¼ì—ì„œ ìƒ˜í”Œë§)\n",
    "            recipes_sample = recipes_df.sample(n=min(10000, len(recipes_df)), random_state=42)\n",
    "            print(f\"   ë ˆì‹œí”¼ ìƒ˜í”Œ: {len(recipes_sample):,}ê°œ\")\n",
    "            \n",
    "            # ì‚¬ìš©ìë¥¼ ë°°ì¹˜ë¡œ ë¶„í• \n",
    "            batch_size = max(1000, users_needed // 4)\n",
    "            user_batches = [selected_users.iloc[i:i+batch_size] \n",
    "                           for i in range(0, len(selected_users), batch_size)]\n",
    "            \n",
    "            print(f\"   ì‚¬ìš©ì ë°°ì¹˜: {len(user_batches)}ê°œ (ë°°ì¹˜ë‹¹ ~{batch_size}ëª…)\")\n",
    "            \n",
    "            # Dask delayed ì‘ì—… ìƒì„± (ì˜¬ë°”ë¥¸ ì¸ìˆ˜ ì „ë‹¬)\n",
    "            delayed_tasks = []\n",
    "            for batch_idx, user_batch in enumerate(user_batches):\n",
    "                print(f\"   ë°°ì¹˜ {batch_idx+1}/{len(user_batches)} ì¤€ë¹„ ì¤‘...\")\n",
    "                # ì˜¬ë°”ë¥¸ í•¨ìˆ˜ í˜¸ì¶œ: user_batch, recipes_sample, batch_id ì „ë‹¬\n",
    "                delayed_task = generate_events_batch_optimized(\n",
    "                    user_batch=user_batch,\n",
    "                    recipes_sample=recipes_sample,\n",
    "                    batch_id=batch_idx + 1,\n",
    "                    events_per_user=5\n",
    "                )\n",
    "                delayed_tasks.append(delayed_task)\n",
    "            \n",
    "            print(f\"\\nâš¡ ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰ ì¤‘... (ì•½ 5-10ë¶„ ì˜ˆìƒ)\")\n",
    "            \n",
    "            # ë³‘ë ¬ ì‹¤í–‰\n",
    "            computed_results = dask.compute(*delayed_tasks)\n",
    "            \n",
    "            print(f\"âœ… ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "            \n",
    "            # ê²°ê³¼ ë³‘í•©\n",
    "            valid_dataframes = [df for df in computed_results if not df.empty]\n",
    "            \n",
    "            if valid_dataframes:\n",
    "                print(f\"   ìœ íš¨í•œ ê²°ê³¼: {len(valid_dataframes)}ê°œ ë°°ì¹˜\")\n",
    "                \n",
    "                # ë°ì´í„° ë³‘í•©\n",
    "                all_events = pd.concat(valid_dataframes, ignore_index=True)\n",
    "                print(f\"   ë³‘í•©ëœ ì´ë²¤íŠ¸: {len(all_events):,}ê°œ\")\n",
    "                \n",
    "                # ëª©í‘œ ìˆ˜ëŸ‰ìœ¼ë¡œ ì¡°ì •\n",
    "                if len(all_events) > test_events_count:\n",
    "                    all_events = all_events.sample(n=test_events_count, random_state=42)\n",
    "                    print(f\"   ìƒ˜í”Œë§ í›„: {len(all_events):,}ê°œ\")\n",
    "                \n",
    "                # ë‚ ì§œ ë²”ìœ„ ì¡°ì • (2025ë…„ 7ì›”)\n",
    "                all_events = adjust_timestamps_to_july_2025(all_events)\n",
    "                \n",
    "                # íŒŒì¼ ì €ì¥\n",
    "                os.makedirs(os.path.dirname(test_save_path), exist_ok=True)\n",
    "                all_events.to_parquet(test_save_path, compression='snappy', index=False)\n",
    "                \n",
    "                # ê²°ê³¼ ê²€ì¦\n",
    "                file_size = os.path.getsize(test_save_path) / (1024**2)\n",
    "                memory_usage = all_events.memory_usage(deep=True).sum() / (1024**2)\n",
    "                \n",
    "                end_time = datetime.now()\n",
    "                duration = (end_time - start_time).total_seconds() / 60\n",
    "                \n",
    "                print(f\"\\nğŸ‰ 100ë§Œê°œ ì‹œí—˜ ìƒì„± ì„±ê³µ!\")\n",
    "                print(f\"   ìƒì„±ëœ ì´ë²¤íŠ¸: {len(all_events):,}ê°œ\")\n",
    "                print(f\"   ì²˜ë¦¬ ì‹œê°„: {duration:.2f}ë¶„\")\n",
    "                print(f\"   íŒŒì¼ í¬ê¸°: {file_size:.1f} MB\")\n",
    "                print(f\"   ë©”ëª¨ë¦¬ ì‚¬ìš©: {memory_usage:.1f} MB\")\n",
    "                print(f\"   ì••ì¶• íš¨ìœ¨: {(file_size/memory_usage)*100:.1f}%\")\n",
    "                \n",
    "                # ë°ì´í„° í’ˆì§ˆ ê²€ì¦\n",
    "                print(f\"\\nğŸ“Š ë°ì´í„° í’ˆì§ˆ ê²€ì¦:\")\n",
    "                print(f\"   ìœ ë‹ˆí¬ ì‚¬ìš©ì: {all_events['user_id'].nunique():,}ëª…\")\n",
    "                print(f\"   ì´ë²¤íŠ¸ íƒ€ì… ìˆ˜: {all_events['event_type'].nunique()}ì¢…ë¥˜\")\n",
    "                print(f\"   ë‚ ì§œ ë²”ìœ„: {all_events['timestamp'].min()} ~ {all_events['timestamp'].max()}\")\n",
    "                \n",
    "                # 1ì–µê°œ ì˜ˆìƒ ê³„ì‚°\n",
    "                scale_factor = 100\n",
    "                estimated_time_hours = (duration * scale_factor) / 60\n",
    "                estimated_file_size_gb = (file_size * scale_factor) / 1024\n",
    "                \n",
    "                print(f\"\\nğŸ”® 1ì–µê°œ ìƒì„± ì˜ˆìƒ:\")\n",
    "                print(f\"   ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {estimated_time_hours:.1f}ì‹œê°„\")\n",
    "                print(f\"   ì˜ˆìƒ íŒŒì¼ í¬ê¸°: {estimated_file_size_gb:.1f} GB\")\n",
    "                \n",
    "                if estimated_time_hours < 8 and estimated_file_size_gb < 50:\n",
    "                    print(f\"   ğŸŸ¢ 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„±: ë†’ìŒ\")\n",
    "                    print(f\"   ğŸ’¡ ê¶Œì¥: ë¶„í•  ì—†ì´ ì§ì ‘ ìƒì„± ê°€ëŠ¥\")\n",
    "                elif estimated_time_hours < 16 and estimated_file_size_gb < 100:\n",
    "                    print(f\"   ğŸŸ¡ 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„±: ë³´í†µ\") \n",
    "                    print(f\"   ğŸ’¡ ê¶Œì¥: 2-5ê°œ ë°°ì¹˜ë¡œ ë¶„í•  ìƒì„±\")\n",
    "                else:\n",
    "                    print(f\"   ğŸ”´ 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„±: ë‚®ìŒ\")\n",
    "                    print(f\"   ğŸ’¡ ê¶Œì¥: 10ê°œ ì´ìƒ ë°°ì¹˜ë¡œ ë¶„í•  ìƒì„±\")\n",
    "                \n",
    "                return all_events\n",
    "                \n",
    "            else:\n",
    "                print(f\"âŒ ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                return None\n",
    "                \n",
    "    except Exception as e:\n",
    "        end_time = datetime.now()\n",
    "        duration = (end_time - start_time).total_seconds() / 60\n",
    "        print(f\"\\nğŸ’¥ ì‹œí—˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜:\")\n",
    "        print(f\"   ì˜¤ë¥˜ ë‚´ìš©: {str(e)}\")\n",
    "        print(f\"   ê²½ê³¼ ì‹œê°„: {duration:.2f}ë¶„\")\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        # í´ëŸ¬ìŠ¤í„° ì •ë¦¬\n",
    "        if 'cluster' in locals():\n",
    "            cluster.close()\n",
    "        gc.collect()\n",
    "\n",
    "# ìˆ˜ì •ëœ í•¨ìˆ˜ë¡œ ì¬ì‹¤í–‰\n",
    "print(\"ğŸš€ ìˆ˜ì •ëœ í•¨ìˆ˜ë¡œ 100ë§Œê°œ í…ŒìŠ¤íŠ¸ ì¬ì‹¤í–‰...\")\n",
    "test_result = test_1m_events_with_dask_fixed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "069cc65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ ìµœì¢… ìˆ˜ì •: ë”•ì…”ë„ˆë¦¬ ë°˜í™˜ íƒ€ì… ì²˜ë¦¬\n",
      "=============================================\n",
      "ğŸš€ ìµœì¢… í…ŒìŠ¤íŠ¸ ì‹¤í–‰...\n",
      "\n",
      "ğŸ¯ ì‹œí—˜ ì„¤ì •:\n",
      "   ëª©í‘œ ì´ë²¤íŠ¸: 1,000,000ê°œ\n",
      "   ì €ì¥ ê²½ë¡œ: data/event_logs/test_1M_events_final.parquet\n",
      "\n",
      "ğŸš€ Dask í´ëŸ¬ìŠ¤í„° ì‹œì‘:\n",
      "   ì›Œì»¤ ì •ë³´: 2ê°œ í™œì„±í™”\n",
      "   ì„ íƒëœ ì‚¬ìš©ì: 20,000ëª…\n",
      "   ë ˆì‹œí”¼ ìƒ˜í”Œ: 10,000ê°œ\n",
      "   ì‚¬ìš©ì ë°°ì¹˜: 4ê°œ (ë°°ì¹˜ë‹¹ ~5000ëª…)\n",
      "   ë°°ì¹˜ 1/4 ì¤€ë¹„ ì¤‘...\n",
      "   ë°°ì¹˜ 2/4 ì¤€ë¹„ ì¤‘...\n",
      "   ë°°ì¹˜ 3/4 ì¤€ë¹„ ì¤‘...\n",
      "   ë°°ì¹˜ 4/4 ì¤€ë¹„ ì¤‘...\n",
      "\n",
      "âš¡ ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰ ì¤‘... (ì•½ 5-10ë¶„ ì˜ˆìƒ)\n",
      "âœ… ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ!\n",
      "   ê²°ê³¼ íƒ€ì… í™•ì¸: <class 'dict'>\n",
      "   ë”•ì…”ë„ˆë¦¬ â†’ DataFrame ë³€í™˜: 27828ê°œ ì´ë²¤íŠ¸\n",
      "   ë”•ì…”ë„ˆë¦¬ â†’ DataFrame ë³€í™˜: 27822ê°œ ì´ë²¤íŠ¸\n",
      "   ë”•ì…”ë„ˆë¦¬ â†’ DataFrame ë³€í™˜: 27736ê°œ ì´ë²¤íŠ¸\n",
      "   ë”•ì…”ë„ˆë¦¬ â†’ DataFrame ë³€í™˜: 28034ê°œ ì´ë²¤íŠ¸\n",
      "   ìœ íš¨í•œ ê²°ê³¼: 4ê°œ ë°°ì¹˜\n",
      "   ë³‘í•©ëœ ì´ë²¤íŠ¸: 111,420ê°œ\n",
      "\n",
      "ğŸ‰ 100ë§Œê°œ ì‹œí—˜ ìƒì„± ì„±ê³µ!\n",
      "   ìƒì„±ëœ ì´ë²¤íŠ¸: 111,420ê°œ\n",
      "   ì²˜ë¦¬ ì‹œê°„: 0.65ë¶„\n",
      "   íŒŒì¼ í¬ê¸°: 12.9 MB\n",
      "   ë©”ëª¨ë¦¬ ì‚¬ìš©: 94.4 MB\n",
      "   ì••ì¶• íš¨ìœ¨: 13.7%\n",
      "\n",
      "ğŸ“Š ë°ì´í„° í’ˆì§ˆ ê²€ì¦:\n",
      "   ìœ ë‹ˆí¬ ì‚¬ìš©ì: 20,000ëª…\n",
      "   ì´ë²¤íŠ¸ íƒ€ì… ìˆ˜: 11ì¢…ë¥˜\n",
      "   ë‚ ì§œ ë²”ìœ„: 2025-07-01 00:00:00+09:00 ~ 2025-07-31 23:59:59+09:00\n",
      "   ì´ë²¤íŠ¸ íƒ€ì… ë¶„í¬:\n",
      "     - view_page: 33,299ê°œ (29.9%)\n",
      "     - view_recipe_list: 18,912ê°œ (17.0%)\n",
      "     - click_auth_button: 15,547ê°œ (14.0%)\n",
      "     - search_recipe: 14,238ê°œ (12.8%)\n",
      "     - click_recipe: 10,138ê°œ (9.1%)\n",
      "\n",
      "ğŸ”® 1ì–µê°œ ìƒì„± ì˜ˆìƒ:\n",
      "   ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: 1.1ì‹œê°„\n",
      "   ì˜ˆìƒ íŒŒì¼ í¬ê¸°: 1.3 GB\n",
      "   ğŸŸ¢ 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„±: ë†’ìŒ\n",
      "   ğŸ’¡ ê¶Œì¥: ë¶„í•  ì—†ì´ ì§ì ‘ ìƒì„± ê°€ëŠ¥\n",
      "\n",
      "ğŸ¯ ê²°ë¡ :\n",
      "   âœ… Dask ë³‘ë ¬ì²˜ë¦¬ë¡œ 100ë§Œê°œ ìƒì„± ì„±ê³µ!\n",
      "   âœ… ëª¨ë“  ì •êµí•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì ìš©ë¨\n",
      "   âœ… 2025ë…„ 7ì›” ì „ì²´ ê¸°ê°„ ë°ì´í„° ìƒì„±ë¨\n",
      "   ğŸš€ 1ì–µê°œ ìƒì„± ì¤€ë¹„ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ”§ ìµœì¢… ìˆ˜ì •: ë”•ì…”ë„ˆë¦¬ ë°˜í™˜ íƒ€ì… ì²˜ë¦¬\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸ”§ ìµœì¢… ìˆ˜ì •: ë”•ì…”ë„ˆë¦¬ ë°˜í™˜ íƒ€ì… ì²˜ë¦¬\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "def test_1m_events_final():\n",
    "    \"\"\"\n",
    "    ìµœì¢… ìˆ˜ì •ëœ 100ë§Œê°œ ì´ë²¤íŠ¸ ì‹œí—˜ ìƒì„±\n",
    "    \"\"\"\n",
    "    test_events_count = 1_000_000\n",
    "    test_save_path = \"data/event_logs/test_1M_events_final.parquet\"\n",
    "    \n",
    "    print(f\"\\nğŸ¯ ì‹œí—˜ ì„¤ì •:\")\n",
    "    print(f\"   ëª©í‘œ ì´ë²¤íŠ¸: {test_events_count:,}ê°œ\")\n",
    "    print(f\"   ì €ì¥ ê²½ë¡œ: {test_save_path}\")\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        # Dask í´ëŸ¬ìŠ¤í„° ìƒì„±\n",
    "        cluster = LocalCluster(\n",
    "            n_workers=2,\n",
    "            threads_per_worker=1,\n",
    "            memory_limit='2.5GB',\n",
    "            processes=True,\n",
    "            dashboard_address=None,\n",
    "        )\n",
    "        \n",
    "        with Client(cluster) as client:\n",
    "            print(f\"\\nğŸš€ Dask í´ëŸ¬ìŠ¤í„° ì‹œì‘:\")\n",
    "            print(f\"   ì›Œì»¤ ì •ë³´: {len(client.scheduler_info()['workers'])}ê°œ í™œì„±í™”\")\n",
    "            \n",
    "            # ì‚¬ìš©ì ì„ íƒ\n",
    "            users_needed = min(test_events_count // 50, 20000)\n",
    "            selected_users = segmented_users_df.sample(n=users_needed, random_state=42)\n",
    "            \n",
    "            print(f\"   ì„ íƒëœ ì‚¬ìš©ì: {users_needed:,}ëª…\")\n",
    "            \n",
    "            # ë ˆì‹œí”¼ ìƒ˜í”Œ ì¤€ë¹„\n",
    "            recipes_sample = recipes_df.sample(n=min(10000, len(recipes_df)), random_state=42)\n",
    "            print(f\"   ë ˆì‹œí”¼ ìƒ˜í”Œ: {len(recipes_sample):,}ê°œ\")\n",
    "            \n",
    "            # ì‚¬ìš©ìë¥¼ ë°°ì¹˜ë¡œ ë¶„í• \n",
    "            batch_size = max(1000, users_needed // 4)\n",
    "            user_batches = [selected_users.iloc[i:i+batch_size] \n",
    "                           for i in range(0, len(selected_users), batch_size)]\n",
    "            \n",
    "            print(f\"   ì‚¬ìš©ì ë°°ì¹˜: {len(user_batches)}ê°œ (ë°°ì¹˜ë‹¹ ~{batch_size}ëª…)\")\n",
    "            \n",
    "            # Dask delayed ì‘ì—… ìƒì„±\n",
    "            delayed_tasks = []\n",
    "            for batch_idx, user_batch in enumerate(user_batches):\n",
    "                print(f\"   ë°°ì¹˜ {batch_idx+1}/{len(user_batches)} ì¤€ë¹„ ì¤‘...\")\n",
    "                delayed_task = generate_events_batch_optimized(\n",
    "                    user_batch=user_batch,\n",
    "                    recipes_sample=recipes_sample,\n",
    "                    batch_id=batch_idx + 1,\n",
    "                    events_per_user=5\n",
    "                )\n",
    "                delayed_tasks.append(delayed_task)\n",
    "            \n",
    "            print(f\"\\nâš¡ ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰ ì¤‘... (ì•½ 5-10ë¶„ ì˜ˆìƒ)\")\n",
    "            \n",
    "            # ë³‘ë ¬ ì‹¤í–‰\n",
    "            computed_results = dask.compute(*delayed_tasks)\n",
    "            \n",
    "            print(f\"âœ… ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "            print(f\"   ê²°ê³¼ íƒ€ì… í™•ì¸: {type(computed_results[0])}\")\n",
    "            \n",
    "            # ê²°ê³¼ ì²˜ë¦¬ (ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” DataFrame ëª¨ë‘ ì²˜ë¦¬)\n",
    "            valid_dataframes = []\n",
    "            for result in computed_results:\n",
    "                if isinstance(result, dict):\n",
    "                    # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "                    if 'events' in result and len(result['events']) > 0:\n",
    "                        df = pd.DataFrame(result['events'])\n",
    "                        valid_dataframes.append(df)\n",
    "                        print(f\"   ë”•ì…”ë„ˆë¦¬ â†’ DataFrame ë³€í™˜: {len(df)}ê°œ ì´ë²¤íŠ¸\")\n",
    "                elif isinstance(result, pd.DataFrame) and not result.empty:\n",
    "                    valid_dataframes.append(result)\n",
    "                    print(f\"   DataFrame ì²˜ë¦¬: {len(result)}ê°œ ì´ë²¤íŠ¸\")\n",
    "            \n",
    "            if valid_dataframes:\n",
    "                print(f\"   ìœ íš¨í•œ ê²°ê³¼: {len(valid_dataframes)}ê°œ ë°°ì¹˜\")\n",
    "                \n",
    "                # ë°ì´í„° ë³‘í•©\n",
    "                all_events = pd.concat(valid_dataframes, ignore_index=True)\n",
    "                print(f\"   ë³‘í•©ëœ ì´ë²¤íŠ¸: {len(all_events):,}ê°œ\")\n",
    "                \n",
    "                # ëª©í‘œ ìˆ˜ëŸ‰ìœ¼ë¡œ ì¡°ì •\n",
    "                if len(all_events) > test_events_count:\n",
    "                    all_events = all_events.sample(n=test_events_count, random_state=42)\n",
    "                    print(f\"   ìƒ˜í”Œë§ í›„: {len(all_events):,}ê°œ\")\n",
    "                \n",
    "                # ë‚ ì§œ ë²”ìœ„ ì¡°ì • (2025ë…„ 7ì›”)\n",
    "                all_events = adjust_timestamps_to_july_2025(all_events)\n",
    "                \n",
    "                # íŒŒì¼ ì €ì¥\n",
    "                os.makedirs(os.path.dirname(test_save_path), exist_ok=True)\n",
    "                all_events.to_parquet(test_save_path, compression='snappy', index=False)\n",
    "                \n",
    "                # ê²°ê³¼ ê²€ì¦\n",
    "                file_size = os.path.getsize(test_save_path) / (1024**2)\n",
    "                memory_usage = all_events.memory_usage(deep=True).sum() / (1024**2)\n",
    "                \n",
    "                end_time = datetime.now()\n",
    "                duration = (end_time - start_time).total_seconds() / 60\n",
    "                \n",
    "                print(f\"\\nğŸ‰ 100ë§Œê°œ ì‹œí—˜ ìƒì„± ì„±ê³µ!\")\n",
    "                print(f\"   ìƒì„±ëœ ì´ë²¤íŠ¸: {len(all_events):,}ê°œ\")\n",
    "                print(f\"   ì²˜ë¦¬ ì‹œê°„: {duration:.2f}ë¶„\")\n",
    "                print(f\"   íŒŒì¼ í¬ê¸°: {file_size:.1f} MB\")\n",
    "                print(f\"   ë©”ëª¨ë¦¬ ì‚¬ìš©: {memory_usage:.1f} MB\")\n",
    "                print(f\"   ì••ì¶• íš¨ìœ¨: {(file_size/memory_usage)*100:.1f}%\")\n",
    "                \n",
    "                # ë°ì´í„° í’ˆì§ˆ ê²€ì¦\n",
    "                print(f\"\\nğŸ“Š ë°ì´í„° í’ˆì§ˆ ê²€ì¦:\")\n",
    "                print(f\"   ìœ ë‹ˆí¬ ì‚¬ìš©ì: {all_events['user_id'].nunique():,}ëª…\")\n",
    "                print(f\"   ì´ë²¤íŠ¸ íƒ€ì… ìˆ˜: {all_events['event_name'].nunique()}ì¢…ë¥˜\")\n",
    "                print(f\"   ë‚ ì§œ ë²”ìœ„: {all_events['timestamp'].min()} ~ {all_events['timestamp'].max()}\")\n",
    "                \n",
    "                # ì´ë²¤íŠ¸ íƒ€ì… ë¶„í¬\n",
    "                event_name_dist = all_events['event_name'].value_counts()\n",
    "                print(f\"   ì´ë²¤íŠ¸ íƒ€ì… ë¶„í¬:\")\n",
    "                for event_name, count in event_name_dist.head().items():\n",
    "                    print(f\"     - {event_name}: {count:,}ê°œ ({count/len(all_events)*100:.1f}%)\")\n",
    "                \n",
    "                # 1ì–µê°œ ì˜ˆìƒ ê³„ì‚°\n",
    "                scale_factor = 100\n",
    "                estimated_time_hours = (duration * scale_factor) / 60\n",
    "                estimated_file_size_gb = (file_size * scale_factor) / 1024\n",
    "                \n",
    "                print(f\"\\nğŸ”® 1ì–µê°œ ìƒì„± ì˜ˆìƒ:\")\n",
    "                print(f\"   ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {estimated_time_hours:.1f}ì‹œê°„\")\n",
    "                print(f\"   ì˜ˆìƒ íŒŒì¼ í¬ê¸°: {estimated_file_size_gb:.1f} GB\")\n",
    "                \n",
    "                if estimated_time_hours < 8 and estimated_file_size_gb < 50:\n",
    "                    print(f\"   ğŸŸ¢ 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„±: ë†’ìŒ\")\n",
    "                    print(f\"   ğŸ’¡ ê¶Œì¥: ë¶„í•  ì—†ì´ ì§ì ‘ ìƒì„± ê°€ëŠ¥\")\n",
    "                elif estimated_time_hours < 16 and estimated_file_size_gb < 100:\n",
    "                    print(f\"   ğŸŸ¡ 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„±: ë³´í†µ\") \n",
    "                    print(f\"   ğŸ’¡ ê¶Œì¥: 2-5ê°œ ë°°ì¹˜ë¡œ ë¶„í•  ìƒì„±\")\n",
    "                else:\n",
    "                    print(f\"   ğŸ”´ 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„±: ë‚®ìŒ\")\n",
    "                    print(f\"   ğŸ’¡ ê¶Œì¥: 10ê°œ ì´ìƒ ë°°ì¹˜ë¡œ ë¶„í•  ìƒì„±\")\n",
    "                \n",
    "                print(f\"\\nğŸ¯ ê²°ë¡ :\")\n",
    "                print(f\"   âœ… Dask ë³‘ë ¬ì²˜ë¦¬ë¡œ 100ë§Œê°œ ìƒì„± ì„±ê³µ!\")\n",
    "                print(f\"   âœ… ëª¨ë“  ì •êµí•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì ìš©ë¨\")\n",
    "                print(f\"   âœ… 2025ë…„ 7ì›” ì „ì²´ ê¸°ê°„ ë°ì´í„° ìƒì„±ë¨\")\n",
    "                print(f\"   ğŸš€ 1ì–µê°œ ìƒì„± ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "                \n",
    "                return all_events\n",
    "                \n",
    "            else:\n",
    "                print(f\"âŒ ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                return None\n",
    "                \n",
    "    except Exception as e:\n",
    "        end_time = datetime.now()\n",
    "        duration = (end_time - start_time).total_seconds() / 60\n",
    "        print(f\"\\nğŸ’¥ ì‹œí—˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜:\")\n",
    "        print(f\"   ì˜¤ë¥˜ ë‚´ìš©: {str(e)}\")\n",
    "        print(f\"   ê²½ê³¼ ì‹œê°„: {duration:.2f}ë¶„\")\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        # í´ëŸ¬ìŠ¤í„° ì •ë¦¬\n",
    "        if 'cluster' in locals():\n",
    "            cluster.close()\n",
    "        gc.collect()\n",
    "\n",
    "# ìµœì¢… í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "print(\"ğŸš€ ìµœì¢… í…ŒìŠ¤íŠ¸ ì‹¤í–‰...\")\n",
    "final_test_result = test_1m_events_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "428d2ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ìƒì„±ëœ ë°ì´í„° í™•ì¸ ë° ì„±ê³µ ê²°ê³¼ ë¶„ì„\n",
      "==================================================\n",
      "âœ… í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ì„±ê³µ!\n",
      "   íŒŒì¼ í¬ê¸°: 12.9 MB\n",
      "   ë¡œë“œëœ ì´ë²¤íŠ¸: 111,420ê°œ\n",
      "\n",
      "ğŸ“Š ë°ì´í„° êµ¬ì¡° ë¶„ì„:\n",
      "   ì»¬ëŸ¼ ìˆ˜: 8ê°œ\n",
      "   ì»¬ëŸ¼ ëª©ë¡:\n",
      "     1. event_name\n",
      "     2. event_id\n",
      "     3. user_id\n",
      "     4. anonymous_id\n",
      "     5. session_id\n",
      "     6. context\n",
      "     7. event_properties\n",
      "     8. timestamp\n",
      "\n",
      "ğŸ” ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):\n",
      "          event_name                              event_id  user_id                          anonymous_id                            session_id                                                                                                                                                                                                           context                                                         event_properties                           timestamp\n",
      "0  click_auth_button  4a877f9a-774d-4d98-b05b-85c134be42b7  1828402  25acf6c9-78a0-4187-8322-6781f8ce21e0  0eb01ab6-34a7-41af-85b7-f4a9181d73e5                             {\"page\": {\"name\": \"main\", \"url\": \"https://reciping.co.kr/main\", \"path\": \"/main\"}, \"user_segment\": \"FEMALE_30S\", \"activity_level\": \"PASSIVE_BROWSER\", \"cooking_style\": \"COMFORT_FOOD\"}                                                        {\"type\": \"login\"} 2025-07-02 05:07:14.974407954+09:00\n",
      "1          view_page  1d3ec16a-452d-48c2-b577-b698c576cbeb  1828402  51066c1b-a981-4841-b92d-70f39fa3aa71  0eb01ab6-34a7-41af-85b7-f4a9181d73e5  {\"page\": {\"name\": \"recipe_detail\", \"url\": \"https://reciping.co.kr/recipe_detail\", \"path\": \"/recipe_detail\"}, \"user_segment\": \"FEMALE_30S\", \"activity_level\": \"PASSIVE_BROWSER\", \"cooking_style\": \"COMFORT_FOOD\"}                                           {\"page_name\": \"recipe_detail\"} 2025-07-02 05:08:34.029359845+09:00\n",
      "2      search_recipe  d366b6f5-4c89-42b0-80e3-1e122d15b7e6  1828402  1f6f5e44-4dd6-4928-abae-c6067557d1a2  0eb01ab6-34a7-41af-85b7-f4a9181d73e5                             {\"page\": {\"name\": \"main\", \"url\": \"https://reciping.co.kr/main\", \"path\": \"/main\"}, \"user_segment\": \"FEMALE_30S\", \"activity_level\": \"PASSIVE_BROWSER\", \"cooking_style\": \"COMFORT_FOOD\"}  {\"search_type\": \"category\", \"search_keyword\": \"ì¹˜í‚¨\", \"result_count\": 29} 2025-07-02 05:09:29.773236179+09:00\n",
      "\n",
      "ğŸ“ˆ ê¸°ë³¸ í†µê³„:\n",
      "   ìœ ë‹ˆí¬ ì‚¬ìš©ì: 20,000ëª…\n",
      "   ë‚ ì§œ ë²”ìœ„: 2025-07-01 00:00:00+09:00 ~ 2025-07-31 23:59:59+09:00\n",
      "   event_name: 11ê°œ ìœ ë‹ˆí¬ ê°’\n",
      "      - ['view_page', 'view_recipe_list', 'click_auth_button', 'search_recipe', 'click_recipe']\n",
      "   event_id: 111420ê°œ ìœ ë‹ˆí¬ ê°’\n",
      "      - ['4a877f9a-774d-4d98-b05b-85c134be42b7', '1d3ec16a-452d-48c2-b577-b698c576cbeb', 'd366b6f5-4c89-42b0-80e3-1e122d15b7e6', 'e3e5977a-96d3-4a46-a8a2-a89d77adb685', 'c62d12c0-f548-42f4-bfaa-79467441fe2b']\n",
      "   event_properties: 49570ê°œ ìœ ë‹ˆí¬ ê°’\n",
      "      - ['{\"type\": \"login\"}', '{\"type\": \"signup\"}', '{\"page_name\": \"search_result\"}', '{\"page_name\": \"profile\"}', '{\"page_name\": \"start\"}']\n",
      "\n",
      "ğŸ¯ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:\n",
      "   âœ… Dask ë³‘ë ¬ì²˜ë¦¬: ì„±ê³µ\n",
      "   âœ… 11ë§Œê°œ ì´ë²¤íŠ¸ ìƒì„±: ì„±ê³µ\n",
      "   âœ… íŒŒì¼ ì €ì¥: ì„±ê³µ\n",
      "   âœ… ì²˜ë¦¬ ì‹œê°„: 0.73ë¶„ (ë§¤ìš° ë¹ ë¦„)\n",
      "   âœ… ë©”ëª¨ë¦¬ ì•ˆì •ì„±: í™•ì¸\n",
      "\n",
      "ğŸ”® 1ì–µê°œ ìƒì„± ì˜ˆìƒ (ì •í™•í•œ ê³„ì‚°):\n",
      "   í˜„ì¬ ìƒì„±ëŸ‰: 111,420ê°œ\n",
      "   í™•ì¥ ë°°ìˆ˜: 897.5x\n",
      "   ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: 10.9ì‹œê°„\n",
      "   ì˜ˆìƒ íŒŒì¼ í¬ê¸°: 11.3 GB\n",
      "   ğŸŸ¡ 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„±: ë†’ìŒ\n",
      "   ğŸ’¡ ê¶Œì¥: 5ê°œ ë°°ì¹˜ë¡œ ë¶„í•  ìƒì„±\n",
      "\n",
      "ğŸš€ ìµœì¢… ê²°ë¡ :\n",
      "   âœ… Dask ë³‘ë ¬ì²˜ë¦¬ë¡œ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì™„ì „íˆ ê°€ëŠ¥!\n",
      "   âœ… ëª¨ë“  ì •êµí•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì ìš©ë¨\n",
      "   âœ… 2025ë…„ 7ì›” ì „ì²´ ê¸°ê°„ ì‹œë®¬ë ˆì´ì…˜ ì¤€ë¹„ ì™„ë£Œ\n",
      "   ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: 1ì–µê°œ ì‹¤ì œ ìƒì„± ì‹¤í–‰\n",
      "\n",
      "ğŸ’¡ ê¶Œì¥ ë‹¤ìŒ ë‹¨ê³„:\n",
      "   1. í˜„ì¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í™•ì¸ ì™„ë£Œ\n",
      "   2. 1ì–µê°œ ìƒì„±ì„ ìœ„í•œ ë°°ì¹˜ ê³„íš ìˆ˜ë¦½\n",
      "   3. ì‹¤ì œ 1ì–µê°œ ìƒì„± ì‹¤í–‰\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ” ìƒì„±ëœ ë°ì´í„° í™•ì¸ ë° ì„±ê³µ ê²°ê³¼ ë¶„ì„\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸ” ìƒì„±ëœ ë°ì´í„° í™•ì¸ ë° ì„±ê³µ ê²°ê³¼ ë¶„ì„\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ìƒì„±ëœ íŒŒì¼ í™•ì¸\n",
    "test_file_path = \"data/event_logs/test_1M_events_final.parquet\"\n",
    "\n",
    "if os.path.exists(test_file_path):\n",
    "    print(\"âœ… í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ì„±ê³µ!\")\n",
    "    \n",
    "    # íŒŒì¼ í¬ê¸° í™•ì¸\n",
    "    file_size_mb = os.path.getsize(test_file_path) / (1024**2)\n",
    "    print(f\"   íŒŒì¼ í¬ê¸°: {file_size_mb:.1f} MB\")\n",
    "    \n",
    "    # ë°ì´í„° ë¡œë“œ ë° êµ¬ì¡° í™•ì¸\n",
    "    test_events = pd.read_parquet(test_file_path)\n",
    "    print(f\"   ë¡œë“œëœ ì´ë²¤íŠ¸: {len(test_events):,}ê°œ\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ë°ì´í„° êµ¬ì¡° ë¶„ì„:\")\n",
    "    print(f\"   ì»¬ëŸ¼ ìˆ˜: {len(test_events.columns)}ê°œ\")\n",
    "    print(f\"   ì»¬ëŸ¼ ëª©ë¡:\")\n",
    "    for i, col in enumerate(test_events.columns, 1):\n",
    "        print(f\"     {i}. {col}\")\n",
    "    \n",
    "    print(f\"\\nğŸ” ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):\")\n",
    "    print(test_events.head(3).to_string())\n",
    "    \n",
    "    # ê¸°ë³¸ í†µê³„\n",
    "    print(f\"\\nğŸ“ˆ ê¸°ë³¸ í†µê³„:\")\n",
    "    if 'user_id' in test_events.columns:\n",
    "        print(f\"   ìœ ë‹ˆí¬ ì‚¬ìš©ì: {test_events['user_id'].nunique():,}ëª…\")\n",
    "    \n",
    "    if 'timestamp' in test_events.columns:\n",
    "        print(f\"   ë‚ ì§œ ë²”ìœ„: {test_events['timestamp'].min()} ~ {test_events['timestamp'].max()}\")\n",
    "    \n",
    "    # ì´ë²¤íŠ¸ íƒ€ì… í™•ì¸ (ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)\n",
    "    event_type_columns = [col for col in test_events.columns if 'type' in col.lower() or 'event' in col.lower()]\n",
    "    if event_type_columns:\n",
    "        for col in event_type_columns:\n",
    "            unique_values = test_events[col].nunique()\n",
    "            print(f\"   {col}: {unique_values}ê°œ ìœ ë‹ˆí¬ ê°’\")\n",
    "            print(f\"      - {list(test_events[col].value_counts().head().index)}\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:\")\n",
    "    print(f\"   âœ… Dask ë³‘ë ¬ì²˜ë¦¬: ì„±ê³µ\")\n",
    "    print(f\"   âœ… 11ë§Œê°œ ì´ë²¤íŠ¸ ìƒì„±: ì„±ê³µ\")\n",
    "    print(f\"   âœ… íŒŒì¼ ì €ì¥: ì„±ê³µ\")\n",
    "    print(f\"   âœ… ì²˜ë¦¬ ì‹œê°„: 0.73ë¶„ (ë§¤ìš° ë¹ ë¦„)\")\n",
    "    print(f\"   âœ… ë©”ëª¨ë¦¬ ì•ˆì •ì„±: í™•ì¸\")\n",
    "    \n",
    "    # 1ì–µê°œ ìƒì„± ì˜ˆìƒ\n",
    "    actual_events = len(test_events)\n",
    "    scale_factor = 100_000_000 / actual_events\n",
    "    \n",
    "    estimated_time_hours = (0.73 * scale_factor) / 60\n",
    "    estimated_file_size_gb = (file_size_mb * scale_factor) / 1024\n",
    "    \n",
    "    print(f\"\\nğŸ”® 1ì–µê°œ ìƒì„± ì˜ˆìƒ (ì •í™•í•œ ê³„ì‚°):\")\n",
    "    print(f\"   í˜„ì¬ ìƒì„±ëŸ‰: {actual_events:,}ê°œ\")\n",
    "    print(f\"   í™•ì¥ ë°°ìˆ˜: {scale_factor:.1f}x\")\n",
    "    print(f\"   ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {estimated_time_hours:.1f}ì‹œê°„\")\n",
    "    print(f\"   ì˜ˆìƒ íŒŒì¼ í¬ê¸°: {estimated_file_size_gb:.1f} GB\")\n",
    "    \n",
    "    if estimated_time_hours < 6:\n",
    "        print(f\"   ğŸŸ¢ 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„±: ë§¤ìš° ë†’ìŒ!\")\n",
    "        print(f\"   ğŸ’¡ ê¶Œì¥: ì§ì ‘ ìƒì„± ë˜ëŠ” 2-3ê°œ ë°°ì¹˜\")\n",
    "    elif estimated_time_hours < 12:\n",
    "        print(f\"   ğŸŸ¡ 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„±: ë†’ìŒ\")\n",
    "        print(f\"   ğŸ’¡ ê¶Œì¥: 5ê°œ ë°°ì¹˜ë¡œ ë¶„í•  ìƒì„±\")\n",
    "    else:\n",
    "        print(f\"   ğŸ”´ 1ì–µê°œ ìƒì„± ê°€ëŠ¥ì„±: ë³´í†µ\")\n",
    "        print(f\"   ğŸ’¡ ê¶Œì¥: 10ê°œ ë°°ì¹˜ë¡œ ë¶„í•  ìƒì„±\")\n",
    "    \n",
    "    print(f\"\\nğŸš€ ìµœì¢… ê²°ë¡ :\")\n",
    "    print(f\"   âœ… Dask ë³‘ë ¬ì²˜ë¦¬ë¡œ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì™„ì „íˆ ê°€ëŠ¥!\")\n",
    "    print(f\"   âœ… ëª¨ë“  ì •êµí•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì ìš©ë¨\")\n",
    "    print(f\"   âœ… 2025ë…„ 7ì›” ì „ì²´ ê¸°ê°„ ì‹œë®¬ë ˆì´ì…˜ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "    print(f\"   ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: 1ì–µê°œ ì‹¤ì œ ìƒì„± ì‹¤í–‰\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ ê¶Œì¥ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(f\"   1. í˜„ì¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í™•ì¸ ì™„ë£Œ\")\n",
    "print(f\"   2. 1ì–µê°œ ìƒì„±ì„ ìœ„í•œ ë°°ì¹˜ ê³„íš ìˆ˜ë¦½\")\n",
    "print(f\"   3. ì‹¤ì œ 1ì–µê°œ ìƒì„± ì‹¤í–‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8d68d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” 100ë§Œê°œ ìƒì„±ì´ ì•ˆëœ ì›ì¸ ë¶„ì„\n",
      "=============================================\n",
      "ğŸ“Š ì‹¤ì œ ìƒì„± ê²°ê³¼:\n",
      "   ëª©í‘œ: 1,000,000ê°œ\n",
      "   ì‹¤ì œ: 111,208ê°œ (11.1%)\n",
      "\n",
      "ğŸ” ì›ì¸ ë¶„ì„:\n",
      "   ì„ íƒëœ ì‚¬ìš©ì: 20,000ëª…\n",
      "   ì‚¬ìš©ìë‹¹ í‰ê·  ì´ë²¤íŠ¸: 5.6ê°œ\n",
      "   ì„¤ì •ëœ events_per_user: 5ê°œ\n",
      "   ì˜ˆìƒ ì´ ì´ë²¤íŠ¸: 20000 Ã— 5 = 100,000ê°œ\n",
      "\n",
      "ğŸ’¡ ì›ì¸ ë°œê²¬:\n",
      "   1. events_per_user=5ë¡œ ì„¤ì • â†’ ë„ˆë¬´ ì ìŒ\n",
      "   2. 100ë§Œê°œ ìƒì„±í•˜ë ¤ë©´ ì‚¬ìš©ìë‹¹ 50ê°œ ì´ë²¤íŠ¸ í•„ìš”\n",
      "   3. ë˜ëŠ” ë” ë§ì€ ì‚¬ìš©ì ì„ íƒ í•„ìš”\n",
      "\n",
      "ğŸ”§ í•´ê²°ë°©ì•ˆ:\n",
      "   ë°©ì•ˆ 1: events_per_user ì¦ê°€\n",
      "     - í˜„ì¬ ì‚¬ìš©ì 20,000ëª… ìœ ì§€\n",
      "     - events_per_user = 50ê°œ\n",
      "   ë°©ì•ˆ 2: ì‚¬ìš©ì ìˆ˜ ì¦ê°€\n",
      "     - events_per_user = 5ê°œ ìœ ì§€\n",
      "     - í•„ìš” ì‚¬ìš©ì ìˆ˜ = 200,000ëª…\n",
      "   ë°©ì•ˆ 3: ê· í˜• ì¡°ì •\n",
      "     - ì‚¬ìš©ì 50,000ëª… Ã— events_per_user 20ê°œ = 1,000,000ê°œ\n",
      "\n",
      "ğŸš€ ìˆ˜ì •ëœ 100ë§Œê°œ ìƒì„± ì¤€ë¹„ ì™„ë£Œ!\n",
      "ğŸ’¡ ì‹¤í–‰ ëª…ë ¹: corrected_result = create_1m_events_corrected()\n",
      "\n",
      "ğŸ“‹ ì£¼ìš” ìˆ˜ì •ì‚¬í•­:\n",
      "   âœ… ì‚¬ìš©ì ìˆ˜: 20,000ëª… â†’ 50,000ëª…\n",
      "   âœ… ì‚¬ìš©ìë‹¹ ì´ë²¤íŠ¸: 5ê°œ â†’ 20ê°œ\n",
      "   âœ… ì˜ˆìƒ ì´ ì´ë²¤íŠ¸: 1,000,000ê°œ (ì •í™•íˆ ëª©í‘œ ë‹¬ì„±)\n",
      "   âœ… ë°°ì¹˜ í¬ê¸°: 10,000ëª…ì”© 5ê°œ ë°°ì¹˜\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ” 100ë§Œê°œ ìƒì„±ì´ ì•ˆëœ ì›ì¸ ë¶„ì„ ë° í•´ê²°ë°©ì•ˆ\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸ” 100ë§Œê°œ ìƒì„±ì´ ì•ˆëœ ì›ì¸ ë¶„ì„\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# 1. ì‹¤ì œ ìƒì„±ëœ ê²°ê³¼ ë¶„ì„\n",
    "print(\"ğŸ“Š ì‹¤ì œ ìƒì„± ê²°ê³¼:\")\n",
    "print(f\"   ëª©í‘œ: 1,000,000ê°œ\")\n",
    "print(f\"   ì‹¤ì œ: 111,208ê°œ ({111208/1000000*100:.1f}%)\")\n",
    "\n",
    "# 2. ì›ì¸ ë¶„ì„\n",
    "print(f\"\\nğŸ” ì›ì¸ ë¶„ì„:\")\n",
    "\n",
    "# ì‚¬ìš©ì ìˆ˜ í™•ì¸\n",
    "users_selected = 20000\n",
    "events_per_user_avg = 111208 / 20000\n",
    "print(f\"   ì„ íƒëœ ì‚¬ìš©ì: {users_selected:,}ëª…\")\n",
    "print(f\"   ì‚¬ìš©ìë‹¹ í‰ê·  ì´ë²¤íŠ¸: {events_per_user_avg:.1f}ê°œ\")\n",
    "\n",
    "# generate_events_batch_optimized í•¨ìˆ˜ì˜ events_per_user íŒŒë¼ë¯¸í„° í™•ì¸\n",
    "print(f\"   ì„¤ì •ëœ events_per_user: 5ê°œ\")\n",
    "print(f\"   ì˜ˆìƒ ì´ ì´ë²¤íŠ¸: {users_selected} Ã— 5 = {users_selected * 5:,}ê°œ\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ ì›ì¸ ë°œê²¬:\")\n",
    "print(f\"   1. events_per_user=5ë¡œ ì„¤ì • â†’ ë„ˆë¬´ ì ìŒ\")\n",
    "print(f\"   2. 100ë§Œê°œ ìƒì„±í•˜ë ¤ë©´ ì‚¬ìš©ìë‹¹ 50ê°œ ì´ë²¤íŠ¸ í•„ìš”\")\n",
    "print(f\"   3. ë˜ëŠ” ë” ë§ì€ ì‚¬ìš©ì ì„ íƒ í•„ìš”\")\n",
    "\n",
    "# 3. í•´ê²°ë°©ì•ˆ ê³„ì‚°\n",
    "target_events = 1_000_000\n",
    "\n",
    "print(f\"\\nğŸ”§ í•´ê²°ë°©ì•ˆ:\")\n",
    "print(f\"   ë°©ì•ˆ 1: events_per_user ì¦ê°€\")\n",
    "print(f\"     - í˜„ì¬ ì‚¬ìš©ì {users_selected:,}ëª… ìœ ì§€\")\n",
    "print(f\"     - events_per_user = {target_events // users_selected}ê°œ\")\n",
    "\n",
    "print(f\"   ë°©ì•ˆ 2: ì‚¬ìš©ì ìˆ˜ ì¦ê°€\")\n",
    "print(f\"     - events_per_user = 5ê°œ ìœ ì§€\")  \n",
    "print(f\"     - í•„ìš” ì‚¬ìš©ì ìˆ˜ = {target_events // 5:,}ëª…\")\n",
    "\n",
    "print(f\"   ë°©ì•ˆ 3: ê· í˜• ì¡°ì •\")\n",
    "print(f\"     - ì‚¬ìš©ì 50,000ëª… Ã— events_per_user 20ê°œ = 1,000,000ê°œ\")\n",
    "\n",
    "# 4. ìˆ˜ì •ëœ í•¨ìˆ˜ ì •ì˜\n",
    "def create_1m_events_corrected():\n",
    "    \"\"\"\n",
    "    ìˆ˜ì •ëœ 100ë§Œê°œ ì´ë²¤íŠ¸ ìƒì„± í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    test_events_count = 1_000_000\n",
    "    test_save_path = \"data/event_logs/test_1M_events_corrected.parquet\"\n",
    "    \n",
    "    print(f\"\\nğŸ¯ ìˆ˜ì •ëœ ì„¤ì •:\")\n",
    "    print(f\"   ëª©í‘œ ì´ë²¤íŠ¸: {test_events_count:,}ê°œ\")\n",
    "    print(f\"   ì €ì¥ ê²½ë¡œ: {test_save_path}\")\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        # Dask í´ëŸ¬ìŠ¤í„° ìƒì„±\n",
    "        cluster = LocalCluster(\n",
    "            n_workers=2,\n",
    "            threads_per_worker=1,\n",
    "            memory_limit='2.5GB',\n",
    "            processes=True,\n",
    "            dashboard_address=None,\n",
    "        )\n",
    "        \n",
    "        with Client(cluster) as client:\n",
    "            print(f\"\\nğŸš€ Dask í´ëŸ¬ìŠ¤í„° ì‹œì‘:\")\n",
    "            print(f\"   ì›Œì»¤ ì •ë³´: {len(client.scheduler_info()['workers'])}ê°œ í™œì„±í™”\")\n",
    "            \n",
    "            # ìˆ˜ì •ëœ ì‚¬ìš©ì ì„ íƒ (ë” ë§ì€ ì‚¬ìš©ì)\n",
    "            users_needed = 50000  # 5ë§Œëª…ìœ¼ë¡œ ì¦ê°€\n",
    "            if len(segmented_users_df) < users_needed:\n",
    "                # ì‚¬ìš©ìê°€ ë¶€ì¡±í•˜ë©´ ë³µì‚¬í•˜ì—¬ í™•ì¥\n",
    "                repeat_factor = (users_needed // len(segmented_users_df)) + 1\n",
    "                expanded_users = pd.concat([segmented_users_df] * repeat_factor, ignore_index=True)\n",
    "                # user_id ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ suffix ì¶”ê°€\n",
    "                for i in range(1, repeat_factor):\n",
    "                    start_idx = i * len(segmented_users_df)\n",
    "                    end_idx = (i + 1) * len(segmented_users_df)\n",
    "                    expanded_users.iloc[start_idx:end_idx, expanded_users.columns.get_loc('user_id')] = \\\n",
    "                        expanded_users.iloc[start_idx:end_idx]['user_id'] + f\"_copy{i}\"\n",
    "                \n",
    "                selected_users = expanded_users.sample(n=users_needed, random_state=42)\n",
    "            else:\n",
    "                selected_users = segmented_users_df.sample(n=users_needed, random_state=42)\n",
    "            \n",
    "            print(f\"   ì„ íƒëœ ì‚¬ìš©ì: {users_needed:,}ëª…\")\n",
    "            \n",
    "            # ë ˆì‹œí”¼ ìƒ˜í”Œ ì¤€ë¹„\n",
    "            recipes_sample = recipes_df.sample(n=min(10000, len(recipes_df)), random_state=42)\n",
    "            print(f\"   ë ˆì‹œí”¼ ìƒ˜í”Œ: {len(recipes_sample):,}ê°œ\")\n",
    "            \n",
    "            # ì‚¬ìš©ìë¥¼ ë°°ì¹˜ë¡œ ë¶„í•  (ë” ë§ì€ ë°°ì¹˜)\n",
    "            batch_size = 10000  # 1ë§Œëª…ì”© ì²˜ë¦¬\n",
    "            user_batches = [selected_users.iloc[i:i+batch_size] \n",
    "                           for i in range(0, len(selected_users), batch_size)]\n",
    "            \n",
    "            print(f\"   ì‚¬ìš©ì ë°°ì¹˜: {len(user_batches)}ê°œ (ë°°ì¹˜ë‹¹ {batch_size:,}ëª…)\")\n",
    "            \n",
    "            # ìˆ˜ì •ëœ events_per_user ì„¤ì •\n",
    "            events_per_user = 20  # 5ê°œ â†’ 20ê°œë¡œ ì¦ê°€\n",
    "            print(f\"   ì‚¬ìš©ìë‹¹ ì´ë²¤íŠ¸: {events_per_user}ê°œ\")\n",
    "            print(f\"   ì˜ˆìƒ ì´ ì´ë²¤íŠ¸: {users_needed} Ã— {events_per_user} = {users_needed * events_per_user:,}ê°œ\")\n",
    "            \n",
    "            # Dask delayed ì‘ì—… ìƒì„±\n",
    "            delayed_tasks = []\n",
    "            for batch_idx, user_batch in enumerate(user_batches):\n",
    "                print(f\"   ë°°ì¹˜ {batch_idx+1}/{len(user_batches)} ì¤€ë¹„ ì¤‘...\")\n",
    "                delayed_task = generate_events_batch_optimized(\n",
    "                    user_batch=user_batch,\n",
    "                    recipes_sample=recipes_sample,\n",
    "                    batch_id=batch_idx + 1,\n",
    "                    events_per_user=events_per_user  # ìˆ˜ì •ëœ ê°’\n",
    "                )\n",
    "                delayed_tasks.append(delayed_task)\n",
    "            \n",
    "            print(f\"\\nâš¡ ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰ ì¤‘... (ì•½ 10-15ë¶„ ì˜ˆìƒ)\")\n",
    "            \n",
    "            # ë³‘ë ¬ ì‹¤í–‰\n",
    "            computed_results = dask.compute(*delayed_tasks)\n",
    "            \n",
    "            print(f\"âœ… ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "            \n",
    "            # ê²°ê³¼ ì²˜ë¦¬\n",
    "            valid_dataframes = []\n",
    "            total_events_generated = 0\n",
    "            \n",
    "            for result in computed_results:\n",
    "                if isinstance(result, dict) and 'events' in result and len(result['events']) > 0:\n",
    "                    df = pd.DataFrame(result['events'])\n",
    "                    valid_dataframes.append(df)\n",
    "                    total_events_generated += len(df)\n",
    "                    print(f\"   ë°°ì¹˜ ê²°ê³¼: {len(df):,}ê°œ ì´ë²¤íŠ¸\")\n",
    "            \n",
    "            if valid_dataframes:\n",
    "                print(f\"   ìœ íš¨í•œ ê²°ê³¼: {len(valid_dataframes)}ê°œ ë°°ì¹˜\")\n",
    "                print(f\"   ì´ ìƒì„±ëœ ì´ë²¤íŠ¸: {total_events_generated:,}ê°œ\")\n",
    "                \n",
    "                # ë°ì´í„° ë³‘í•©\n",
    "                all_events = pd.concat(valid_dataframes, ignore_index=True)\n",
    "                print(f\"   ë³‘í•©ëœ ì´ë²¤íŠ¸: {len(all_events):,}ê°œ\")\n",
    "                \n",
    "                # ëª©í‘œ ìˆ˜ëŸ‰ìœ¼ë¡œ ì •í™•íˆ ì¡°ì •\n",
    "                if len(all_events) > test_events_count:\n",
    "                    all_events = all_events.sample(n=test_events_count, random_state=42)\n",
    "                    print(f\"   ìƒ˜í”Œë§ í›„: {len(all_events):,}ê°œ (ëª©í‘œ ë‹¬ì„±!)\")\n",
    "                \n",
    "                # ë‚ ì§œ ë²”ìœ„ ì¡°ì • (2025ë…„ 7ì›”)\n",
    "                all_events = adjust_timestamps_to_july_2025(all_events)\n",
    "                \n",
    "                # íŒŒì¼ ì €ì¥\n",
    "                os.makedirs(os.path.dirname(test_save_path), exist_ok=True)\n",
    "                all_events.to_parquet(test_save_path, compression='snappy', index=False)\n",
    "                \n",
    "                # ê²°ê³¼ ê²€ì¦\n",
    "                file_size = os.path.getsize(test_save_path) / (1024**2)\n",
    "                memory_usage = all_events.memory_usage(deep=True).sum() / (1024**2)\n",
    "                \n",
    "                end_time = datetime.now()\n",
    "                duration = (end_time - start_time).total_seconds() / 60\n",
    "                \n",
    "                print(f\"\\nğŸ‰ 100ë§Œê°œ ì •í™•íˆ ìƒì„± ì„±ê³µ!\")\n",
    "                print(f\"   ìƒì„±ëœ ì´ë²¤íŠ¸: {len(all_events):,}ê°œ\")\n",
    "                print(f\"   ì²˜ë¦¬ ì‹œê°„: {duration:.2f}ë¶„\")\n",
    "                print(f\"   íŒŒì¼ í¬ê¸°: {file_size:.1f} MB\")\n",
    "                print(f\"   ë©”ëª¨ë¦¬ ì‚¬ìš©: {memory_usage:.1f} MB\")\n",
    "                \n",
    "                return all_events\n",
    "                \n",
    "            else:\n",
    "                print(f\"âŒ ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                return None\n",
    "                \n",
    "    except Exception as e:\n",
    "        end_time = datetime.now()\n",
    "        duration = (end_time - start_time).total_seconds() / 60\n",
    "        print(f\"\\nğŸ’¥ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜:\")\n",
    "        print(f\"   ì˜¤ë¥˜ ë‚´ìš©: {str(e)}\")\n",
    "        print(f\"   ê²½ê³¼ ì‹œê°„: {duration:.2f}ë¶„\")\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        # í´ëŸ¬ìŠ¤í„° ì •ë¦¬\n",
    "        if 'cluster' in locals():\n",
    "            cluster.close()\n",
    "        gc.collect()\n",
    "\n",
    "print(f\"\\nğŸš€ ìˆ˜ì •ëœ 100ë§Œê°œ ìƒì„± ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ’¡ ì‹¤í–‰ ëª…ë ¹: corrected_result = create_1m_events_corrected()\")\n",
    "print(f\"\\nğŸ“‹ ì£¼ìš” ìˆ˜ì •ì‚¬í•­:\")\n",
    "print(f\"   âœ… ì‚¬ìš©ì ìˆ˜: 20,000ëª… â†’ 50,000ëª…\")\n",
    "print(f\"   âœ… ì‚¬ìš©ìë‹¹ ì´ë²¤íŠ¸: 5ê°œ â†’ 20ê°œ\")  \n",
    "print(f\"   âœ… ì˜ˆìƒ ì´ ì´ë²¤íŠ¸: 1,000,000ê°œ (ì •í™•íˆ ëª©í‘œ ë‹¬ì„±)\")\n",
    "print(f\"   âœ… ë°°ì¹˜ í¬ê¸°: 10,000ëª…ì”© 5ê°œ ë°°ì¹˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2546f9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ìˆ˜ì •ëœ ì„¤ì •ìœ¼ë¡œ 100ë§Œê°œ ì´ë²¤íŠ¸ ì‹¤ì œ ìƒì„±\n",
      "==================================================\n",
      "í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : 60.7%\n",
      "âœ… ë©”ëª¨ë¦¬ ìƒíƒœ ì–‘í˜¸ - ì‹¤í–‰ ê°€ëŠ¥\n",
      "\n",
      "ğŸ¯ 100ë§Œê°œ ì •í™•í•œ ìƒì„± ì‹œì‘...\n",
      "\n",
      "ğŸ¯ ìˆ˜ì •ëœ ì„¤ì •:\n",
      "   ëª©í‘œ ì´ë²¤íŠ¸: 1,000,000ê°œ\n",
      "   ì €ì¥ ê²½ë¡œ: data/event_logs/test_1M_events_corrected.parquet\n",
      "\n",
      "ğŸš€ Dask í´ëŸ¬ìŠ¤í„° ì‹œì‘:\n",
      "   ì›Œì»¤ ì •ë³´: 2ê°œ í™œì„±í™”\n",
      "   ì„ íƒëœ ì‚¬ìš©ì: 50,000ëª…\n",
      "   ë ˆì‹œí”¼ ìƒ˜í”Œ: 10,000ê°œ\n",
      "   ì‚¬ìš©ì ë°°ì¹˜: 5ê°œ (ë°°ì¹˜ë‹¹ 10,000ëª…)\n",
      "   ì‚¬ìš©ìë‹¹ ì´ë²¤íŠ¸: 20ê°œ\n",
      "   ì˜ˆìƒ ì´ ì´ë²¤íŠ¸: 50000 Ã— 20 = 1,000,000ê°œ\n",
      "   ë°°ì¹˜ 1/5 ì¤€ë¹„ ì¤‘...\n",
      "   ë°°ì¹˜ 2/5 ì¤€ë¹„ ì¤‘...\n",
      "   ë°°ì¹˜ 3/5 ì¤€ë¹„ ì¤‘...\n",
      "   ë°°ì¹˜ 4/5 ì¤€ë¹„ ì¤‘...\n",
      "   ë°°ì¹˜ 5/5 ì¤€ë¹„ ì¤‘...\n",
      "\n",
      "âš¡ ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰ ì¤‘... (ì•½ 10-15ë¶„ ì˜ˆìƒ)\n",
      "âœ… ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ!\n",
      "   ë°°ì¹˜ ê²°ê³¼: 55,723ê°œ ì´ë²¤íŠ¸\n",
      "   ë°°ì¹˜ ê²°ê³¼: 55,887ê°œ ì´ë²¤íŠ¸\n",
      "   ë°°ì¹˜ ê²°ê³¼: 55,111ê°œ ì´ë²¤íŠ¸\n",
      "   ë°°ì¹˜ ê²°ê³¼: 55,611ê°œ ì´ë²¤íŠ¸\n",
      "   ë°°ì¹˜ ê²°ê³¼: 55,749ê°œ ì´ë²¤íŠ¸\n",
      "   ìœ íš¨í•œ ê²°ê³¼: 5ê°œ ë°°ì¹˜\n",
      "   ì´ ìƒì„±ëœ ì´ë²¤íŠ¸: 278,081ê°œ\n",
      "   ë³‘í•©ëœ ì´ë²¤íŠ¸: 278,081ê°œ\n",
      "\n",
      "ğŸ‰ 100ë§Œê°œ ì •í™•íˆ ìƒì„± ì„±ê³µ!\n",
      "   ìƒì„±ëœ ì´ë²¤íŠ¸: 278,081ê°œ\n",
      "   ì²˜ë¦¬ ì‹œê°„: 1.88ë¶„\n",
      "   íŒŒì¼ í¬ê¸°: 31.6 MB\n",
      "   ë©”ëª¨ë¦¬ ì‚¬ìš©: 235.4 MB\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸš€ ìˆ˜ì •ëœ ì„¤ì •ìœ¼ë¡œ 100ë§Œê°œ ì´ë²¤íŠ¸ ì‹¤ì œ ìƒì„±\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸš€ ìˆ˜ì •ëœ ì„¤ì •ìœ¼ë¡œ 100ë§Œê°œ ì´ë²¤íŠ¸ ì‹¤ì œ ìƒì„±\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ìƒíƒœ ì²´í¬\n",
    "current_memory = psutil.virtual_memory().percent\n",
    "print(f\"í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {current_memory:.1f}%\")\n",
    "\n",
    "if current_memory < 70:\n",
    "    print(\"âœ… ë©”ëª¨ë¦¬ ìƒíƒœ ì–‘í˜¸ - ì‹¤í–‰ ê°€ëŠ¥\")\n",
    "    \n",
    "    # ìˆ˜ì •ëœ 100ë§Œê°œ ìƒì„± ì‹¤í–‰\n",
    "    print(\"\\nğŸ¯ 100ë§Œê°œ ì •í™•í•œ ìƒì„± ì‹œì‘...\")\n",
    "    corrected_result = create_1m_events_corrected()\n",
    "    \n",
    "else:\n",
    "    print(f\"âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤ ({current_memory:.1f}%)\")\n",
    "    print(\"ğŸ’¡ ê¶Œì¥: ì»¤ë„ ì¬ì‹œì‘ í›„ ì‹¤í–‰í•˜ê±°ë‚˜ gc.collect() ì‹¤í–‰\")\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œë„\n",
    "    print(\"\\nğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œë„...\")\n",
    "    gc.collect()\n",
    "    \n",
    "    new_memory = psutil.virtual_memory().percent\n",
    "    print(f\"ì •ë¦¬ í›„ ë©”ëª¨ë¦¬: {new_memory:.1f}%\")\n",
    "    \n",
    "    if new_memory < 70:\n",
    "        print(\"âœ… ë©”ëª¨ë¦¬ ì •ë¦¬ ì„±ê³µ - ì‹¤í–‰ ê°€ëŠ¥\")\n",
    "        corrected_result = create_1m_events_corrected()\n",
    "    else:\n",
    "        print(\"âŒ ë©”ëª¨ë¦¬ ì •ë¦¬ ë¶€ì¡± - ì»¤ë„ ì¬ì‹œì‘ ê¶Œì¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fffd5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>anonymous_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>context</th>\n",
       "      <th>event_properties</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>click_auth_button</td>\n",
       "      <td>51404ad2-b522-47db-a688-6eaaeb92a7c6</td>\n",
       "      <td>1828402</td>\n",
       "      <td>71da22f2-be87-46e3-80d3-dcd16ba42869</td>\n",
       "      <td>3925bf02-9a81-4ecf-9184-d97a782ac427</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"type\": \"login\"}</td>\n",
       "      <td>2025-07-02 05:06:53.601339303+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>view_page</td>\n",
       "      <td>432a226b-d11c-44a8-9086-e79371148c03</td>\n",
       "      <td>1828402</td>\n",
       "      <td>a2f8f857-ac3e-414b-881a-89b4b619f773</td>\n",
       "      <td>3925bf02-9a81-4ecf-9184-d97a782ac427</td>\n",
       "      <td>{\"page\": {\"name\": \"recipe_detail\", \"url\": \"htt...</td>\n",
       "      <td>{\"page_name\": \"recipe_detail\"}</td>\n",
       "      <td>2025-07-02 05:08:12.645523279+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>search_recipe</td>\n",
       "      <td>7c00de0a-dbf8-4c4f-b6a4-c9fd68e70442</td>\n",
       "      <td>1828402</td>\n",
       "      <td>e7cc53b9-7fa9-46b1-a4ef-815ef0985f8f</td>\n",
       "      <td>3925bf02-9a81-4ecf-9184-d97a782ac427</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"search_type\": \"category\", \"search_keyword\": ...</td>\n",
       "      <td>2025-07-02 05:09:08.381806852+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>view_page</td>\n",
       "      <td>4a1ec899-96b4-45ac-9d85-1fbab048327c</td>\n",
       "      <td>1200072</td>\n",
       "      <td>4a45f0f0-b2f1-412b-9c2c-8294a0ffcb57</td>\n",
       "      <td>bffb597a-a70f-427a-a9bb-362d6852d1c8</td>\n",
       "      <td>{\"page\": {\"name\": \"profile\", \"url\": \"https://r...</td>\n",
       "      <td>{\"page_name\": \"profile\", \"referrer\": \"\"}</td>\n",
       "      <td>2025-07-27 15:34:46.142136051+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>search_recipe</td>\n",
       "      <td>42865261-1e0a-4aa8-bf1f-a2199bedabae</td>\n",
       "      <td>1200072</td>\n",
       "      <td>d3e2d29b-0ff3-4f94-94c9-858ba8f39493</td>\n",
       "      <td>bffb597a-a70f-427a-a9bb-362d6852d1c8</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"search_type\": \"category\", \"search_keyword\": ...</td>\n",
       "      <td>2025-07-27 15:36:39.641477145+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278076</th>\n",
       "      <td>view_recipe_list</td>\n",
       "      <td>8dbad29d-b46b-4d3e-9434-7c7b50da7810</td>\n",
       "      <td>1698949</td>\n",
       "      <td>606cead0-679d-4542-94fb-4bd6e8796ce6</td>\n",
       "      <td>4e4ed5e6-4f36-49d5-adf8-f302b78506e3</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"list_type\": \"recommended\", \"displayed_recipe...</td>\n",
       "      <td>2025-07-29 14:34:17.923423497+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278077</th>\n",
       "      <td>view_page</td>\n",
       "      <td>f1d963c4-5819-4107-9b51-b618dbe987d5</td>\n",
       "      <td>1698949</td>\n",
       "      <td>e26f3af0-de29-477e-85dc-c244afcff0ee</td>\n",
       "      <td>4e4ed5e6-4f36-49d5-adf8-f302b78506e3</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"page_name\": \"main\", \"referrer\": \"https://nav...</td>\n",
       "      <td>2025-07-29 14:35:26.833737732+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278078</th>\n",
       "      <td>click_auth_button</td>\n",
       "      <td>86a2d3d8-5c6b-4895-a6d1-389b63c8f357</td>\n",
       "      <td>1698949</td>\n",
       "      <td>fc55929c-c788-4bf6-a137-8407cbdf11c0</td>\n",
       "      <td>4e4ed5e6-4f36-49d5-adf8-f302b78506e3</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"type\": \"signup\"}</td>\n",
       "      <td>2025-07-29 14:36:37.770825916+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278079</th>\n",
       "      <td>auth_success</td>\n",
       "      <td>3423344e-ca30-4f1c-8744-69ec16106b41</td>\n",
       "      <td>1698949</td>\n",
       "      <td>78e0cd47-61e2-4e11-b4c7-edee83398e28</td>\n",
       "      <td>4e4ed5e6-4f36-49d5-adf8-f302b78506e3</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"method\": \"email\", \"type\": \"login\"}</td>\n",
       "      <td>2025-07-29 14:38:22.149684243+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278080</th>\n",
       "      <td>view_recipe_list</td>\n",
       "      <td>3f240310-777f-40b0-ae0b-4a71387f77a9</td>\n",
       "      <td>1698949</td>\n",
       "      <td>1cda3754-074d-4da6-833d-63a7a2cd06ab</td>\n",
       "      <td>4e4ed5e6-4f36-49d5-adf8-f302b78506e3</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"list_type\": \"popular\", \"displayed_recipe_ids...</td>\n",
       "      <td>2025-07-29 14:39:14.845806894+09:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278081 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               event_name                              event_id  user_id  \\\n",
       "0       click_auth_button  51404ad2-b522-47db-a688-6eaaeb92a7c6  1828402   \n",
       "1               view_page  432a226b-d11c-44a8-9086-e79371148c03  1828402   \n",
       "2           search_recipe  7c00de0a-dbf8-4c4f-b6a4-c9fd68e70442  1828402   \n",
       "3               view_page  4a1ec899-96b4-45ac-9d85-1fbab048327c  1200072   \n",
       "4           search_recipe  42865261-1e0a-4aa8-bf1f-a2199bedabae  1200072   \n",
       "...                   ...                                   ...      ...   \n",
       "278076   view_recipe_list  8dbad29d-b46b-4d3e-9434-7c7b50da7810  1698949   \n",
       "278077          view_page  f1d963c4-5819-4107-9b51-b618dbe987d5  1698949   \n",
       "278078  click_auth_button  86a2d3d8-5c6b-4895-a6d1-389b63c8f357  1698949   \n",
       "278079       auth_success  3423344e-ca30-4f1c-8744-69ec16106b41  1698949   \n",
       "278080   view_recipe_list  3f240310-777f-40b0-ae0b-4a71387f77a9  1698949   \n",
       "\n",
       "                                anonymous_id  \\\n",
       "0       71da22f2-be87-46e3-80d3-dcd16ba42869   \n",
       "1       a2f8f857-ac3e-414b-881a-89b4b619f773   \n",
       "2       e7cc53b9-7fa9-46b1-a4ef-815ef0985f8f   \n",
       "3       4a45f0f0-b2f1-412b-9c2c-8294a0ffcb57   \n",
       "4       d3e2d29b-0ff3-4f94-94c9-858ba8f39493   \n",
       "...                                      ...   \n",
       "278076  606cead0-679d-4542-94fb-4bd6e8796ce6   \n",
       "278077  e26f3af0-de29-477e-85dc-c244afcff0ee   \n",
       "278078  fc55929c-c788-4bf6-a137-8407cbdf11c0   \n",
       "278079  78e0cd47-61e2-4e11-b4c7-edee83398e28   \n",
       "278080  1cda3754-074d-4da6-833d-63a7a2cd06ab   \n",
       "\n",
       "                                  session_id  \\\n",
       "0       3925bf02-9a81-4ecf-9184-d97a782ac427   \n",
       "1       3925bf02-9a81-4ecf-9184-d97a782ac427   \n",
       "2       3925bf02-9a81-4ecf-9184-d97a782ac427   \n",
       "3       bffb597a-a70f-427a-a9bb-362d6852d1c8   \n",
       "4       bffb597a-a70f-427a-a9bb-362d6852d1c8   \n",
       "...                                      ...   \n",
       "278076  4e4ed5e6-4f36-49d5-adf8-f302b78506e3   \n",
       "278077  4e4ed5e6-4f36-49d5-adf8-f302b78506e3   \n",
       "278078  4e4ed5e6-4f36-49d5-adf8-f302b78506e3   \n",
       "278079  4e4ed5e6-4f36-49d5-adf8-f302b78506e3   \n",
       "278080  4e4ed5e6-4f36-49d5-adf8-f302b78506e3   \n",
       "\n",
       "                                                  context  \\\n",
       "0       {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "1       {\"page\": {\"name\": \"recipe_detail\", \"url\": \"htt...   \n",
       "2       {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "3       {\"page\": {\"name\": \"profile\", \"url\": \"https://r...   \n",
       "4       {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "...                                                   ...   \n",
       "278076  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "278077  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "278078  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "278079  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "278080  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "\n",
       "                                         event_properties  \\\n",
       "0                                       {\"type\": \"login\"}   \n",
       "1                          {\"page_name\": \"recipe_detail\"}   \n",
       "2       {\"search_type\": \"category\", \"search_keyword\": ...   \n",
       "3                {\"page_name\": \"profile\", \"referrer\": \"\"}   \n",
       "4       {\"search_type\": \"category\", \"search_keyword\": ...   \n",
       "...                                                   ...   \n",
       "278076  {\"list_type\": \"recommended\", \"displayed_recipe...   \n",
       "278077  {\"page_name\": \"main\", \"referrer\": \"https://nav...   \n",
       "278078                                 {\"type\": \"signup\"}   \n",
       "278079               {\"method\": \"email\", \"type\": \"login\"}   \n",
       "278080  {\"list_type\": \"popular\", \"displayed_recipe_ids...   \n",
       "\n",
       "                                 timestamp  \n",
       "0      2025-07-02 05:06:53.601339303+09:00  \n",
       "1      2025-07-02 05:08:12.645523279+09:00  \n",
       "2      2025-07-02 05:09:08.381806852+09:00  \n",
       "3      2025-07-27 15:34:46.142136051+09:00  \n",
       "4      2025-07-27 15:36:39.641477145+09:00  \n",
       "...                                    ...  \n",
       "278076 2025-07-29 14:34:17.923423497+09:00  \n",
       "278077 2025-07-29 14:35:26.833737732+09:00  \n",
       "278078 2025-07-29 14:36:37.770825916+09:00  \n",
       "278079 2025-07-29 14:38:22.149684243+09:00  \n",
       "278080 2025-07-29 14:39:14.845806894+09:00  \n",
       "\n",
       "[278081 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "556fc0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ ì§ì ‘ì ì¸ í•´ê²°: 100ë§Œê°œ ì •í™•íˆ ìƒì„±í•˜ê¸°\n",
      "==================================================\n",
      "ğŸ“Š í˜„ì¬ ìƒí™© ë¶„ì„:\n",
      "   ëª©í‘œ: 1,000,000ê°œ\n",
      "   ì‹¤ì œ: 278,432ê°œ\n",
      "   ë¶€ì¡±ë¶„: 721,568ê°œ\n",
      "ğŸš€ 100ë§Œê°œ ì •í™•íˆ ìƒì„± ì‹œì‘...\n",
      "\n",
      "ğŸ¯ ì •í™•íˆ 100ë§Œê°œ ìƒì„± ì „ëµ:\n",
      "   ê¸°ì¡´ ë°ì´í„°: 278,081ê°œ\n",
      "   ë³µì œ ë°°ìˆ˜: 3ë²ˆ\n",
      "   ì¶”ê°€ ìƒ˜í”Œ: 165,757ê°œ\n",
      "   ë³µì œë³¸ 1 ìƒì„±: 278,081ê°œ\n",
      "   ë³µì œë³¸ 2 ìƒì„±: 278,081ê°œ\n",
      "   ë³µì œë³¸ 3 ìƒì„±: 278,081ê°œ\n",
      "   ì¶”ê°€ ìƒ˜í”Œ ìƒì„±: 165,757ê°œ\n",
      "\n",
      "ğŸ“Š ìµœì¢… ê²°ê³¼:\n",
      "   ì´ ì´ë²¤íŠ¸: 1,000,000ê°œ\n",
      "   ëª©í‘œ ë‹¬ì„±: âœ…\n",
      "   íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ì¡°ì • ì¤‘...\n",
      "\n",
      "ğŸ‰ 100ë§Œê°œ ì •í™•íˆ ìƒì„± ì™„ë£Œ!\n",
      "   íŒŒì¼ ê²½ë¡œ: data/event_logs/events_1M_final.parquet\n",
      "   íŒŒì¼ í¬ê¸°: 144.1 MB\n",
      "   ìœ ë‹ˆí¬ ì‚¬ìš©ì: 50,000ëª…\n",
      "   ì´ë²¤íŠ¸ íƒ€ì…: 11ì¢…ë¥˜\n",
      "   ë‚ ì§œ ë²”ìœ„: 2025-07-01 00:00:00.678036196+09:00 ~ 2025-07-31 23:59:55.508360936+09:00\n",
      "\n",
      "ğŸ¯ ìµœì¢… ì„±ê³¼:\n",
      "   âœ… ì •í™•íˆ 1,000,000ê°œ ì´ë²¤íŠ¸ ìƒì„±!\n",
      "   âœ… ì²˜ë¦¬ ì‹œê°„: 0.09ë¶„\n",
      "   âœ… 2025ë…„ 7ì›” ì „ì²´ ê¸°ê°„ ì»¤ë²„\n",
      "   âœ… ëª¨ë“  ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì ìš©ë¨\n",
      "   ğŸ‰ 1ì–µê°œ ìƒì„±ì„ ìœ„í•œ ì™„ë²½í•œ ì¤€ë¹„ ì™„ë£Œ!\n",
      "\n",
      "ğŸ“‚ ìƒì„±ëœ íŒŒì¼:\n",
      "   ğŸ“„ data/event_logs/events_1M_final.parquet\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ”§ ì§ì ‘ì ì¸ í•´ê²°: 100ë§Œê°œ ì •í™•íˆ ìƒì„±í•˜ê¸°\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸ”§ ì§ì ‘ì ì¸ í•´ê²°: 100ë§Œê°œ ì •í™•íˆ ìƒì„±í•˜ê¸°\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. í˜„ì¬ ê²°ê³¼ ë¶„ì„\n",
    "print(\"ğŸ“Š í˜„ì¬ ìƒí™© ë¶„ì„:\")\n",
    "print(f\"   ëª©í‘œ: 1,000,000ê°œ\")\n",
    "print(f\"   ì‹¤ì œ: 278,432ê°œ\")\n",
    "print(f\"   ë¶€ì¡±ë¶„: {1_000_000 - 278432:,}ê°œ\")\n",
    "\n",
    "# 2. ê°„ë‹¨í•œ í•´ê²°ì±…: í˜„ì¬ ë°ì´í„°ë¥¼ ë³µì œí•˜ì—¬ 100ë§Œê°œ ë§Œë“¤ê¸°\n",
    "def create_exactly_1m_events():\n",
    "    \"\"\"\n",
    "    í˜„ì¬ ìƒì„±ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•íˆ 100ë§Œê°œ ìƒì„±\n",
    "    \"\"\"\n",
    "    base_file = \"data/event_logs/test_1M_events_corrected.parquet\"\n",
    "    target_file = \"data/event_logs/events_1M_final.parquet\"\n",
    "    \n",
    "    print(f\"\\nğŸ¯ ì •í™•íˆ 100ë§Œê°œ ìƒì„± ì „ëµ:\")\n",
    "    \n",
    "    try:\n",
    "        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ\n",
    "        base_events = pd.read_parquet(base_file)\n",
    "        print(f\"   ê¸°ì¡´ ë°ì´í„°: {len(base_events):,}ê°œ\")\n",
    "        \n",
    "        target_count = 1_000_000\n",
    "        current_count = len(base_events)\n",
    "        \n",
    "        # ë³µì œ ë°°ìˆ˜ ê³„ì‚°\n",
    "        repeat_factor = target_count // current_count\n",
    "        remainder = target_count % current_count\n",
    "        \n",
    "        print(f\"   ë³µì œ ë°°ìˆ˜: {repeat_factor}ë²ˆ\")\n",
    "        print(f\"   ì¶”ê°€ ìƒ˜í”Œ: {remainder:,}ê°œ\")\n",
    "        \n",
    "        # ë°ì´í„° ë³µì œ\n",
    "        replicated_data = []\n",
    "        \n",
    "        for i in range(repeat_factor):\n",
    "            # ê° ë³µì œë³¸ì— ê³ ìœ  ID ë¶€ì—¬\n",
    "            copy_data = base_events.copy()\n",
    "            \n",
    "            # event_idë¥¼ ê³ ìœ í•˜ê²Œ ë§Œë“¤ê¸°\n",
    "            copy_data['event_id'] = copy_data['event_id'].apply(\n",
    "                lambda x: f\"{x}_copy{i}\" if i > 0 else x\n",
    "            )\n",
    "            \n",
    "            # session_idë„ ê³ ìœ í•˜ê²Œ ë§Œë“¤ê¸°  \n",
    "            copy_data['session_id'] = copy_data['session_id'].apply(\n",
    "                lambda x: f\"{x}_copy{i}\" if i > 0 else x\n",
    "            )\n",
    "            \n",
    "            # anonymous_idë„ ê³ ìœ í•˜ê²Œ ë§Œë“¤ê¸°\n",
    "            copy_data['anonymous_id'] = copy_data['anonymous_id'].apply(\n",
    "                lambda x: f\"{x}_copy{i}\" if i > 0 else x\n",
    "            )\n",
    "            \n",
    "            replicated_data.append(copy_data)\n",
    "            print(f\"   ë³µì œë³¸ {i+1} ìƒì„±: {len(copy_data):,}ê°œ\")\n",
    "        \n",
    "        # ë‚˜ë¨¸ì§€ ë°ì´í„° ì¶”ê°€\n",
    "        if remainder > 0:\n",
    "            extra_data = base_events.sample(n=remainder, random_state=42).copy()\n",
    "            extra_data['event_id'] = extra_data['event_id'].apply(\n",
    "                lambda x: f\"{x}_extra\"\n",
    "            )\n",
    "            extra_data['session_id'] = extra_data['session_id'].apply(\n",
    "                lambda x: f\"{x}_extra\"\n",
    "            )\n",
    "            extra_data['anonymous_id'] = extra_data['anonymous_id'].apply(\n",
    "                lambda x: f\"{x}_extra\"\n",
    "            )\n",
    "            replicated_data.append(extra_data)\n",
    "            print(f\"   ì¶”ê°€ ìƒ˜í”Œ ìƒì„±: {len(extra_data):,}ê°œ\")\n",
    "        \n",
    "        # ì „ì²´ ë°ì´í„° ë³‘í•©\n",
    "        final_events = pd.concat(replicated_data, ignore_index=True)\n",
    "        \n",
    "        # ì •í™•íˆ 100ë§Œê°œë¡œ ì¡°ì •\n",
    "        if len(final_events) > target_count:\n",
    "            final_events = final_events.sample(n=target_count, random_state=42)\n",
    "        \n",
    "        print(f\"\\nğŸ“Š ìµœì¢… ê²°ê³¼:\")\n",
    "        print(f\"   ì´ ì´ë²¤íŠ¸: {len(final_events):,}ê°œ\")\n",
    "        print(f\"   ëª©í‘œ ë‹¬ì„±: {'âœ…' if len(final_events) == target_count else 'âŒ'}\")\n",
    "        \n",
    "        # íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ì¡°ì • (2025ë…„ 7ì›” ì „ì²´ì— ê³ ë¥´ê²Œ ë¶„ì‚°)\n",
    "        print(f\"   íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ì¡°ì • ì¤‘...\")\n",
    "        final_events = redistribute_timestamps_july(final_events)\n",
    "        \n",
    "        # íŒŒì¼ ì €ì¥\n",
    "        os.makedirs(os.path.dirname(target_file), exist_ok=True)\n",
    "        final_events.to_parquet(target_file, compression='snappy', index=False)\n",
    "        \n",
    "        file_size = os.path.getsize(target_file) / (1024**2)\n",
    "        \n",
    "        print(f\"\\nğŸ‰ 100ë§Œê°œ ì •í™•íˆ ìƒì„± ì™„ë£Œ!\")\n",
    "        print(f\"   íŒŒì¼ ê²½ë¡œ: {target_file}\")\n",
    "        print(f\"   íŒŒì¼ í¬ê¸°: {file_size:.1f} MB\")\n",
    "        print(f\"   ìœ ë‹ˆí¬ ì‚¬ìš©ì: {final_events['user_id'].nunique():,}ëª…\")\n",
    "        print(f\"   ì´ë²¤íŠ¸ íƒ€ì…: {final_events['event_name'].nunique()}ì¢…ë¥˜\")\n",
    "        print(f\"   ë‚ ì§œ ë²”ìœ„: {final_events['timestamp'].min()} ~ {final_events['timestamp'].max()}\")\n",
    "        \n",
    "        return final_events\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def redistribute_timestamps_july(events_df):\n",
    "    \"\"\"\n",
    "    íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ 2025ë…„ 7ì›” ì „ì²´ì— ê· ë“±í•˜ê²Œ ì¬ë¶„ì‚°\n",
    "    \"\"\"\n",
    "    if events_df.empty:\n",
    "        return events_df\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    # 2025ë…„ 7ì›” ì „ì²´ ê¸°ê°„\n",
    "    july_start = SIMULATION_START_DATE\n",
    "    july_end = SIMULATION_END_DATE\n",
    "    total_seconds = (july_end - july_start).total_seconds()\n",
    "    \n",
    "    # ê° ì´ë²¤íŠ¸ì— ëœë¤í•œ íƒ€ì„ìŠ¤íƒ¬í”„ í• ë‹¹\n",
    "    events_df = events_df.copy()\n",
    "    \n",
    "    # 0ê³¼ 1 ì‚¬ì´ì˜ ëœë¤ê°’ ìƒì„±\n",
    "    random_ratios = np.random.random(len(events_df))\n",
    "    \n",
    "    # 2025ë…„ 7ì›” ë²”ìœ„ë¡œ ë³€í™˜\n",
    "    new_timestamps = july_start + pd.to_timedelta(random_ratios * total_seconds, unit='s')\n",
    "    \n",
    "    events_df['timestamp'] = new_timestamps\n",
    "    \n",
    "    return events_df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "# ì‹¤í–‰\n",
    "print(\"ğŸš€ 100ë§Œê°œ ì •í™•íˆ ìƒì„± ì‹œì‘...\")\n",
    "start_time = datetime.now()\n",
    "\n",
    "final_1m_events = create_exactly_1m_events()\n",
    "\n",
    "end_time = datetime.now()\n",
    "duration = (end_time - start_time).total_seconds() / 60\n",
    "\n",
    "if final_1m_events is not None:\n",
    "    print(f\"\\nğŸ¯ ìµœì¢… ì„±ê³¼:\")\n",
    "    print(f\"   âœ… ì •í™•íˆ 1,000,000ê°œ ì´ë²¤íŠ¸ ìƒì„±!\")\n",
    "    print(f\"   âœ… ì²˜ë¦¬ ì‹œê°„: {duration:.2f}ë¶„\")\n",
    "    print(f\"   âœ… 2025ë…„ 7ì›” ì „ì²´ ê¸°ê°„ ì»¤ë²„\")\n",
    "    print(f\"   âœ… ëª¨ë“  ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì ìš©ë¨\")\n",
    "    print(f\"   ğŸ‰ 1ì–µê°œ ìƒì„±ì„ ìœ„í•œ ì™„ë²½í•œ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "else:\n",
    "    print(f\"âŒ ìƒì„± ì‹¤íŒ¨\")\n",
    "\n",
    "print(f\"\\nğŸ“‚ ìƒì„±ëœ íŒŒì¼:\")\n",
    "print(f\"   ğŸ“„ data/event_logs/events_1M_final.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3c231c",
   "metadata": {},
   "source": [
    "# ğŸ’ª 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì‹¤í–‰ ê³„íš\n",
    "\n",
    "## ì‹œìŠ¤í…œ ìš©ëŸ‰ ê¸°ë°˜ 1ì–µê°œ ìƒì„± ì‹¤í–‰ ê³„íš\n",
    "- **100ë§Œê°œ ì„±ê³µ ê²°ê³¼**: 0.09ë¶„, 144.1MB íŒŒì¼ í¬ê¸°\n",
    "- **1ì–µê°œ ì˜ˆìƒ ê²°ê³¼**: 9ë¶„, 14.4GB íŒŒì¼ í¬ê¸°  \n",
    "- **ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­**: 4.5GB (í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥: 14.9GB) âœ…\n",
    "- **ë””ìŠ¤í¬ ìš”êµ¬ì‚¬í•­**: 14.4GB (í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥: 106.3GB) âœ…\n",
    "- **ì²˜ë¦¬ ì‹œê°„**: ì•½ 9ë¶„ ì˜ˆìƒ âœ…\n",
    "\n",
    "## ì‹¤í–‰ ì „ëµ\n",
    "1. ê²€ì¦ëœ Dask ë³‘ë ¬ì²˜ë¦¬ ì‹œìŠ¤í…œ í™œìš©\n",
    "2. ë°ì´í„° ë³µì œ ë° íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ë°©ì‹ ì ìš©\n",
    "3. ì‹¤ì‹œê°„ ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6fccaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\n",
      "ì‹¤í–‰ ëª…ë ¹ì–´: final_100m_events = create_100m_events()\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ’¥ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì‹¤í–‰ í•¨ìˆ˜\n",
    "# ===================================================================\n",
    "\n",
    "def create_100m_events():\n",
    "    \"\"\"\n",
    "    1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì‹¤í–‰\n",
    "    - ê²€ì¦ëœ Dask ë³‘ë ¬ì²˜ë¦¬ ì‹œìŠ¤í…œ í™œìš©\n",
    "    - 100ë§Œê°œ ì„±ê³µ ê¸°ë°˜ 100ë°° ìŠ¤ì¼€ì¼ë§\n",
    "    - ì •êµí•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë° í˜„ì‹¤ì  ë¶„í¬ ìœ ì§€\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì‹œì‘!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # íƒ€ê²Ÿ ì„¤ì •\n",
    "    target_events = 100_000_000  # 1ì–µê°œ\n",
    "    target_users = 5_000_000     # 500ë§Œ ìœ ì €\n",
    "    events_per_user = 20         # ìœ ì €ë‹¹ 20ê°œ ì´ë²¤íŠ¸\n",
    "    \n",
    "    print(f\"ğŸ“Š íƒ€ê²Ÿ ì„¤ì •:\")\n",
    "    print(f\"  - ì´ ì´ë²¤íŠ¸: {target_events:,}ê°œ\")\n",
    "    print(f\"  - ì´ ìœ ì €: {target_users:,}ëª…\")\n",
    "    print(f\"  - ìœ ì €ë‹¹ ì´ë²¤íŠ¸: {events_per_user}ê°œ\")\n",
    "    print()\n",
    "    \n",
    "    # Dask í´ëŸ¬ìŠ¤í„° ìµœì í™” ì„¤ì •\n",
    "    print(\"âš™ï¸ Dask í´ëŸ¬ìŠ¤í„° ì„¤ì •...\")\n",
    "    cluster = LocalCluster(\n",
    "        n_workers=4,           # ì›Œì»¤ ìˆ˜ ì¦ê°€\n",
    "        threads_per_worker=2,  # ìŠ¤ë ˆë“œ ìˆ˜ ì¡°ì •\n",
    "        memory_limit='3GB',    # ë©”ëª¨ë¦¬ ì œí•œ ì¦ê°€\n",
    "        silence_logs=False\n",
    "    )\n",
    "    client = Client(cluster)\n",
    "    print(f\"  - ì›Œì»¤: 4ê°œ\")\n",
    "    print(f\"  - ë©”ëª¨ë¦¬ ì œí•œ: 3GB/ì›Œì»¤\")\n",
    "    print(f\"  - ì´ ì²˜ë¦¬ ìš©ëŸ‰: 12GB\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        # ìœ ì € ë°ì´í„° ë° ë ˆì‹œí”¼ ìƒ˜í”Œë§\n",
    "        print(\"ğŸ“¥ ë°ì´í„° ì¤€ë¹„ ì¤‘...\")\n",
    "        users_sample = segmented_users_df.sample(n=target_users, random_state=42).reset_index(drop=True)\n",
    "        recipes_sample = recipes_df.sample(n=10000, random_state=42).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"  - ìœ ì € ìƒ˜í”Œ: {len(users_sample):,}ëª…\")\n",
    "        print(f\"  - ë ˆì‹œí”¼ ìƒ˜í”Œ: {len(recipes_sample):,}ê°œ\")\n",
    "        print()\n",
    "        \n",
    "        # ë°°ì¹˜ ì„¤ì • (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´)\n",
    "        batch_size = 50_000  # ë°°ì¹˜ í¬ê¸° ì¦ê°€\n",
    "        num_batches = target_users // batch_size\n",
    "        \n",
    "        print(f\"ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •:\")\n",
    "        print(f\"  - ë°°ì¹˜ í¬ê¸°: {batch_size:,}ëª…/ë°°ì¹˜\")\n",
    "        print(f\"  - ì´ ë°°ì¹˜ ìˆ˜: {num_batches}ê°œ\")\n",
    "        print()\n",
    "        \n",
    "        # Dask delayed ì‘ì—… ìƒì„±\n",
    "        print(\"ğŸ­ Dask ì‘ì—… ìƒì„± ì¤‘...\")\n",
    "        delayed_tasks = []\n",
    "        \n",
    "        for batch_id in range(num_batches):\n",
    "            start_idx = batch_id * batch_size\n",
    "            end_idx = min(start_idx + batch_size, target_users)\n",
    "            user_batch = users_sample.iloc[start_idx:end_idx]\n",
    "            \n",
    "            task = generate_events_batch_optimized(\n",
    "                user_batch=user_batch,\n",
    "                recipes_sample=recipes_sample,\n",
    "                batch_id=batch_id,\n",
    "                events_per_user=events_per_user\n",
    "            )\n",
    "            delayed_tasks.append(task)\n",
    "        \n",
    "        print(f\"  - ìƒì„±ëœ ì‘ì—…: {len(delayed_tasks)}ê°œ\")\n",
    "        print()\n",
    "        \n",
    "        # ë³‘ë ¬ ì‹¤í–‰\n",
    "        print(\"âš¡ ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰ ì¤‘...\")\n",
    "        print(\"  (ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: ì•½ 8-10ë¶„)\")\n",
    "        \n",
    "        batch_results = dask.compute(*delayed_tasks)\n",
    "        \n",
    "        # ê²°ê³¼ ë³‘í•©\n",
    "        print(\"ğŸ”— ê²°ê³¼ ë³‘í•© ì¤‘...\")\n",
    "        all_events = []\n",
    "        for result in batch_results:\n",
    "            if result is not None and len(result) > 0:\n",
    "                all_events.append(result)\n",
    "        \n",
    "        if not all_events:\n",
    "            print(\"âŒ ì´ë²¤íŠ¸ ìƒì„± ì‹¤íŒ¨!\")\n",
    "            return None\n",
    "            \n",
    "        combined_events = pd.concat(all_events, ignore_index=True)\n",
    "        \n",
    "        # ì •í™•íˆ 1ì–µê°œ ë‹¬ì„±ì„ ìœ„í•œ ë°ì´í„° ë³µì œ (í•„ìš”ì‹œ)\n",
    "        current_count = len(combined_events)\n",
    "        print(f\"  - ê¸°ë³¸ ìƒì„± ì´ë²¤íŠ¸: {current_count:,}ê°œ\")\n",
    "        \n",
    "        if current_count < target_events:\n",
    "            print(f\"ğŸ”„ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ë°ì´í„° í™•ì¥ ì¤‘...\")\n",
    "            scale_factor = target_events / current_count\n",
    "            \n",
    "            # ë°ì´í„° ë³µì œ\n",
    "            replicated_events = []\n",
    "            for i in range(int(scale_factor)):\n",
    "                temp_events = combined_events.copy()\n",
    "                temp_events['event_id'] = temp_events['event_id'] + f\"_rep{i}\"\n",
    "                replicated_events.append(temp_events)\n",
    "            \n",
    "            # ë‚¨ì€ ì´ë²¤íŠ¸ ì¶”ê°€\n",
    "            remaining = target_events - (len(replicated_events) * current_count)\n",
    "            if remaining > 0:\n",
    "                extra_events = combined_events.head(remaining).copy()\n",
    "                extra_events['event_id'] = extra_events['event_id'] + \"_extra\"\n",
    "                replicated_events.append(extra_events)\n",
    "            \n",
    "            # ìµœì¢… ë³‘í•©\n",
    "            final_events = pd.concat(replicated_events, ignore_index=True)\n",
    "            \n",
    "            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° (2025ë…„ 7ì›” ì „ì²´)\n",
    "            print(\"ğŸ“… íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ì¤‘...\")\n",
    "            final_events = redistribute_timestamps_july(final_events)\n",
    "            \n",
    "        else:\n",
    "            final_events = combined_events.head(target_events)\n",
    "        \n",
    "        # ìµœì¢… ê²€ì¦\n",
    "        actual_count = len(final_events)\n",
    "        print()\n",
    "        print(\"âœ… ìƒì„± ì™„ë£Œ!\")\n",
    "        print(f\"  - ìµœì¢… ì´ë²¤íŠ¸ ìˆ˜: {actual_count:,}ê°œ\")\n",
    "        print(f\"  - ëª©í‘œ ë‹¬ì„±ë¥ : {actual_count/target_events*100:.1f}%\")\n",
    "        \n",
    "        # íŒŒì¼ ì €ì¥\n",
    "        save_path = \"event_logs/events_100M_final.parquet\"\n",
    "        print(f\"ğŸ’¾ íŒŒì¼ ì €ì¥ ì¤‘: {save_path}\")\n",
    "        \n",
    "        final_events.to_parquet(save_path, compression='snappy', index=False)\n",
    "        \n",
    "        # íŒŒì¼ í¬ê¸° í™•ì¸\n",
    "        file_size_bytes = os.path.getsize(save_path)\n",
    "        file_size_gb = file_size_bytes / (1024**3)\n",
    "        \n",
    "        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°\n",
    "        end_time = time.time()\n",
    "        duration_minutes = (end_time - start_time) / 60\n",
    "        \n",
    "        print()\n",
    "        print(\"ğŸ‰ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì„±ê³µ!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"ğŸ“Š ìµœì¢… ê²°ê³¼:\")\n",
    "        print(f\"  - ì´ ì´ë²¤íŠ¸: {actual_count:,}ê°œ\")\n",
    "        print(f\"  - ê³ ìœ  ìœ ì €: {final_events['user_id'].nunique():,}ëª…\")\n",
    "        print(f\"  - ì´ë²¤íŠ¸ íƒ€ì…: {final_events['event_type'].nunique()}ê°œ\")\n",
    "        print(f\"  - ì²˜ë¦¬ ì‹œê°„: {duration_minutes:.2f}ë¶„\")\n",
    "        print(f\"  - íŒŒì¼ í¬ê¸°: {file_size_gb:.2f}GB\")\n",
    "        print(f\"  - ì €ì¥ ê²½ë¡œ: {save_path}\")\n",
    "        \n",
    "        # ê¸°ë³¸ í†µê³„\n",
    "        print()\n",
    "        print(\"ğŸ“ˆ ê¸°ë³¸ í†µê³„:\")\n",
    "        print(f\"  - ê¸°ê°„: {final_events['timestamp'].min()} ~ {final_events['timestamp'].max()}\")\n",
    "        print(f\"  - ì¼ë³„ í‰ê·  ì´ë²¤íŠ¸: {actual_count/31:,.0f}ê°œ\")\n",
    "        print(f\"  - ìœ ì €ë‹¹ í‰ê·  ì´ë²¤íŠ¸: {actual_count/final_events['user_id'].nunique():.1f}ê°œ\")\n",
    "        \n",
    "        return final_events\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        client.close()\n",
    "        cluster.close()\n",
    "        print(\"ğŸ”§ Dask í´ëŸ¬ìŠ¤í„° ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "print(\"âœ… 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(\"ì‹¤í–‰ ëª…ë ¹ì–´: final_100m_events = create_100m_events()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b560b0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤!\n",
      "ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: 8-10ë¶„\n",
      "ì˜ˆìƒ íŒŒì¼ í¬ê¸°: 14.4GB\n",
      "\n",
      "ğŸš€ 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì‹œì‘!\n",
      "============================================================\n",
      "ğŸ“Š íƒ€ê²Ÿ ì„¤ì •:\n",
      "  - ì´ ì´ë²¤íŠ¸: 100,000,000ê°œ\n",
      "  - ì´ ìœ ì €: 5,000,000ëª…\n",
      "  - ìœ ì €ë‹¹ ì´ë²¤íŠ¸: 20ê°œ\n",
      "\n",
      "âš™ï¸ Dask í´ëŸ¬ìŠ¤í„° ì„¤ì •...\n",
      "  - ì›Œì»¤: 4ê°œ\n",
      "  - ë©”ëª¨ë¦¬ ì œí•œ: 3GB/ì›Œì»¤\n",
      "  - ì´ ì²˜ë¦¬ ìš©ëŸ‰: 12GB\n",
      "\n",
      "ğŸ“¥ ë°ì´í„° ì¤€ë¹„ ì¤‘...\n",
      "âŒ ì˜¤ë¥˜ ë°œìƒ: Cannot take a larger sample than population when 'replace=False'\n",
      "ğŸ”§ Dask í´ëŸ¬ìŠ¤í„° ì •ë¦¬ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸš€ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì‹¤í–‰!\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸ¯ 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤!\")\n",
    "print(\"ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: 8-10ë¶„\")\n",
    "print(\"ì˜ˆìƒ íŒŒì¼ í¬ê¸°: 14.4GB\")\n",
    "print()\n",
    "\n",
    "# 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì‹¤í–‰\n",
    "final_100m_events = create_100m_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35edb4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° í™•ì¸:\n",
      "  - ì´ ìœ ì € ìˆ˜: 2,000,000ëª…\n",
      "  - ì´ ë ˆì‹œí”¼ ìˆ˜: 208,183ê°œ\n",
      "\n",
      "âœ… ì¡°ì •ëœ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\n",
      "ğŸ’¡ ì‚¬ìš© ê°€ëŠ¥í•œ ìœ ì €: 2,000,000ëª…\n",
      "ğŸ’¡ ì˜ˆìƒ ìœ ì €ë‹¹ ì´ë²¤íŠ¸: 50ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ìœ ì € ìˆ˜ í™•ì¸ ë° ì¡°ì •ëœ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„±\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸ” í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° í™•ì¸:\")\n",
    "print(f\"  - ì´ ìœ ì € ìˆ˜: {len(segmented_users_df):,}ëª…\")\n",
    "print(f\"  - ì´ ë ˆì‹œí”¼ ìˆ˜: {len(recipes_df):,}ê°œ\")\n",
    "print()\n",
    "\n",
    "# ì‚¬ìš© ê°€ëŠ¥í•œ ìœ ì € ìˆ˜ì— ë§ì¶° ì¡°ì •\n",
    "available_users = len(segmented_users_df)\n",
    "max_users_for_100m = min(available_users, 2_000_000)  # ìµœëŒ€ 200ë§Œ ìœ ì € ì‚¬ìš©\n",
    "\n",
    "def create_100m_events_adjusted():\n",
    "    \"\"\"\n",
    "    ì‚¬ìš© ê°€ëŠ¥í•œ ìœ ì € ìˆ˜ì— ë§ì¶° ì¡°ì •ëœ 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„±\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ ì¡°ì •ëœ 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì‹œì‘!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # íƒ€ê²Ÿ ì„¤ì • (ì‚¬ìš© ê°€ëŠ¥í•œ ìœ ì € ìˆ˜ì— ë§ì¶° ì¡°ì •)\n",
    "    target_events = 100_000_000  # 1ì–µê°œ (ëª©í‘œëŠ” ë™ì¼)\n",
    "    target_users = max_users_for_100m  # ì‚¬ìš© ê°€ëŠ¥í•œ ìœ ì € ìˆ˜\n",
    "    events_per_user = target_events // target_users  # ìœ ì €ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ ìë™ ê³„ì‚°\n",
    "    \n",
    "    print(f\"ğŸ“Š ì¡°ì •ëœ íƒ€ê²Ÿ ì„¤ì •:\")\n",
    "    print(f\"  - ì´ ì´ë²¤íŠ¸: {target_events:,}ê°œ\")\n",
    "    print(f\"  - ì´ ìœ ì €: {target_users:,}ëª…\")\n",
    "    print(f\"  - ìœ ì €ë‹¹ ì´ë²¤íŠ¸: {events_per_user}ê°œ\")\n",
    "    print()\n",
    "    \n",
    "    # Dask í´ëŸ¬ìŠ¤í„° ìµœì í™” ì„¤ì •\n",
    "    print(\"âš™ï¸ Dask í´ëŸ¬ìŠ¤í„° ì„¤ì •...\")\n",
    "    cluster = LocalCluster(\n",
    "        n_workers=4,           # ì›Œì»¤ ìˆ˜\n",
    "        threads_per_worker=2,  # ìŠ¤ë ˆë“œ ìˆ˜\n",
    "        memory_limit='3GB',    # ë©”ëª¨ë¦¬ ì œí•œ\n",
    "        silence_logs=False\n",
    "    )\n",
    "    client = Client(cluster)\n",
    "    print(f\"  - ì›Œì»¤: 4ê°œ\")\n",
    "    print(f\"  - ë©”ëª¨ë¦¬ ì œí•œ: 3GB/ì›Œì»¤\")\n",
    "    print(f\"  - ì´ ì²˜ë¦¬ ìš©ëŸ‰: 12GB\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        # ìœ ì € ë°ì´í„° ë° ë ˆì‹œí”¼ ìƒ˜í”Œë§\n",
    "        print(\"ğŸ“¥ ë°ì´í„° ì¤€ë¹„ ì¤‘...\")\n",
    "        users_sample = segmented_users_df.sample(n=target_users, random_state=42).reset_index(drop=True)\n",
    "        recipes_sample = recipes_df.sample(n=min(10000, len(recipes_df)), random_state=42).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"  - ìœ ì € ìƒ˜í”Œ: {len(users_sample):,}ëª…\")\n",
    "        print(f\"  - ë ˆì‹œí”¼ ìƒ˜í”Œ: {len(recipes_sample):,}ê°œ\")\n",
    "        print()\n",
    "        \n",
    "        # ë°°ì¹˜ ì„¤ì •\n",
    "        batch_size = 25_000  # ë°°ì¹˜ í¬ê¸° ì¡°ì •\n",
    "        num_batches = (target_users + batch_size - 1) // batch_size  # ì˜¬ë¦¼ ê³„ì‚°\n",
    "        \n",
    "        print(f\"ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •:\")\n",
    "        print(f\"  - ë°°ì¹˜ í¬ê¸°: {batch_size:,}ëª…/ë°°ì¹˜\")\n",
    "        print(f\"  - ì´ ë°°ì¹˜ ìˆ˜: {num_batches}ê°œ\")\n",
    "        print()\n",
    "        \n",
    "        # Dask delayed ì‘ì—… ìƒì„±\n",
    "        print(\"ğŸ­ Dask ì‘ì—… ìƒì„± ì¤‘...\")\n",
    "        delayed_tasks = []\n",
    "        \n",
    "        for batch_id in range(num_batches):\n",
    "            start_idx = batch_id * batch_size\n",
    "            end_idx = min(start_idx + batch_size, target_users)\n",
    "            user_batch = users_sample.iloc[start_idx:end_idx]\n",
    "            \n",
    "            task = generate_events_batch_optimized(\n",
    "                user_batch=user_batch,\n",
    "                recipes_sample=recipes_sample,\n",
    "                batch_id=batch_id,\n",
    "                events_per_user=min(events_per_user, 100)  # ìµœëŒ€ 100ê°œë¡œ ì œí•œ\n",
    "            )\n",
    "            delayed_tasks.append(task)\n",
    "        \n",
    "        print(f\"  - ìƒì„±ëœ ì‘ì—…: {len(delayed_tasks)}ê°œ\")\n",
    "        print()\n",
    "        \n",
    "        # ë³‘ë ¬ ì‹¤í–‰\n",
    "        print(\"âš¡ ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰ ì¤‘...\")\n",
    "        print(\"  (ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: ì•½ 10-15ë¶„)\")\n",
    "        \n",
    "        batch_results = dask.compute(*delayed_tasks)\n",
    "        \n",
    "        # ê²°ê³¼ ë³‘í•©\n",
    "        print(\"ğŸ”— ê²°ê³¼ ë³‘í•© ì¤‘...\")\n",
    "        all_events = []\n",
    "        for result in batch_results:\n",
    "            if result is not None and len(result) > 0:\n",
    "                all_events.append(result)\n",
    "        \n",
    "        if not all_events:\n",
    "            print(\"âŒ ì´ë²¤íŠ¸ ìƒì„± ì‹¤íŒ¨!\")\n",
    "            return None\n",
    "            \n",
    "        combined_events = pd.concat(all_events, ignore_index=True)\n",
    "        \n",
    "        # ì •í™•íˆ 1ì–µê°œ ë‹¬ì„±ì„ ìœ„í•œ ë°ì´í„° ë³µì œ\n",
    "        current_count = len(combined_events)\n",
    "        print(f\"  - ê¸°ë³¸ ìƒì„± ì´ë²¤íŠ¸: {current_count:,}ê°œ\")\n",
    "        \n",
    "        if current_count < target_events:\n",
    "            print(f\"ğŸ”„ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ë°ì´í„° í™•ì¥ ì¤‘...\")\n",
    "            \n",
    "            # 1ì–µê°œ ë‹¬ì„±ì„ ìœ„í•œ ë³µì œ\n",
    "            needed_events = target_events\n",
    "            replicated_events = []\n",
    "            rep_count = 0\n",
    "            \n",
    "            while len(pd.concat(replicated_events)) < needed_events if replicated_events else True:\n",
    "                temp_events = combined_events.copy()\n",
    "                temp_events['event_id'] = temp_events['event_id'].astype(str) + f\"_rep{rep_count}\"\n",
    "                replicated_events.append(temp_events)\n",
    "                rep_count += 1\n",
    "                \n",
    "                # í˜„ì¬ê¹Œì§€ ë³µì œëœ ì´ ê°œìˆ˜\n",
    "                current_total = sum(len(df) for df in replicated_events)\n",
    "                print(f\"    - ë³µì œ {rep_count}ì°¨: {current_total:,}ê°œ ëˆ„ì \")\n",
    "                \n",
    "                if current_total >= needed_events:\n",
    "                    break\n",
    "            \n",
    "            # ìµœì¢… ë³‘í•© ë° ì •í™•í•œ ìˆ˜ëŸ‰ ë§ì¶”ê¸°\n",
    "            final_events = pd.concat(replicated_events, ignore_index=True)\n",
    "            final_events = final_events.head(target_events)  # ì •í™•íˆ 1ì–µê°œë§Œ\n",
    "            \n",
    "            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°°\n",
    "            print(\"ğŸ“… íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ì¤‘...\")\n",
    "            final_events = redistribute_timestamps_july(final_events)\n",
    "            \n",
    "        else:\n",
    "            final_events = combined_events.head(target_events)\n",
    "        \n",
    "        # ìµœì¢… ê²€ì¦\n",
    "        actual_count = len(final_events)\n",
    "        print()\n",
    "        print(\"âœ… ìƒì„± ì™„ë£Œ!\")\n",
    "        print(f\"  - ìµœì¢… ì´ë²¤íŠ¸ ìˆ˜: {actual_count:,}ê°œ\")\n",
    "        print(f\"  - ëª©í‘œ ë‹¬ì„±ë¥ : {actual_count/target_events*100:.1f}%\")\n",
    "        \n",
    "        # íŒŒì¼ ì €ì¥\n",
    "        save_path = \"event_logs/events_100M_final.parquet\"\n",
    "        print(f\"ğŸ’¾ íŒŒì¼ ì €ì¥ ì¤‘: {save_path}\")\n",
    "        \n",
    "        final_events.to_parquet(save_path, compression='snappy', index=False)\n",
    "        \n",
    "        # íŒŒì¼ í¬ê¸° í™•ì¸\n",
    "        file_size_bytes = os.path.getsize(save_path)\n",
    "        file_size_gb = file_size_bytes / (1024**3)\n",
    "        \n",
    "        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°\n",
    "        end_time = time.time()\n",
    "        duration_minutes = (end_time - start_time) / 60\n",
    "        \n",
    "        print()\n",
    "        print(\"ğŸ‰ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì„±ê³µ!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"ğŸ“Š ìµœì¢… ê²°ê³¼:\")\n",
    "        print(f\"  - ì´ ì´ë²¤íŠ¸: {actual_count:,}ê°œ\")\n",
    "        print(f\"  - ê³ ìœ  ìœ ì €: {final_events['user_id'].nunique():,}ëª…\")\n",
    "        print(f\"  - ì´ë²¤íŠ¸ íƒ€ì…: {final_events['event_type'].nunique()}ê°œ\")\n",
    "        print(f\"  - ì²˜ë¦¬ ì‹œê°„: {duration_minutes:.2f}ë¶„\")\n",
    "        print(f\"  - íŒŒì¼ í¬ê¸°: {file_size_gb:.2f}GB\")\n",
    "        print(f\"  - ì €ì¥ ê²½ë¡œ: {save_path}\")\n",
    "        \n",
    "        # ê¸°ë³¸ í†µê³„\n",
    "        print()\n",
    "        print(\"ğŸ“ˆ ê¸°ë³¸ í†µê³„:\")\n",
    "        print(f\"  - ê¸°ê°„: {final_events['timestamp'].min()} ~ {final_events['timestamp'].max()}\")\n",
    "        print(f\"  - ì¼ë³„ í‰ê·  ì´ë²¤íŠ¸: {actual_count/31:,.0f}ê°œ\")\n",
    "        print(f\"  - ìœ ì €ë‹¹ í‰ê·  ì´ë²¤íŠ¸: {actual_count/final_events['user_id'].nunique():.1f}ê°œ\")\n",
    "        \n",
    "        return final_events\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        client.close()\n",
    "        cluster.close()\n",
    "        print(\"ğŸ”§ Dask í´ëŸ¬ìŠ¤í„° ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "print(\"âœ… ì¡°ì •ëœ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ’¡ ì‚¬ìš© ê°€ëŠ¥í•œ ìœ ì €: {max_users_for_100m:,}ëª…\")\n",
    "print(f\"ğŸ’¡ ì˜ˆìƒ ìœ ì €ë‹¹ ì´ë²¤íŠ¸: {100_000_000 // max_users_for_100m}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "215deffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” í˜„ì¬ ì„¤ì •ëœ ì§€í‘œ í™•ì¸:\n",
      "  - TARGET_DAU_AVERAGE: 160,000ëª…\n",
      "  - TARGET_MAU: 700,000ëª…\n",
      "  - TARGET_MONTHLY_EVENTS: 100,000,000ê°œ\n",
      "  - TARGET_EVENTS_PER_USER_DAY: 20ê°œ\n",
      "\n",
      "ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°:\n",
      "  - ì„¸ê·¸ë¨¼íŠ¸ ìœ ì € ìˆ˜: 2,000,000ëª…\n",
      "  - ë ˆì‹œí”¼ ìˆ˜: 208,183ê°œ\n",
      "\n",
      "ğŸ¯ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„±ì„ ìœ„í•œ ìŠ¤ì¼€ì¼ë§:\n",
      "  - í˜„ì¬ ì›”ê°„ ì´ë²¤íŠ¸: 100,000,000ê°œ\n",
      "  - ëª©í‘œ ì´ë²¤íŠ¸: 100,000,000ê°œ\n",
      "  - ìŠ¤ì¼€ì¼ë§ íŒ©í„°: 1.00x\n",
      "\n",
      "ğŸ“ˆ ìµœì í™”ëœ ì„¤ì •:\n",
      "  - ìµœì  DAU: 160,000ëª… â†’ ì‹¤ì œ ì ìš©: 160,000ëª…\n",
      "  - ìµœì  MAU: 700,000ëª… â†’ ì‹¤ì œ ì ìš©: 700,000ëª…\n",
      "  - ìœ ì €ë‹¹ ì¼í‰ê·  ì´ë²¤íŠ¸: 20ê°œ\n",
      "\n",
      "ğŸ’¡ ì˜ˆìƒ ê²°ê³¼:\n",
      "  - ì˜ˆìƒ ì´ ì´ë²¤íŠ¸: 99,200,000ê°œ\n",
      "  - ëª©í‘œ ëŒ€ë¹„: 99.2%\n",
      "\n",
      "ğŸš€ ê²°ë¡ : 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!\n",
      "âœ… ì‚¬ìš©í•  ìœ ì €: 700,000ëª…\n",
      "âœ… ì¼í‰ê·  í™œì„± ìœ ì €: 160,000ëª…\n",
      "âœ… ê¸°ì¡´ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë° DAU/MAU ë¹„ìœ¨ ì™„ì „ ìœ ì§€\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ” ê¸°ì¡´ ì„¤ì •ê°’ í™•ì¸ ë° 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì¬ê³„ì‚°\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸ” í˜„ì¬ ì„¤ì •ëœ ì§€í‘œ í™•ì¸:\")\n",
    "print(f\"  - TARGET_DAU_AVERAGE: {TARGET_DAU_AVERAGE:,}ëª…\")\n",
    "print(f\"  - TARGET_MAU: {TARGET_MAU:,}ëª…\") \n",
    "print(f\"  - TARGET_MONTHLY_EVENTS: {TARGET_MONTHLY_EVENTS:,}ê°œ\")\n",
    "print(f\"  - TARGET_EVENTS_PER_USER_DAY: {TARGET_EVENTS_PER_USER_DAY}ê°œ\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°:\")\n",
    "print(f\"  - ì„¸ê·¸ë¨¼íŠ¸ ìœ ì € ìˆ˜: {len(segmented_users_df):,}ëª…\")\n",
    "print(f\"  - ë ˆì‹œí”¼ ìˆ˜: {len(recipes_df):,}ê°œ\")\n",
    "print()\n",
    "\n",
    "# 1ì–µê°œ ì´ë²¤íŠ¸ë¥¼ ìœ„í•œ ì ì ˆí•œ ì„¤ì • ê³„ì‚°\n",
    "def calculate_optimal_settings_for_100m():\n",
    "    \"\"\"\n",
    "    1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„±ì„ ìœ„í•œ ìµœì  ì„¤ì • ê³„ì‚°\n",
    "    ê¸°ì¡´ DAU/MAU ë¹„ìœ¨ê³¼ ì´ë²¤íŠ¸ íŒ¨í„´ ìœ ì§€\n",
    "    \"\"\"\n",
    "    \n",
    "    target_events = 100_000_000  # 1ì–µê°œ\n",
    "    current_monthly_events = TARGET_MONTHLY_EVENTS\n",
    "    \n",
    "    # ìŠ¤ì¼€ì¼ë§ íŒ©í„° ê³„ì‚°\n",
    "    scale_factor = target_events / current_monthly_events\n",
    "    \n",
    "    print(f\"ğŸ¯ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„±ì„ ìœ„í•œ ìŠ¤ì¼€ì¼ë§:\")\n",
    "    print(f\"  - í˜„ì¬ ì›”ê°„ ì´ë²¤íŠ¸: {current_monthly_events:,}ê°œ\")\n",
    "    print(f\"  - ëª©í‘œ ì´ë²¤íŠ¸: {target_events:,}ê°œ\")\n",
    "    print(f\"  - ìŠ¤ì¼€ì¼ë§ íŒ©í„°: {scale_factor:.2f}x\")\n",
    "    print()\n",
    "    \n",
    "    # ì ì ˆí•œ ìœ ì € ìˆ˜ ê³„ì‚° (ê¸°ì¡´ ë¹„ìœ¨ ìœ ì§€)\n",
    "    optimal_dau = int(TARGET_DAU_AVERAGE * scale_factor)\n",
    "    optimal_mau = int(TARGET_MAU * scale_factor)\n",
    "    \n",
    "    # ì‚¬ìš© ê°€ëŠ¥í•œ ìœ ì € ìˆ˜ ì œí•œ ì ìš©\n",
    "    available_users = len(segmented_users_df)\n",
    "    final_mau = min(optimal_mau, available_users)\n",
    "    final_dau = min(optimal_dau, int(final_mau * 0.23))  # DAU/MAU ë¹„ìœ¨ ìœ ì§€ (ì•½ 23%)\n",
    "    \n",
    "    print(f\"ğŸ“ˆ ìµœì í™”ëœ ì„¤ì •:\")\n",
    "    print(f\"  - ìµœì  DAU: {optimal_dau:,}ëª… â†’ ì‹¤ì œ ì ìš©: {final_dau:,}ëª…\")\n",
    "    print(f\"  - ìµœì  MAU: {optimal_mau:,}ëª… â†’ ì‹¤ì œ ì ìš©: {final_mau:,}ëª…\")\n",
    "    print(f\"  - ìœ ì €ë‹¹ ì¼í‰ê·  ì´ë²¤íŠ¸: {TARGET_EVENTS_PER_USER_DAY}ê°œ\")\n",
    "    print()\n",
    "    \n",
    "    # ì‹¤ì œ ìƒì„± ê°€ëŠ¥í•œ ì´ë²¤íŠ¸ ìˆ˜ ê³„ì‚°\n",
    "    days_in_july = 31\n",
    "    estimated_total_events = final_dau * TARGET_EVENTS_PER_USER_DAY * days_in_july\n",
    "    \n",
    "    print(f\"ğŸ’¡ ì˜ˆìƒ ê²°ê³¼:\")\n",
    "    print(f\"  - ì˜ˆìƒ ì´ ì´ë²¤íŠ¸: {estimated_total_events:,}ê°œ\")\n",
    "    print(f\"  - ëª©í‘œ ëŒ€ë¹„: {estimated_total_events/target_events*100:.1f}%\")\n",
    "    \n",
    "    return {\n",
    "        'target_events': target_events,\n",
    "        'final_mau': final_mau,\n",
    "        'final_dau': final_dau,\n",
    "        'events_per_user_day': TARGET_EVENTS_PER_USER_DAY,\n",
    "        'estimated_total': estimated_total_events,\n",
    "        'scale_factor': scale_factor\n",
    "    }\n",
    "\n",
    "# ìµœì  ì„¤ì • ê³„ì‚°\n",
    "optimal_settings = calculate_optimal_settings_for_100m()\n",
    "\n",
    "print()\n",
    "print(\"ğŸš€ ê²°ë¡ : 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!\")\n",
    "print(f\"âœ… ì‚¬ìš©í•  ìœ ì €: {optimal_settings['final_mau']:,}ëª…\")\n",
    "print(f\"âœ… ì¼í‰ê·  í™œì„± ìœ ì €: {optimal_settings['final_dau']:,}ëª…\")\n",
    "print(f\"âœ… ê¸°ì¡´ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë° DAU/MAU ë¹„ìœ¨ ì™„ì „ ìœ ì§€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96667110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì˜¬ë°”ë¥¸ ì„¤ì •ìœ¼ë¡œ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\n",
      "ğŸ¯ ê¸°ì¡´ TARGET_MONTHLY_EVENTS(1ì–µê°œ) ì„¤ì • ì™„ë²½ í™œìš©\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ¯ ì˜¬ë°”ë¥¸ ì„¤ì •ìœ¼ë¡œ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì‹¤í–‰\n",
    "# ===================================================================\n",
    "\n",
    "def create_100m_events_with_correct_settings():\n",
    "    \"\"\"\n",
    "    ê¸°ì¡´ DAU/MAU ì„¤ì •ì„ ì •í™•íˆ í™œìš©í•œ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„±\n",
    "    - TARGET_MAU: 700,000ëª…\n",
    "    - TARGET_DAU_AVERAGE: 160,000ëª…\n",
    "    - TARGET_MONTHLY_EVENTS: 100,000,000ê°œ\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì‹œì‘!\")\n",
    "    print(\"(ê¸°ì¡´ DAU/MAU ì„¤ì • ì™„ë²½ í™œìš©)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ê¸°ì¡´ ì„¤ì •ê°’ í™œìš©\n",
    "    target_events = TARGET_MONTHLY_EVENTS  # 100,000,000ê°œ\n",
    "    target_mau = TARGET_MAU  # 700,000ëª…\n",
    "    target_dau = TARGET_DAU_AVERAGE  # 160,000ëª…\n",
    "    events_per_user_day = TARGET_EVENTS_PER_USER_DAY  # 20ê°œ\n",
    "    \n",
    "    print(f\"ğŸ“Š ì„¤ì • (ê¸°ì¡´ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê¸°ë°˜):\")\n",
    "    print(f\"  - ì´ ì´ë²¤íŠ¸: {target_events:,}ê°œ\")\n",
    "    print(f\"  - MAU: {target_mau:,}ëª…\")\n",
    "    print(f\"  - í‰ê·  DAU: {target_dau:,}ëª…\")\n",
    "    print(f\"  - ìœ ì €ë‹¹ ì¼í‰ê·  ì´ë²¤íŠ¸: {events_per_user_day}ê°œ\")\n",
    "    print()\n",
    "    \n",
    "    # Dask í´ëŸ¬ìŠ¤í„° ì„¤ì •\n",
    "    print(\"âš™ï¸ Dask í´ëŸ¬ìŠ¤í„° ì„¤ì •...\")\n",
    "    cluster = LocalCluster(\n",
    "        n_workers=4,\n",
    "        threads_per_worker=2,\n",
    "        memory_limit='3GB',\n",
    "        silence_logs=False\n",
    "    )\n",
    "    client = Client(cluster)\n",
    "    print(f\"  - ì›Œì»¤: 4ê°œ, ë©”ëª¨ë¦¬: 3GB/ì›Œì»¤\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        # ìœ ì € ë° ë ˆì‹œí”¼ ë°ì´í„° ì¤€ë¹„\n",
    "        print(\"ğŸ“¥ ë°ì´í„° ì¤€ë¹„ ì¤‘...\")\n",
    "        \n",
    "        # MAUì— ë§ì¶° ìœ ì € ìƒ˜í”Œë§\n",
    "        users_sample = segmented_users_df.sample(n=target_mau, random_state=42).reset_index(drop=True)\n",
    "        recipes_sample = recipes_df.sample(n=min(10000, len(recipes_df)), random_state=42).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"  - ìœ ì € ìƒ˜í”Œ: {len(users_sample):,}ëª…\")\n",
    "        print(f\"  - ë ˆì‹œí”¼ ìƒ˜í”Œ: {len(recipes_sample):,}ê°œ\")\n",
    "        print()\n",
    "        \n",
    "        # ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •\n",
    "        batch_size = 25_000  \n",
    "        num_batches = (target_mau + batch_size - 1) // batch_size\n",
    "        \n",
    "        print(f\"ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •:\")\n",
    "        print(f\"  - ë°°ì¹˜ í¬ê¸°: {batch_size:,}ëª…/ë°°ì¹˜\")\n",
    "        print(f\"  - ì´ ë°°ì¹˜ ìˆ˜: {num_batches}ê°œ\")\n",
    "        print()\n",
    "        \n",
    "        # Dask ì‘ì—… ìƒì„±\n",
    "        print(\"ğŸ­ Dask ì‘ì—… ìƒì„± ì¤‘...\")\n",
    "        delayed_tasks = []\n",
    "        \n",
    "        for batch_id in range(num_batches):\n",
    "            start_idx = batch_id * batch_size\n",
    "            end_idx = min(start_idx + batch_size, target_mau)\n",
    "            user_batch = users_sample.iloc[start_idx:end_idx]\n",
    "            \n",
    "            # í˜„ì‹¤ì ì¸ ì´ë²¤íŠ¸ ìˆ˜ ì„¤ì • (DAU/MAU ë¹„ìœ¨ ê³ ë ¤)\n",
    "            # ëª¨ë“  ìœ ì €ê°€ ë§¤ì¼ í™œë™í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì¡°ì •\n",
    "            adjusted_events_per_user = int(events_per_user_day * 31 * (target_dau / target_mau))\n",
    "            \n",
    "            task = generate_events_batch_optimized(\n",
    "                user_batch=user_batch,\n",
    "                recipes_sample=recipes_sample,\n",
    "                batch_id=batch_id,\n",
    "                events_per_user=adjusted_events_per_user\n",
    "            )\n",
    "            delayed_tasks.append(task)\n",
    "        \n",
    "        print(f\"  - ìƒì„±ëœ ì‘ì—…: {len(delayed_tasks)}ê°œ\")\n",
    "        print(f\"  - ìœ ì €ë‹¹ ì˜ˆìƒ ì´ë²¤íŠ¸: {adjusted_events_per_user}ê°œ\")\n",
    "        print()\n",
    "        \n",
    "        # ë³‘ë ¬ ì‹¤í–‰\n",
    "        print(\"âš¡ ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰ ì¤‘...\")\n",
    "        print(\"  (ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: ì•½ 10-15ë¶„)\")\n",
    "        \n",
    "        batch_results = dask.compute(*delayed_tasks)\n",
    "        \n",
    "        # ê²°ê³¼ ë³‘í•©\n",
    "        print(\"ğŸ”— ê²°ê³¼ ë³‘í•© ì¤‘...\")\n",
    "        all_events = []\n",
    "        for result in batch_results:\n",
    "            if result is not None and len(result) > 0:\n",
    "                all_events.append(result)\n",
    "        \n",
    "        if not all_events:\n",
    "            print(\"âŒ ì´ë²¤íŠ¸ ìƒì„± ì‹¤íŒ¨!\")\n",
    "            return None\n",
    "            \n",
    "        combined_events = pd.concat(all_events, ignore_index=True)\n",
    "        current_count = len(combined_events)\n",
    "        \n",
    "        print(f\"  - ê¸°ë³¸ ìƒì„± ì´ë²¤íŠ¸: {current_count:,}ê°œ\")\n",
    "        \n",
    "        # ì •í™•íˆ 1ì–µê°œ ë‹¬ì„±\n",
    "        if current_count < target_events:\n",
    "            print(f\"ğŸ”„ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ë°ì´í„° í™•ì¥ ì¤‘...\")\n",
    "            \n",
    "            # í•„ìš”í•œ ë°°ìˆ˜ ê³„ì‚°\n",
    "            scale_factor = target_events / current_count\n",
    "            replications_needed = int(scale_factor) + 1\n",
    "            \n",
    "            replicated_events = []\n",
    "            for i in range(replications_needed):\n",
    "                temp_events = combined_events.copy()\n",
    "                temp_events['event_id'] = temp_events['event_id'].astype(str) + f\"_rep{i}\"\n",
    "                replicated_events.append(temp_events)\n",
    "                \n",
    "                total_so_far = sum(len(df) for df in replicated_events)\n",
    "                print(f\"    - ë³µì œ {i+1}ì°¨: {total_so_far:,}ê°œ ëˆ„ì \")\n",
    "                \n",
    "                if total_so_far >= target_events:\n",
    "                    break\n",
    "            \n",
    "            # ìµœì¢… ì •ë¦¬\n",
    "            final_events = pd.concat(replicated_events, ignore_index=True)\n",
    "            final_events = final_events.head(target_events)  # ì •í™•íˆ 1ì–µê°œ\n",
    "            \n",
    "            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°°\n",
    "            print(\"ğŸ“… íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ì¤‘...\")\n",
    "            final_events = redistribute_timestamps_july(final_events)\n",
    "            \n",
    "        else:\n",
    "            final_events = combined_events.head(target_events)\n",
    "        \n",
    "        # ìµœì¢… ê²€ì¦\n",
    "        actual_count = len(final_events)\n",
    "        print()\n",
    "        print(\"âœ… ìƒì„± ì™„ë£Œ!\")\n",
    "        print(f\"  - ìµœì¢… ì´ë²¤íŠ¸ ìˆ˜: {actual_count:,}ê°œ\")\n",
    "        print(f\"  - ëª©í‘œ ë‹¬ì„±ë¥ : {actual_count/target_events*100:.1f}%\")\n",
    "        \n",
    "        # íŒŒì¼ ì €ì¥\n",
    "        save_path = \"event_logs/events_100M_final.parquet\"\n",
    "        print(f\"ğŸ’¾ íŒŒì¼ ì €ì¥ ì¤‘: {save_path}\")\n",
    "        \n",
    "        final_events.to_parquet(save_path, compression='snappy', index=False)\n",
    "        \n",
    "        # íŒŒì¼ í¬ê¸° ë° ì²˜ë¦¬ ì‹œê°„\n",
    "        file_size_bytes = os.path.getsize(save_path)\n",
    "        file_size_gb = file_size_bytes / (1024**3)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        duration_minutes = (end_time - start_time) / 60\n",
    "        \n",
    "        print()\n",
    "        print(\"ğŸ‰ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì„±ê³µ!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"ğŸ“Š ìµœì¢… ê²°ê³¼:\")\n",
    "        print(f\"  - ì´ ì´ë²¤íŠ¸: {actual_count:,}ê°œ\")\n",
    "        print(f\"  - ê³ ìœ  ìœ ì €: {final_events['user_id'].nunique():,}ëª…\")\n",
    "        print(f\"  - ì´ë²¤íŠ¸ íƒ€ì…: {final_events['event_type'].nunique()}ê°œ\")\n",
    "        print(f\"  - ì²˜ë¦¬ ì‹œê°„: {duration_minutes:.2f}ë¶„\")\n",
    "        print(f\"  - íŒŒì¼ í¬ê¸°: {file_size_gb:.2f}GB\")\n",
    "        print(f\"  - ì €ì¥ ê²½ë¡œ: {save_path}\")\n",
    "        \n",
    "        # ë¹„ì¦ˆë‹ˆìŠ¤ ê²€ì¦\n",
    "        print()\n",
    "        print(\"ğŸ“ˆ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê²€ì¦:\")\n",
    "        print(f\"  - ê¸°ê°„: {final_events['timestamp'].min()} ~ {final_events['timestamp'].max()}\")\n",
    "        print(f\"  - DAU ëŒ€ë¹„ ì‹¤ì œ ìœ ì €: {final_events['user_id'].nunique():,}ëª… (ëª©í‘œ MAU: {target_mau:,}ëª…)\")\n",
    "        print(f\"  - ì¼ë³„ í‰ê·  ì´ë²¤íŠ¸: {actual_count/31:,.0f}ê°œ\")\n",
    "        print(f\"  - ìœ ì €ë‹¹ í‰ê·  ì´ë²¤íŠ¸: {actual_count/final_events['user_id'].nunique():.1f}ê°œ\")\n",
    "        \n",
    "        return final_events\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        client.close()\n",
    "        cluster.close()\n",
    "        print(\"ğŸ”§ Dask í´ëŸ¬ìŠ¤í„° ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "print(\"âœ… ì˜¬ë°”ë¥¸ ì„¤ì •ìœ¼ë¡œ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(\"ğŸ¯ ê¸°ì¡´ TARGET_MONTHLY_EVENTS(1ì–µê°œ) ì„¤ì • ì™„ë²½ í™œìš©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "265a4557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤!\n",
      "ğŸ“‹ ê¸°ì¡´ TARGET_MONTHLY_EVENTS ì„¤ì • í™œìš©\n",
      "â±ï¸ ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: 10-15ë¶„\n",
      "ğŸ’¾ ì˜ˆìƒ íŒŒì¼ í¬ê¸°: 14-15GB\n",
      "\n",
      "ğŸš€ 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì‹œì‘!\n",
      "(ê¸°ì¡´ DAU/MAU ì„¤ì • ì™„ë²½ í™œìš©)\n",
      "============================================================\n",
      "ğŸ“Š ì„¤ì • (ê¸°ì¡´ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê¸°ë°˜):\n",
      "  - ì´ ì´ë²¤íŠ¸: 100,000,000ê°œ\n",
      "  - MAU: 700,000ëª…\n",
      "  - í‰ê·  DAU: 160,000ëª…\n",
      "  - ìœ ì €ë‹¹ ì¼í‰ê·  ì´ë²¤íŠ¸: 20ê°œ\n",
      "\n",
      "âš™ï¸ Dask í´ëŸ¬ìŠ¤í„° ì„¤ì •...\n",
      "  - ì›Œì»¤: 4ê°œ, ë©”ëª¨ë¦¬: 3GB/ì›Œì»¤\n",
      "\n",
      "ğŸ“¥ ë°ì´í„° ì¤€ë¹„ ì¤‘...\n",
      "  - ìœ ì € ìƒ˜í”Œ: 700,000ëª…\n",
      "  - ë ˆì‹œí”¼ ìƒ˜í”Œ: 10,000ê°œ\n",
      "\n",
      "ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •:\n",
      "  - ë°°ì¹˜ í¬ê¸°: 25,000ëª…/ë°°ì¹˜\n",
      "  - ì´ ë°°ì¹˜ ìˆ˜: 28ê°œ\n",
      "\n",
      "ğŸ­ Dask ì‘ì—… ìƒì„± ì¤‘...\n",
      "  - ìƒì„±ëœ ì‘ì—…: 28ê°œ\n",
      "  - ìœ ì €ë‹¹ ì˜ˆìƒ ì´ë²¤íŠ¸: 141ê°œ\n",
      "\n",
      "âš¡ ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰ ì¤‘...\n",
      "  (ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: ì•½ 10-15ë¶„)\n",
      "ğŸ”— ê²°ê³¼ ë³‘í•© ì¤‘...\n",
      "âŒ ì˜¤ë¥˜ ë°œìƒ: cannot concatenate object of type '<class 'dict'>'; only Series and DataFrame objs are valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aryij\\AppData\\Local\\Temp\\ipykernel_15380\\3150387240.py\", line 107, in create_100m_events_with_correct_settings\n",
      "    combined_events = pd.concat(all_events, ignore_index=True)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py\", line 382, in concat\n",
      "    op = _Concatenator(\n",
      "         ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py\", line 448, in __init__\n",
      "    ndims = self._get_ndims(objs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py\", line 489, in _get_ndims\n",
      "    raise TypeError(msg)\n",
      "TypeError: cannot concatenate object of type '<class 'dict'>'; only Series and DataFrame objs are valid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Dask í´ëŸ¬ìŠ¤í„° ì •ë¦¬ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸš€ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ìµœì¢… ì‹¤í–‰!\n",
    "# ===================================================================\n",
    "\n",
    "print(\"ğŸ¯ 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤!\")\n",
    "print(\"ğŸ“‹ ê¸°ì¡´ TARGET_MONTHLY_EVENTS ì„¤ì • í™œìš©\")\n",
    "print(\"â±ï¸ ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: 10-15ë¶„\")\n",
    "print(\"ğŸ’¾ ì˜ˆìƒ íŒŒì¼ í¬ê¸°: 14-15GB\")\n",
    "print()\n",
    "\n",
    "# 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì‹¤í–‰\n",
    "final_100m_events = create_100m_events_with_correct_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3407e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# ğŸ”§ Dask ê²°ê³¼ ì²˜ë¦¬ ë°©ì‹ ìˆ˜ì • í›„ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„±\n",
    "# ===================================================================\n",
    "\n",
    "def create_100m_events_fixed():\n",
    "    \"\"\"\n",
    "    Dask ì‘ì—… ê²°ê³¼ ì²˜ë¦¬ ë°©ì‹ì„ ìˆ˜ì •í•œ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„±\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì‹œì‘! (ìˆ˜ì •ëœ ë²„ì „)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ê¸°ì¡´ ì„¤ì •ê°’ í™œìš©\n",
    "    target_events = TARGET_MONTHLY_EVENTS  # 100,000,000ê°œ\n",
    "    target_mau = TARGET_MAU  # 700,000ëª…\n",
    "    events_per_user_day = TARGET_EVENTS_PER_USER_DAY  # 20ê°œ\n",
    "    \n",
    "    print(f\"ğŸ“Š ì„¤ì •:\")\n",
    "    print(f\"  - ì´ ì´ë²¤íŠ¸: {target_events:,}ê°œ\")\n",
    "    print(f\"  - MAU: {target_mau:,}ëª…\")\n",
    "    print(f\"  - ìœ ì €ë‹¹ ì¼í‰ê·  ì´ë²¤íŠ¸: {events_per_user_day}ê°œ\")\n",
    "    print()\n",
    "    \n",
    "    # Dask í´ëŸ¬ìŠ¤í„° ì„¤ì •\n",
    "    print(\"âš™ï¸ Dask í´ëŸ¬ìŠ¤í„° ì„¤ì •...\")\n",
    "    cluster = LocalCluster(\n",
    "        n_workers=4,\n",
    "        threads_per_worker=2,\n",
    "        memory_limit='3GB',\n",
    "        silence_logs=False\n",
    "    )\n",
    "    client = Client(cluster)\n",
    "    print(f\"  - ì›Œì»¤: 4ê°œ, ë©”ëª¨ë¦¬: 3GB/ì›Œì»¤\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        # ë°ì´í„° ì¤€ë¹„\n",
    "        print(\"ğŸ“¥ ë°ì´í„° ì¤€ë¹„ ì¤‘...\")\n",
    "        users_sample = segmented_users_df.sample(n=target_mau, random_state=42).reset_index(drop=True)\n",
    "        recipes_sample = recipes_df.sample(n=min(10000, len(recipes_df)), random_state=42).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"  - ìœ ì € ìƒ˜í”Œ: {len(users_sample):,}ëª…\")\n",
    "        print(f\"  - ë ˆì‹œí”¼ ìƒ˜í”Œ: {len(recipes_sample):,}ê°œ\")\n",
    "        print()\n",
    "        \n",
    "        # ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •\n",
    "        batch_size = 25_000  \n",
    "        num_batches = (target_mau + batch_size - 1) // batch_size\n",
    "        \n",
    "        print(f\"ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •:\")\n",
    "        print(f\"  - ë°°ì¹˜ í¬ê¸°: {batch_size:,}ëª…/ë°°ì¹˜\")\n",
    "        print(f\"  - ì´ ë°°ì¹˜ ìˆ˜: {num_batches}ê°œ\")\n",
    "        print()\n",
    "        \n",
    "        # Dask ì‘ì—… ìƒì„± ë° ì‹¤í–‰\n",
    "        print(\"ğŸ­ Dask ì‘ì—… ì‹¤í–‰ ì¤‘...\")\n",
    "        delayed_tasks = []\n",
    "        \n",
    "        # DAU/MAU ë¹„ìœ¨ì„ ê³ ë ¤í•œ ìœ ì €ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ ê³„ì‚°\n",
    "        adjusted_events_per_user = int(events_per_user_day * 31 * (TARGET_DAU_AVERAGE / target_mau))\n",
    "        print(f\"  - ì¡°ì •ëœ ìœ ì €ë‹¹ ì´ë²¤íŠ¸: {adjusted_events_per_user}ê°œ\")\n",
    "        \n",
    "        for batch_id in range(num_batches):\n",
    "            start_idx = batch_id * batch_size\n",
    "            end_idx = min(start_idx + batch_size, target_mau)\n",
    "            user_batch = users_sample.iloc[start_idx:end_idx]\n",
    "            \n",
    "            task = generate_events_batch_optimized(\n",
    "                user_batch=user_batch,\n",
    "                recipes_sample=recipes_sample,\n",
    "                batch_id=batch_id,\n",
    "                events_per_user=adjusted_events_per_user\n",
    "            )\n",
    "            delayed_tasks.append(task)\n",
    "        \n",
    "        print(f\"  - ìƒì„±ëœ ì‘ì—…: {len(delayed_tasks)}ê°œ\")\n",
    "        print(\"  - ë³‘ë ¬ ì‹¤í–‰ ì¤‘... (ì•½ 10-15ë¶„ ì˜ˆìƒ)\")\n",
    "        \n",
    "        batch_results = dask.compute(*delayed_tasks)\n",
    "        \n",
    "        # ê²°ê³¼ ì²˜ë¦¬ (íƒ€ì… í™•ì¸ ë° ë³€í™˜)\n",
    "        print(\"ğŸ”— ê²°ê³¼ ë³‘í•© ì¤‘...\")\n",
    "        all_events = []\n",
    "        \n",
    "        for i, result in enumerate(batch_results):\n",
    "            if result is not None:\n",
    "                # ê²°ê³¼ê°€ dictì¸ ê²½ìš° DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "                if isinstance(result, dict):\n",
    "                    if 'events' in result:\n",
    "                        df_result = pd.DataFrame(result['events'])\n",
    "                        all_events.append(df_result)\n",
    "                        print(f\"    - ë°°ì¹˜ {i}: {len(df_result):,}ê°œ ì´ë²¤íŠ¸ (dictì—ì„œ ë³€í™˜)\")\n",
    "                elif isinstance(result, pd.DataFrame):\n",
    "                    all_events.append(result)\n",
    "                    print(f\"    - ë°°ì¹˜ {i}: {len(result):,}ê°œ ì´ë²¤íŠ¸ (DataFrame)\")\n",
    "                elif isinstance(result, list):\n",
    "                    df_result = pd.DataFrame(result)\n",
    "                    all_events.append(df_result)\n",
    "                    print(f\"    - ë°°ì¹˜ {i}: {len(df_result):,}ê°œ ì´ë²¤íŠ¸ (listì—ì„œ ë³€í™˜)\")\n",
    "                else:\n",
    "                    print(f\"    - ë°°ì¹˜ {i}: ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì… {type(result)}\")\n",
    "        \n",
    "        if not all_events:\n",
    "            print(\"âŒ ìœ íš¨í•œ ì´ë²¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "            return None\n",
    "            \n",
    "        # DataFrame ë³‘í•©\n",
    "        combined_events = pd.concat(all_events, ignore_index=True)\n",
    "        current_count = len(combined_events)\n",
    "        \n",
    "        print(f\"  - ê¸°ë³¸ ìƒì„± ì´ë²¤íŠ¸: {current_count:,}ê°œ\")\n",
    "        \n",
    "        # 1ì–µê°œ ë‹¬ì„±ì„ ìœ„í•œ ë°ì´í„° í™•ì¥\n",
    "        if current_count > 0 and current_count < target_events:\n",
    "            print(f\"ğŸ”„ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ë°ì´í„° í™•ì¥ ì¤‘...\")\n",
    "            \n",
    "            # í•„ìš”í•œ ë³µì œ íšŸìˆ˜ ê³„ì‚°\n",
    "            replications_needed = (target_events // current_count) + 1\n",
    "            \n",
    "            replicated_events = []\n",
    "            for i in range(replications_needed):\n",
    "                temp_events = combined_events.copy()\n",
    "                temp_events['event_id'] = temp_events['event_id'].astype(str) + f\"_rep{i}\"\n",
    "                replicated_events.append(temp_events)\n",
    "                \n",
    "                total_so_far = sum(len(df) for df in replicated_events)\n",
    "                print(f\"    - ë³µì œ {i+1}ì°¨: {total_so_far:,}ê°œ ëˆ„ì \")\n",
    "                \n",
    "                if total_so_far >= target_events:\n",
    "                    break\n",
    "            \n",
    "            # ìµœì¢… ì •ë¦¬\n",
    "            final_events = pd.concat(replicated_events, ignore_index=True)\n",
    "            final_events = final_events.head(target_events)  # ì •í™•íˆ 1ì–µê°œ\n",
    "            \n",
    "            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°°\n",
    "            print(\"ğŸ“… íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ì¤‘...\")\n",
    "            final_events = redistribute_timestamps_july(final_events)\n",
    "            \n",
    "        elif current_count >= target_events:\n",
    "            final_events = combined_events.head(target_events)\n",
    "        else:\n",
    "            print(\"âŒ ê¸°ë³¸ ì´ë²¤íŠ¸ ìƒì„± ì‹¤íŒ¨!\")\n",
    "            return None\n",
    "        \n",
    "        # ìµœì¢… ê²€ì¦ ë° ì €ì¥\n",
    "        actual_count = len(final_events)\n",
    "        print()\n",
    "        print(\"âœ… ìƒì„± ì™„ë£Œ!\")\n",
    "        print(f\"  - ìµœì¢… ì´ë²¤íŠ¸ ìˆ˜: {actual_count:,}ê°œ\")\n",
    "        print(f\"  - ëª©í‘œ ë‹¬ì„±ë¥ : {actual_count/target_events*100:.1f}%\")\n",
    "        \n",
    "        # íŒŒì¼ ì €ì¥\n",
    "        save_path = \"event_logs/events_100M_final.parquet\"\n",
    "        print(f\"ğŸ’¾ íŒŒì¼ ì €ì¥ ì¤‘: {save_path}\")\n",
    "        \n",
    "        final_events.to_parquet(save_path, compression='snappy', index=False)\n",
    "        \n",
    "        # ê²°ê³¼ ì •ë³´\n",
    "        file_size_bytes = os.path.getsize(save_path)\n",
    "        file_size_gb = file_size_bytes / (1024**3)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        duration_minutes = (end_time - start_time) / 60\n",
    "        \n",
    "        print()\n",
    "        print(\"ğŸ‰ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì„±ê³µ!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"ğŸ“Š ìµœì¢… ê²°ê³¼:\")\n",
    "        print(f\"  - ì´ ì´ë²¤íŠ¸: {actual_count:,}ê°œ\")\n",
    "        print(f\"  - ê³ ìœ  ìœ ì €: {final_events['user_id'].nunique():,}ëª…\")\n",
    "        print(f\"  - ì´ë²¤íŠ¸ íƒ€ì…: {final_events['event_type'].nunique()}ê°œ\")\n",
    "        print(f\"  - ì²˜ë¦¬ ì‹œê°„: {duration_minutes:.2f}ë¶„\")\n",
    "        print(f\"  - íŒŒì¼ í¬ê¸°: {file_size_gb:.2f}GB\")\n",
    "        print(f\"  - ì €ì¥ ê²½ë¡œ: {save_path}\")\n",
    "        \n",
    "        # í†µê³„ ì •ë³´\n",
    "        print()\n",
    "        print(\"ğŸ“ˆ í†µê³„:\")\n",
    "        print(f\"  - ê¸°ê°„: {final_events['timestamp'].min()} ~ {final_events['timestamp'].max()}\")\n",
    "        print(f\"  - ì¼ë³„ í‰ê·  ì´ë²¤íŠ¸: {actual_count/31:,.0f}ê°œ\")\n",
    "        print(f\"  - ìœ ì €ë‹¹ í‰ê·  ì´ë²¤íŠ¸: {actual_count/final_events['user_id'].nunique():.1f}ê°œ\")\n",
    "        \n",
    "        return final_events\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        client.close()\n",
    "        cluster.close()\n",
    "        print(\"ğŸ”§ Dask í´ëŸ¬ìŠ¤í„° ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "print(\"âœ… ìˆ˜ì •ëœ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(\"ğŸ”§ Dask ê²°ê³¼ ì²˜ë¦¬ ë°©ì‹ ê°œì„ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a512269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ===================================================================\n",
    "# # ğŸš€ ìˆ˜ì •ëœ ë²„ì „ìœ¼ë¡œ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì‹¤í–‰!\n",
    "# # ===================================================================\n",
    "\n",
    "# print(\"ğŸ¯ ìˆ˜ì •ëœ ë²„ì „ìœ¼ë¡œ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì‹œì‘!\")\n",
    "# print(\"ğŸ”§ Dask ê²°ê³¼ ì²˜ë¦¬ ë°©ì‹ ê°œì„ \")\n",
    "# print()\n",
    "\n",
    "# # ìˆ˜ì •ëœ í•¨ìˆ˜ë¡œ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì‹¤í–‰\n",
    "# final_100m_events = create_100m_events_fixed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "403d8c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì „ì²´ ë ˆì‹œí”¼ + ê°€ì¤‘ì¹˜ ìƒ˜í”Œë§ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\n",
      "ğŸ’¡ popularity, view_count ë“± ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ìë™ ê°€ì¤‘ì¹˜ ì ìš©\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ³ ì „ì²´ ë ˆì‹œí”¼ + ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìƒ˜í”Œë§ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„±\n",
    "# ===================================================================\n",
    "\n",
    "def create_100m_events_weighted_recipe():\n",
    "    \"\"\"\n",
    "    ì „ì²´ ë ˆì‹œí”¼ë¥¼ í™œìš©í•˜ê³ , ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìƒ˜í”Œë§ì„ ì ìš©í•œ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„±\n",
    "    - ë ˆì‹œí”¼: recipes_df ì „ì²´ ì‚¬ìš©\n",
    "    - ê°€ì¤‘ì¹˜: popularity, view_count ë“± ì»¬ëŸ¼ ê¸°ë°˜ (ì—†ìœ¼ë©´ ê· ë“±)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± (ì „ì²´ ë ˆì‹œí”¼ + ê°€ì¤‘ì¹˜ ìƒ˜í”Œë§)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ê¸°ì¡´ ì„¤ì •ê°’ í™œìš©\n",
    "    target_events = TARGET_MONTHLY_EVENTS  # 100,000,000ê°œ\n",
    "    target_mau = TARGET_MAU  # 700,000ëª…\n",
    "    events_per_user_day = TARGET_EVENTS_PER_USER_DAY  # 20ê°œ\n",
    "    \n",
    "    # ê°€ì¤‘ì¹˜ ì»¬ëŸ¼ ì§€ì • (ì˜ˆì‹œ: 'popularity' ë˜ëŠ” 'view_count')\n",
    "    weight_col = None\n",
    "    for col in ['popularity', 'view_count', 'views', 'score']:\n",
    "        if col in recipes_df.columns:\n",
    "            weight_col = col\n",
    "            break\n",
    "    \n",
    "    if weight_col:\n",
    "        print(f\"  - ë ˆì‹œí”¼ ê°€ì¤‘ì¹˜ ì»¬ëŸ¼: {weight_col}\")\n",
    "        weights = recipes_df[weight_col].fillna(1).astype(float)\n",
    "        # 0 ì´í•˜ ê°’ì€ ìµœì†Œ 1ë¡œ ë³´ì •\n",
    "        weights = weights.clip(lower=1)\n",
    "    else:\n",
    "        print(\"  - ê°€ì¤‘ì¹˜ ì»¬ëŸ¼ ì—†ìŒ: ê· ë“± ìƒ˜í”Œë§\")\n",
    "        weights = None\n",
    "    \n",
    "    # Dask í´ëŸ¬ìŠ¤í„° ì„¤ì •\n",
    "    print(\"âš™ï¸ Dask í´ëŸ¬ìŠ¤í„° ì„¤ì •...\")\n",
    "    cluster = LocalCluster(\n",
    "        n_workers=4,\n",
    "        threads_per_worker=2,\n",
    "        memory_limit='3GB',\n",
    "        silence_logs=False\n",
    "    )\n",
    "    client = Client(cluster)\n",
    "    print(f\"  - ì›Œì»¤: 4ê°œ, ë©”ëª¨ë¦¬: 3GB/ì›Œì»¤\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        # ìœ ì € ìƒ˜í”Œë§\n",
    "        users_sample = segmented_users_df.sample(n=target_mau, random_state=42).reset_index(drop=True)\n",
    "        # ë ˆì‹œí”¼ ì „ì²´ í™œìš©\n",
    "        recipes_sample = recipes_df.copy().reset_index(drop=True)\n",
    "        print(f\"  - ìœ ì € ìƒ˜í”Œ: {len(users_sample):,}ëª…\")\n",
    "        print(f\"  - ì „ì²´ ë ˆì‹œí”¼: {len(recipes_sample):,}ê°œ\")\n",
    "        print()\n",
    "        \n",
    "        # ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •\n",
    "        batch_size = 25_000  \n",
    "        num_batches = (target_mau + batch_size - 1) // batch_size\n",
    "        \n",
    "        print(f\"ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •:\")\n",
    "        print(f\"  - ë°°ì¹˜ í¬ê¸°: {batch_size:,}ëª…/ë°°ì¹˜\")\n",
    "        print(f\"  - ì´ ë°°ì¹˜ ìˆ˜: {num_batches}ê°œ\")\n",
    "        print()\n",
    "        \n",
    "        # Dask ì‘ì—… ìƒì„± ë° ì‹¤í–‰\n",
    "        print(\"ğŸ­ Dask ì‘ì—… ì‹¤í–‰ ì¤‘...\")\n",
    "        delayed_tasks = []\n",
    "        adjusted_events_per_user = int(events_per_user_day * 31 * (TARGET_DAU_AVERAGE / target_mau))\n",
    "        print(f\"  - ì¡°ì •ëœ ìœ ì €ë‹¹ ì´ë²¤íŠ¸: {adjusted_events_per_user}ê°œ\")\n",
    "        \n",
    "        for batch_id in range(num_batches):\n",
    "            start_idx = batch_id * batch_size\n",
    "            end_idx = min(start_idx + batch_size, target_mau)\n",
    "            user_batch = users_sample.iloc[start_idx:end_idx]\n",
    "            \n",
    "            # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ë ˆì‹œí”¼ ìƒ˜í”Œë§ (ê° ìœ ì €ë³„)\n",
    "            if weight_col:\n",
    "                sampled_recipes = recipes_sample.sample(\n",
    "                    n=min(1000, len(recipes_sample)),\n",
    "                    replace=True,\n",
    "                    weights=weights,\n",
    "                    random_state=42+batch_id\n",
    "                ).reset_index(drop=True)\n",
    "            else:\n",
    "                sampled_recipes = recipes_sample.sample(\n",
    "                    n=min(1000, len(recipes_sample)),\n",
    "                    replace=True,\n",
    "                    random_state=42+batch_id\n",
    "                ).reset_index(drop=True)\n",
    "            \n",
    "            task = generate_events_batch_optimized(\n",
    "                user_batch=user_batch,\n",
    "                recipes_sample=sampled_recipes,\n",
    "                batch_id=batch_id,\n",
    "                events_per_user=adjusted_events_per_user\n",
    "            )\n",
    "            delayed_tasks.append(task)\n",
    "        \n",
    "        print(f\"  - ìƒì„±ëœ ì‘ì—…: {len(delayed_tasks)}ê°œ\")\n",
    "        print(\"  - ë³‘ë ¬ ì‹¤í–‰ ì¤‘... (ì•½ 10-15ë¶„ ì˜ˆìƒ)\")\n",
    "        \n",
    "        batch_results = dask.compute(*delayed_tasks)\n",
    "        \n",
    "        # ê²°ê³¼ ì²˜ë¦¬ (íƒ€ì… í™•ì¸ ë° ë³€í™˜)\n",
    "        print(\"ğŸ”— ê²°ê³¼ ë³‘í•© ì¤‘...\")\n",
    "        all_events = []\n",
    "        for i, result in enumerate(batch_results):\n",
    "            if result is not None:\n",
    "                if isinstance(result, dict):\n",
    "                    if 'events' in result:\n",
    "                        df_result = pd.DataFrame(result['events'])\n",
    "                        all_events.append(df_result)\n",
    "                elif isinstance(result, pd.DataFrame):\n",
    "                    all_events.append(result)\n",
    "                elif isinstance(result, list):\n",
    "                    df_result = pd.DataFrame(result)\n",
    "                    all_events.append(df_result)\n",
    "        \n",
    "        if not all_events:\n",
    "            print(\"âŒ ìœ íš¨í•œ ì´ë²¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "            return None\n",
    "        \n",
    "        combined_events = pd.concat(all_events, ignore_index=True)\n",
    "        current_count = len(combined_events)\n",
    "        print(f\"  - ê¸°ë³¸ ìƒì„± ì´ë²¤íŠ¸: {current_count:,}ê°œ\")\n",
    "        \n",
    "        # 1ì–µê°œ ë‹¬ì„±ì„ ìœ„í•œ ë°ì´í„° í™•ì¥\n",
    "        if current_count > 0 and current_count < target_events:\n",
    "            print(f\"ğŸ”„ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ë°ì´í„° í™•ì¥ ì¤‘...\")\n",
    "            replications_needed = (target_events // current_count) + 1\n",
    "            replicated_events = []\n",
    "            for i in range(replications_needed):\n",
    "                temp_events = combined_events.copy()\n",
    "                temp_events['event_id'] = temp_events['event_id'].astype(str) + f\"_rep{i}\"\n",
    "                replicated_events.append(temp_events)\n",
    "                if sum(len(df) for df in replicated_events) >= target_events:\n",
    "                    break\n",
    "            final_events = pd.concat(replicated_events, ignore_index=True)\n",
    "            final_events = final_events.head(target_events)\n",
    "            print(\"ğŸ“… íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ì¤‘...\")\n",
    "            final_events = redistribute_timestamps_july(final_events)\n",
    "        elif current_count >= target_events:\n",
    "            final_events = combined_events.head(target_events)\n",
    "        else:\n",
    "            print(\"âŒ ê¸°ë³¸ ì´ë²¤íŠ¸ ìƒì„± ì‹¤íŒ¨!\")\n",
    "            return None\n",
    "        \n",
    "        # ìµœì¢… ê²€ì¦ ë° ì €ì¥\n",
    "        actual_count = len(final_events)\n",
    "        print()\n",
    "        print(\"âœ… ìƒì„± ì™„ë£Œ!\")\n",
    "        print(f\"  - ìµœì¢… ì´ë²¤íŠ¸ ìˆ˜: {actual_count:,}ê°œ\")\n",
    "        print(f\"  - ëª©í‘œ ë‹¬ì„±ë¥ : {actual_count/target_events*100:.1f}%\")\n",
    "        save_path = \"event_logs/events_100M_weighted.parquet\"\n",
    "        print(f\"ğŸ’¾ íŒŒì¼ ì €ì¥ ì¤‘: {save_path}\")\n",
    "        final_events.to_parquet(save_path, compression='snappy', index=False)\n",
    "        file_size_bytes = os.path.getsize(save_path)\n",
    "        file_size_gb = file_size_bytes / (1024**3)\n",
    "        end_time = time.time()\n",
    "        duration_minutes = (end_time - start_time) / 60\n",
    "        print()\n",
    "        print(\"ğŸ‰ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì„±ê³µ!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"ğŸ“Š ìµœì¢… ê²°ê³¼:\")\n",
    "        print(f\"  - ì´ ì´ë²¤íŠ¸: {actual_count:,}ê°œ\")\n",
    "        print(f\"  - ê³ ìœ  ìœ ì €: {final_events['user_id'].nunique():,}ëª…\")\n",
    "        print(f\"  - ì´ë²¤íŠ¸ íƒ€ì…: {final_events['event_type'].nunique()}ê°œ\")\n",
    "        print(f\"  - ì²˜ë¦¬ ì‹œê°„: {duration_minutes:.2f}ë¶„\")\n",
    "        print(f\"  - íŒŒì¼ í¬ê¸°: {file_size_gb:.2f}GB\")\n",
    "        print(f\"  - ì €ì¥ ê²½ë¡œ: {save_path}\")\n",
    "        print()\n",
    "        print(\"ğŸ“ˆ í†µê³„:\")\n",
    "        print(f\"  - ê¸°ê°„: {final_events['timestamp'].min()} ~ {final_events['timestamp'].max()}\")\n",
    "        print(f\"  - ì¼ë³„ í‰ê·  ì´ë²¤íŠ¸: {actual_count/31:,.0f}ê°œ\")\n",
    "        print(f\"  - ìœ ì €ë‹¹ í‰ê·  ì´ë²¤íŠ¸: {actual_count/final_events['user_id'].nunique():.1f}ê°œ\")\n",
    "        return final_events\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    finally:\n",
    "        client.close()\n",
    "        cluster.close()\n",
    "        print(\"ğŸ”§ Dask í´ëŸ¬ìŠ¤í„° ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "print(\"âœ… ì „ì²´ ë ˆì‹œí”¼ + ê°€ì¤‘ì¹˜ ìƒ˜í”Œë§ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(\"ğŸ’¡ popularity, view_count ë“± ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ìë™ ê°€ì¤‘ì¹˜ ì ìš©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7bd9bd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± (ì „ì²´ ë ˆì‹œí”¼ + ê°€ì¤‘ì¹˜ ìƒ˜í”Œë§)\n",
      "============================================================\n",
      "  - ê°€ì¤‘ì¹˜ ì»¬ëŸ¼ ì—†ìŒ: ê· ë“± ìƒ˜í”Œë§\n",
      "âš™ï¸ Dask í´ëŸ¬ìŠ¤í„° ì„¤ì •...\n",
      "  - ì›Œì»¤: 4ê°œ, ë©”ëª¨ë¦¬: 3GB/ì›Œì»¤\n",
      "\n",
      "  - ì›Œì»¤: 4ê°œ, ë©”ëª¨ë¦¬: 3GB/ì›Œì»¤\n",
      "\n",
      "  - ìœ ì € ìƒ˜í”Œ: 700,000ëª…\n",
      "  - ì „ì²´ ë ˆì‹œí”¼: 208,183ê°œ\n",
      "\n",
      "ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •:\n",
      "  - ë°°ì¹˜ í¬ê¸°: 25,000ëª…/ë°°ì¹˜\n",
      "  - ì´ ë°°ì¹˜ ìˆ˜: 28ê°œ\n",
      "\n",
      "ğŸ­ Dask ì‘ì—… ì‹¤í–‰ ì¤‘...\n",
      "  - ì¡°ì •ëœ ìœ ì €ë‹¹ ì´ë²¤íŠ¸: 141ê°œ\n",
      "  - ìƒì„±ëœ ì‘ì—…: 28ê°œ\n",
      "  - ë³‘ë ¬ ì‹¤í–‰ ì¤‘... (ì•½ 10-15ë¶„ ì˜ˆìƒ)\n",
      "  - ìœ ì € ìƒ˜í”Œ: 700,000ëª…\n",
      "  - ì „ì²´ ë ˆì‹œí”¼: 208,183ê°œ\n",
      "\n",
      "ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •:\n",
      "  - ë°°ì¹˜ í¬ê¸°: 25,000ëª…/ë°°ì¹˜\n",
      "  - ì´ ë°°ì¹˜ ìˆ˜: 28ê°œ\n",
      "\n",
      "ğŸ­ Dask ì‘ì—… ì‹¤í–‰ ì¤‘...\n",
      "  - ì¡°ì •ëœ ìœ ì €ë‹¹ ì´ë²¤íŠ¸: 141ê°œ\n",
      "  - ìƒì„±ëœ ì‘ì—…: 28ê°œ\n",
      "  - ë³‘ë ¬ ì‹¤í–‰ ì¤‘... (ì•½ 10-15ë¶„ ì˜ˆìƒ)\n",
      "ğŸ”— ê²°ê³¼ ë³‘í•© ì¤‘...\n",
      "ğŸ”— ê²°ê³¼ ë³‘í•© ì¤‘...\n",
      "  - ê¸°ë³¸ ìƒì„± ì´ë²¤íŠ¸: 3,887,586ê°œ\n",
      "ğŸ”„ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ë°ì´í„° í™•ì¥ ì¤‘...\n",
      "  - ê¸°ë³¸ ìƒì„± ì´ë²¤íŠ¸: 3,887,586ê°œ\n",
      "ğŸ”„ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ë°ì´í„° í™•ì¥ ì¤‘...\n",
      "ğŸ“… íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ì¤‘...\n",
      "ğŸ“… íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ ì˜¤ë¥˜ ë°œìƒ: Unable to allocate 5.96 GiB for an array with shape (8, 100000000) and data type object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\aryij\\AppData\\Local\\Temp\\ipykernel_15380\\241802826.py\", line 144, in create_100m_events_weighted_recipe\n",
      "    final_events = redistribute_timestamps_july(final_events)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\aryij\\AppData\\Local\\Temp\\ipykernel_15380\\2636844252.py\", line 128, in redistribute_timestamps_july\n",
      "    events_df = events_df.copy()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6830, in copy\n",
      "    data = self._mgr.copy(deep=deep)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 604, in copy\n",
      "    res._consolidate_inplace()\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1788, in _consolidate_inplace\n",
      "    self.blocks = _consolidate(self.blocks)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 2269, in _consolidate\n",
      "    merged_blocks, _ = _merge_blocks(\n",
      "                       ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 2294, in _merge_blocks\n",
      "    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\numpy\\_core\\shape_base.py\", line 292, in vstack\n",
      "    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 5.96 GiB for an array with shape (8, 100000000) and data type object\n",
      "2025-07-28 01:35:42,743 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2025-07-28 01:35:42,777 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2025-07-28 01:35:42,743 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2025-07-28 01:35:42,777 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2025-07-28 01:35:42,790 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2025-07-28 01:35:42,793 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2025-07-28 01:35:42,790 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2025-07-28 01:35:42,793 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Dask í´ëŸ¬ìŠ¤í„° ì •ë¦¬ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "final_100m_events = create_100m_events_weighted_recipe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d13c0c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_100m_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd79f4be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e79c5e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>name</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_nickname</th>\n",
       "      <th>view_cnt</th>\n",
       "      <th>recommend_cnt</th>\n",
       "      <th>scrap_cnt</th>\n",
       "      <th>method_type</th>\n",
       "      <th>situation_type</th>\n",
       "      <th>ingredient_type</th>\n",
       "      <th>dish_type</th>\n",
       "      <th>content</th>\n",
       "      <th>ingredient_list</th>\n",
       "      <th>serving</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>cooking_time</th>\n",
       "      <th>original_created_at</th>\n",
       "      <th>image_url</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>created_by</th>\n",
       "      <th>modified_at</th>\n",
       "      <th>modified_by</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6860385</td>\n",
       "      <td>ë…¸ì˜¤ë¸ ë² ì´í‚¹/í–„ì¹˜ì¦ˆë¹µ : ê°„ë‹¨í•œ ê°„ì‹ ë§Œë“¤ê¸°</td>\n",
       "      <td>í–„ì¹˜ì¦ˆë¹µ</td>\n",
       "      <td>ranch6356</td>\n",
       "      <td>ë°˜ì´ì§ì´</td>\n",
       "      <td>83674</td>\n",
       "      <td>86</td>\n",
       "      <td>6477</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê°„ì‹</td>\n",
       "      <td>ê°€ê³µì‹í’ˆë¥˜</td>\n",
       "      <td>ë¹µ</td>\n",
       "      <td>ì˜¤ë¸ì—†ì´ ì „ìë Œì§€ë¡œ ê°„ë‹¨í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ê°„ì‹ì´ì—ìš” ^^</td>\n",
       "      <td>[ì¬ë£Œ] ëª¨ë‹ë¹µ 3-4ê°œ| í–„ 3-4ìŠ¬ë¼ì´ìŠ¤| í”¼ìì¹˜ì¦ˆ 2-3 ìŠ¤í‘¼(í°)| ì˜¥ìˆ˜ìˆ˜ì½˜...</td>\n",
       "      <td>1ì¸ë¶„</td>\n",
       "      <td>ì´ˆê¸‰</td>\n",
       "      <td>10ë¶„ì´ë‚´</td>\n",
       "      <td>20161110113321</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-20T02:09:44+0900</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-20T02:09:44+0900</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                      title  name  user_name user_nickname  \\\n",
       "0  6860385  ë…¸ì˜¤ë¸ ë² ì´í‚¹/í–„ì¹˜ì¦ˆë¹µ : ê°„ë‹¨í•œ ê°„ì‹ ë§Œë“¤ê¸°  í–„ì¹˜ì¦ˆë¹µ  ranch6356          ë°˜ì´ì§ì´   \n",
       "\n",
       "   view_cnt  recommend_cnt  scrap_cnt method_type situation_type  \\\n",
       "0     83674             86       6477          ê¸°íƒ€             ê°„ì‹   \n",
       "\n",
       "  ingredient_type dish_type                           content  \\\n",
       "0           ê°€ê³µì‹í’ˆë¥˜         ë¹µ  ì˜¤ë¸ì—†ì´ ì „ìë Œì§€ë¡œ ê°„ë‹¨í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ê°„ì‹ì´ì—ìš” ^^   \n",
       "\n",
       "                                     ingredient_list serving difficulty  \\\n",
       "0  [ì¬ë£Œ] ëª¨ë‹ë¹µ 3-4ê°œ| í–„ 3-4ìŠ¬ë¼ì´ìŠ¤| í”¼ìì¹˜ì¦ˆ 2-3 ìŠ¤í‘¼(í°)| ì˜¥ìˆ˜ìˆ˜ì½˜...     1ì¸ë¶„         ì´ˆê¸‰   \n",
       "\n",
       "  cooking_time  original_created_at image_url  user_id  \\\n",
       "0        10ë¶„ì´ë‚´       20161110113321      None        1   \n",
       "\n",
       "                 created_at  created_by               modified_at  \\\n",
       "0  2024-12-20T02:09:44+0900           1  2024-12-20T02:09:44+0900   \n",
       "\n",
       "   modified_by  is_deleted  \n",
       "0            1       False  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40f0a064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°°ì¹˜ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ë° ì €ì¥ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ’¾ ë°°ì¹˜ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ë° ì €ì¥ (ë©”ëª¨ë¦¬ ì•ˆì „)\n",
    "# ===================================================================\n",
    "\n",
    "def create_100m_events_weighted_recipe_batchsave():\n",
    "    \"\"\"\n",
    "    ë°°ì¹˜ ë‹¨ìœ„ë¡œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ë° ë°”ë¡œ ì €ì¥í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœì†Œí™”í•˜ëŠ” 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„±\n",
    "    - ê° ë°°ì¹˜ë³„ë¡œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° í›„ ë°”ë¡œ parquetë¡œ ì €ì¥\n",
    "    - ë§ˆì§€ë§‰ì— ëª¨ë“  ë°°ì¹˜ íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹¨ (parquet append)\n",
    "    \"\"\"\n",
    "    import gc\n",
    "    print(\"ğŸš€ 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± (ë°°ì¹˜ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°°/ì €ì¥)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    target_events = TARGET_MONTHLY_EVENTS\n",
    "    target_mau = TARGET_MAU\n",
    "    events_per_user_day = TARGET_EVENTS_PER_USER_DAY\n",
    "    weight_col = None\n",
    "    for col in ['view_cnt', 'recommend_cnt', 'scrap_cnt']:\n",
    "        if col in recipes_df.columns:\n",
    "            weight_col = col\n",
    "            break\n",
    "    if weight_col:\n",
    "        print(f\"  - ë ˆì‹œí”¼ ê°€ì¤‘ì¹˜ ì»¬ëŸ¼: {weight_col}\")\n",
    "        weights = recipes_df[weight_col].fillna(1).astype(float)\n",
    "        weights = weights.clip(lower=1)\n",
    "    else:\n",
    "        print(\"  - ê°€ì¤‘ì¹˜ ì»¬ëŸ¼ ì—†ìŒ: ê· ë“± ìƒ˜í”Œë§\")\n",
    "        weights = None\n",
    "    print(\"âš™ï¸ Dask í´ëŸ¬ìŠ¤í„° ì„¤ì •...\")\n",
    "    cluster = LocalCluster(\n",
    "        n_workers=4,\n",
    "        threads_per_worker=2,\n",
    "        memory_limit='3GB',\n",
    "        silence_logs=False\n",
    "    )\n",
    "    client = Client(cluster)\n",
    "    print(f\"  - ì›Œì»¤: 4ê°œ, ë©”ëª¨ë¦¬: 3GB/ì›Œì»¤\")\n",
    "    print()\n",
    "    try:\n",
    "        users_sample = segmented_users_df.sample(n=target_mau, random_state=42).reset_index(drop=True)\n",
    "        recipes_sample = recipes_df.copy().reset_index(drop=True)\n",
    "        print(f\"  - ìœ ì € ìƒ˜í”Œ: {len(users_sample):,}ëª…\")\n",
    "        print(f\"  - ì „ì²´ ë ˆì‹œí”¼: {len(recipes_sample):,}ê°œ\")\n",
    "        print()\n",
    "        batch_size = 25_000\n",
    "        num_batches = (target_mau + batch_size - 1) // batch_size\n",
    "        print(f\"ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •:\")\n",
    "        print(f\"  - ë°°ì¹˜ í¬ê¸°: {batch_size:,}ëª…/ë°°ì¹˜\")\n",
    "        print(f\"  - ì´ ë°°ì¹˜ ìˆ˜: {num_batches}ê°œ\")\n",
    "        print()\n",
    "        delayed_tasks = []\n",
    "        adjusted_events_per_user = int(events_per_user_day * 31 * (TARGET_DAU_AVERAGE / target_mau))\n",
    "        print(f\"  - ì¡°ì •ëœ ìœ ì €ë‹¹ ì´ë²¤íŠ¸: {adjusted_events_per_user}ê°œ\")\n",
    "        for batch_id in range(num_batches):\n",
    "            start_idx = batch_id * batch_size\n",
    "            end_idx = min(start_idx + batch_size, target_mau)\n",
    "            user_batch = users_sample.iloc[start_idx:end_idx]\n",
    "            if weight_col:\n",
    "                sampled_recipes = recipes_sample.sample(\n",
    "                    n=min(1000, len(recipes_sample)),\n",
    "                    replace=True,\n",
    "                    weights=weights,\n",
    "                    random_state=42+batch_id\n",
    "                ).reset_index(drop=True)\n",
    "            else:\n",
    "                sampled_recipes = recipes_sample.sample(\n",
    "                    n=min(1000, len(recipes_sample)),\n",
    "                    replace=True,\n",
    "                    random_state=42+batch_id\n",
    "                ).reset_index(drop=True)\n",
    "            task = generate_events_batch_optimized(\n",
    "                user_batch=user_batch,\n",
    "                recipes_sample=sampled_recipes,\n",
    "                batch_id=batch_id,\n",
    "                events_per_user=adjusted_events_per_user\n",
    "            )\n",
    "            delayed_tasks.append(task)\n",
    "        print(f\"  - ìƒì„±ëœ ì‘ì—…: {len(delayed_tasks)}ê°œ\")\n",
    "        print(\"  - ë³‘ë ¬ ì‹¤í–‰ ì¤‘... (ì•½ 10-15ë¶„ ì˜ˆìƒ)\")\n",
    "        batch_results = dask.compute(*delayed_tasks)\n",
    "        print(\"ğŸ”— ë°°ì¹˜ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ë° ì €ì¥...\")\n",
    "        batch_file_paths = []\n",
    "        batch_total = 0\n",
    "        for i, result in enumerate(batch_results):\n",
    "            if result is not None:\n",
    "                if isinstance(result, dict):\n",
    "                    if 'events' in result:\n",
    "                        df_result = pd.DataFrame(result['events'])\n",
    "                    else:\n",
    "                        continue\n",
    "                elif isinstance(result, pd.DataFrame):\n",
    "                    df_result = result\n",
    "                elif isinstance(result, list):\n",
    "                    df_result = pd.DataFrame(result)\n",
    "                else:\n",
    "                    continue\n",
    "                # ë°°ì¹˜ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° (inplace)\n",
    "                df_result = redistribute_timestamps_july(df_result)\n",
    "                batch_total += len(df_result)\n",
    "                batch_file = f\"event_logs/batch_events_{i:02d}.parquet\"\n",
    "                df_result.to_parquet(batch_file, compression='snappy', index=False)\n",
    "                batch_file_paths.append(batch_file)\n",
    "                print(f\"  - ë°°ì¹˜ {i+1}/{num_batches}: {len(df_result):,}ê°œ ì €ì¥ ({batch_file})\")\n",
    "                del df_result\n",
    "                gc.collect()\n",
    "        print(f\"  - ì „ì²´ ë°°ì¹˜ ì´ë²¤íŠ¸ ìˆ˜: {batch_total:,}ê°œ\")\n",
    "        print(\"ğŸ“¦ ëª¨ë“  ë°°ì¹˜ íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ì¤‘...\")\n",
    "        # Parquet append ë°©ì‹ìœ¼ë¡œ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ í•©ì¹˜ê¸°\n",
    "        import pyarrow.parquet as pq\n",
    "        import pyarrow as pa\n",
    "        final_path = \"event_logs/events_100M_weighted_batch.parquet\"\n",
    "        writer = None\n",
    "        for batch_file in batch_file_paths:\n",
    "            table = pq.read_table(batch_file)\n",
    "            if writer is None:\n",
    "                writer = pq.ParquetWriter(final_path, table.schema, compression='snappy')\n",
    "            writer.write_table(table)\n",
    "            del table\n",
    "            gc.collect()\n",
    "        if writer:\n",
    "            writer.close()\n",
    "        print(f\"ğŸ’¾ ìµœì¢… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {final_path}\")\n",
    "        file_size_bytes = os.path.getsize(final_path)\n",
    "        file_size_gb = file_size_bytes / (1024**3)\n",
    "        end_time = time.time()\n",
    "        duration_minutes = (end_time - start_time) / 60\n",
    "        print()\n",
    "        print(\"ğŸ‰ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì„±ê³µ!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"ğŸ“Š ìµœì¢… ê²°ê³¼:\")\n",
    "        print(f\"  - ì´ ì´ë²¤íŠ¸: {batch_total:,}ê°œ\")\n",
    "        print(f\"  - ì²˜ë¦¬ ì‹œê°„: {duration_minutes:.2f}ë¶„\")\n",
    "        print(f\"  - íŒŒì¼ í¬ê¸°: {file_size_gb:.2f}GB\")\n",
    "        print(f\"  - ì €ì¥ ê²½ë¡œ: {final_path}\")\n",
    "        return final_path\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    finally:\n",
    "        client.close()\n",
    "        cluster.close()\n",
    "        print(\"ğŸ”§ Dask í´ëŸ¬ìŠ¤í„° ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "print(\"âœ… ë°°ì¹˜ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ë° ì €ì¥ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "447d0573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± (ë°°ì¹˜ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°°/ì €ì¥)\n",
      "============================================================\n",
      "  - ë ˆì‹œí”¼ ê°€ì¤‘ì¹˜ ì»¬ëŸ¼: view_cnt\n",
      "âš™ï¸ Dask í´ëŸ¬ìŠ¤í„° ì„¤ì •...\n",
      "  - ì›Œì»¤: 4ê°œ, ë©”ëª¨ë¦¬: 3GB/ì›Œì»¤\n",
      "\n",
      "  - ìœ ì € ìƒ˜í”Œ: 700,000ëª…\n",
      "  - ì „ì²´ ë ˆì‹œí”¼: 208,183ê°œ\n",
      "\n",
      "ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •:\n",
      "  - ë°°ì¹˜ í¬ê¸°: 25,000ëª…/ë°°ì¹˜\n",
      "  - ì´ ë°°ì¹˜ ìˆ˜: 28ê°œ\n",
      "\n",
      "  - ì¡°ì •ëœ ìœ ì €ë‹¹ ì´ë²¤íŠ¸: 141ê°œ\n",
      "  - ìƒì„±ëœ ì‘ì—…: 28ê°œ\n",
      "  - ë³‘ë ¬ ì‹¤í–‰ ì¤‘... (ì•½ 10-15ë¶„ ì˜ˆìƒ)\n",
      "ğŸ”— ë°°ì¹˜ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ë° ì €ì¥...\n",
      "âŒ ì˜¤ë¥˜ ë°œìƒ: Cannot save file into a non-existent directory: 'event_logs'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aryij\\AppData\\Local\\Temp\\ipykernel_21776\\3888487932.py\", line 103, in create_100m_events_weighted_recipe_batchsave\n",
      "    df_result.to_parquet(batch_file, compression='snappy', index=False)\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\pandas\\util\\_decorators.py\", line 333, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\pandas\\core\\frame.py\", line 3118, in to_parquet\n",
      "    return to_parquet(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\pandas\\io\\parquet.py\", line 482, in to_parquet\n",
      "    impl.write(\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\pandas\\io\\parquet.py\", line 199, in write\n",
      "    path_or_handle, handles, filesystem = _get_path_or_handle(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\pandas\\io\\parquet.py\", line 141, in _get_path_or_handle\n",
      "    handles = get_handle(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\", line 749, in get_handle\n",
      "    check_parent_directory(str(handle))\n",
      "  File \"c:\\Users\\aryij\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\de-ER0ku5Vt-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\", line 616, in check_parent_directory\n",
      "    raise OSError(rf\"Cannot save file into a non-existent directory: '{parent}'\")\n",
      "OSError: Cannot save file into a non-existent directory: 'event_logs'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Dask í´ëŸ¬ìŠ¤í„° ì •ë¦¬ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ë°°ì¹˜ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ë° ì €ì¥ ì‹¤í–‰\n",
    "final_events_100m = create_100m_events_weighted_recipe_batchsave()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a61c2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be9e4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d455cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°°ì¹˜ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ë° ì €ì¥ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ! (data/event_logs)\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ğŸ’¾ ë°°ì¹˜ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ë° ì €ì¥ (ê²½ë¡œ: data/event_logs)\n",
    "# ===================================================================\n",
    "\n",
    "def create_100m_events_weighted_recipe_batchsave():\n",
    "    \"\"\"\n",
    "    ë°°ì¹˜ ë‹¨ìœ„ë¡œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ë° ë°”ë¡œ ì €ì¥í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœì†Œí™”í•˜ëŠ” 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„±\n",
    "    - ê° ë°°ì¹˜ë³„ë¡œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° í›„ ë°”ë¡œ parquetë¡œ ì €ì¥\n",
    "    - ë§ˆì§€ë§‰ì— ëª¨ë“  ë°°ì¹˜ íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹¨ (parquet append)\n",
    "    - ì €ì¥ ê²½ë¡œ: data/event_logs\n",
    "    \"\"\"\n",
    "    import gc\n",
    "    import os\n",
    "    print(\"ğŸš€ 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± (ë°°ì¹˜ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°°/ì €ì¥)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "    save_dir = \"data/event_logs\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    target_events = TARGET_MONTHLY_EVENTS\n",
    "    target_mau = TARGET_MAU\n",
    "    events_per_user_day = TARGET_EVENTS_PER_USER_DAY\n",
    "    weight_col = None\n",
    "    for col in ['view_cnt', 'recommend_cnt', 'scrap_cnt']:\n",
    "        if col in recipes_df.columns:\n",
    "            weight_col = col\n",
    "            break\n",
    "    if weight_col:\n",
    "        print(f\"  - ë ˆì‹œí”¼ ê°€ì¤‘ì¹˜ ì»¬ëŸ¼: {weight_col}\")\n",
    "        weights = recipes_df[weight_col].fillna(1).astype(float)\n",
    "        weights = weights.clip(lower=1)\n",
    "    else:\n",
    "        print(\"  - ê°€ì¤‘ì¹˜ ì»¬ëŸ¼ ì—†ìŒ: ê· ë“± ìƒ˜í”Œë§\")\n",
    "        weights = None\n",
    "    print(\"âš™ï¸ Dask í´ëŸ¬ìŠ¤í„° ì„¤ì •...\")\n",
    "    cluster = LocalCluster(\n",
    "        n_workers=4,\n",
    "        threads_per_worker=2,\n",
    "        memory_limit='3GB',\n",
    "        silence_logs=False\n",
    "    )\n",
    "    client = Client(cluster)\n",
    "    print(f\"  - ì›Œì»¤: 4ê°œ, ë©”ëª¨ë¦¬: 3GB/ì›Œì»¤\")\n",
    "    print()\n",
    "    try:\n",
    "        users_sample = segmented_users_df.sample(n=target_mau, random_state=42).reset_index(drop=True)\n",
    "        recipes_sample = recipes_df.copy().reset_index(drop=True)\n",
    "        print(f\"  - ìœ ì € ìƒ˜í”Œ: {len(users_sample):,}ëª…\")\n",
    "        print(f\"  - ì „ì²´ ë ˆì‹œí”¼: {len(recipes_sample):,}ê°œ\")\n",
    "        print()\n",
    "        batch_size = 25_000\n",
    "        num_batches = (target_mau + batch_size - 1) // batch_size\n",
    "        print(f\"ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •:\")\n",
    "        print(f\"  - ë°°ì¹˜ í¬ê¸°: {batch_size:,}ëª…/ë°°ì¹˜\")\n",
    "        print(f\"  - ì´ ë°°ì¹˜ ìˆ˜: {num_batches}ê°œ\")\n",
    "        print()\n",
    "        delayed_tasks = []\n",
    "        adjusted_events_per_user = int(events_per_user_day * 31 * (TARGET_DAU_AVERAGE / target_mau))\n",
    "        print(f\"  - ì¡°ì •ëœ ìœ ì €ë‹¹ ì´ë²¤íŠ¸: {adjusted_events_per_user}ê°œ\")\n",
    "        for batch_id in range(num_batches):\n",
    "            start_idx = batch_id * batch_size\n",
    "            end_idx = min(start_idx + batch_size, target_mau)\n",
    "            user_batch = users_sample.iloc[start_idx:end_idx]\n",
    "            if weight_col:\n",
    "                sampled_recipes = recipes_sample.sample(\n",
    "                    n=min(1000, len(recipes_sample)),\n",
    "                    replace=True,\n",
    "                    weights=weights,\n",
    "                    random_state=42+batch_id\n",
    "                ).reset_index(drop=True)\n",
    "            else:\n",
    "                sampled_recipes = recipes_sample.sample(\n",
    "                    n=min(1000, len(recipes_sample)),\n",
    "                    replace=True,\n",
    "                    random_state=42+batch_id\n",
    "                ).reset_index(drop=True)\n",
    "            task = generate_events_batch_optimized(\n",
    "                user_batch=user_batch,\n",
    "                recipes_sample=sampled_recipes,\n",
    "                batch_id=batch_id,\n",
    "                events_per_user=adjusted_events_per_user\n",
    "            )\n",
    "            delayed_tasks.append(task)\n",
    "        print(f\"  - ìƒì„±ëœ ì‘ì—…: {len(delayed_tasks)}ê°œ\")\n",
    "        print(\"  - ë³‘ë ¬ ì‹¤í–‰ ì¤‘... (ì•½ 10-15ë¶„ ì˜ˆìƒ)\")\n",
    "        batch_results = dask.compute(*delayed_tasks)\n",
    "        print(\"ğŸ”— ë°°ì¹˜ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ë° ì €ì¥...\")\n",
    "        batch_file_paths = []\n",
    "        batch_total = 0\n",
    "        for i, result in enumerate(batch_results):\n",
    "            if result is not None:\n",
    "                if isinstance(result, dict):\n",
    "                    if 'events' in result:\n",
    "                        df_result = pd.DataFrame(result['events'])\n",
    "                    else:\n",
    "                        continue\n",
    "                elif isinstance(result, pd.DataFrame):\n",
    "                    df_result = result\n",
    "                elif isinstance(result, list):\n",
    "                    df_result = pd.DataFrame(result)\n",
    "                else:\n",
    "                    continue\n",
    "                # ë°°ì¹˜ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°°\n",
    "                df_result = redistribute_timestamps_july(df_result)\n",
    "                batch_total += len(df_result)\n",
    "                batch_file = os.path.join(save_dir, f\"batch_events_{i:02d}.parquet\")\n",
    "                df_result.to_parquet(batch_file, compression='snappy', index=False)\n",
    "                batch_file_paths.append(batch_file)\n",
    "                print(f\"  - ë°°ì¹˜ {i+1}/{num_batches}: {len(df_result):,}ê°œ ì €ì¥ ({batch_file})\")\n",
    "                del df_result\n",
    "                gc.collect()\n",
    "        print(f\"  - ì „ì²´ ë°°ì¹˜ ì´ë²¤íŠ¸ ìˆ˜: {batch_total:,}ê°œ\")\n",
    "        print(\"ğŸ“¦ ëª¨ë“  ë°°ì¹˜ íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ì¤‘...\")\n",
    "        import pyarrow.parquet as pq\n",
    "        import pyarrow as pa\n",
    "        final_path = os.path.join(save_dir, \"events_100M_weighted_batch.parquet\")\n",
    "        writer = None\n",
    "        for batch_file in batch_file_paths:\n",
    "            table = pq.read_table(batch_file)\n",
    "            if writer is None:\n",
    "                writer = pq.ParquetWriter(final_path, table.schema, compression='snappy')\n",
    "            writer.write_table(table)\n",
    "            del table\n",
    "            gc.collect()\n",
    "        if writer:\n",
    "            writer.close()\n",
    "        print(f\"ğŸ’¾ ìµœì¢… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {final_path}\")\n",
    "        file_size_bytes = os.path.getsize(final_path)\n",
    "        file_size_gb = file_size_bytes / (1024**3)\n",
    "        end_time = time.time()\n",
    "        duration_minutes = (end_time - start_time) / 60\n",
    "        print()\n",
    "        print(\"ğŸ‰ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì„±ê³µ!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"ğŸ“Š ìµœì¢… ê²°ê³¼:\")\n",
    "        print(f\"  - ì´ ì´ë²¤íŠ¸: {batch_total:,}ê°œ\")\n",
    "        print(f\"  - ì²˜ë¦¬ ì‹œê°„: {duration_minutes:.2f}ë¶„\")\n",
    "        print(f\"  - íŒŒì¼ í¬ê¸°: {file_size_gb:.2f}GB\")\n",
    "        print(f\"  - ì €ì¥ ê²½ë¡œ: {final_path}\")\n",
    "        return final_path\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    finally:\n",
    "        client.close()\n",
    "        cluster.close()\n",
    "        print(\"ğŸ”§ Dask í´ëŸ¬ìŠ¤í„° ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "print(\"âœ… ë°°ì¹˜ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ë° ì €ì¥ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ! (data/event_logs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a002b935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ 1ì–µê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± (ë°°ì¹˜ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°°/ì €ì¥)\n",
      "============================================================\n",
      "  - ë ˆì‹œí”¼ ê°€ì¤‘ì¹˜ ì»¬ëŸ¼: view_cnt\n",
      "âš™ï¸ Dask í´ëŸ¬ìŠ¤í„° ì„¤ì •...\n",
      "  - ì›Œì»¤: 4ê°œ, ë©”ëª¨ë¦¬: 3GB/ì›Œì»¤\n",
      "\n",
      "  - ì›Œì»¤: 4ê°œ, ë©”ëª¨ë¦¬: 3GB/ì›Œì»¤\n",
      "\n",
      "  - ìœ ì € ìƒ˜í”Œ: 700,000ëª…\n",
      "  - ì „ì²´ ë ˆì‹œí”¼: 208,183ê°œ\n",
      "\n",
      "ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •:\n",
      "  - ë°°ì¹˜ í¬ê¸°: 25,000ëª…/ë°°ì¹˜\n",
      "  - ì´ ë°°ì¹˜ ìˆ˜: 28ê°œ\n",
      "\n",
      "  - ì¡°ì •ëœ ìœ ì €ë‹¹ ì´ë²¤íŠ¸: 141ê°œ\n",
      "  - ìƒì„±ëœ ì‘ì—…: 28ê°œ\n",
      "  - ë³‘ë ¬ ì‹¤í–‰ ì¤‘... (ì•½ 10-15ë¶„ ì˜ˆìƒ)\n",
      "  - ìœ ì € ìƒ˜í”Œ: 700,000ëª…\n",
      "  - ì „ì²´ ë ˆì‹œí”¼: 208,183ê°œ\n",
      "\n",
      "ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •:\n",
      "  - ë°°ì¹˜ í¬ê¸°: 25,000ëª…/ë°°ì¹˜\n",
      "  - ì´ ë°°ì¹˜ ìˆ˜: 28ê°œ\n",
      "\n",
      "  - ì¡°ì •ëœ ìœ ì €ë‹¹ ì´ë²¤íŠ¸: 141ê°œ\n",
      "  - ìƒì„±ëœ ì‘ì—…: 28ê°œ\n",
      "  - ë³‘ë ¬ ì‹¤í–‰ ì¤‘... (ì•½ 10-15ë¶„ ì˜ˆìƒ)\n",
      "ğŸ”— ë°°ì¹˜ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ë° ì €ì¥...\n",
      "ğŸ”— ë°°ì¹˜ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ë° ì €ì¥...\n",
      "  - ë°°ì¹˜ 1/28: 139,061ê°œ ì €ì¥ (data/event_logs\\batch_events_00.parquet)\n",
      "  - ë°°ì¹˜ 1/28: 139,061ê°œ ì €ì¥ (data/event_logs\\batch_events_00.parquet)\n",
      "  - ë°°ì¹˜ 2/28: 138,329ê°œ ì €ì¥ (data/event_logs\\batch_events_01.parquet)\n",
      "  - ë°°ì¹˜ 2/28: 138,329ê°œ ì €ì¥ (data/event_logs\\batch_events_01.parquet)\n",
      "  - ë°°ì¹˜ 3/28: 138,962ê°œ ì €ì¥ (data/event_logs\\batch_events_02.parquet)\n",
      "  - ë°°ì¹˜ 3/28: 138,962ê°œ ì €ì¥ (data/event_logs\\batch_events_02.parquet)\n",
      "  - ë°°ì¹˜ 4/28: 139,656ê°œ ì €ì¥ (data/event_logs\\batch_events_03.parquet)\n",
      "  - ë°°ì¹˜ 4/28: 139,656ê°œ ì €ì¥ (data/event_logs\\batch_events_03.parquet)\n",
      "  - ë°°ì¹˜ 5/28: 139,001ê°œ ì €ì¥ (data/event_logs\\batch_events_04.parquet)\n",
      "  - ë°°ì¹˜ 5/28: 139,001ê°œ ì €ì¥ (data/event_logs\\batch_events_04.parquet)\n",
      "  - ë°°ì¹˜ 6/28: 138,831ê°œ ì €ì¥ (data/event_logs\\batch_events_05.parquet)\n",
      "  - ë°°ì¹˜ 6/28: 138,831ê°œ ì €ì¥ (data/event_logs\\batch_events_05.parquet)\n",
      "  - ë°°ì¹˜ 7/28: 138,865ê°œ ì €ì¥ (data/event_logs\\batch_events_06.parquet)\n",
      "  - ë°°ì¹˜ 7/28: 138,865ê°œ ì €ì¥ (data/event_logs\\batch_events_06.parquet)\n",
      "  - ë°°ì¹˜ 8/28: 139,277ê°œ ì €ì¥ (data/event_logs\\batch_events_07.parquet)\n",
      "  - ë°°ì¹˜ 8/28: 139,277ê°œ ì €ì¥ (data/event_logs\\batch_events_07.parquet)\n",
      "  - ë°°ì¹˜ 9/28: 138,534ê°œ ì €ì¥ (data/event_logs\\batch_events_08.parquet)\n",
      "  - ë°°ì¹˜ 9/28: 138,534ê°œ ì €ì¥ (data/event_logs\\batch_events_08.parquet)\n",
      "  - ë°°ì¹˜ 10/28: 139,075ê°œ ì €ì¥ (data/event_logs\\batch_events_09.parquet)\n",
      "  - ë°°ì¹˜ 10/28: 139,075ê°œ ì €ì¥ (data/event_logs\\batch_events_09.parquet)\n",
      "  - ë°°ì¹˜ 11/28: 138,250ê°œ ì €ì¥ (data/event_logs\\batch_events_10.parquet)\n",
      "  - ë°°ì¹˜ 11/28: 138,250ê°œ ì €ì¥ (data/event_logs\\batch_events_10.parquet)\n",
      "  - ë°°ì¹˜ 12/28: 138,830ê°œ ì €ì¥ (data/event_logs\\batch_events_11.parquet)\n",
      "  - ë°°ì¹˜ 12/28: 138,830ê°œ ì €ì¥ (data/event_logs\\batch_events_11.parquet)\n",
      "  - ë°°ì¹˜ 13/28: 139,244ê°œ ì €ì¥ (data/event_logs\\batch_events_12.parquet)\n",
      "  - ë°°ì¹˜ 13/28: 139,244ê°œ ì €ì¥ (data/event_logs\\batch_events_12.parquet)\n",
      "  - ë°°ì¹˜ 14/28: 138,414ê°œ ì €ì¥ (data/event_logs\\batch_events_13.parquet)\n",
      "  - ë°°ì¹˜ 14/28: 138,414ê°œ ì €ì¥ (data/event_logs\\batch_events_13.parquet)\n",
      "  - ë°°ì¹˜ 15/28: 138,722ê°œ ì €ì¥ (data/event_logs\\batch_events_14.parquet)\n",
      "  - ë°°ì¹˜ 15/28: 138,722ê°œ ì €ì¥ (data/event_logs\\batch_events_14.parquet)\n",
      "  - ë°°ì¹˜ 16/28: 139,527ê°œ ì €ì¥ (data/event_logs\\batch_events_15.parquet)\n",
      "  - ë°°ì¹˜ 16/28: 139,527ê°œ ì €ì¥ (data/event_logs\\batch_events_15.parquet)\n",
      "  - ë°°ì¹˜ 17/28: 138,932ê°œ ì €ì¥ (data/event_logs\\batch_events_16.parquet)\n",
      "  - ë°°ì¹˜ 17/28: 138,932ê°œ ì €ì¥ (data/event_logs\\batch_events_16.parquet)\n",
      "  - ë°°ì¹˜ 18/28: 138,455ê°œ ì €ì¥ (data/event_logs\\batch_events_17.parquet)\n",
      "  - ë°°ì¹˜ 18/28: 138,455ê°œ ì €ì¥ (data/event_logs\\batch_events_17.parquet)\n",
      "  - ë°°ì¹˜ 19/28: 139,040ê°œ ì €ì¥ (data/event_logs\\batch_events_18.parquet)\n",
      "  - ë°°ì¹˜ 19/28: 139,040ê°œ ì €ì¥ (data/event_logs\\batch_events_18.parquet)\n",
      "  - ë°°ì¹˜ 20/28: 138,604ê°œ ì €ì¥ (data/event_logs\\batch_events_19.parquet)\n",
      "  - ë°°ì¹˜ 20/28: 138,604ê°œ ì €ì¥ (data/event_logs\\batch_events_19.parquet)\n",
      "  - ë°°ì¹˜ 21/28: 139,478ê°œ ì €ì¥ (data/event_logs\\batch_events_20.parquet)\n",
      "  - ë°°ì¹˜ 21/28: 139,478ê°œ ì €ì¥ (data/event_logs\\batch_events_20.parquet)\n",
      "  - ë°°ì¹˜ 22/28: 139,034ê°œ ì €ì¥ (data/event_logs\\batch_events_21.parquet)\n",
      "  - ë°°ì¹˜ 22/28: 139,034ê°œ ì €ì¥ (data/event_logs\\batch_events_21.parquet)\n",
      "  - ë°°ì¹˜ 23/28: 138,540ê°œ ì €ì¥ (data/event_logs\\batch_events_22.parquet)\n",
      "  - ë°°ì¹˜ 23/28: 138,540ê°œ ì €ì¥ (data/event_logs\\batch_events_22.parquet)\n",
      "  - ë°°ì¹˜ 24/28: 139,022ê°œ ì €ì¥ (data/event_logs\\batch_events_23.parquet)\n",
      "  - ë°°ì¹˜ 24/28: 139,022ê°œ ì €ì¥ (data/event_logs\\batch_events_23.parquet)\n",
      "  - ë°°ì¹˜ 25/28: 139,068ê°œ ì €ì¥ (data/event_logs\\batch_events_24.parquet)\n",
      "  - ë°°ì¹˜ 25/28: 139,068ê°œ ì €ì¥ (data/event_logs\\batch_events_24.parquet)\n",
      "  - ë°°ì¹˜ 26/28: 138,357ê°œ ì €ì¥ (data/event_logs\\batch_events_25.parquet)\n",
      "  - ë°°ì¹˜ 26/28: 138,357ê°œ ì €ì¥ (data/event_logs\\batch_events_25.parquet)\n",
      "  - ë°°ì¹˜ 27/28: 139,081ê°œ ì €ì¥ (data/event_logs\\batch_events_26.parquet)\n",
      "  - ë°°ì¹˜ 27/28: 139,081ê°œ ì €ì¥ (data/event_logs\\batch_events_26.parquet)\n",
      "  - ë°°ì¹˜ 28/28: 138,708ê°œ ì €ì¥ (data/event_logs\\batch_events_27.parquet)\n",
      "  - ë°°ì¹˜ 28/28: 138,708ê°œ ì €ì¥ (data/event_logs\\batch_events_27.parquet)\n",
      "  - ì „ì²´ ë°°ì¹˜ ì´ë²¤íŠ¸ ìˆ˜: 3,888,897ê°œ\n",
      "ğŸ“¦ ëª¨ë“  ë°°ì¹˜ íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ì¤‘...\n",
      "  - ì „ì²´ ë°°ì¹˜ ì´ë²¤íŠ¸ ìˆ˜: 3,888,897ê°œ\n",
      "ğŸ“¦ ëª¨ë“  ë°°ì¹˜ íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ì¤‘...\n",
      "ğŸ’¾ ìµœì¢… íŒŒì¼ ì €ì¥ ì™„ë£Œ: data/event_logs\\events_100M_weighted_batch.parquet\n",
      "\n",
      "ğŸ‰ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì„±ê³µ!\n",
      "============================================================\n",
      "ğŸ“Š ìµœì¢… ê²°ê³¼:\n",
      "  - ì´ ì´ë²¤íŠ¸: 3,888,897ê°œ\n",
      "  - ì²˜ë¦¬ ì‹œê°„: 7.98ë¶„\n",
      "  - íŒŒì¼ í¬ê¸°: 0.43GB\n",
      "  - ì €ì¥ ê²½ë¡œ: data/event_logs\\events_100M_weighted_batch.parquet\n",
      "ğŸ’¾ ìµœì¢… íŒŒì¼ ì €ì¥ ì™„ë£Œ: data/event_logs\\events_100M_weighted_batch.parquet\n",
      "\n",
      "ğŸ‰ 1ì–µê°œ ì´ë²¤íŠ¸ ìƒì„± ì„±ê³µ!\n",
      "============================================================\n",
      "ğŸ“Š ìµœì¢… ê²°ê³¼:\n",
      "  - ì´ ì´ë²¤íŠ¸: 3,888,897ê°œ\n",
      "  - ì²˜ë¦¬ ì‹œê°„: 7.98ë¶„\n",
      "  - íŒŒì¼ í¬ê¸°: 0.43GB\n",
      "  - ì €ì¥ ê²½ë¡œ: data/event_logs\\events_100M_weighted_batch.parquet\n",
      "ğŸ”§ Dask í´ëŸ¬ìŠ¤í„° ì •ë¦¬ ì™„ë£Œ\n",
      "ğŸ”§ Dask í´ëŸ¬ìŠ¤í„° ì •ë¦¬ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ë°°ì¹˜ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¬ë¶„ë°° ë° ì €ì¥ ì‹¤í–‰\n",
    "final_events_100m = create_100m_events_weighted_recipe_batchsave()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189a382a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0446e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ 3,888,897ê°œ â†’ 1ì–µê°œë¡œ ë³µì œ/í™•ì¥(Dask)í•©ë‹ˆë‹¤.\n",
      "1,389,591ê°œ ì €ì¥ ì™„ë£Œ\n",
      "2,777,609ê°œ ì €ì¥ ì™„ë£Œ\n",
      "3,888,897ê°œ ì €ì¥ ì™„ë£Œ\n",
      "5,278,488ê°œ ì €ì¥ ì™„ë£Œ\n",
      "6,666,506ê°œ ì €ì¥ ì™„ë£Œ\n",
      "7,777,794ê°œ ì €ì¥ ì™„ë£Œ\n",
      "9,167,385ê°œ ì €ì¥ ì™„ë£Œ\n",
      "10,555,403ê°œ ì €ì¥ ì™„ë£Œ\n",
      "11,666,691ê°œ ì €ì¥ ì™„ë£Œ\n",
      "13,056,282ê°œ ì €ì¥ ì™„ë£Œ\n",
      "14,444,300ê°œ ì €ì¥ ì™„ë£Œ\n",
      "15,555,588ê°œ ì €ì¥ ì™„ë£Œ\n",
      "16,945,179ê°œ ì €ì¥ ì™„ë£Œ\n",
      "18,333,197ê°œ ì €ì¥ ì™„ë£Œ\n",
      "19,444,485ê°œ ì €ì¥ ì™„ë£Œ\n",
      "20,834,076ê°œ ì €ì¥ ì™„ë£Œ\n",
      "22,222,094ê°œ ì €ì¥ ì™„ë£Œ\n",
      "23,333,382ê°œ ì €ì¥ ì™„ë£Œ\n",
      "24,722,973ê°œ ì €ì¥ ì™„ë£Œ\n",
      "26,110,991ê°œ ì €ì¥ ì™„ë£Œ\n",
      "27,222,279ê°œ ì €ì¥ ì™„ë£Œ\n",
      "28,611,870ê°œ ì €ì¥ ì™„ë£Œ\n",
      "29,999,888ê°œ ì €ì¥ ì™„ë£Œ\n",
      "31,111,176ê°œ ì €ì¥ ì™„ë£Œ\n",
      "32,500,767ê°œ ì €ì¥ ì™„ë£Œ\n",
      "33,888,785ê°œ ì €ì¥ ì™„ë£Œ\n",
      "35,000,073ê°œ ì €ì¥ ì™„ë£Œ\n",
      "36,389,664ê°œ ì €ì¥ ì™„ë£Œ\n",
      "37,777,682ê°œ ì €ì¥ ì™„ë£Œ\n",
      "38,888,970ê°œ ì €ì¥ ì™„ë£Œ\n",
      "40,278,561ê°œ ì €ì¥ ì™„ë£Œ\n",
      "41,666,579ê°œ ì €ì¥ ì™„ë£Œ\n",
      "42,777,867ê°œ ì €ì¥ ì™„ë£Œ\n",
      "44,167,458ê°œ ì €ì¥ ì™„ë£Œ\n",
      "45,555,476ê°œ ì €ì¥ ì™„ë£Œ\n",
      "46,666,764ê°œ ì €ì¥ ì™„ë£Œ\n",
      "48,056,355ê°œ ì €ì¥ ì™„ë£Œ\n",
      "49,444,373ê°œ ì €ì¥ ì™„ë£Œ\n",
      "50,555,661ê°œ ì €ì¥ ì™„ë£Œ\n",
      "51,945,252ê°œ ì €ì¥ ì™„ë£Œ\n",
      "53,333,270ê°œ ì €ì¥ ì™„ë£Œ\n",
      "54,444,558ê°œ ì €ì¥ ì™„ë£Œ\n",
      "55,834,149ê°œ ì €ì¥ ì™„ë£Œ\n",
      "57,222,167ê°œ ì €ì¥ ì™„ë£Œ\n",
      "58,333,455ê°œ ì €ì¥ ì™„ë£Œ\n",
      "59,723,046ê°œ ì €ì¥ ì™„ë£Œ\n",
      "61,111,064ê°œ ì €ì¥ ì™„ë£Œ\n",
      "62,222,352ê°œ ì €ì¥ ì™„ë£Œ\n",
      "63,611,943ê°œ ì €ì¥ ì™„ë£Œ\n",
      "64,999,961ê°œ ì €ì¥ ì™„ë£Œ\n",
      "66,111,249ê°œ ì €ì¥ ì™„ë£Œ\n",
      "67,500,840ê°œ ì €ì¥ ì™„ë£Œ\n",
      "68,888,858ê°œ ì €ì¥ ì™„ë£Œ\n",
      "70,000,146ê°œ ì €ì¥ ì™„ë£Œ\n",
      "71,389,737ê°œ ì €ì¥ ì™„ë£Œ\n",
      "72,777,755ê°œ ì €ì¥ ì™„ë£Œ\n",
      "73,889,043ê°œ ì €ì¥ ì™„ë£Œ\n",
      "75,278,634ê°œ ì €ì¥ ì™„ë£Œ\n",
      "76,666,652ê°œ ì €ì¥ ì™„ë£Œ\n",
      "77,777,940ê°œ ì €ì¥ ì™„ë£Œ\n",
      "79,167,531ê°œ ì €ì¥ ì™„ë£Œ\n",
      "80,555,549ê°œ ì €ì¥ ì™„ë£Œ\n",
      "81,666,837ê°œ ì €ì¥ ì™„ë£Œ\n",
      "83,056,428ê°œ ì €ì¥ ì™„ë£Œ\n",
      "84,444,446ê°œ ì €ì¥ ì™„ë£Œ\n",
      "85,555,734ê°œ ì €ì¥ ì™„ë£Œ\n",
      "86,945,325ê°œ ì €ì¥ ì™„ë£Œ\n",
      "88,333,343ê°œ ì €ì¥ ì™„ë£Œ\n",
      "89,444,631ê°œ ì €ì¥ ì™„ë£Œ\n",
      "90,834,222ê°œ ì €ì¥ ì™„ë£Œ\n",
      "92,222,240ê°œ ì €ì¥ ì™„ë£Œ\n",
      "93,333,528ê°œ ì €ì¥ ì™„ë£Œ\n",
      "94,723,119ê°œ ì €ì¥ ì™„ë£Œ\n",
      "96,111,137ê°œ ì €ì¥ ì™„ë£Œ\n",
      "97,222,425ê°œ ì €ì¥ ì™„ë£Œ\n",
      "98,612,016ê°œ ì €ì¥ ì™„ë£Œ\n",
      "100,000,000ê°œ ì €ì¥ ì™„ë£Œ\n",
      "1ì–µê°œ ì™„ì„±! (ì—¬ëŸ¬ íŒŒì¼ â†’ ìµœì¢… ë³‘í•©)\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "final_path = \"data/event_logs/events_100M_weighted_batch.parquet\"\n",
    "target_count = 100_000_000\n",
    "chunk_size = 10_000_000\n",
    "tmp_dir = \"data/event_logs/events_100M_final_chunks\"\n",
    "os.makedirs(tmp_dir, exist_ok=True)\n",
    "\n",
    "ddf = dd.read_parquet(final_path)\n",
    "current_count = ddf.shape[0].compute()\n",
    "\n",
    "if current_count < target_count:\n",
    "    print(f\"í˜„ì¬ {current_count:,}ê°œ â†’ 1ì–µê°œë¡œ ë³µì œ/í™•ì¥(Dask)í•©ë‹ˆë‹¤.\")\n",
    "    replications_needed = (target_count // current_count) + 1\n",
    "    ddf_list = []\n",
    "    for i in range(replications_needed):\n",
    "        temp = ddf.copy()\n",
    "        temp = temp.assign(event_id=temp.event_id.astype(str) + f\"_rep{i}\")\n",
    "        ddf_list.append(temp)\n",
    "    ddf_all = dd.concat(ddf_list)\n",
    "    ddf_all = ddf_all.reset_index(drop=True)\n",
    "    # íŒŒí‹°ì…˜ ë‹¨ìœ„ë¡œ ì—¬ëŸ¬ ê°œì˜ parquet íŒŒì¼ë¡œ ì €ì¥\n",
    "    total_saved = 0\n",
    "    chunk_idx = 0\n",
    "    for partition in ddf_all.partitions:\n",
    "        chunk = partition.compute()\n",
    "        if total_saved + len(chunk) > target_count:\n",
    "            chunk = chunk.iloc[:target_count - total_saved]\n",
    "        chunk.to_parquet(f\"{tmp_dir}/chunk_{chunk_idx:03d}.parquet\", compression=\"snappy\", index=False)\n",
    "        total_saved += len(chunk)\n",
    "        print(f\"{total_saved:,}ê°œ ì €ì¥ ì™„ë£Œ\")\n",
    "        chunk_idx += 1\n",
    "        if total_saved >= target_count:\n",
    "            break\n",
    "    # ì—¬ëŸ¬ íŒŒì¼ì„ Daskë¡œ í•©ì³ì„œ ìµœì¢… 1ê°œ íŒŒì¼ë¡œ ì €ì¥\n",
    "    ddf_final = dd.read_parquet(f\"{tmp_dir}/*.parquet\")\n",
    "    ddf_final.to_parquet(\"data/event_logs/events_logs_100M_final.parquet\", compression=\"snappy\", write_index=False)\n",
    "    print(\"1ì–µê°œ ì™„ì„±! (ì—¬ëŸ¬ íŒŒì¼ â†’ ìµœì¢… ë³‘í•©)\")\n",
    "else:\n",
    "    print(\"ì´ë¯¸ 1ì–µê°œ ì´ìƒì…ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d46da678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# events = pd.read_parquet(\"data/event_logs/events_logs_100M_final.parquet\")\n",
    "# print(f\"ìµœì¢… ì´ë²¤íŠ¸ ìˆ˜: {len(events):,}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0abf5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = dd.read_parquet(\"data/event_logs/events_logs_100M_final\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "387346cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê°€ì¥ ë¹ ë¥¸ ë‚ ì§œë¥¼ ì°¾ê¸° ìœ„í•´ Dask ì—°ì‚°ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "ì—°ì‚° ì™„ë£Œ!\n",
      "\n",
      "ê°€ì¥ ë¹ ë¥¸ timestamp:\n",
      "2025-07-01 00:00:00.062036373+09:00\n",
      "\n",
      "ê²°ê³¼ íƒ€ì…: <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# 1. Dask ë°ì´í„°í”„ë ˆì„ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "events_df = dd.read_parquet(\"data/event_logs/events_logs_100M_final\")\n",
    "\n",
    "# 2. 'timestamp' ì»¬ëŸ¼ì—ì„œ ìµœì†Œê°’(ê°€ì¥ ë¹ ë¥¸ ë‚ ì§œ)ì„ ì°¾ëŠ” ì‘ì—… ì •ì˜\n",
    "#    ì´ ë‹¨ê³„ì—ì„œëŠ” ì‹¤ì œ ê³„ì‚°ì´ ì¼ì–´ë‚˜ì§€ ì•Šê³ , ê³„ì‚° ê³„íšë§Œ ì„¸ì›Œì§‘ë‹ˆë‹¤.\n",
    "min_timestamp_task = events_df['timestamp'].min()\n",
    "\n",
    "# 3. .compute()ë¥¼ í˜¸ì¶œí•˜ì—¬ ì‹¤ì œ ê³„ì‚°ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ê¸°\n",
    "print(\"ê°€ì¥ ë¹ ë¥¸ ë‚ ì§œë¥¼ ì°¾ê¸° ìœ„í•´ Dask ì—°ì‚°ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "earliest_timestamp = min_timestamp_task.compute()\n",
    "print(\"ì—°ì‚° ì™„ë£Œ!\")\n",
    "\n",
    "# 4. ê²°ê³¼ í™•ì¸\n",
    "print(\"\\nê°€ì¥ ë¹ ë¥¸ timestamp:\")\n",
    "print(earliest_timestamp)\n",
    "\n",
    "# ê²°ê³¼ì˜ íƒ€ì… í™•ì¸ (ë³´í†µ pandas.Timestamp ê°ì²´ë¡œ ë°˜í™˜ë©ë‹ˆë‹¤)\n",
    "print(\"\\nê²°ê³¼ íƒ€ì…:\", type(earliest_timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c414b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(events_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd3ce641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>anonymous_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>context</th>\n",
       "      <th>event_properties</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>search_recipe</td>\n",
       "      <td>43b5ebda-b3b5-4212-8015-287fc5f563ea_rep0</td>\n",
       "      <td>597732</td>\n",
       "      <td>46fab577-3213-46a1-8dd5-11df6768f400</td>\n",
       "      <td>982cbf62-4152-4544-91f2-46a22959d2d6</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"search_type\": \"menu\", \"search_keyword\": \"ì¹˜í‚¨\"...</td>\n",
       "      <td>2025-07-01 00:00:17.935199083+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>click_auth_button</td>\n",
       "      <td>c6b325e3-5b3c-4039-a6a5-549d98ad46ad_rep0</td>\n",
       "      <td>1215590</td>\n",
       "      <td>222bb10e-4256-43e8-bccf-fef66a8ffe50</td>\n",
       "      <td>ab3cde2e-59cc-48ac-9c59-7d4fdcf8b557</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"type\": \"login\"}</td>\n",
       "      <td>2025-07-01 00:00:27.506597580+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>click_auth_button</td>\n",
       "      <td>9a99424f-d7ae-49a6-abb8-0e7f535f37cd_rep0</td>\n",
       "      <td>1517868</td>\n",
       "      <td>b2c370af-9c81-4d64-96f0-5bc422c47c2f</td>\n",
       "      <td>90469a87-4c4e-40e9-bfc6-eea97d38d0a5</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"type\": \"signup\"}</td>\n",
       "      <td>2025-07-01 00:00:54.612085667+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>view_recipe_list</td>\n",
       "      <td>e2182271-3f01-4d95-9996-681ebd4cd385_rep0</td>\n",
       "      <td>162076</td>\n",
       "      <td>4d3ba90a-7c08-486b-884b-e453cc0875b6</td>\n",
       "      <td>4c976c55-6b2f-4b65-98f1-135cdd5c718d</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"list_type\": \"recommended\", \"displayed_recipe...</td>\n",
       "      <td>2025-07-01 00:01:06.872241827+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>auth_success</td>\n",
       "      <td>b40ac36a-0dcd-4f0a-82bd-b4950da5cb17_rep0</td>\n",
       "      <td>1785809</td>\n",
       "      <td>9688787f-fb73-446d-b72c-e5da2dcbbd3c</td>\n",
       "      <td>ced386e7-b969-4295-b913-caa93feef0d3</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"method\": \"kakao\", \"type\": \"signup\"}</td>\n",
       "      <td>2025-07-01 00:01:11.521842240+09:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          event_name                                   event_id  user_id  \\\n",
       "0      search_recipe  43b5ebda-b3b5-4212-8015-287fc5f563ea_rep0   597732   \n",
       "1  click_auth_button  c6b325e3-5b3c-4039-a6a5-549d98ad46ad_rep0  1215590   \n",
       "2  click_auth_button  9a99424f-d7ae-49a6-abb8-0e7f535f37cd_rep0  1517868   \n",
       "3   view_recipe_list  e2182271-3f01-4d95-9996-681ebd4cd385_rep0   162076   \n",
       "4       auth_success  b40ac36a-0dcd-4f0a-82bd-b4950da5cb17_rep0  1785809   \n",
       "\n",
       "                           anonymous_id                            session_id  \\\n",
       "0  46fab577-3213-46a1-8dd5-11df6768f400  982cbf62-4152-4544-91f2-46a22959d2d6   \n",
       "1  222bb10e-4256-43e8-bccf-fef66a8ffe50  ab3cde2e-59cc-48ac-9c59-7d4fdcf8b557   \n",
       "2  b2c370af-9c81-4d64-96f0-5bc422c47c2f  90469a87-4c4e-40e9-bfc6-eea97d38d0a5   \n",
       "3  4d3ba90a-7c08-486b-884b-e453cc0875b6  4c976c55-6b2f-4b65-98f1-135cdd5c718d   \n",
       "4  9688787f-fb73-446d-b72c-e5da2dcbbd3c  ced386e7-b969-4295-b913-caa93feef0d3   \n",
       "\n",
       "                                             context  \\\n",
       "0  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "1  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "2  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "3  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "4  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "\n",
       "                                    event_properties  \\\n",
       "0  {\"search_type\": \"menu\", \"search_keyword\": \"ì¹˜í‚¨\"...   \n",
       "1                                  {\"type\": \"login\"}   \n",
       "2                                 {\"type\": \"signup\"}   \n",
       "3  {\"list_type\": \"recommended\", \"displayed_recipe...   \n",
       "4              {\"method\": \"kakao\", \"type\": \"signup\"}   \n",
       "\n",
       "                            timestamp  \n",
       "0 2025-07-01 00:00:17.935199083+09:00  \n",
       "1 2025-07-01 00:00:27.506597580+09:00  \n",
       "2 2025-07-01 00:00:54.612085667+09:00  \n",
       "3 2025-07-01 00:01:06.872241827+09:00  \n",
       "4 2025-07-01 00:01:11.521842240+09:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c00179c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>anonymous_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>context</th>\n",
       "      <th>event_properties</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1387979</th>\n",
       "      <td>view_page</td>\n",
       "      <td>c17795c1-47d3-42ba-9cd0-eedf5ec6d272_rep25</td>\n",
       "      <td>678372</td>\n",
       "      <td>59c3d7a3-4bda-4de7-9d02-0a5f7dd20f9f</td>\n",
       "      <td>d074662b-cef6-49a5-822f-4cae7c1bbfc8</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"page_name\": \"main\", \"referrer\": \"https://goo...</td>\n",
       "      <td>2025-07-31 23:47:53.296279434+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387980</th>\n",
       "      <td>view_page</td>\n",
       "      <td>167f0082-30af-4ef3-8fd0-49821a331ce4_rep25</td>\n",
       "      <td>723912</td>\n",
       "      <td>8e739c59-5aa9-4d6b-bea3-add7cf6e1698</td>\n",
       "      <td>dddfdaa9-8a14-456b-b6a3-0d4a9ecaa81b</td>\n",
       "      <td>{\"page\": {\"name\": \"profile\", \"url\": \"https://r...</td>\n",
       "      <td>{\"page_name\": \"profile\"}</td>\n",
       "      <td>2025-07-31 23:48:32.494216675+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387981</th>\n",
       "      <td>view_page</td>\n",
       "      <td>8dd15bf7-a444-4e2a-93ce-3392117fa278_rep25</td>\n",
       "      <td>801851</td>\n",
       "      <td>5402d759-eefe-4041-a6de-1099a3303385</td>\n",
       "      <td>3b66f169-5c68-435c-ba1d-76e9cf68e87c</td>\n",
       "      <td>{\"page\": {\"name\": \"start\", \"url\": \"https://rec...</td>\n",
       "      <td>{\"page_name\": \"start\"}</td>\n",
       "      <td>2025-07-31 23:48:32.509363821+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387982</th>\n",
       "      <td>view_recipe_list</td>\n",
       "      <td>536ea7ae-66e7-447a-a044-d6e1b8fc4826_rep25</td>\n",
       "      <td>504323</td>\n",
       "      <td>e62f46ef-8eec-4c93-9a05-becabe2a705f</td>\n",
       "      <td>42d80850-b943-4b24-b53b-7a204c93318e</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"list_type\": \"popular\", \"displayed_recipe_ids...</td>\n",
       "      <td>2025-07-31 23:49:04.206501635+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387983</th>\n",
       "      <td>click_recipe</td>\n",
       "      <td>261bb003-a9c1-41a5-a868-464d3abcc752_rep25</td>\n",
       "      <td>330382</td>\n",
       "      <td>965f72c8-a31d-497e-a766-d071eeb90ed3</td>\n",
       "      <td>93aa8d5c-5db1-4b3a-87a9-f0c4ff847992</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"recipe_id\": \"6893936\", \"rank\": 10}</td>\n",
       "      <td>2025-07-31 23:49:08.795700719+09:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               event_name                                    event_id user_id  \\\n",
       "1387979         view_page  c17795c1-47d3-42ba-9cd0-eedf5ec6d272_rep25  678372   \n",
       "1387980         view_page  167f0082-30af-4ef3-8fd0-49821a331ce4_rep25  723912   \n",
       "1387981         view_page  8dd15bf7-a444-4e2a-93ce-3392117fa278_rep25  801851   \n",
       "1387982  view_recipe_list  536ea7ae-66e7-447a-a044-d6e1b8fc4826_rep25  504323   \n",
       "1387983      click_recipe  261bb003-a9c1-41a5-a868-464d3abcc752_rep25  330382   \n",
       "\n",
       "                                 anonymous_id  \\\n",
       "1387979  59c3d7a3-4bda-4de7-9d02-0a5f7dd20f9f   \n",
       "1387980  8e739c59-5aa9-4d6b-bea3-add7cf6e1698   \n",
       "1387981  5402d759-eefe-4041-a6de-1099a3303385   \n",
       "1387982  e62f46ef-8eec-4c93-9a05-becabe2a705f   \n",
       "1387983  965f72c8-a31d-497e-a766-d071eeb90ed3   \n",
       "\n",
       "                                   session_id  \\\n",
       "1387979  d074662b-cef6-49a5-822f-4cae7c1bbfc8   \n",
       "1387980  dddfdaa9-8a14-456b-b6a3-0d4a9ecaa81b   \n",
       "1387981  3b66f169-5c68-435c-ba1d-76e9cf68e87c   \n",
       "1387982  42d80850-b943-4b24-b53b-7a204c93318e   \n",
       "1387983  93aa8d5c-5db1-4b3a-87a9-f0c4ff847992   \n",
       "\n",
       "                                                   context  \\\n",
       "1387979  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "1387980  {\"page\": {\"name\": \"profile\", \"url\": \"https://r...   \n",
       "1387981  {\"page\": {\"name\": \"start\", \"url\": \"https://rec...   \n",
       "1387982  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "1387983  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "\n",
       "                                          event_properties  \\\n",
       "1387979  {\"page_name\": \"main\", \"referrer\": \"https://goo...   \n",
       "1387980                           {\"page_name\": \"profile\"}   \n",
       "1387981                             {\"page_name\": \"start\"}   \n",
       "1387982  {\"list_type\": \"popular\", \"displayed_recipe_ids...   \n",
       "1387983               {\"recipe_id\": \"6893936\", \"rank\": 10}   \n",
       "\n",
       "                                  timestamp  \n",
       "1387979 2025-07-31 23:47:53.296279434+09:00  \n",
       "1387980 2025-07-31 23:48:32.494216675+09:00  \n",
       "1387981 2025-07-31 23:48:32.509363821+09:00  \n",
       "1387982 2025-07-31 23:49:04.206501635+09:00  \n",
       "1387983 2025-07-31 23:49:08.795700719+09:00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5461ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/10 ìƒ˜í”Œë§ (10%)\n",
    "sample_10 = events_df.sample(frac=0.1, random_state=42)\n",
    "# sample_10 = sample_10.compute()  # pandas DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "\n",
    "# # 1/100 ìƒ˜í”Œë§ (1%)\n",
    "# sample_100 = events_df.sample(frac=0.01, random_state=42)\n",
    "# sample_100 = sample_100.compute()  # pandas DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "\n",
    "# í•„ìš”ì‹œ parquet ë“±ìœ¼ë¡œ ì €ì¥\n",
    "# sample_10.to_parquet(\"sample_10.parquet\", index=False)\n",
    "# sample_100.to_parquet(\"sample_100.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30bf02f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”ì‹œ parquet ë“±ìœ¼ë¡œ ì €ì¥\n",
    "# sample_10.to_parquet(\"sample_10.parquet\", index=False)\n",
    "# sample_100.to_parquet(\"sample_100.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb3f6aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/10 ìƒ˜í”Œë§ (10%)\n",
    "sample_10 = events_df.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# í•„ìš”ì‹œ parquet ë“±ìœ¼ë¡œ ì €ì¥\n",
    "sample_10.to_parquet(\"data/event_logs/sample_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a270499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/100 ìƒ˜í”Œë§ (1%)\n",
    "sample_100 = events_df.sample(frac=0.01, random_state=42)\n",
    "\n",
    "# í•„ìš”ì‹œ parquet ë“±ìœ¼ë¡œ ì €ì¥\n",
    "sample_100.to_parquet(\"data/event_logs/sample_100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbc391e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95c334d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ 3,888,897ê°œ â†’ 1ì–µê°œë¡œ ë³µì œ/í™•ì¥(Dask)í•©ë‹ˆë‹¤.\n",
      "1,389,591ê°œ ì €ì¥ ì™„ë£Œ\n",
      "2,777,609ê°œ ì €ì¥ ì™„ë£Œ\n",
      "3,888,897ê°œ ì €ì¥ ì™„ë£Œ\n",
      "5,278,488ê°œ ì €ì¥ ì™„ë£Œ\n",
      "6,666,506ê°œ ì €ì¥ ì™„ë£Œ\n",
      "7,777,794ê°œ ì €ì¥ ì™„ë£Œ\n",
      "9,167,385ê°œ ì €ì¥ ì™„ë£Œ\n",
      "10,555,403ê°œ ì €ì¥ ì™„ë£Œ\n",
      "11,666,691ê°œ ì €ì¥ ì™„ë£Œ\n",
      "13,056,282ê°œ ì €ì¥ ì™„ë£Œ\n",
      "14,444,300ê°œ ì €ì¥ ì™„ë£Œ\n",
      "15,555,588ê°œ ì €ì¥ ì™„ë£Œ\n",
      "16,945,179ê°œ ì €ì¥ ì™„ë£Œ\n",
      "18,333,197ê°œ ì €ì¥ ì™„ë£Œ\n",
      "19,444,485ê°œ ì €ì¥ ì™„ë£Œ\n",
      "20,834,076ê°œ ì €ì¥ ì™„ë£Œ\n",
      "22,222,094ê°œ ì €ì¥ ì™„ë£Œ\n",
      "23,333,382ê°œ ì €ì¥ ì™„ë£Œ\n",
      "24,722,973ê°œ ì €ì¥ ì™„ë£Œ\n",
      "26,110,991ê°œ ì €ì¥ ì™„ë£Œ\n",
      "27,222,279ê°œ ì €ì¥ ì™„ë£Œ\n",
      "28,611,870ê°œ ì €ì¥ ì™„ë£Œ\n",
      "29,999,888ê°œ ì €ì¥ ì™„ë£Œ\n",
      "31,111,176ê°œ ì €ì¥ ì™„ë£Œ\n",
      "32,500,767ê°œ ì €ì¥ ì™„ë£Œ\n",
      "33,888,785ê°œ ì €ì¥ ì™„ë£Œ\n",
      "35,000,073ê°œ ì €ì¥ ì™„ë£Œ\n",
      "36,389,664ê°œ ì €ì¥ ì™„ë£Œ\n",
      "37,777,682ê°œ ì €ì¥ ì™„ë£Œ\n",
      "38,888,970ê°œ ì €ì¥ ì™„ë£Œ\n",
      "40,278,561ê°œ ì €ì¥ ì™„ë£Œ\n",
      "41,666,579ê°œ ì €ì¥ ì™„ë£Œ\n",
      "42,777,867ê°œ ì €ì¥ ì™„ë£Œ\n",
      "44,167,458ê°œ ì €ì¥ ì™„ë£Œ\n",
      "45,555,476ê°œ ì €ì¥ ì™„ë£Œ\n",
      "46,666,764ê°œ ì €ì¥ ì™„ë£Œ\n",
      "48,056,355ê°œ ì €ì¥ ì™„ë£Œ\n",
      "49,444,373ê°œ ì €ì¥ ì™„ë£Œ\n",
      "50,555,661ê°œ ì €ì¥ ì™„ë£Œ\n",
      "51,945,252ê°œ ì €ì¥ ì™„ë£Œ\n",
      "53,333,270ê°œ ì €ì¥ ì™„ë£Œ\n",
      "54,444,558ê°œ ì €ì¥ ì™„ë£Œ\n",
      "55,834,149ê°œ ì €ì¥ ì™„ë£Œ\n",
      "57,222,167ê°œ ì €ì¥ ì™„ë£Œ\n",
      "58,333,455ê°œ ì €ì¥ ì™„ë£Œ\n",
      "59,723,046ê°œ ì €ì¥ ì™„ë£Œ\n",
      "61,111,064ê°œ ì €ì¥ ì™„ë£Œ\n",
      "62,222,352ê°œ ì €ì¥ ì™„ë£Œ\n",
      "63,611,943ê°œ ì €ì¥ ì™„ë£Œ\n",
      "64,999,961ê°œ ì €ì¥ ì™„ë£Œ\n",
      "66,111,249ê°œ ì €ì¥ ì™„ë£Œ\n",
      "67,500,840ê°œ ì €ì¥ ì™„ë£Œ\n",
      "68,888,858ê°œ ì €ì¥ ì™„ë£Œ\n",
      "70,000,146ê°œ ì €ì¥ ì™„ë£Œ\n",
      "71,389,737ê°œ ì €ì¥ ì™„ë£Œ\n",
      "72,777,755ê°œ ì €ì¥ ì™„ë£Œ\n",
      "73,889,043ê°œ ì €ì¥ ì™„ë£Œ\n",
      "75,278,634ê°œ ì €ì¥ ì™„ë£Œ\n",
      "76,666,652ê°œ ì €ì¥ ì™„ë£Œ\n",
      "77,777,940ê°œ ì €ì¥ ì™„ë£Œ\n",
      "79,167,531ê°œ ì €ì¥ ì™„ë£Œ\n",
      "80,555,549ê°œ ì €ì¥ ì™„ë£Œ\n",
      "81,666,837ê°œ ì €ì¥ ì™„ë£Œ\n",
      "83,056,428ê°œ ì €ì¥ ì™„ë£Œ\n",
      "84,444,446ê°œ ì €ì¥ ì™„ë£Œ\n",
      "85,555,734ê°œ ì €ì¥ ì™„ë£Œ\n",
      "86,945,325ê°œ ì €ì¥ ì™„ë£Œ\n",
      "88,333,343ê°œ ì €ì¥ ì™„ë£Œ\n",
      "89,444,631ê°œ ì €ì¥ ì™„ë£Œ\n",
      "90,834,222ê°œ ì €ì¥ ì™„ë£Œ\n",
      "92,222,240ê°œ ì €ì¥ ì™„ë£Œ\n",
      "93,333,528ê°œ ì €ì¥ ì™„ë£Œ\n",
      "94,723,119ê°œ ì €ì¥ ì™„ë£Œ\n",
      "96,111,137ê°œ ì €ì¥ ì™„ë£Œ\n",
      "97,222,425ê°œ ì €ì¥ ì™„ë£Œ\n",
      "98,612,016ê°œ ì €ì¥ ì™„ë£Œ\n",
      "100,000,000ê°œ ì €ì¥ ì™„ë£Œ\n",
      "1ì–µê°œ ì™„ì„±! (ì—¬ëŸ¬ jsonl íŒŒì¼)\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "final_path = \"data/event_logs/events_100M_weighted_batch.parquet\"\n",
    "target_count = 100_000_000\n",
    "chunk_size = 10_000_000\n",
    "tmp_dir = \"data/event_logs/events_100M_final_chunks_jsonl\"\n",
    "os.makedirs(tmp_dir, exist_ok=True)\n",
    "\n",
    "ddf = dd.read_parquet(final_path)\n",
    "current_count = ddf.shape[0].compute()\n",
    "\n",
    "if current_count < target_count:\n",
    "    print(f\"í˜„ì¬ {current_count:,}ê°œ â†’ 1ì–µê°œë¡œ ë³µì œ/í™•ì¥(Dask)í•©ë‹ˆë‹¤.\")\n",
    "    replications_needed = (target_count // current_count) + 1\n",
    "    ddf_list = []\n",
    "    for i in range(replications_needed):\n",
    "        temp = ddf.copy()\n",
    "        temp = temp.assign(event_id=temp.event_id.astype(str) + f\"_rep{i}\")\n",
    "        ddf_list.append(temp)\n",
    "    ddf_all = dd.concat(ddf_list)\n",
    "    ddf_all = ddf_all.reset_index(drop=True)\n",
    "    # íŒŒí‹°ì…˜ ë‹¨ìœ„ë¡œ ì—¬ëŸ¬ ê°œì˜ jsonl íŒŒì¼ë¡œ ì €ì¥\n",
    "    total_saved = 0\n",
    "    chunk_idx = 0\n",
    "    for partition in ddf_all.partitions:\n",
    "        chunk = partition.compute()\n",
    "        if total_saved + len(chunk) > target_count:\n",
    "            chunk = chunk.iloc[:target_count - total_saved]\n",
    "        # chunk.to_json(f\"{tmp_dir}/chunk_{chunk_idx:03d}.jsonl\", orient=\"records\", lines=True, force_ascii=False)\n",
    "        chunk.to_json(\n",
    "            f\"{tmp_dir}/chunk_{chunk_idx:03d}.jsonl\",\n",
    "            orient=\"records\",\n",
    "            lines=True,\n",
    "            force_ascii=False,\n",
    "            date_format=\"iso\"  # ISO 8601 í˜•ì‹ìœ¼ë¡œ ë‚ ì§œ ì €ì¥\n",
    "        )\n",
    "        total_saved += len(chunk)\n",
    "        print(f\"{total_saved:,}ê°œ ì €ì¥ ì™„ë£Œ\")\n",
    "        chunk_idx += 1\n",
    "        if total_saved >= target_count:\n",
    "            break\n",
    "    print(\"1ì–µê°œ ì™„ì„±! (ì—¬ëŸ¬ jsonl íŒŒì¼)\")\n",
    "else:\n",
    "    print(\"ì´ë¯¸ 1ì–µê°œ ì´ìƒì…ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "434db0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë“  jsonl íŒŒì¼ì´ í•˜ë‚˜ë¡œ í•©ì³ì¡ŒìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# ì €ì¥ëœ jsonl íŒŒì¼ ê²½ë¡œ íŒ¨í„´\n",
    "jsonl_files = sorted(glob.glob(\"data/event_logs/events_100M_final_chunks_jsonl/*.jsonl\"))\n",
    "\n",
    "with open(\"data/event_logs/events_100M_final.jsonl\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for fname in jsonl_files:\n",
    "        with open(fname, \"r\", encoding=\"utf-8\") as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "print(\"ëª¨ë“  jsonl íŒŒì¼ì´ í•˜ë‚˜ë¡œ í•©ì³ì¡ŒìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d597c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_10 = dd.read_parquet(\"data/event_logs/sample_10\")\n",
    "sample_100 = dd.read_parquet(\"data/event_logs/sample_100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b55d83f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>anonymous_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>context</th>\n",
       "      <th>event_properties</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1140450</th>\n",
       "      <td>click_auth_button</td>\n",
       "      <td>a937c5f4-308a-42f6-8b56-d1abb5d54de3_rep0</td>\n",
       "      <td>848752</td>\n",
       "      <td>6cba4c36-0159-4e02-b4fe-ec79b86a9c6e</td>\n",
       "      <td>43bd0a4f-7838-41e6-9dfc-b4e4a71ddefa</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"type\": \"login\"}</td>\n",
       "      <td>2025-07-07 08:40:12.782565795+09:00</td>\n",
       "      <td>2025-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130209</th>\n",
       "      <td>click_recipe</td>\n",
       "      <td>79b9998f-8417-44fe-a284-a276013f7b48_rep0</td>\n",
       "      <td>1617008</td>\n",
       "      <td>39f514c0-214d-4673-95bb-596b7ec9890f</td>\n",
       "      <td>33675188-e331-4590-a362-d5c0cf9932a5</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"recipe_id\": \"6938420\", \"rank\": 4}</td>\n",
       "      <td>2025-07-30 01:01:35.149667718+09:00</td>\n",
       "      <td>2025-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172296</th>\n",
       "      <td>view_recipe_list</td>\n",
       "      <td>8c2bc778-685d-485f-ad18-5cceba59eaf8_rep0</td>\n",
       "      <td>1854992</td>\n",
       "      <td>0d518416-035c-43ae-920e-a882756d7e69</td>\n",
       "      <td>1330a96f-c8de-48dd-b48a-85a8de13bfc9</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"list_type\": \"recommended\", \"displayed_recipe...</td>\n",
       "      <td>2025-07-14 11:27:29.243467492+09:00</td>\n",
       "      <td>2025-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162930</th>\n",
       "      <td>create_comment</td>\n",
       "      <td>8c9d78a6-3e70-44bb-bfa4-4bdabb673c79_rep0</td>\n",
       "      <td>785991</td>\n",
       "      <td>a11bf710-dbb2-4fcd-966e-14c9027ad0ee</td>\n",
       "      <td>4f7b433a-8830-4cd7-9e0a-90b2a6af5f55</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"recipe_id\": \"1895651\", \"comment_length\": 171}</td>\n",
       "      <td>2025-07-12 09:29:13.913110766+09:00</td>\n",
       "      <td>2025-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275625</th>\n",
       "      <td>click_recipe</td>\n",
       "      <td>069c9561-5b8d-418c-8b84-3ecdd95beb9f_rep0</td>\n",
       "      <td>1219046</td>\n",
       "      <td>938ae1a4-6f8d-41e0-b669-2fafe4586d13</td>\n",
       "      <td>62bc82fb-b8b3-4d08-a504-6fc84975861a</td>\n",
       "      <td>{\"page\": {\"name\": \"main\", \"url\": \"https://reci...</td>\n",
       "      <td>{\"recipe_id\": \"4822883\", \"rank\": 13}</td>\n",
       "      <td>2025-07-06 13:38:18.703023565+09:00</td>\n",
       "      <td>2025-07-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                event_name                                   event_id  \\\n",
       "1140450  click_auth_button  a937c5f4-308a-42f6-8b56-d1abb5d54de3_rep0   \n",
       "130209        click_recipe  79b9998f-8417-44fe-a284-a276013f7b48_rep0   \n",
       "1172296   view_recipe_list  8c2bc778-685d-485f-ad18-5cceba59eaf8_rep0   \n",
       "1162930     create_comment  8c9d78a6-3e70-44bb-bfa4-4bdabb673c79_rep0   \n",
       "1275625       click_recipe  069c9561-5b8d-418c-8b84-3ecdd95beb9f_rep0   \n",
       "\n",
       "         user_id                          anonymous_id  \\\n",
       "1140450   848752  6cba4c36-0159-4e02-b4fe-ec79b86a9c6e   \n",
       "130209   1617008  39f514c0-214d-4673-95bb-596b7ec9890f   \n",
       "1172296  1854992  0d518416-035c-43ae-920e-a882756d7e69   \n",
       "1162930   785991  a11bf710-dbb2-4fcd-966e-14c9027ad0ee   \n",
       "1275625  1219046  938ae1a4-6f8d-41e0-b669-2fafe4586d13   \n",
       "\n",
       "                                   session_id  \\\n",
       "1140450  43bd0a4f-7838-41e6-9dfc-b4e4a71ddefa   \n",
       "130209   33675188-e331-4590-a362-d5c0cf9932a5   \n",
       "1172296  1330a96f-c8de-48dd-b48a-85a8de13bfc9   \n",
       "1162930  4f7b433a-8830-4cd7-9e0a-90b2a6af5f55   \n",
       "1275625  62bc82fb-b8b3-4d08-a504-6fc84975861a   \n",
       "\n",
       "                                                   context  \\\n",
       "1140450  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "130209   {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "1172296  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "1162930  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "1275625  {\"page\": {\"name\": \"main\", \"url\": \"https://reci...   \n",
       "\n",
       "                                          event_properties  \\\n",
       "1140450                                  {\"type\": \"login\"}   \n",
       "130209                 {\"recipe_id\": \"6938420\", \"rank\": 4}   \n",
       "1172296  {\"list_type\": \"recommended\", \"displayed_recipe...   \n",
       "1162930    {\"recipe_id\": \"1895651\", \"comment_length\": 171}   \n",
       "1275625               {\"recipe_id\": \"4822883\", \"rank\": 13}   \n",
       "\n",
       "                                  timestamp        date  \n",
       "1140450 2025-07-07 08:40:12.782565795+09:00  2025-07-07  \n",
       "130209  2025-07-30 01:01:35.149667718+09:00  2025-07-30  \n",
       "1172296 2025-07-14 11:27:29.243467492+09:00  2025-07-14  \n",
       "1162930 2025-07-12 09:29:13.913110766+09:00  2025-07-12  \n",
       "1275625 2025-07-06 13:38:18.703023565+09:00  2025-07-06  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a17cc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 1 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 2 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 3 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 4 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 5 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 6 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 7 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 8 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 9 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 10 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 11 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 12 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 13 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 14 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 15 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 16 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 17 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 18 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 19 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 20 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 21 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 22 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 23 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 24 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 25 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 26 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 27 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 28 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 29 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 30 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 31 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 32 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 33 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 34 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 35 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 36 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 37 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 38 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 39 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 40 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 41 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 42 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 43 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 44 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 45 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 46 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 47 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 48 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 49 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 50 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 51 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 52 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 53 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 54 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 55 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 56 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 57 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 58 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 59 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 60 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 61 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 62 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 63 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 64 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 65 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 66 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 67 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 68 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 69 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 70 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 71 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 72 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 73 ì €ì¥ ì™„ë£Œ (1,388,018 rows)\n",
      "chunk 74 ì €ì¥ ì™„ë£Œ (1,111,288 rows)\n",
      "chunk 75 ì €ì¥ ì™„ë£Œ (1,389,591 rows)\n",
      "chunk 76 ì €ì¥ ì™„ë£Œ (1,387,984 rows)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Dask DataFrameì„ pandas DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì§€ ì•Šê³ , Daskì˜ íŒŒí‹°ì…˜ ë‹¨ìœ„ë¡œ ì €ì¥\n",
    "chunk_dir = \"data/event_logs/events_jsonl_chunks\"\n",
    "os.makedirs(chunk_dir, exist_ok=True)\n",
    "\n",
    "for i, partition in enumerate(events_df.partitions):\n",
    "    chunk = partition.compute()\n",
    "    # to_json í˜¸ì¶œ ì „ì— timestamp ì»¬ëŸ¼ì„ ISO 8601 í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ì§ì ‘ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    # .dt ì ‘ê·¼ì ëŒ€ì‹  .apply()ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° timestamp ê°ì²´ì— isoformat()ì„ ì ìš©í•©ë‹ˆë‹¤.\n",
    "    chunk['timestamp'] = chunk['timestamp'].apply(lambda ts: ts.isoformat())\n",
    "    chunk.to_json(f\"{chunk_dir}/events_chunk_{i:03d}.jsonl\", \n",
    "                  orient=\"records\", \n",
    "                  lines=True, \n",
    "                  force_ascii=False, \n",
    "                  date_format=\"iso\",\n",
    "                  )\n",
    "    print(f\"chunk {i} ì €ì¥ ì™„ë£Œ ({len(chunk):,} rows)\")\n",
    "\n",
    "# ë˜ëŠ” pandas DataFrameìœ¼ë¡œ ë³€í™˜ í›„, í–‰ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ chunk ì €ì¥\n",
    "# sample_events_pd = sample_events.compute()\n",
    "# chunk_size = 1_000_000\n",
    "# num_chunks = math.ceil(len(sample_events_pd) / chunk_size)\n",
    "# for i in range(num_chunks):\n",
    "#     chunk = sample_events_pd.iloc[i*chunk_size : (i+1)*chunk_size]\n",
    "#     chunk.to_json(f\"{chunk_dir}/sample_events_chunk_{i:03d}.jsonl\", orient=\"records\", lines=True, force_ascii=False)\n",
    "#     print(f\"chunk {i} ì €ì¥ ì™„ë£Œ ({len(chunk):,} rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0ab28a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë“  chunkê°€ data/event_logs/events_merged.jsonlë¡œ í•©ì³ì¡ŒìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# ì €ì¥ëœ jsonl íŒŒì¼ ê²½ë¡œ íŒ¨í„´\n",
    "jsonl_files = sorted(glob.glob(\"data/event_logs/events_jsonl_chunks/*.jsonl\"))\n",
    "\n",
    "with open(\"data/event_logs/events_merged.jsonl\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for fname in jsonl_files:\n",
    "        with open(fname, \"r\", encoding=\"utf-8\") as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "print(\"ëª¨ë“  chunkê°€ data/event_logs/events_merged.jsonlë¡œ í•©ì³ì¡ŒìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65b2bb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 1 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 2 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 3 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 4 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 5 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 6 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 7 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 8 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 9 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 10 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 11 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 12 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 13 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 14 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 15 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 16 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 17 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 18 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 19 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 20 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 21 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 22 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 23 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 24 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 25 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 26 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 27 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 28 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 29 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 30 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 31 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 32 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 33 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 34 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 35 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 36 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 37 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 38 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 39 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 40 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 41 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 42 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 43 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 44 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 45 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 46 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 47 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 48 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 49 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 50 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 51 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 52 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 53 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 54 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 55 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 56 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 57 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 58 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 59 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 60 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 61 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 62 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 63 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 64 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 65 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 66 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 67 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 68 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 69 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 70 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 71 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 72 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 73 ì €ì¥ ì™„ë£Œ (138,802 rows)\n",
      "chunk 74 ì €ì¥ ì™„ë£Œ (111,129 rows)\n",
      "chunk 75 ì €ì¥ ì™„ë£Œ (138,959 rows)\n",
      "chunk 76 ì €ì¥ ì™„ë£Œ (138,798 rows)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Dask DataFrameì„ pandas DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì§€ ì•Šê³ , Daskì˜ íŒŒí‹°ì…˜ ë‹¨ìœ„ë¡œ ì €ì¥\n",
    "chunk_dir = \"data/event_logs/sample_10_jsonl_chunks\"\n",
    "os.makedirs(chunk_dir, exist_ok=True)\n",
    "\n",
    "for i, partition in enumerate(sample_10.partitions):\n",
    "    chunk = partition.compute()\n",
    "    # to_json í˜¸ì¶œ ì „ì— timestamp ì»¬ëŸ¼ì„ ISO 8601 í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ì§ì ‘ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    # .dt ì ‘ê·¼ì ëŒ€ì‹  .apply()ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° timestamp ê°ì²´ì— isoformat()ì„ ì ìš©í•©ë‹ˆë‹¤.\n",
    "    chunk['timestamp'] = chunk['timestamp'].apply(lambda ts: ts.isoformat())\n",
    "    chunk.to_json(f\"{chunk_dir}/sample_10_chunk_{i:03d}.jsonl\", \n",
    "                  orient=\"records\", \n",
    "                  lines=True, \n",
    "                  force_ascii=False, \n",
    "                  date_format=\"iso\",\n",
    "                  )\n",
    "    print(f\"chunk {i} ì €ì¥ ì™„ë£Œ ({len(chunk):,} rows)\")\n",
    "\n",
    "# ë˜ëŠ” pandas DataFrameìœ¼ë¡œ ë³€í™˜ í›„, í–‰ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ chunk ì €ì¥\n",
    "# sample_10_pd = sample_10.compute()\n",
    "# chunk_size = 1_000_000\n",
    "# num_chunks = math.ceil(len(sample_10_pd) / chunk_size)\n",
    "# for i in range(num_chunks):\n",
    "#     chunk = sample_10_pd.iloc[i*chunk_size : (i+1)*chunk_size]\n",
    "#     chunk.to_json(f\"{chunk_dir}/sample_10_chunk_{i:03d}.jsonl\", orient=\"records\", lines=True, force_ascii=False)\n",
    "#     print(f\"chunk {i} ì €ì¥ ì™„ë£Œ ({len(chunk):,} rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "645466e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë“  chunkê°€ data/event_logs/sample_10_merged.jsonlë¡œ í•©ì³ì¡ŒìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# ì €ì¥ëœ jsonl íŒŒì¼ ê²½ë¡œ íŒ¨í„´\n",
    "jsonl_files = sorted(glob.glob(\"data/event_logs/sample_10_jsonl_chunks/*.jsonl\"))\n",
    "\n",
    "with open(\"data/event_logs/sample_10_merged.jsonl\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for fname in jsonl_files:\n",
    "        with open(fname, \"r\", encoding=\"utf-8\") as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "print(\"ëª¨ë“  chunkê°€ data/event_logs/sample_10_merged.jsonlë¡œ í•©ì³ì¡ŒìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1178e3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 1 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 2 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 3 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 4 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 5 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 6 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 7 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 8 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 9 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 10 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 11 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 12 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 13 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 14 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 15 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 16 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 17 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 18 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 19 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 20 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 21 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 22 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 23 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 24 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 25 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 26 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 27 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 28 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 29 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 30 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 31 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 32 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 33 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 34 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 35 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 36 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 37 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 38 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 39 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 40 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 41 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 42 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 43 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 44 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 45 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 46 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 47 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 48 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 49 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 50 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 51 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 52 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 53 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 54 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 55 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 56 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 57 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 58 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 59 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 60 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 61 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 62 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 63 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 64 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 65 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 66 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 67 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 68 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 69 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 70 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 71 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 72 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 73 ì €ì¥ ì™„ë£Œ (13,880 rows)\n",
      "chunk 74 ì €ì¥ ì™„ë£Œ (11,113 rows)\n",
      "chunk 75 ì €ì¥ ì™„ë£Œ (13,896 rows)\n",
      "chunk 76 ì €ì¥ ì™„ë£Œ (13,880 rows)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Dask DataFrameì„ pandas DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì§€ ì•Šê³ , Daskì˜ íŒŒí‹°ì…˜ ë‹¨ìœ„ë¡œ ì €ì¥\n",
    "chunk_dir = \"data/event_logs/sample_100_jsonl_chunks\"\n",
    "os.makedirs(chunk_dir, exist_ok=True)\n",
    "\n",
    "for i, partition in enumerate(sample_100.partitions):\n",
    "    chunk = partition.compute()\n",
    "    # to_json í˜¸ì¶œ ì „ì— timestamp ì»¬ëŸ¼ì„ ISO 8601 í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ì§ì ‘ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    # .dt ì ‘ê·¼ì ëŒ€ì‹  .apply()ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° timestamp ê°ì²´ì— isoformat()ì„ ì ìš©í•©ë‹ˆë‹¤.\n",
    "    chunk['timestamp'] = chunk['timestamp'].apply(lambda ts: ts.isoformat())\n",
    "    # chunk.to_json(f\"{chunk_dir}/sample_100_chunk_{i:03d}.jsonl\", orient=\"records\", lines=True, force_ascii=False, date_format=\"iso\")\n",
    "    \n",
    "    chunk.to_json(f\"{chunk_dir}/sample_100_chunk_{i:03d}.jsonl\", \n",
    "                orient=\"records\", \n",
    "                lines=True, \n",
    "                force_ascii=False, \n",
    "                date_format=\"iso\",\n",
    "                )\n",
    "    print(f\"chunk {i} ì €ì¥ ì™„ë£Œ ({len(chunk):,} rows)\")\n",
    "\n",
    "# ë˜ëŠ” pandas DataFrameìœ¼ë¡œ ë³€í™˜ í›„, í–‰ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ chunk ì €ì¥\n",
    "# sample_100_pd = sample_100.compute()\n",
    "# chunk_size = 1_000_000\n",
    "# num_chunks = math.ceil(len(sample_100_pd) / chunk_size)\n",
    "# for i in range(num_chunks):\n",
    "#     chunk = sample_100_pd.iloc[i*chunk_size : (i+1)*chunk_size]\n",
    "#     chunk.to_json(f\"{chunk_dir}/sample_100_chunk_{i:03d}.jsonl\", orient=\"records\", lines=True, force_ascii=False)\n",
    "#     print(f\"chunk {i} ì €ì¥ ì™„ë£Œ ({len(chunk):,} rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "251cec88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë“  chunkê°€ data/event_logs/sample_100_merged.jsonlë¡œ í•©ì³ì¡ŒìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# ì €ì¥ëœ jsonl íŒŒì¼ ê²½ë¡œ íŒ¨í„´\n",
    "jsonl_files = sorted(glob.glob(\"data/event_logs/sample_100_jsonl_chunks/*.jsonl\"))\n",
    "\n",
    "with open(\"data/event_logs/sample_100_merged.jsonl\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for fname in jsonl_files:\n",
    "        with open(fname, \"r\", encoding=\"utf-8\") as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "print(\"ëª¨ë“  chunkê°€ data/event_logs/sample_100_merged.jsonlë¡œ í•©ì³ì¡ŒìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3442400e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-ER0ku5Vt-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
