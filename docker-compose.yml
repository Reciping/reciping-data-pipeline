# docker-compose.yml

services:
  # 1. ë©”íƒ€ë°ì´í„°ë¥¼ ì €ì¥í•  PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì„œë²„
  postgres:
    image: postgres:12
    container_name: postgres_for_hive
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=metastore_db
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hivepassword
    command: postgres -c "fsync=off"

  # 2. í•˜ì´ë¸Œ ë©”íƒ€ìŠ¤í† ì–´ ì„œë¹„ìŠ¤ (S3 ì§€ì› í¬í•¨)
  metastore:
    image: apache/hive:4.0.0
    container_name: hive_metastore
    depends_on:
      - postgres
    ports:
      - "9083:9083"
    volumes:
      # Sparkì—ì„œ ë¹Œë“œëœ JAR íŒŒì¼ë“¤ì„ Hive Metastoreì™€ ê³µìœ 
      - spark_jars:/shared-jars:ro
    env_file:
      - .env  # AWS ìê²©ì¦ëª…
    environment:
      - SERVICE_NAME=metastore
      - DB_TYPE=postgres
      - DB_HOSTNAME=postgres
      - DB_PORT=5432
      - DB_DATABASE=metastore_db
      - DB_USER=hive
      - DB_PASSWORD=hivepassword
      # S3 warehouse ê²½ë¡œ ì„¤ì •
      - HIVE_CONF_hive_metastore_warehouse_dir=s3a://reciping-user-event-logs/iceberg/warehouse/
      # S3A ì„¤ì •
      - HIVE_CONF_fs_s3a_impl=org.apache.hadoop.fs.s3a.S3AFileSystem
      - HIVE_CONF_fs_s3a_aws_credentials_provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
      - HIVE_CONF_fs_s3a_path_style_access=true
      # JAR íŒŒì¼ classpathì— ì¶”ê°€
      - HIVE_AUX_JARS_PATH=/shared-jars
    command: >
      bash -c "
        echo 'ğŸ”§ S3 JAR íŒŒì¼ë“¤ì„ Hive Metastoreì— ë³µì‚¬ ì¤‘...'
        && cp /shared-jars/aws-java-sdk-bundle-*.jar /opt/hive/lib/ 2>/dev/null || echo 'AWS SDK ë³µì‚¬ ì‹¤íŒ¨'
        && cp /shared-jars/hadoop-aws-*.jar /opt/hive/lib/ 2>/dev/null || echo 'Hadoop AWS ë³µì‚¬ ì‹¤íŒ¨'
        && echo 'âœ… JAR íŒŒì¼ ë³µì‚¬ ì™„ë£Œ!'
        && /entrypoint.sh
      "

  # 3. Spark ê°œë°œ í™˜ê²½ ì„œë¹„ìŠ¤
  spark-dev:
    build: .
    container_name: spark_dev_env
    user: "root"
    env_file:
      - .env
    volumes:
      - .:/app
      - ~/.aws:/root/.aws:ro
      # Spark JAR íŒŒì¼ë“¤ì„ ê³µìœ  ë³¼ë¥¨ì— ë³µì‚¬
      - spark_jars:/shared-jars
    tty: true
    entrypoint: ["/usr/local/bin/entrypoint.sh"]
    command: ["tail", "-f", "/dev/null"]
    environment:
      - POETRY_VIRTUALENVS_CREATE=false
      - POETRY_CONFIG_DIR=/app/.config
      - HADOOP_USER_NAME=root
      - USER=root
      - LOGNAME=root
      - USERNAME=root

# Docker ë³¼ë¥¨ ì •ì˜
volumes:
  spark_jars:
