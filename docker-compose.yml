# docker-compose.yml

services:
  # 1. 메타데이터를 저장할 PostgreSQL 데이터베이스 서버
  postgres:
    image: postgres:12
    container_name: postgres_for_hive
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=metastore_db
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hivepassword
    command: postgres -c "fsync=off"

  # 2. 하이브 메타스토어 서비스 (애플리케이션 서버)
  metastore:
    image: apache/hive:4.0.0
    container_name: hive_metastore
    depends_on:
      - postgres
    ports:
      - "9083:9083" # 스파크가 접속할 포트
    environment:
      - SERVICE_NAME=metastore
      - DB_TYPE=postgres
      - DB_HOSTNAME=postgres
      - DB_PORT=5432
      - DB_DATABASE=metastore_db
      - DB_USER=hive
      - DB_PASSWORD=hivepassword
      - HIVE_CONF_hive_metastore_warehouse_dir=/tmp # 임시 경로, 실제 데이터는 S3에 저장
    command: ["/opt/hive/bin/hive", "--service", "metastore"]

  # 3. 새로 추가된 Spark 개발 환경 서비스
  spark-dev:
    build: .  # 현재 폴더의 Dockerfile을 사용해 이미지를 빌드합니다.
    container_name: spark_dev_env
    depends_on:
      - metastore
    volumes:
      # 로컬 프로젝트 폴더와 컨테이너의 /app 폴더를 동기화합니다.
      # 로컬에서 코드를 수정하면 컨테이너 내부에 즉시 반영됩니다.
      - .:/app
      # 로컬 PC의 AWS 자격증명 파일(~/.aws)을 컨테이너 내부 non-root 유저의
      # 홈 디렉토리(/home/spark/.aws)로 읽기 전용(:ro) 공유합니다.
      - ~/.aws:/home/spark/.aws:ro
    tty: true  # 컨테이너가 바로 종료되지 않고 계속 실행 상태를 유지하도록 합니다.

    # 컨테이너가 시작될 때 가장 먼저 실행할 스크립트를 지정합니다.
    # 이 스크립트가 /home/spark 폴더의 권한 문제를 해결하는 핵심 역할을 합니다.
    entrypoint: ["/usr/local/bin/entrypoint.sh"]

    # entrypoint.sh 스크립트가 실행된 후, 컨테이너가 종료되지 않고 계속 대기하도록
    # 아무것도 하지 않는 명령을 전달합니다.
    command: ["tail", "-f", "/dev/null"]

    # --- ✅ 이 부분을 최종적으로 적용하세요 ---
    environment:
      # Poetry가 불필요한 가상환경을 생성하려는 시도 자체를 막습니다.
      # 이것이 'Creating virtualenv...' 로그와 관련 권한 문제를 해결하는 가장 확실한 방법입니다.
      - POETRY_VIRTUALENVS_CREATE=false

      # 만약의 경우를 대비해, Poetry 설정 파일 저장 경로를
      # 권한이 확실한 /app 폴더 내부로 지정하는 예비 설정입니다.
      - POETRY_CONFIG_DIR=/app/.config
      
      # Hadoop 사용자 환경 변수 추가
      - HADOOP_USER_NAME=root
      - USER=root
      - LOGNAME=root
      - USERNAME=root
      
      # AWS 자격 증명 환경 변수 추가
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=ap-northeast-2

  # spark-dev:
  #   build: . # 현재 폴더의 Dockerfile을 사용해 이미지를 빌드
  #   container_name: spark_dev_env
  #   depends_on:
  #     - metastore
  #   user: "1001"
  #   volumes:
  #     - .:/app # 로컬 폴더와 컨테이너의 /app 폴더를 동기화
  #     - ~/.aws:/root/.aws:ro # 로컬의 AWS 자격증명을 컨테이너에 읽기 전용으로 공유
  #   entrypoint: ["/usr/local/bin/entrypoint.sh"]
  #   command: ["tail", "-f", "/dev/null"]
  #   tty: true # 컨테이너가 바로 종료되지 않도록 설정