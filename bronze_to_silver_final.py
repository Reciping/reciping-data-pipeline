# main_bronze_to_silver.py (KST íŒŒí‹°ì…”ë‹ ë° ì½”ë“œ ìµœì í™” ìµœì¢…ë³¸)
# ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ ë°˜ì˜:
# 1. event_name ì»¬ëŸ¼ëª… ìœ ì§€ (event_type ë¦¬ë„¤ì„ ì•ˆí•¨)
# 2. archive/old_versions/bronze_to_silver.py ë³€í™˜ ë¡œì§ ì™„ì „ ì ìš©
# 3. Asia/Seoul íƒ€ì„ì¡´ ì„¤ì •ìœ¼ë¡œ í•œêµ­ ì‹œê°„ ìœ ì§€

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ìŠ¤íŒŒí¬ì˜ ë‚´ì¥ í•¨ìˆ˜ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json, year, month, dayofmonth, hour, date_format, format_string
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType, ArrayType, DateType, TimestampType

def main():
    """
    Bronze Layerì˜ ì›ë³¸ ì´ë²¤íŠ¸ ë¡œê·¸(JSONL)ë¥¼ ì½ì–´ ì •ì œí•˜ê³  êµ¬ì¡°í™”í•œ ë’¤,
    ë¶„ì„ì— ìµœì í™”ëœ Silver Layer(Parquet)ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•˜ëŠ” PySpark ETL ì‘ì—….
    
    ì‚¬ìš©ì ìš”ì²­ì‚¬í•­:
    1. event_name ì»¬ëŸ¼ëª… ê·¸ëŒ€ë¡œ ìœ ì§€
    2. archive/old_versions/bronze_to_silver.pyì˜ ë³€í™˜ ë¡œì§ ì™„ì „ ì ìš©
    3. í•œêµ­ ì‹œê°„(KST) íƒ€ì„ì¡´ ìœ ì§€
    """
    # -----------------------------------------------------------------------------
    # 1. ìŠ¤íŒŒí¬ ì„¸ì…˜ ìƒì„± (ETL ì‘ì—…ì˜ ì‹œì‘ì )
    # -----------------------------------------------------------------------------
    # SparkSessionì€ ìŠ¤íŒŒí¬ì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì§„ì…ì ì…ë‹ˆë‹¤.
    spark = SparkSession.builder \
        .appName("BronzeToSilver-UserEvents-ETL-KST-Final") \
        .config("spark.sql.session.timeZone", "Asia/Seoul") \
        .config("spark.driver.memory", "4g") \
        .config("spark.executor.memory", "4g") \
        .config("spark.driver.maxResultSize", "2g") \
        .config("spark.driver.host", "127.0.0.1") \
        .config("spark.ui.enabled", "false") \
        .config("spark.jars.packages", "org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.367") \
        .config("spark.hadoop.fs.s3a.aws.credentials.provider", "com.amazonaws.auth.profile.ProfileCredentialsProvider") \
        .getOrCreate()

    # ì‹¤í–‰ ë¡œê·¸ë¥¼ WARN ë ˆë²¨ë¡œ ì„¤ì •í•˜ì—¬ ì •ë³´ì„± ë¡œê·¸ëŠ” ì¤„ì´ê³  ê²½ê³  ë° ì—ëŸ¬ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.
    spark.sparkContext.setLogLevel("WARN")
    print("âœ… SparkSessionì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"â° íƒ€ì„ì¡´ ì„¤ì •: {spark.conf.get('spark.sql.session.timeZone')}")

    # -----------------------------------------------------------------------------
    # 2. ê²½ë¡œ ë³€ìˆ˜ ì •ì˜
    # -----------------------------------------------------------------------------
    # ì›ë³¸ ë°ì´í„°ê°€ ìˆëŠ” S3 ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
    bronze_s3_path = "s3a://reciping-user-event-logs/bronze/landing-zone/events/"
    # ê²°ê³¼ë¬¼ì„ ì €ì¥í•  S3 ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
    silver_s3_path = "s3a://reciping-user-event-logs/silver/user-behavior-events/"

    print(f"Bronze ë°ì´í„° ì†ŒìŠ¤: {bronze_s3_path}")
    print(f"Silver ë°ì´í„° ëª©ì ì§€: {silver_s3_path}")

    # -----------------------------------------------------------------------------
    # 3. ë°ì´í„° ì¶”ì¶œ (Extract)
    # -----------------------------------------------------------------------------
    # Bronze ê²½ë¡œì˜ ëª¨ë“  JSONL íŒŒì¼ì„ ì½ì–´ ìŠ¤íŒŒí¬ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.
    df_bronze = spark.read.json(bronze_s3_path)
    print("âœ… Bronze Layerë¡œë¶€í„° ë°ì´í„° ì½ê¸° ì™„ë£Œ.")
    
    row_count = df_bronze.count()
    print(f"ğŸ“Š ì›ë³¸ ë°ì´í„° í–‰ ìˆ˜: {row_count:,}")
    
    # -----------------------------------------------------------------------------
    # 4. ë°ì´í„° ë³€í™˜ (Transform)
    # -----------------------------------------------------------------------------

    # --- 4.1. ì¤‘ì²©ëœ JSON ë¬¸ìì—´ì„ íŒŒì‹±í•˜ê¸° ìœ„í•œ ìŠ¤í‚¤ë§ˆë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì •ì˜í•©ë‹ˆë‹¤. ---
    context_schema = StructType([
        StructField("page", StructType([
            StructField("name", StringType(), True),
            StructField("url", StringType(), True),
            StructField("path", StringType(), True)
        ]), True),
        StructField("user_segment", StringType(), True),
        StructField("activity_level", StringType(), True),
        StructField("cooking_style", StringType(), True),
        StructField("ab_test", StructType([
            StructField("scenario", StringType(), True),
            StructField("group", StringType(), True),
            StructField("start_date", StringType(), True),
            StructField("end_date", StringType(), True)
        ]), True)
    ])

    event_properties_schema = StructType([
        StructField("page_name", StringType(), True),
        StructField("referrer", StringType(), True),
        StructField("path", StringType(), True),
        StructField("method", StringType(), True),
        StructField("type", StringType(), True),
        StructField("search_type", StringType(), True),
        StructField("search_keyword", StringType(), True),
        StructField("selected_filters", ArrayType(StringType()), True),
        StructField("result_count", IntegerType(), True),
        StructField("list_type", StringType(), True),
        StructField("displayed_recipe_ids", ArrayType(StringType()), True),
        StructField("recipe_id", StringType(), True),
        StructField("rank", IntegerType(), True),
        StructField("action", StringType(), True),
        StructField("comment_length", IntegerType(), True),
        StructField("category", StringType(), True),
        StructField("ingredient_count", IntegerType(), True),
        StructField("ad_id", StringType(), True),
        StructField("ad_type", StringType(), True),
        StructField("position", StringType(), True),
        StructField("target_url", StringType(), True)
    ])

    # --- 4.2. JSON íŒŒì‹± ë° íƒ€ì„ìŠ¤íƒ¬í”„ ìë£Œí˜• ë³€í™˜ ---
    df_transformed = df_bronze \
        .withColumn("parsed_context", from_json(col("context"), context_schema)) \
        .withColumn("parsed_properties", from_json(col("event_properties"), event_properties_schema)) \
        .withColumn("timestamp", col("timestamp").cast(TimestampType())) \
        .withColumn("date", col("date").cast(DateType())) \
        .drop("context", "event_properties")

    print("âœ… JSON íŒŒì‹± ë° íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜ ì™„ë£Œ.")

    # --- 4.3. Silver Layer ì €ì¥ì„ ìœ„í•œ íŒŒí‹°ì…˜ ì»¬ëŸ¼ ìƒì„± (KST ê¸°ì¤€) ---
    # ì„¸ì…˜ ì‹œê°„ëŒ€ê°€ "Asia/Seoul"ì´ë¯€ë¡œ, year(), month() ë“± í•¨ìˆ˜ê°€ KST ê¸°ì¤€ìœ¼ë¡œ ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    df_with_partitions = df_transformed \
        .withColumn("year", year(col("timestamp"))) \
        .withColumn("month", month(col("timestamp"))) \
        .withColumn("day", dayofmonth(col("timestamp"))) \
        .withColumn("hour", hour(col("timestamp"))) \
        .withColumn("day_of_week", date_format(col("timestamp"), "E")) # 'Mon', 'Tue' ë“± ìš”ì¼ ì¶”ì¶œ

    print("âœ… KST ê¸°ì¤€ íŒŒí‹°ì…˜ ì»¬ëŸ¼(year, month, day, hour) ìƒì„± ì™„ë£Œ.")

    # --- 4.4. ìµœì¢… ì»¬ëŸ¼ ì„ íƒ ë° ì •ë¦¬ (í‰íƒ„í™”) ---
    df_silver = df_with_partitions.select(
        # ê¸°ë³¸ ì´ë²¤íŠ¸ ì •ë³´ (event_name ì»¬ëŸ¼ëª… ìœ ì§€)
        "event_id", 
        "event_name", 
        "user_id", 
        "anonymous_id", 
        "session_id", 
        
        # ì‹œê°„ ê´€ë ¨ ì»¬ëŸ¼
        col("timestamp").alias("utc_timestamp"), 
        "date",
        
        # KST ê¸°ì¤€ íŒŒìƒ ì»¬ëŸ¼ë“¤
        "year", 
        "month", 
        "day", 
        "hour",
        "day_of_week",
        
        # Contextì—ì„œ íŒŒìƒëœ ì»¬ëŸ¼ë“¤
        col("parsed_context.page.name").alias("page_name"),
        col("parsed_context.page.url").alias("page_url"),
        col("parsed_context.page.path").alias("page_path"),
        col("parsed_context.user_segment").alias("user_segment"),
        col("parsed_context.activity_level").alias("activity_level"),
        col("parsed_context.cooking_style").alias("cooking_style"),
        col("parsed_context.ab_test.group").alias("ab_test_group"),
        col("parsed_context.ab_test.scenario").alias("ab_test_scenario"),
        
        # Event Propertiesì—ì„œ íŒŒìƒëœ ì»¬ëŸ¼ë“¤
        col("parsed_properties.page_name").alias("prop_page_name"),
        col("parsed_properties.referrer").alias("prop_referrer"),
        col("parsed_properties.path").alias("prop_path"),
        col("parsed_properties.method").alias("prop_method"),
        col("parsed_properties.type").alias("prop_type"),
        col("parsed_properties.search_type").alias("prop_search_type"),
        col("parsed_properties.search_keyword").alias("prop_search_keyword"),
        col("parsed_properties.selected_filters").alias("prop_selected_filters"),
        col("parsed_properties.result_count").alias("prop_result_count"),
        col("parsed_properties.list_type").alias("prop_list_type"),
        col("parsed_properties.displayed_recipe_ids").alias("prop_displayed_recipe_ids"),
        col("parsed_properties.recipe_id").cast(LongType()).alias("prop_recipe_id"),
        col("parsed_properties.rank").alias("prop_rank"),
        col("parsed_properties.action").alias("prop_action"),
        col("parsed_properties.comment_length").alias("prop_comment_length"),
        col("parsed_properties.category").alias("prop_category"),
        col("parsed_properties.ingredient_count").alias("prop_ingredient_count"),
        col("parsed_properties.ad_id").alias("prop_ad_id"),
        col("parsed_properties.ad_type").alias("prop_ad_type"),
        col("parsed_properties.position").alias("prop_position"),
        col("parsed_properties.target_url").alias("prop_target_url")
    )
    
    # --- 4.5. ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ ---
    df_silver = df_silver.filter(col("event_id").isNotNull()).dropDuplicates(["event_id"])
    print("âœ… ì»¬ëŸ¼ í‰íƒ„í™” ë° ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ ì™„ë£Œ.")

    clean_count = df_silver.count()
    print(f"ğŸ“Š ì •ì œëœ ë°ì´í„° í–‰ ìˆ˜: {clean_count:,}")

    # --- 4.6. íƒ€ì„ì¡´ í™•ì¸ì„ ìœ„í•œ ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥ ---
    print("\nğŸ“… íƒ€ì„ì¡´ í™•ì¸ì„ ìœ„í•œ ìƒ˜í”Œ ë°ì´í„°:")
    df_silver.select("utc_timestamp", "year", "month", "day", "hour").show(5)

    # -----------------------------------------------------------------------------
    # 5. ë°ì´í„° ì ì¬ (Load) - Silver Layerì— ìµœì¢… ê²°ê³¼ë¥¼ ì €ì¥
    # -----------------------------------------------------------------------------
    print("Silver Layerë¡œ ë°ì´í„° ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    # KST ê¸°ì¤€ìœ¼ë¡œ ìƒì„±í•œ year, month, day, hour ì»¬ëŸ¼ì„ ì‚¬ìš©í•´ ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ ë§Œë“­ë‹ˆë‹¤.
    df_silver.write \
        .mode("overwrite") \
        .partitionBy("year", "month", "day", "hour") \
        .parquet(silver_s3_path)

    print(f"âœ…âœ…âœ… ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ {silver_s3_path} ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! âœ…âœ…âœ…")

    # --- íŒŒí‹°ì…˜ ì •ë³´ í™•ì¸ ---
    print("\nğŸ“… íŒŒí‹°ì…˜ë³„ ë°ì´í„° ë¶„í¬:")
    df_silver.groupBy("year", "month", "day").count().orderBy("year", "month", "day").show()

    # -----------------------------------------------------------------------------
    # 6. ìŠ¤íŒŒí¬ ì„¸ì…˜ ì¢…ë£Œ
    # -----------------------------------------------------------------------------
    spark.stop()
    print("âœ… SparkSessionì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


# ì´ ìŠ¤í¬ë¦½íŠ¸ê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œë§Œ main() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
if __name__ == "__main__":
    main()
