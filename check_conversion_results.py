#!/usr/bin/env python3
"""
Conversion Rate ë©”íŠ¸ë¦­ ê²°ê³¼ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸
"""

from pyspark.sql import SparkSession
import sys

def main():
    print("ğŸš€ Conversion Rate ë©”íŠ¸ë¦­ ê²°ê³¼ í™•ì¸ ì‹œì‘!")
    
    # Spark ì„¸ì…˜ ìƒì„±
    spark = SparkSession.builder \
        .appName("CheckConversionRate") \
        .config("spark.sql.catalog.iceberg_catalog", "org.apache.iceberg.spark.SparkCatalog") \
        .config("spark.sql.catalog.iceberg_catalog.type", "hive") \
        .config("spark.sql.catalog.iceberg_catalog.uri", "thrift://metastore:9083") \
        .config("spark.sql.catalog.iceberg_catalog.warehouse", "s3a://reciping-user-event-logs/iceberg/warehouse/") \
        .config("spark.sql.extensions", "org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions") \
        .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem") \
        .config("spark.hadoop.fs.s3a.path.style.access", "true") \
        .config("spark.hadoop.fs.s3a.endpoint", "http://localstack:4566") \
        .config("spark.hadoop.fs.s3a.access.key", "test") \
        .config("spark.hadoop.fs.s3a.secret.key", "test") \
        .getOrCreate()
    
    try:
        print("\nğŸ“Š 1. ë©”íŠ¸ë¦­ í…Œì´ë¸” ëª©ë¡ í™•ì¸")
        tables_df = spark.sql("SHOW TABLES IN iceberg_catalog.recipe_analytics")
        print("í…Œì´ë¸” ëª©ë¡:")
        tables_df.filter(tables_df.tableName.startswith("metrics_")).show(20, False)
        
        print("\nğŸ“ˆ 2. Conversion Rate ë©”íŠ¸ë¦­ ë°ì´í„° í™•ì¸")
        conversion_df = spark.sql("""
        SELECT 
            date,
            funnel_stage,
            total_users,
            converted_users,
            conversion_rate,
            benchmark_rate,
            improvement_target
        FROM iceberg_catalog.recipe_analytics.metrics_conversion_rate 
        ORDER BY date DESC, funnel_stage 
        LIMIT 15
        """)
        
        print("Conversion Rate ë©”íŠ¸ë¦­ ê²°ê³¼:")
        conversion_df.show(15, False)
        
        print("\nğŸ“Š 3. í†µê³„ ìš”ì•½")
        total_count = spark.sql("SELECT COUNT(*) as total FROM iceberg_catalog.recipe_analytics.metrics_conversion_rate").collect()[0][0]
        print(f"ì´ ë ˆì½”ë“œ ìˆ˜: {total_count}")
        
        funnel_stages = spark.sql("""
        SELECT funnel_stage, COUNT(*) as count, AVG(conversion_rate) as avg_rate
        FROM iceberg_catalog.recipe_analytics.metrics_conversion_rate 
        GROUP BY funnel_stage 
        ORDER BY funnel_stage
        """)
        print("\ní¼ë„ ë‹¨ê³„ë³„ í†µê³„:")
        funnel_stages.show(10, False)
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False
    
    finally:
        spark.stop()
    
    print("âœ… Conversion Rate ë©”íŠ¸ë¦­ í™•ì¸ ì™„ë£Œ!")
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
