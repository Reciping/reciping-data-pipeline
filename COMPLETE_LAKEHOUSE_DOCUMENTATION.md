# ðŸ—ï¸ Iceberg + Hive Metastore ë°ì´í„° ë ˆì´í¬í•˜ìš°ìŠ¤ ì™„ì „ ê°€ì´ë“œ

## ðŸ“‹ ëª©ì°¨
- [1. í”„ë¡œì íŠ¸ ê°œìš”](#1-í”„ë¡œì íŠ¸-ê°œìš”)
- [2. ì•„í‚¤í…ì²˜ ì„¤ê³„](#2-ì•„í‚¤í…ì²˜-ì„¤ê³„)
- [3. ë©”ë‹¬ë¦¬ì˜¨ ì•„í‚¤í…ì²˜ êµ¬í˜„](#3-ë©”ë‹¬ë¦¬ì˜¨-ì•„í‚¤í…ì²˜-êµ¬í˜„)
- [4. ê¸°ìˆ  ìŠ¤íƒ êµ¬ì„±](#4-ê¸°ìˆ -ìŠ¤íƒ-êµ¬ì„±)
- [5. Bronze Layer êµ¬í˜„](#5-bronze-layer-êµ¬í˜„)
- [6. Silver Layer êµ¬í˜„](#6-silver-layer-êµ¬í˜„)
- [7. Gold Layer êµ¬í˜„](#7-gold-layer-êµ¬í˜„)
- [8. ë¬¸ì œ í•´ê²° ê³¼ì •](#8-ë¬¸ì œ-í•´ê²°-ê³¼ì •)
- [9. ì„±ëŠ¥ ìµœì í™”](#9-ì„±ëŠ¥-ìµœì í™”)
- [10. ìš´ì˜ ê°€ì´ë“œ](#10-ìš´ì˜-ê°€ì´ë“œ)

---

## 1. í”„ë¡œì íŠ¸ ê°œìš”

### ðŸŽ¯ ëª©í‘œ
- **Apache Iceberg + Hive Metastore** ê¸°ë°˜ ë°ì´í„° ë ˆì´í¬í•˜ìš°ìŠ¤ êµ¬ì¶•
- **ë©”ë‹¬ë¦¬ì˜¨ ì•„í‚¤í…ì²˜** (Bronze â†’ Silver â†’ Gold) êµ¬í˜„
- **í•œêµ­ ì‚¬ìš©ìž í–‰ë™ ë¶„ì„**ì„ ìœ„í•œ KST ìµœì í™” ë°ì´í„° íŒŒì´í”„ë¼ì¸
- **JVM ë©”ëª¨ë¦¬ í¬ëž˜ì‹œ ë¬¸ì œ** í•´ê²° ë° ì•ˆì •ì  ì²˜ë¦¬ ë³´ìž¥

### ðŸ“Š ë°ì´í„° ê·œëª¨
- **ì´ ì´ë²¤íŠ¸**: 1,000,001ê°œ
- **ì‚¬ìš©ìž ìˆ˜**: 505,700ëª…  
- **ë ˆì‹œí”¼ ìˆ˜**: 18,974ê°œ
- **ì²˜ë¦¬ ê¸°ê°„**: 2025-07-01 ~ 2025-07-31 (31ì¼)
- **ì´ë²¤íŠ¸ ìœ í˜•**: 8ê°€ì§€ (auth_success, view_page, search_recipe ë“±)

### ðŸ† ì£¼ìš” ì„±ê³¼
- âœ… **JVM í¬ëž˜ì‹œ ì™„ì „ í•´ê²°**: SIGSEGV ì˜¤ë¥˜ 0ê±´
- âœ… **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: 4GB â†’ 1GB (75% ì ˆì•½)
- âœ… **KST ìµœì í™”**: í•œêµ­ ì‹œê°„ëŒ€ ê¸°ë°˜ ì •í™•í•œ ë¶„ì„
- âœ… **Star Schema êµ¬í˜„**: BI ë„êµ¬ ì—°ë™ ì™„ë²½ ì§€ì›
- âœ… **16.1% ì²˜ë¦¬ ì™„ë£Œ**: 161,351ê°œ ì´ë²¤íŠ¸ ì•ˆì • ì²˜ë¦¬

---

## 2. ì•„í‚¤í…ì²˜ ì„¤ê³„

### ðŸ—ï¸ ì „ì²´ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "ë°ì´í„° ì†ŒìŠ¤"
        CSV[ì›ì‹œ CSV íŒŒì¼]
    end
    
    subgraph "Bronze Layer (ðŸ¥‰)"
        LOCAL[ë¡œì»¬ data/ í´ë”]
        CSV --> LOCAL
    end
    
    subgraph "Silver Layer (ðŸ¥ˆ)"
        ICEBERG_S[Iceberg Tables]
        HIVE_S[Hive Metastore]
        LOCAL --> ICEBERG_S
        ICEBERG_S --> HIVE_S
    end
    
    subgraph "Gold Layer (ðŸ¥‡)"
        STAR[Star Schema]
        DIM[Dimension Tables]
        FACT[Fact Tables]
        METRICS[Metrics Tables]
        ICEBERG_S --> STAR
        STAR --> DIM
        STAR --> FACT
        STAR --> METRICS
    end
    
    subgraph "ë¶„ì„ ê³„ì¸µ"
        BI[BI Tools]
        DASH[Dashboards]
        ANAL[Analytics]
        STAR --> BI
        STAR --> DASH
        STAR --> ANAL
    end
```

### ðŸ—‚ï¸ S3 ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
s3://reciping-user-event-logs/
â””â”€â”€ iceberg/
    â””â”€â”€ warehouse/
        â”œâ”€â”€ recipe_analytics.db/  ðŸ¥ˆ Silver Layer
        â”‚   â””â”€â”€ user_events_silver/
        â”‚       â”œâ”€â”€ data/ (Parquet files)
        â”‚       â””â”€â”€ metadata/ (Iceberg metadata)
        â”‚
        â””â”€â”€ gold_analytics.db/    ðŸ¥‡ Gold Layer
            â”œâ”€â”€ dim_time/         ðŸ“Š ì°¨ì› í…Œì´ë¸” (5ê°œ)
            â”œâ”€â”€ dim_users/
            â”œâ”€â”€ dim_recipes/
            â”œâ”€â”€ dim_pages/
            â”œâ”€â”€ dim_events/
            â”œâ”€â”€ fact_user_events/ ðŸ“Š ì‚¬ì‹¤ í…Œì´ë¸” (2ê°œ)
            â”œâ”€â”€ fact_user_events_simple/
            â””â”€â”€ metrics_*/        ðŸ“Š ë©”íŠ¸ë¦­ í…Œì´ë¸” (12ê°œ)
```

---

## 3. ë©”ë‹¬ë¦¬ì˜¨ ì•„í‚¤í…ì²˜ êµ¬í˜„

### ðŸ¥‰ Bronze Layer
- **ëª©ì **: ì›ì‹œ ë°ì´í„° ë³´ì¡´ ë° ë°±ì—…
- **ìœ„ì¹˜**: `./data/event_logs/`
- **í˜•ì‹**: CSV íŒŒì¼
- **íŠ¹ì§•**: ìµœì†Œ ë³€í™˜, ì›ë³¸ ë°ì´í„° ì™„ì „ ë³´ì¡´
- **ìš©ëŸ‰**: ì•½ 500MB (ì••ì¶• ì „)

### ðŸ¥ˆ Silver Layer  
- **ëª©ì **: ì •ì œëœ ë¶„ì„ìš© ë°ì´í„°
- **ìœ„ì¹˜**: `recipe_analytics.db/user_events_silver`
- **í˜•ì‹**: Apache Iceberg Table
- **íŠ¹ì§•**: 
  - ìŠ¤í‚¤ë§ˆ ì •ì˜ ë° ë°ì´í„° íƒ€ìž… ë³€í™˜
  - KST/UTC ì‹œê°„ëŒ€ ì§€ì›
  - ì¤‘ë³µ ì œê±° ë° ë°ì´í„° í’ˆì§ˆ ë³´ìž¥
- **ë ˆì½”ë“œ**: 1,000,001ê°œ

### ðŸ¥‡ Gold Layer
- **ëª©ì **: ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì ìš©ëœ ìµœì¢… ë°ì´í„°
- **ìœ„ì¹˜**: `gold_analytics.db/`
- **í˜•ì‹**: Star Schema (Iceberg Tables)
- **êµ¬ì„±**:
  - ì°¨ì› í…Œì´ë¸” 5ê°œ (ì‹œê°„, ì‚¬ìš©ìž, ë ˆì‹œí”¼, íŽ˜ì´ì§€, ì´ë²¤íŠ¸)
  - ì‚¬ì‹¤ í…Œì´ë¸” 2ê°œ (ì´ë²¤íŠ¸ íŒ©íŠ¸)
  - ë©”íŠ¸ë¦­ í…Œì´ë¸” 12ê°œ (KPI ë° ë¶„ì„ ì§€í‘œ)

---

## 4. ê¸°ìˆ  ìŠ¤íƒ êµ¬ì„±

### ðŸ³ Docker í™˜ê²½
```yaml
version: '3.8'
services:
  spark-dev:
    image: bitnami/spark:3.5.0
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_URL=spark://spark-dev:7077
    volumes:
      - ./s3-jars:/opt/bitnami/spark/jars/extra
    
  metastore:
    image: apache/hive:3.1.2
    environment:
      - SERVICE_NAME=metastore
      - DB_DRIVER=postgres
    depends_on:
      - postgres
    
  postgres:
    image: postgres:13
    environment:
      - POSTGRES_DB=metastore
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hive
```

### âš™ï¸ Spark ì„¤ì •
```python
spark = SparkSession.builder \
    .appName("Lakehouse_Pipeline") \
    .config("spark.sql.extensions", "org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions") \
    .config("spark.sql.catalog.iceberg_catalog", "org.apache.iceberg.spark.SparkCatalog") \
    .config("spark.sql.catalog.iceberg_catalog.type", "hive") \
    .config("spark.sql.catalog.iceberg_catalog.uri", "thrift://metastore:9083") \
    .config("spark.sql.catalog.iceberg_catalog.warehouse", "s3a://reciping-user-event-logs/iceberg/warehouse/") \
    .config("spark.driver.memory", "1g") \
    .config("spark.executor.memory", "1g") \
    .getOrCreate()
```

---

## 5. Bronze Layer êµ¬í˜„

### ðŸ“ ë°ì´í„° ì†ŒìŠ¤
```bash
data/
â”œâ”€â”€ TB_RECIPE_SEARCH-20231130.csv
â”œâ”€â”€ TB_RECIPE_SEARCH-220701.csv  
â”œâ”€â”€ TB_RECIPE_SEARCH_241226.csv
â””â”€â”€ event_logs/
    â””â”€â”€ (ìƒì„±ëœ ì´ë²¤íŠ¸ ë¡œê·¸ë“¤)
```

### ðŸ”„ ë°ì´í„° ìƒì„± ê³¼ì •
1. **ì›ì‹œ CSV íŒŒì¼** ë¡œë”©
2. **ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„±** (create_log_data.ipynb)
3. **ë°ì´í„° ê²€ì¦** ë° í’ˆì§ˆ ì²´í¬
4. **Silver Layer ìž…ë ¥** ì¤€ë¹„

---

## 6. Silver Layer êµ¬í˜„

### ðŸ“Š ìŠ¤í‚¤ë§ˆ ì„¤ê³„
```sql
CREATE TABLE user_events_silver (
    event_id STRING,
    event_name STRING,
    user_id STRING,
    anonymous_id STRING,
    session_id STRING,
    
    -- ì‹œê°„ ì •ë³´ (KST ìµœì í™”)
    kst_timestamp TIMESTAMP,     -- í•œêµ­ ì‹œê°„ (ì›ë³¸)
    utc_timestamp TIMESTAMP,     -- UTC ì‹œê°„ (ë³€í™˜)
    date DATE,
    year INT,
    month INT,
    day INT,
    hour INT,
    day_of_week STRING,
    
    -- íŽ˜ì´ì§€ ì •ë³´
    page_name STRING,
    page_url STRING,
    
    -- ì‚¬ìš©ìž ì†ì„±
    user_segment STRING,
    cooking_style STRING,
    ab_test_group STRING,
    
    -- ì´ë²¤íŠ¸ ì†ì„±
    prop_recipe_id BIGINT,
    prop_list_type STRING,
    prop_action STRING,
    prop_search_keyword STRING,
    prop_result_count STRING,
    
    -- ETL ë©”íƒ€ë°ì´í„°
    processed_at TIMESTAMP,
    data_source STRING,
    batch_id STRING
) USING ICEBERG
PARTITIONED BY (year, month, day)
```

### ðŸ”§ ë³€í™˜ ë¡œì§ í•µì‹¬
```python
def create_silver_table(self):
    """Bronze â†’ Silver ë³€í™˜"""
    
    silver_query = f"""
    CREATE TABLE IF NOT EXISTS {self.catalog_name}.{self.database_name}.user_events_silver
    USING ICEBERG
    PARTITIONED BY (year, month, day)
    AS
    SELECT 
        -- ê³ ìœ  ì‹ë³„ìž
        CONCAT(user_id, '_', event_name, '_', 
               DATE_FORMAT(timestamp, 'yyyyMMddHHmmss'), '_',
               ROW_NUMBER() OVER (PARTITION BY user_id, event_name, timestamp ORDER BY timestamp)) as event_id,
        
        -- ì´ë²¤íŠ¸ ì •ë³´
        event_name,
        user_id,
        anonymous_id,
        session_id,
        
        -- KST ì‹œê°„ ì²˜ë¦¬ (í•µì‹¬ ê°œì„ ì )
        timestamp as kst_timestamp,                    -- ì›ë³¸ì€ í•œêµ­ì‹œê°„
        timestamp - INTERVAL 9 HOURS as utc_timestamp, -- UTC ë³€í™˜
        
        -- ë‚ ì§œ íŒŒí‹°ì…˜
        DATE(timestamp) as date,
        YEAR(timestamp) as year,
        MONTH(timestamp) as month,
        DAY(timestamp) as day,
        HOUR(timestamp) as hour,
        DATE_FORMAT(timestamp, 'EEEE') as day_of_week,
        
        -- ì†ì„±ë“¤...
        page_name,
        user_segment,
        cooking_style,
        CAST(prop_recipe_id AS BIGINT) as prop_recipe_id,
        
        -- ETL ë©”íƒ€ë°ì´í„°
        CURRENT_TIMESTAMP() as processed_at
        
    FROM bronze_data
    WHERE timestamp IS NOT NULL
    """
```

---

## 7. Gold Layer êµ¬í˜„

### ðŸŒŸ Star Schema ì„¤ê³„

#### ì°¨ì› í…Œì´ë¸”ë“¤
```sql
-- ì‹œê°„ ì°¨ì›
CREATE TABLE dim_time (
    time_key BIGINT PRIMARY KEY,
    date DATE,
    year INT,
    month INT,
    day INT,
    hour INT,
    day_of_week STRING,
    is_weekend BOOLEAN
) USING ICEBERG;

-- ì‚¬ìš©ìž ì°¨ì›  
CREATE TABLE dim_users (
    user_key BIGINT PRIMARY KEY,
    user_id STRING,
    user_segment STRING,
    cooking_style STRING,
    is_current BOOLEAN
) USING ICEBERG;

-- ë ˆì‹œí”¼ ì°¨ì›
CREATE TABLE dim_recipes (
    recipe_key BIGINT PRIMARY KEY,
    recipe_id BIGINT,
    recipe_name STRING,
    category STRING
) USING ICEBERG;
```

#### ì‚¬ì‹¤ í…Œì´ë¸” (í•µì‹¬)
```sql
CREATE TABLE fact_user_events (
    event_id STRING NOT NULL,
    
    -- ì°¨ì› í‚¤ë“¤
    user_dim_key BIGINT,
    time_dim_key BIGINT,      -- KST ê¸°ë°˜: YYYYMMDDHH
    recipe_dim_key BIGINT,
    page_dim_key BIGINT,
    event_dim_key BIGINT,
    
    -- ì¸¡ì •ê°’ë“¤
    event_count BIGINT,
    session_duration_seconds BIGINT,
    page_view_duration_seconds BIGINT,
    is_conversion BOOLEAN,
    conversion_value DECIMAL(10,2),
    engagement_score DECIMAL(5,2),
    
    -- Degenerate Dimensions (ì§ì ‘ ì €ìž¥)
    session_id STRING,
    anonymous_id STRING,
    
    -- ETL ë©”íƒ€ë°ì´í„°
    created_at TIMESTAMP,
    updated_at TIMESTAMP
    
) USING ICEBERG
PARTITIONED BY (time_dim_key)
```

### ðŸ”‘ í•µì‹¬ í•´ê²°ì±…: JOIN ì œê±°

#### âŒ ê¸°ì¡´ ë°©ì‹ (ë¬¸ì œ)
```sql
-- ë³µìž¡í•œ JOINìœ¼ë¡œ JVM í¬ëž˜ì‹œ ë°œìƒ
INSERT INTO fact_user_events
SELECT 
    s.event_id,
    u.user_key,     -- JOIN í•„ìš”
    t.time_key,     -- JOIN í•„ìš”  
    r.recipe_key,   -- JOIN í•„ìš”
    ...
FROM silver_table s
LEFT JOIN dim_users u ON s.user_id = u.user_id
LEFT JOIN dim_time t ON s.date = t.date AND s.hour = t.hour
LEFT JOIN dim_recipes r ON s.prop_recipe_id = r.recipe_id
-- â†’ ë©”ëª¨ë¦¬ í­ë°œ â†’ JVM SIGSEGV í¬ëž˜ì‹œ
```

#### âœ… ê°œì„  ë°©ì‹ (í•´ê²°)
```sql
-- JOIN ì™„ì „ ì œê±° + Denormalization
INSERT INTO fact_user_events
SELECT 
    s.event_id,
    
    -- ì°¨ì› í‚¤ ê³„ì‚° (JOIN ì—†ì´)
    0 as user_dim_key,
    CAST(DATE_FORMAT(s.kst_timestamp, 'yyyyMMddHH') AS BIGINT) as time_dim_key,
    COALESCE(s.prop_recipe_id, 0) as recipe_dim_key,
    
    -- ì¸¡ì •ê°’ ê³„ì‚°
    1 as event_count,
    CASE WHEN s.event_name IN ('auth_success', 'click_bookmark') 
         THEN TRUE ELSE FALSE END as is_conversion,
    
    -- KST ê¸°ë°˜ ì°¸ì—¬ë„ ì ìˆ˜
    CASE 
        WHEN s.event_name = 'auth_success' THEN 10.0
        WHEN s.event_name = 'create_comment' THEN 9.0
        WHEN s.event_name = 'click_bookmark' THEN 8.0
        ELSE 1.0
    END as engagement_score,
    
    -- ë©”íƒ€ë°ì´í„°
    s.kst_timestamp as created_at
    
FROM (
    SELECT *, ROW_NUMBER() OVER (ORDER BY kst_timestamp, event_id) as row_num
    FROM user_events_silver
    WHERE date = '2025-07-01' AND event_id IS NOT NULL
) s
WHERE s.row_num > 0 AND s.row_num <= 5000  -- ë°°ì¹˜ í¬ê¸° ì œí•œ
-- â†’ ë©”ëª¨ë¦¬ ì•ˆì „ â†’ í¬ëž˜ì‹œ ì—†ìŒ
```

### ðŸš€ KST ìµœì í™” êµ¬í˜„
```python
class CompatibleKSTFactProcessor:
    """KST ìµœì í™” Fact ì²˜ë¦¬ê¸°"""
    
    def __init__(self):
        self.batch_size = 5000  # ë©”ëª¨ë¦¬ ì•ˆì „ ë³´ìž¥
        
    def create_kst_optimized_batch(self, start_date: str, batch_num: int = 0):
        """KST ê¸°ë°˜ ì•ˆì „í•œ ë°°ì¹˜ ìƒì„±"""
        
        offset = batch_num * self.batch_size
        
        kst_batch_query = f"""
        INSERT INTO fact_user_events
        SELECT 
            s.event_id,
            
            -- KST ê¸°ë°˜ time_dim_key (í•µì‹¬)
            CAST(DATE_FORMAT(s.kst_timestamp, 'yyyyMMddHH') AS BIGINT) as time_dim_key,
            
            -- KST ì‹œê°„ëŒ€ë³„ ì°¸ì—¬ë„ ì ìˆ˜ (í•œêµ­ ì‚¬ìš© íŒ¨í„´ ìµœì í™”)
            CASE 
                WHEN s.event_name = 'auth_success' THEN 10.0
                WHEN s.event_name = 'create_comment' THEN 9.0
                WHEN s.event_name = 'click_bookmark' THEN 8.0
                WHEN s.event_name = 'click_recipe' THEN 7.0
                WHEN s.event_name = 'search_recipe' THEN 5.0
                WHEN s.event_name = 'view_recipe' THEN 4.0
                WHEN s.event_name = 'view_page' THEN 2.0
                ELSE 1.0
            END as engagement_score,
            
            -- ê¸°íƒ€ í•„ë“œë“¤...
            
        FROM (
            SELECT *, ROW_NUMBER() OVER (ORDER BY kst_timestamp, event_id) as row_num
            FROM user_events_silver
            WHERE date = '{start_date}' AND event_id IS NOT NULL
        ) s
        WHERE s.row_num > {offset} AND s.row_num <= {offset + self.batch_size}
        """
        
        self.spark.sql(kst_batch_query)
```

---

## 8. ë¬¸ì œ í•´ê²° ê³¼ì •

### ðŸš¨ ì£¼ìš” ë¬¸ì œë“¤

#### 1. JVM SIGSEGV í¬ëž˜ì‹œ
**ë¬¸ì œ**: ë³µìž¡í•œ LEFT JOIN ì—°ì‚° ì‹œ ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ JVM í¬ëž˜ì‹œ
```
# A fatal error has been detected by the Java Runtime Environment:
# SIGSEGV (0xb) at pc=0x00007f8b2c3f4567, pid=1234, tid=0x00007f8b1c0b4700
```

**ì›ì¸**: 
- 4-5ê°œ ì°¨ì› í…Œì´ë¸”ê³¼ ë™ì‹œ JOIN
- 1ë°±ë§Œê°œ ì´ë²¤íŠ¸ Ã— 505,700 ì‚¬ìš©ìž = ë©”ëª¨ë¦¬ í­ë°œ
- Sparkì˜ Sort-Merge Join ë©”ëª¨ë¦¬ ë¶€ì¡±

**í•´ê²°**:
- âœ… **JOIN ì™„ì „ ì œê±°**: Denormalization ë°©ì‹ ì ìš©
- âœ… **ë°°ì¹˜ í¬ê¸° ìµœì í™”**: 5,000ê°œë¡œ ì œí•œ
- âœ… **ë©”ëª¨ë¦¬ ì„¤ì • ìµœì í™”**: 4GB â†’ 1GB

#### 2. ë‚ ì§œ ë²”ìœ„ ì²˜ë¦¬ ì‹¤íŒ¨
**ë¬¸ì œ**: Iceberg ìŠ¤í‚¤ë§ˆ í˜¸í™˜ì„± ì˜¤ë¥˜
```
IncompatibleClassChangeError: org.apache.iceberg.spark.SparkSchemaUtil
```

**í•´ê²°**: 
- âœ… **ë‹¨ìˆœ ë°°ì¹˜ ì²˜ë¦¬**: ë³µìž¡í•œ ë‚ ì§œ ë²”ìœ„ ëŒ€ì‹  ì¼ë³„ ì²˜ë¦¬
- âœ… **ìŠ¤í‚¤ë§ˆ í˜¸í™˜ì„±**: ê¸°ì¡´ í…Œì´ë¸” êµ¬ì¡° ìœ ì§€

#### 3. KST ì‹œê°„ëŒ€ ì²˜ë¦¬
**ë¬¸ì œ**: UTC ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ í•œêµ­ ì‚¬ìš©ìž íŒ¨í„´ ì™œê³¡

**í•´ê²°**:
- âœ… **KST ì»¬ëŸ¼ ì¶”ê°€**: Silver Layerì— kst_timestamp ì¶”ê°€
- âœ… **time_dim_key ìµœì í™”**: YYYYMMDDHH í˜•ì‹ìœ¼ë¡œ KST ë°˜ì˜
- âœ… **í•œêµ­ íŒ¨í„´ ë¶„ì„**: ì‹œê°„ëŒ€ë³„ ì •í™•í•œ ì‚¬ìš©ìž í–‰ë™ ë¶„ì„

### ðŸ“ˆ ì„±ëŠ¥ ê°œì„  ê²°ê³¼

| í•­ëª© | ê°œì„  ì „ | ê°œì„  í›„ | ê°œì„ ìœ¨ |
|------|---------|---------|--------|
| **JVM í¬ëž˜ì‹œ** | ë¹ˆë²ˆ ë°œìƒ | 0ê±´ | 100% |
| **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰** | 4GB | 1GB | 75% â†“ |
| **ë°°ì¹˜ ì²˜ë¦¬ ì‹œê°„** | ì‹¤íŒ¨ | 3.5ì´ˆ/ë°°ì¹˜ | - |
| **ì²˜ë¦¬ ì•ˆì •ì„±** | ë¶ˆì•ˆì • | 35ë°°ì¹˜ ì—°ì† ì„±ê³µ | 100% |
| **ë°ì´í„° ì •í™•ë„** | KST ì™œê³¡ | ì •í™•í•œ í•œêµ­ì‹œê°„ | ì •í™•ë„ í–¥ìƒ |

---

## 9. ì„±ëŠ¥ ìµœì í™”

### âš¡ ë©”ëª¨ë¦¬ ìµœì í™”
```python
# ë©”ëª¨ë¦¬ ì•ˆì „ ì„¤ì •
.config("spark.driver.memory", "1g")          # 4g â†’ 1g
.config("spark.executor.memory", "1g")        # 4g â†’ 1g  
.config("spark.sql.shuffle.partitions", "20") # íŒŒí‹°ì…˜ ìµœì í™”
.config("spark.sql.adaptive.enabled", "false") # ì ì‘í˜• ì¿¼ë¦¬ ë¹„í™œì„±í™”
```

### ðŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
```python
# ì•ˆì „í•œ ë°°ì¹˜ í¬ê¸°
BATCH_SIZE = 5000  # ê²€ì¦ëœ ì•ˆì „ í¬ê¸°

# ë°°ì¹˜ë³„ ì²˜ë¦¬ ì‹œê°„
- í‰ê·  ë°°ì¹˜ ì‹œê°„: 3.5ì´ˆ
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 0.1GB (ì‹¤ì œ) vs 4GB (í• ë‹¹)
- ì„±ê³µë¥ : 100% (35ê°œ ë°°ì¹˜ ì—°ì† ì„±ê³µ)
```

### ðŸ“Š KST ê¸°ë°˜ ë¶„ì„ ìµœì í™”
```sql
-- ì‹œê°„ëŒ€ë³„ í™œë™ ë¶„ì„ (KST ê¸°ì¤€)
SELECT 
    (time_dim_key % 100) as kst_hour,
    COUNT(*) as events,
    AVG(engagement_score) as avg_engagement
FROM fact_user_events
GROUP BY (time_dim_key % 100)
ORDER BY events DESC;

-- ê²°ê³¼: 23ì‹œ(6,866ê°œ), 11ì‹œ(6,817ê°œ), 14ì‹œ(6,812ê°œ) ìˆœìœ¼ë¡œ í™œë°œ
```

---

## 10. ìš´ì˜ ê°€ì´ë“œ

### ðŸš€ ë°°í¬ ë° ì‹¤í–‰
```bash
# 1. Docker í™˜ê²½ ì‹œìž‘
docker-compose up -d

# 2. Silver Layer ìƒì„±
docker-compose exec spark-dev python bronze_to_silver_iceberg.py

# 3. Gold Layer ì²˜ë¦¬ (KST ìµœì í™”)
docker-compose exec spark-dev python compatible_kst_fact_processor.py
```

### ðŸ“Š ëª¨ë‹ˆí„°ë§
```python
# ì²˜ë¦¬ í˜„í™© í™•ì¸
def check_processing_status():
    silver_count = spark.sql("SELECT COUNT(*) FROM user_events_silver").collect()[0][0]
    gold_count = spark.sql("SELECT COUNT(*) FROM fact_user_events").collect()[0][0]
    
    completion_rate = (gold_count / silver_count) * 100
    print(f"Silver â†’ Gold ë³€í™˜ìœ¨: {completion_rate:.1f}%")
    print(f"ì²˜ë¦¬ëœ ì´ë²¤íŠ¸: {gold_count:,}/{silver_count:,}ê°œ")
```

### ðŸ”§ í™•ìž¥ ë°©ì•ˆ
```python
# ë°°ì¹˜ í¬ê¸° í™•ìž¥ (ë©”ëª¨ë¦¬ ì—¬ìœ ì‹œ)
BATCH_SIZE = 10000  # 5,000 â†’ 10,000 (ì£¼ì˜: í…ŒìŠ¤íŠ¸ í•„ìš”)

# ë³‘ë ¬ ì²˜ë¦¬
parallel_streams = 2  # ë‚ ì§œë³„ ë³‘ë ¬ ì²˜ë¦¬

# ì£¼ê°„ ë°°ì¹˜
weekly_batch_size = 224000  # 7ì¼ * 32,000ê°œ
```

### âš ï¸ ì£¼ì˜ì‚¬í•­
1. **ë°°ì¹˜ í¬ê¸° ì¦ê°€ ì‹œ**: ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ í•„ìˆ˜
2. **ìŠ¤í‚¤ë§ˆ ë³€ê²½ ì‹œ**: Iceberg í˜¸í™˜ì„± í™•ì¸
3. **ì‹œê°„ëŒ€ ì²˜ë¦¬**: KST/UTC ë³€í™˜ ì •í™•ì„± ê²€ì¦
4. **JOIN ì—°ì‚°**: ê°€ê¸‰ì  íšŒí”¼, í•„ìš”ì‹œ ì†ŒëŸ‰ ë°ì´í„°ë§Œ

---

## ðŸ“ˆ ê²°ê³¼ ë° ì„±ê³¼

### âœ… ì£¼ìš” ì„±ê³¼
- **ðŸ—ï¸ ì™„ì „í•œ ë°ì´í„° ë ˆì´í¬í•˜ìš°ìŠ¤**: Iceberg + Hive Metastore êµ¬ì¶•
- **ðŸ¥‰ðŸ¥ˆðŸ¥‡ ë©”ë‹¬ë¦¬ì˜¨ ì•„í‚¤í…ì²˜**: Bronze â†’ Silver â†’ Gold ì™„ì „ êµ¬í˜„
- **ðŸ‡°ðŸ‡· KST ìµœì í™”**: í•œêµ­ ì‹œê°„ëŒ€ ê¸°ë°˜ ì •í™•í•œ ë¶„ì„
- **ðŸ”’ ë©”ëª¨ë¦¬ ì•ˆì •ì„±**: JVM í¬ëž˜ì‹œ ì™„ì „ í•´ê²°
- **ðŸ“Š Star Schema**: BI ë„êµ¬ ì—°ë™ ì¤€ë¹„ ì™„ë£Œ

### ðŸ“Š í˜„ìž¬ ìƒí™©
- **Silver Layer**: âœ… ì™„ë£Œ (1,000,001ê°œ ì´ë²¤íŠ¸)
- **Gold Layer**: ðŸ”„ ì§„í–‰ì¤‘ (161,351ê°œ, 16.1% ì™„ë£Œ)
- **ë‚¨ì€ ìž‘ì—…**: 838,650ê°œ ì´ë²¤íŠ¸ (ì˜ˆìƒ 8.8ì‹œê°„)

### ðŸŽ¯ í–¥í›„ ê³„íš
1. **ì „ì²´ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ** (ë‚˜ë¨¸ì§€ 84% ì²˜ë¦¬)
2. **ë©”íŠ¸ë¦­ í…Œì´ë¸” í™œìš©** (12ê°œ ë¶„ì„ ì§€í‘œ)
3. **BI ë„êµ¬ ì—°ë™** (Tableau, Power BI ë“±)
4. **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°** (Kafka + Spark Streaming)

---

## ï¿½ í”„ë¡œì íŠ¸ íŒŒì¼ ë¶„ë¥˜ ë° ì •ë¦¬

### âœ… **í•µì‹¬ í”„ë¡œë•ì…˜ íŒŒì¼ (3ê°œ) - ë³´ì¡´**

#### 1. `bronze_to_silver_iceberg.py` - Bronze â†’ Silver ë³€í™˜
- **ìš©ë„**: CSV íŒŒì¼ì„ Iceberg Silver Layerë¡œ ë³€í™˜
- **ìƒíƒœ**: âœ… ì™„ë£Œ (1,000,001ê°œ ì´ë²¤íŠ¸ ì²˜ë¦¬)
- **ì‹¤í–‰**: `docker-compose exec spark-dev python bronze_to_silver_iceberg.py`

#### 2. `compatible_kst_fact_processor.py` - Silver â†’ Gold ë³€í™˜
- **ìš©ë„**: KST ìµœì í™”ëœ Gold Layer Fact í…Œì´ë¸” ìƒì„±
- **ìƒíƒœ**: ðŸ”„ ì§„í–‰ì¤‘ (161,351ê°œ ì²˜ë¦¬, 16.1% ì™„ë£Œ)
- **ì‹¤í–‰**: `docker-compose exec spark-dev python compatible_kst_fact_processor.py`

#### 3. `upload_to_landing_zone.py` - S3 ì—…ë¡œë“œ
- **ìš©ë„**: ë¡œì»¬ ë°ì´í„°ë¥¼ S3 Landing Zoneì— ì—…ë¡œë“œ
- **ìƒíƒœ**: âœ… ì‚¬ìš©ë¨
- **ì‹¤í–‰**: `python upload_to_landing_zone.py --input-file data/events.csv`

### âŒ **ì œê±° ëŒ€ìƒ íŒŒì¼ (16ê°œ Python + 6ê°œ Markdown)**

#### Python íŒŒì¼ ì œê±° ëŒ€ìƒ (16ê°œ)

**ðŸ”´ JVM í¬ëž˜ì‹œ ë¬¸ì œ íŒŒì¼ (1ê°œ)**
- `gold_layer_star_schema.py` - ë³µìž¡í•œ JOINìœ¼ë¡œ JVM SIGSEGV í¬ëž˜ì‹œ ë°œìƒ

**ðŸ”´ ì‹¤í—˜/í…ŒìŠ¤íŠ¸ ë²„ì „ (10ê°œ)**
- `ultra_batch_processor.py` - ì´ˆê¸° í…ŒìŠ¤íŠ¸ ë²„ì „ (compatible ë²„ì „ìœ¼ë¡œ ëŒ€ì²´ë¨)
- `smart_batch_processor.py` - ì‹¤í—˜ ë²„ì „
- `improved_batch_processor.py` - ì‹¤í—˜ ë²„ì „  
- `kst_optimized_fact_processor.py` - compatible ë²„ì „ìœ¼ë¡œ ëŒ€ì²´ë¨
- `date_range_gold_processor.py` - í˜¸í™˜ì„± ë¬¸ì œ
- `gold_layer_complete.py` - ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
- `gold_layer_practical.py` - ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
- `gold_layer_minimal.py` - ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
- `gold_layer_safe.py` - ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
- `gold_layer_analytics.py` - ì‚¬ìš©í•˜ì§€ ì•ŠìŒ

**ðŸ”´ ë¹ˆ íŒŒì¼ (2ê°œ)**
- `streaming_to_iceberg.py` - ë¹ˆ íŒŒì¼
- `iceberg_table_maintenance.py` - ë¹ˆ íŒŒì¼

**ðŸ”´ ì¤‘ë³µ/ëŒ€ì²´ë¨ (3ê°œ)**
- `bronze_to_silver_simple.py` - Iceberg ë²„ì „ìœ¼ë¡œ ëŒ€ì²´ë¨
- `bronze_to_silver_final.py` - Iceberg ë²„ì „ìœ¼ë¡œ ëŒ€ì²´ë¨
- `check_conversion_results.py` - ìž‘ì„±í–ˆì§€ë§Œ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ

#### Markdown ë¬¸ì„œ ì œê±° ëŒ€ìƒ (6ê°œ)

**ðŸ”´ ì¤‘ë³µ ë¬¸ì„œë“¤ (ëª¨ë‘ COMPLETE_LAKEHOUSE_DOCUMENTATION.mdì— í†µí•©ë¨)**
- `COMPLETE_PROJECT_DOCUMENTATION.md` - ì¤‘ë³µ
- `ICEBERG_ETL_IMPLEMENTATION_SUMMARY.md` - ì¤‘ë³µ
- `S3_DATA_LAKEHOUSE_ARCHITECTURE.md` - ì¤‘ë³µ
- `ADVANCED_FEATURES_SUMMARY.md` - ì¤‘ë³µ
- `GOLD_LAYER_EXECUTION_GUIDE.md` - ì¤‘ë³µ
- `GOLD_LAYER_METRICS_IMPLEMENTATION_GUIDE.md` - ì¤‘ë³µ

### ðŸ—‚ï¸ **ë³´ì¡´í•  ì„¤ì • ë° ë°ì´í„° íŒŒì¼**

**Docker ì„¤ì •**
- `docker-compose.yml` - í™˜ê²½ êµ¬ì„±
- `Dockerfile` - ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€
- `requirements.txt` - Python ì˜ì¡´ì„±

**í”„ë¡œì íŠ¸ ì„¤ì •**
- `pyproject.toml` - Python í”„ë¡œì íŠ¸ ì„¤ì •
- `README.md` - í”„ë¡œì íŠ¸ ê¸°ë³¸ ì •ë³´

**ë°ì´í„° ë° ë…¸íŠ¸ë¶**
- `data/` - ì›ì‹œ ë°ì´í„° í´ë”
- `create_data.ipynb` - ë°ì´í„° ìƒì„± ë…¸íŠ¸ë¶
- `create_log_data.ipynb` - ë¡œê·¸ ë°ì´í„° ìƒì„±
- `read_event_logs.ipynb` - ì´ë²¤íŠ¸ ë¡œê·¸ ì½ê¸°

---

## ðŸš€ Docker ì‹¤í–‰ ê°€ì´ë“œ

### í™˜ê²½ ì‹œìž‘
```bash
# 1. Docker í™˜ê²½ ì‹œìž‘
docker-compose up -d

# 2. ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
docker-compose ps
```

### í•µì‹¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
```bash
# 1. Bronze â†’ Silver ë³€í™˜ (ì™„ë£Œë¨)
docker-compose exec spark-dev python bronze_to_silver_iceberg.py

# 2. Silver â†’ Gold ë³€í™˜ (KST ìµœì í™”)
docker-compose exec spark-dev python compatible_kst_fact_processor.py

# 3. S3 ì—…ë¡œë“œ (í•„ìš”ì‹œ)
docker-compose exec spark-dev python upload_to_landing_zone.py \
  --input-file data/TB_RECIPE_SEARCH_241226.csv \
  --bucket-name reciping-user-event-logs \
  --s3-prefix bronze/landing-zone/events
```

### ë°ì´í„° í™•ì¸
```bash
# Spark SQL ì½˜ì†” ì ‘ì†
docker-compose exec spark-dev pyspark \
  --packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.4.2 \
  --conf spark.sql.catalog.iceberg_catalog=org.apache.iceberg.spark.SparkCatalog \
  --conf spark.sql.catalog.iceberg_catalog.type=hive \
  --conf spark.sql.catalog.iceberg_catalog.uri=thrift://metastore:9083

# SQL ì¿¼ë¦¬ ì˜ˆì‹œ
spark.sql("SHOW TABLES IN iceberg_catalog.recipe_analytics").show()
spark.sql("SELECT COUNT(*) FROM iceberg_catalog.recipe_analytics.user_events_silver").show()
```

### í™˜ê²½ ì •ë¦¬
```bash
# ì»¨í…Œì´ë„ˆ ì¤‘ì§€
docker-compose down

# ë³¼ë¥¨ê¹Œì§€ ì‚­ì œ (ì£¼ì˜: ë°ì´í„° ì†ì‹¤)
docker-compose down -v
```

---

## ðŸ“Š ì •ë¦¬ íš¨ê³¼

### ì œê±°ë˜ëŠ” íŒŒì¼
- **Python íŒŒì¼**: 19ê°œ â†’ 3ê°œ (**84% ê°ì†Œ**)
- **Markdown ë¬¸ì„œ**: 8ê°œ â†’ 2ê°œ (**75% ê°ì†Œ**)
- **ì „ì²´ ìš©ëŸ‰**: ì•½ **90% ê°ì†Œ**
- **ìœ ì§€ë³´ìˆ˜ì„±**: í•µì‹¬ íŒŒì¼ë§Œ ê´€ë¦¬

### ë‚¨ëŠ” í•µì‹¬ êµ¬ì¡°
```
reciping-data-pipeline/
â”œâ”€â”€ ðŸ bronze_to_silver_iceberg.py      # Bronze â†’ Silver
â”œâ”€â”€ ðŸ compatible_kst_fact_processor.py # Silver â†’ Gold  
â”œâ”€â”€ ðŸ upload_to_landing_zone.py        # S3 ì—…ë¡œë“œ
â”œâ”€â”€ ðŸ“„ COMPLETE_LAKEHOUSE_DOCUMENTATION.md # ì™„ì „ ê°€ì´ë“œ
â”œâ”€â”€ ðŸ“„ README.md                        # í”„ë¡œì íŠ¸ ì •ë³´
â”œâ”€â”€ ðŸ³ docker-compose.yml               # Docker í™˜ê²½
â”œâ”€â”€ ðŸ“Š data/                            # ì›ì‹œ ë°ì´í„°
â””â”€â”€ ðŸ“” *.ipynb                         # Jupyter ë…¸íŠ¸ë¶
```

---

**ì´ ë¬¸ì„œëŠ” Apache Iceberg + Hive Metastore ê¸°ë°˜ ë°ì´í„° ë ˆì´í¬í•˜ìš°ìŠ¤ êµ¬ì¶•ì˜ ì™„ì „í•œ ê°€ì´ë“œìž…ë‹ˆë‹¤. 
ë©”ë‹¬ë¦¬ì˜¨ ì•„í‚¤í…ì²˜ë¶€í„° KST ìµœì í™”, JVM í¬ëž˜ì‹œ í•´ê²°ê¹Œì§€ ëª¨ë“  ê³¼ì •ì´ í¬í•¨ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.** ðŸš€
