# ===================================================================
# 1ï¸âƒ£ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ Import
# ===================================================================

import os
import uuid
import json
import random
import gc

import argparse
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Any, Optional

# ë°ì´í„° ì²˜ë¦¬
import numpy as np
import pandas as pd

# Dask (ë¶„ì‚° ì²˜ë¦¬)
import dask
import dask.dataframe as dd
from dask import delayed

from confluent_kafka import Producer
import socket

# ì„¤ì •
pd.set_option('display.max_columns', None)

print("âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")



# ===================================================================
# 2ï¸âƒ£ ë°ì´í„° ë¡œë”© ë° ê¸°ë³¸ ì„¤ì •
# ===================================================================

# S3 ê²½ë¡œ ì •ì˜
s3_base_path = 's3://reciping-user-event-logs/meta-data'

# S3ì—ì„œ Parquet íŒŒì¼ ì½ê¸°
print("â˜ï¸ S3ì—ì„œ ë©”íƒ€ë°ì´í„° ë¡œë”© ì‹œì‘...")
recipes_df = pd.read_parquet(f'{s3_base_path}/total_recipes.parquet')
users_df = pd.read_parquet(f'{s3_base_path}/user.parquet')
profiles_df = pd.read_parquet(f'{s3_base_path}/user_profiles.parquet')

print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ:")
print(f"   - ë ˆì‹œí”¼: {len(recipes_df):,}ê°œ")
print(f"   - ì‚¬ìš©ì: {len(users_df):,}ëª…")
print(f"   - í”„ë¡œí•„: {len(profiles_df):,}ê°œ")

# Demographic Segment ë¶„í¬ ì •ì˜
DEMOGRAPHIC_DISTRIBUTION = {
    'FEMALE_20S': 0.142,    # 14.2%
    'FEMALE_30S': 0.207,    # 20.7%
    'FEMALE_40_PLUS': 0.356, # 35.6%
    'MALE_20S': 0.062,      # 6.2%
    'MALE_30S': 0.085,      # 8.5%
    'MALE_40_PLUS': 0.148   # 14.8%
}

# í–‰ë™ íƒœê·¸ ì •ì˜
INTENSITY_PERSONAS = {
    'POWER_USER': {'ratio': 0.15, 'description': 'íŒŒì›Œ_ìœ ì €, ì£¼ 5íšŒ ì´ìƒ í™œë™'},
    'ACTIVE_USER': {'ratio': 0.55, 'description': 'í™œì„±_ìœ ì €, ì£¼ 2-4íšŒ í™œë™'},
    'CASUAL_USER': {'ratio': 0.30, 'description': 'ìºì£¼ì–¼_ìœ ì €, ì£¼ 1íšŒ ì´í•˜ í™œë™'}
}

COOKING_STYLE_PERSONAS = {
    'DESSERT_FOCUSED': {'ratio': 0.20, 'description': 'ë””ì €íŠ¸_ì¤‘ì‹¬, ë² ì´í‚¹ ë””ì €íŠ¸ ì œì‘ ì„ í˜¸'},
    'HEALTHY_CONSCIOUS': {'ratio': 0.25, 'description': 'ê±´ê°•ì‹_ì§€í–¥, ë‹¤ì´ì–´íŠ¸ ì›°ë¹™ ìš”ë¦¬ ì„ í˜¸'},
    'COMFORT_FOOD': {'ratio': 0.25, 'description': 'ë“ ë“ í•œ_ì‹ì‚¬, ë©”ì¸ ìš”ë¦¬ í•œ ë¼ ì‹ì‚¬ ì„ í˜¸'},
    'QUICK_CONVENIENT': {'ratio': 0.20, 'description': 'ê°„í¸_ìš”ë¦¬, ì‹œê°„ì ˆì•½ ê°„ë‹¨ ìš”ë¦¬ ì„ í˜¸'},
    'DIVERSE_EXPLORER': {'ratio': 0.10, 'description': 'ë‹¤ì–‘í•œ_íƒí—˜, íŠ¹ë³„í•œ íŒ¨í„´ ì—†ì´ ë‹¤ì–‘í•˜ê²Œ íƒìƒ‰'}
}


# ===================================================================
# 3ï¸âƒ£ ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ ì„¤ì • (ì›” 1ì–µ ê±´ ëŒ€ìš©ëŸ‰)
# ===================================================================

from datetime import timezone, timedelta

# í•œêµ­ì‹œê°„(KST) ì„¤ì • 
KST = timezone(timedelta(hours=9))

# ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„: 2025ë…„ 6ì›” (ì„±ìˆ˜ê¸° 1ê°œì›”)
SIMULATION_START_DATE = datetime(2025, 6, 1, tzinfo=KST)
# SIMULATION_END_DATE = datetime(2025, 7, 31, 23, 59, 59, tzinfo=KST)
# SIMULATION_START_DATE = datetime(2025, 8, 1, tzinfo=KST)
SIMULATION_END_DATE = datetime(2025, 8, 31, 23, 59, 59, tzinfo=KST)

# ëŒ€ìš©ëŸ‰ ëª©í‘œ ì§€í‘œ (ì„±ìˆ™í•œ ì„œë¹„ìŠ¤)
TARGET_MONTHLY_EVENTS = 100_000_000  # ì›” 1ì–µ ê±´
# TARGET_DAU_AVERAGE = 160_000         # í‰ê·  ì¼ê°„ í™œì„± ì‚¬ìš©ì
TARGET_DAU_AVERAGE = 1000         # í‰ê·  ì¼ê°„ í™œì„± ì‚¬ìš©ì
# TARGET_MAU = 700_000                 # ì›”ê°„ í™œì„± ì‚¬ìš©ì
TARGET_MAU = 2000                 # ì›”ê°„ í™œì„± ì‚¬ìš©ì
TARGET_EVENTS_PER_USER_DAY = 20      # 1ì¸ë‹¹ ì¼í‰ê·  ì´ë²¤íŠ¸

# ì£¼ê°„ íŒ¨í„´ (ì„±ìˆ™í•œ ì„œë¹„ìŠ¤ì˜ ì£¼ê¸°ì  íŒ¨í„´)
WEEKDAY_MULTIPLIER = {
    0: 0.85,  # ì›”ìš”ì¼ (ë‚®ìŒ)
    1: 0.90,  # í™”ìš”ì¼
    2: 0.95,  # ìˆ˜ìš”ì¼ 
    3: 0.95,  # ëª©ìš”ì¼
    4: 1.20,  # ê¸ˆìš”ì¼ (ì£¼ë§ ì¤€ë¹„ë¡œ ì¦ê°€)
    5: 1.30,  # í† ìš”ì¼ (ì£¼ë§ í”¼í¬)
    6: 1.25   # ì¼ìš”ì¼ (ì£¼ë§ í”¼í¬)
}

# ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ì¬ì •ì˜ (3ê°œ ê·¸ë£¹)
USER_SEGMENTS = {
    'POWER_USER': {
        'ratio': 0.10,  # 10%
        'daily_events': (40, 50),
        'description': 'íŒŒì›Œìœ ì €: ë ˆì‹œí”¼ ì‘ì„±, ëŒ“ê¸€ ë“± ë†’ì€ ê¸°ì—¬ë„'
    },
    'ACTIVE_EXPLORER': {
        'ratio': 0.60,  # 60% 
        'daily_events': (15, 20),
        'description': 'ì ê·¹ì  íƒìƒ‰ ìœ ì €: ê²€ìƒ‰, í•„í„° ë“± ë‹¤ì–‘í•œ ê¸°ëŠ¥ í™œìš©'
    },
    'PASSIVE_BROWSER': {
        'ratio': 0.30,  # 30%
        'daily_events': (5, 10), 
        'description': 'ì†Œê·¹ì  íƒìƒ‰ ìœ ì €: ì¶”ì²œ ëª©ë¡ ìœ„ì£¼ ê°€ë²¼ìš´ ì†Œë¹„'
    }
}

# KPI ëª©í‘œ ìˆ˜ì¤€
TARGET_KPI = {
    'ad_ctr': 0.015,              # ê´‘ê³  í´ë¦­ë¥  1.5%
    'recipe_detail_conversion': 0.10,  # ìƒì„¸ í˜ì´ì§€ ì „í™˜ìœ¨ 10%
    'retention_day1': 0.30,      # Day 1 ìœ ì§€ìœ¨ 30%
    'retention_day7': 0.15,      # Day 7 ìœ ì§€ìœ¨ 15%
    'retention_day30': 0.08      # Day 30 ìœ ì§€ìœ¨ 8%
}

# AB í…ŒìŠ¤íŠ¸ ì„¤ì • (í•œêµ­ì‹œê°„ ì ìš©)
# AB_TEST_START_DATE = datetime(2025, 7, 8, tzinfo=KST)
# AB_TEST_END_DATE = datetime(2025, 7, 22, tzinfo=KST)
AB_TEST_START_DATE = datetime(2025, 8, 8, tzinfo=KST)
AB_TEST_END_DATE = datetime(2025, 8, 22, tzinfo=KST)

AB_TEST_SCENARIO_CODE = 'BEHAVIORAL_TARGETING_MVP_V1'
AB_TEST_CONTROL_CTR = 0.018      # Control: ê¸°ì¡´ ëœë¤ ê´‘ê³  ì„œë¹™ 1.8%
AB_TEST_TREATMENT_CTR = 0.022    # Treatment: í–‰ë™ íƒœê·¸ ê¸°ë°˜ íƒ€ê²ŸíŒ… 2.2%

# ì„¸ê·¸ë¨¼íŠ¸ë³„ AB í…ŒìŠ¤íŠ¸ ëª©í‘œ CTR
AB_TEST_SEGMENT_TARGETS = {
    ('FEMALE_30S', 'POWER_USER', 'DESSERT_FOCUSED'): {'current': 0.021, 'target': 0.028},
    ('MALE_20S', 'ACTIVE_EXPLORER', 'QUICK_CONVENIENT'): {'current': 0.015, 'target': 0.019},
    ('FEMALE_40_PLUS', 'ACTIVE_EXPLORER', 'HEALTHY_CONSCIOUS'): {'current': 0.018, 'target': 0.023},
    ('MALE_30S', 'PASSIVE_BROWSER', 'DIVERSE_EXPLORER'): {'current': 0.014, 'target': 0.017}
}

print("âœ… ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ ì„¤ì • ì™„ë£Œ")
print(f"ğŸ“… ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„: {SIMULATION_START_DATE.strftime('%Y-%m-%d %H:%M %Z')} ~ {SIMULATION_END_DATE.strftime('%Y-%m-%d %H:%M %Z')}")
print(f"ğŸ¯ ëª©í‘œ ì›”ê°„ ì´ë²¤íŠ¸: {TARGET_MONTHLY_EVENTS:,}ê±´")
print(f"ğŸ‘¥ í‰ê·  DAU: {TARGET_DAU_AVERAGE:,}ëª…, MAU: {TARGET_MAU:,}ëª…")
print(f"ğŸ“Š 1ì¸ë‹¹ ì¼í‰ê·  ì´ë²¤íŠ¸: {TARGET_EVENTS_PER_USER_DAY}ê°œ")
print(f"â° ì‹œê°„ëŒ€: í•œêµ­ì‹œê°„(KST, UTC+9)")
print(f"ï¿½ íŒ¨í„´: ì£¼ê¸°ì  (ì£¼ë§ í”¼í¬: {max(WEEKDAY_MULTIPLIER.values()):.1f}x)")


# ===================================================================
# 3ï¸âƒ£-1 ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ì˜ ì£¼ê¸°ì  DAU ê³„ì‚° í•¨ìˆ˜
# ===================================================================

def calculate_cyclical_dau(target_date):
    """
    ì„±ìˆ™í•œ ì„œë¹„ìŠ¤ì˜ ì£¼ê¸°ì  DAU ê³„ì‚° (S-ì»¤ë¸Œ ëŒ€ì‹  ì£¼ê°„/ì¼ì¼ íŒ¨í„´)
    
    Args:
        target_date: ê³„ì‚°í•  ë‚ ì§œ (datetime ê°ì²´)
    
    Returns:
        int: í•´ë‹¹ ë‚ ì§œì˜ DAU
    """
    
    # ê¸°ë³¸ DAU (í‰ê· ê°’)
    base_dau = TARGET_DAU_AVERAGE
    
    # ìš”ì¼ë³„ ê°€ì¤‘ì¹˜ ì ìš©
    weekday = target_date.weekday()  # 0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼
    weekday_multiplier = WEEKDAY_MULTIPLIER.get(weekday, 1.0)
    
    # ì›”ë³„ ê³„ì ˆì„± (7ì›”ì€ ì„±ìˆ˜ê¸°ë¡œ ê°€ì •)
    month_multiplier = 1.1  # 7ì›” ì„±ìˆ˜ê¸° 10% ì¦ê°€
    
    # ìµœì¢… DAU ê³„ì‚°
    final_dau = int(base_dau * weekday_multiplier * month_multiplier)
    
    return final_dau

def calculate_daily_events_target(dau):
    """ì¼ë³„ ëª©í‘œ ì´ë²¤íŠ¸ ìˆ˜ ê³„ì‚°"""
    return dau * TARGET_EVENTS_PER_USER_DAY

def get_korean_timestamp(dt):
    """datetime ê°ì²´ë¥¼ í•œêµ­ì‹œê°„ ISO8601 ë¬¸ìì—´ë¡œ ë³€í™˜"""
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=KST)
    elif dt.tzinfo != KST:
        dt = dt.astimezone(KST)
    
    return dt.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + '+09:00'

# í…ŒìŠ¤íŠ¸: 7ì›” ì²« ì£¼ DAU íŒ¨í„´ í™•ì¸
# print("\nğŸ“Š 7ì›” ì²« ì£¼ DAU íŒ¨í„´ ë¯¸ë¦¬ë³´ê¸°:")
# test_start = datetime(2025, 7, 1)
print("\nğŸ“Š 8ì›” ì²« ì£¼ DAU íŒ¨í„´ ë¯¸ë¦¬ë³´ê¸°:")
test_start = datetime(2025, 8, 1)
for i in range(7):
    test_date = test_start + timedelta(days=i)
    dau = calculate_cyclical_dau(test_date)
    events = calculate_daily_events_target(dau)
    weekday_name = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼'][test_date.weekday()]
    
    print(f"   {test_date.strftime('%m/%d')} ({weekday_name}): DAU {dau:,}ëª… â†’ ëª©í‘œ ì´ë²¤íŠ¸ {events:,}ê±´")

print(f"\nâœ… ì£¼ê¸°ì  DAU ê³„ì‚° í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ")
print(f"ğŸ“ˆ ì£¼ë§ í”¼í¬: í† ìš”ì¼ {int(TARGET_DAU_AVERAGE * WEEKDAY_MULTIPLIER[5] * 1.1):,}ëª…")
print(f"ğŸ“‰ ì£¼ì¤‘ ìµœì €: ì›”ìš”ì¼ {int(TARGET_DAU_AVERAGE * WEEKDAY_MULTIPLIER[0] * 1.1):,}ëª…")


# ===================================================================
# 3ï¸âƒ£-2 ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ AB í…ŒìŠ¤íŠ¸ ê´€ë ¨ í•¨ìˆ˜ (ì„¸ê·¸ë¨¼íŠ¸ë³„ ëª©í‘œ CTR ì ìš©)
# ===================================================================

import hashlib

def is_ab_test_period(target_date):
    """AB í…ŒìŠ¤íŠ¸ ê¸°ê°„ì¸ì§€ í™•ì¸ (í•œêµ­ì‹œê°„ ê¸°ì¤€)"""
    return AB_TEST_START_DATE.date() <= target_date <= AB_TEST_END_DATE.date()

def assign_ab_test_group(user_id):
    """ì‚¬ìš©ìë¥¼ AB í…ŒìŠ¤íŠ¸ ê·¸ë£¹ì— í• ë‹¹ (ì¼ê´€ì„± ìˆê²Œ)"""
    user_hash = int(hashlib.md5(str(user_id).encode()).hexdigest(), 16)
    return 'treatment' if user_hash % 2 == 0 else 'control'

def get_segment_combination_key(user_data):
    """ì‚¬ìš©ì ë°ì´í„°ì—ì„œ ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•© í‚¤ ìƒì„±"""
    demographic = user_data.get('demographic_segment', '')
    activity = user_data.get('activity_segment', '')
    cooking_style = user_data.get('cooking_style_persona', '')
    
    return (demographic, activity, cooking_style)

def get_target_ctr_for_segment(segment_key, ab_group):
    """ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•©ë³„ ëª©í‘œ CTR ë°˜í™˜"""
    
    # ì •ì˜ëœ ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•©ì¸ ê²½ìš° ëª©í‘œ CTR ì‚¬ìš©
    if segment_key in AB_TEST_SEGMENT_TARGETS:
        targets = AB_TEST_SEGMENT_TARGETS[segment_key]
        if ab_group == 'treatment':
            return targets['target']
        else:
            return targets['current']
    
    # ê¸°ë³¸ CTR ì‚¬ìš©
    if ab_group == 'treatment':
        return AB_TEST_TREATMENT_CTR
    else:
        return AB_TEST_CONTROL_CTR

def apply_ab_test_logic_v2(event_name, properties, user_data, session_time):
    """ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ AB í…ŒìŠ¤íŠ¸ ë¡œì§ ì ìš©"""
    
    # AB í…ŒìŠ¤íŠ¸ ê¸°ê°„ì´ ì•„ë‹ˆë©´ ì›ë˜ ì†ì„± ë°˜í™˜
    if not is_ab_test_period(session_time.date()):
        return properties
    
    # ê´‘ê³  ê´€ë ¨ ì´ë²¤íŠ¸ì—ë§Œ AB í…ŒìŠ¤íŠ¸ ì ìš©
    if event_name not in ['view_ads', 'click_ads']:
        return properties
    
    # ì‚¬ìš©ì ê·¸ë£¹ ê²°ì •
    ab_group = assign_ab_test_group(user_data['id'])
    segment_key = get_segment_combination_key(user_data)
    
    # AB í…ŒìŠ¤íŠ¸ ì†ì„± ì¶”ê°€
    properties['ab_test_scenario'] = AB_TEST_SCENARIO_CODE
    properties['ab_test_group'] = ab_group
    properties['user_segment_combination'] = f"{segment_key[0]}_{segment_key[1]}_{segment_key[2]}"
    
    # ê´‘ê³  íƒ€ê²ŸíŒ… ë°©ì‹ ì ìš©
    if event_name == 'view_ads':
        if ab_group == 'treatment':
            # Treatment ê·¸ë£¹: í–‰ë™ íƒœê·¸ ê¸°ë°˜ íƒ€ê²ŸíŒ…
            properties['ad_targeting_method'] = 'behavioral_targeting'
            
            # ì‚¬ìš©ìì˜ ìš”ë¦¬ ìŠ¤íƒ€ì¼ì— ë§ëŠ” íƒœê·¸ ìƒì„±
            cooking_style = user_data.get('cooking_style_persona', '')
            if cooking_style == 'DESSERT_FOCUSED':
                properties['targeting_tags'] = ['dessert_lover', 'baking_tools', 'sweet_ingredients']
            elif cooking_style == 'HEALTHY_CONSCIOUS':
                properties['targeting_tags'] = ['healthy_food', 'diet_conscious', 'organic_ingredients']
            elif cooking_style == 'QUICK_CONVENIENT':
                properties['targeting_tags'] = ['quick_meal', 'time_saving', 'easy_cooking']
            elif cooking_style == 'COMFORT_FOOD':
                properties['targeting_tags'] = ['hearty_meals', 'family_cooking', 'comfort_food']
            else:  # DIVERSE_EXPLORER
                properties['targeting_tags'] = ['premium_ingredients', 'exotic_recipes', 'cooking_challenge']
            
            properties['personalization_score'] = round(random.uniform(0.7, 0.95), 2)
        else:
            # Control ê·¸ë£¹: ëœë¤ ê´‘ê³  ì„œë¹™
            properties['ad_targeting_method'] = 'random_serving'
            properties['targeting_tags'] = []
            properties['personalization_score'] = round(random.uniform(0.1, 0.3), 2)
    
    elif event_name == 'click_ads':
        # ì„¸ê·¸ë¨¼íŠ¸ë³„ ëª©í‘œ CTR ì ìš©
        target_ctr = get_target_ctr_for_segment(segment_key, ab_group)
        
        if random.random() < target_ctr:
            properties['click_predicted'] = True
            properties['targeting_success'] = (ab_group == 'treatment')
            
            if ab_group == 'treatment':
                properties['relevance_score'] = round(random.uniform(0.8, 0.95), 2)
                properties['targeting_method_used'] = 'behavioral_targeting'
            else:
                properties['relevance_score'] = round(random.uniform(0.3, 0.6), 2)
                properties['targeting_method_used'] = 'random_serving'
        else:
            properties['click_predicted'] = False
            properties['targeting_success'] = False
    
    return properties

print("âœ… ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ AB í…ŒìŠ¤íŠ¸ ê´€ë ¨ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ")
print(f"ğŸ§ª AB í…ŒìŠ¤íŠ¸ ì •ë³´:")
print(f"   - í…ŒìŠ¤íŠ¸ ê¸°ê°„: {AB_TEST_START_DATE.strftime('%Y-%m-%d')} ~ {AB_TEST_END_DATE.strftime('%Y-%m-%d')} (í•œêµ­ì‹œê°„)")
print(f"   - ì‹œë‚˜ë¦¬ì˜¤: {AB_TEST_SCENARIO_CODE}")
print(f"   - ëŒ€ìƒ ì´ë²¤íŠ¸: view_ads, click_ads")
print(f"   - ì„¸ê·¸ë¨¼íŠ¸ë³„ ì°¨ë“± ëª©í‘œ CTR ì ìš©")

print(f"\nğŸ“Š ì„¸ê·¸ë¨¼íŠ¸ë³„ ëª©í‘œ CTR:")
for segment_combo, targets in AB_TEST_SEGMENT_TARGETS.items():
    demographic, activity, cooking = segment_combo
    current_ctr = targets['current']
    target_ctr = targets['target']
    improvement = ((target_ctr - current_ctr) / current_ctr) * 100
    
    print(f"   - {demographic} Ã— {activity} Ã— {cooking}:")
    print(f"     Control: {current_ctr:.1%} â†’ Treatment: {target_ctr:.1%} (+{improvement:.0f}%)")



# ===================================================================
# 4ï¸âƒ£ ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ (3ê°œ ê·¸ë£¹)
# ===================================================================

def assign_mature_service_user_segments(users_df, profiles_df):
    """ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ì˜ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹"""
    
    print("ğŸ­ ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ ì‹œì‘...")
    
    # ì‚¬ìš©ìì™€ í”„ë¡œí•„ ë³‘í•©
    merged_df = pd.merge(users_df, profiles_df, left_on='id', right_on='user_id', how='inner')
    
    # ê¸°ì¡´ Demographic Segment ìœ ì§€ (ì„±ë³„Ã—ì—°ë ¹ëŒ€)
    segment_list = list(DEMOGRAPHIC_DISTRIBUTION.keys())
    segment_weights = list(DEMOGRAPHIC_DISTRIBUTION.values())
    
    merged_df['demographic_segment'] = np.random.choice(
        segment_list, 
        size=len(merged_df), 
        p=segment_weights
    )
    
    # ìƒˆë¡œìš´ í™œë™ ìˆ˜ì¤€ ì„¸ê·¸ë¨¼íŠ¸ (3ê°œ ê·¸ë£¹)
    activity_segments = list(USER_SEGMENTS.keys())
    activity_weights = [segment['ratio'] for segment in USER_SEGMENTS.values()]
    
    merged_df['activity_segment'] = np.random.choice(
        activity_segments,
        size=len(merged_df),
        p=activity_weights
    )
    
    # ìš”ë¦¬ ìŠ¤íƒ€ì¼ ì„ í˜¸ë„ ìœ ì§€ (ê¸°ì¡´ 5ê°œ ê·¸ë£¹)
    cooking_list = list(COOKING_STYLE_PERSONAS.keys())
    cooking_weights = [persona['ratio'] for persona in COOKING_STYLE_PERSONAS.values()]
    
    merged_df['cooking_style_persona'] = np.random.choice(
        cooking_list,
        size=len(merged_df),
        p=cooking_weights
    )
    
    print(f"âœ… ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ ì™„ë£Œ: {len(merged_df):,}ëª…")
    
    # ë¶„í¬ í™•ì¸
    print(f"\nğŸ“Š Demographic Segment ë¶„í¬:")
    demographic_dist = merged_df['demographic_segment'].value_counts(normalize=True)
    for segment, ratio in demographic_dist.items():
        print(f"   - {segment}: {ratio:.1%}")
    
    print(f"\nâš¡ í™œë™ ìˆ˜ì¤€ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í¬:")
    activity_dist = merged_df['activity_segment'].value_counts(normalize=True)
    for segment, ratio in activity_dist.items():
        desc = USER_SEGMENTS[segment]['description']
        daily_events = USER_SEGMENTS[segment]['daily_events']
        print(f"   - {segment}: {ratio:.1%} (ì¼í‰ê·  {daily_events[0]}-{daily_events[1]}ê°œ)")
        print(f"     â”” {desc}")
    
    print(f"\nğŸ³ ìš”ë¦¬ ìŠ¤íƒ€ì¼ ë¶„í¬:")
    cooking_dist = merged_df['cooking_style_persona'].value_counts(normalize=True)
    for cooking, ratio in cooking_dist.items():
        print(f"   - {cooking}: {ratio:.1%}")
    
    return merged_df

print("âœ… ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ")
print("ğŸ”„ ë³€ê²½ì‚¬í•­:")
print("   - ì´ìš© ê°•ë„ â†’ í™œë™ ìˆ˜ì¤€ (3ê°œ ê·¸ë£¹)")
print("   - POWER_USER(10%), ACTIVE_EXPLORER(60%), PASSIVE_BROWSER(30%)")
print("   - ê° ê·¸ë£¹ë³„ ì¼í‰ê·  ì´ë²¤íŠ¸ ìˆ˜ ì°¨ë“± ì ìš©")



# ===================================================================
# ğŸ—‚ï¸ EVENT_SCHEMA ì •ì˜ (ë‹¤ìŒ ì´ë²¤íŠ¸ ë¡œì§)
# ===================================================================

EVENT_SCHEMA = {
    'view_page': {
        'next_events': ['search_recipe', 'view_recipe_list', 'view_ads', 'click_auth_button']
    },
    'click_auth_button': {
        'next_events': ['auth_success', 'view_page']
    },
    'auth_success': {
        'next_events': ['view_page', 'view_recipe_list']
    },
    'search_recipe': {
        'next_events': ['view_recipe_list', 'click_recipe', 'view_page']
    },
    'view_recipe_list': {
        'next_events': ['click_recipe', 'search_recipe', 'view_page']
    },
    'click_recipe': {
        'next_events': ['click_bookmark', 'click_like', 'create_comment', 'view_page']
    },
    'click_bookmark': {
        'next_events': ['view_page', 'view_recipe_list', 'click_like']
    },
    'click_like': {
        'next_events': ['view_page', 'view_recipe_list', 'create_comment']
    },
    'create_comment': {
        'next_events': ['view_page', 'view_recipe_list']
    },
    'create_recipe_success': {
        'next_events': ['view_page', 'view_recipe_list']
    },
    'view_ads': {
        'next_events': ['click_ads', 'view_page', 'view_recipe_list']
    },
    'click_ads': {
        'next_events': ['view_page']
    }
}

print("âœ… EVENT_SCHEMA ì •ì˜ ì™„ë£Œ")
print(f"ğŸ“Š ì •ì˜ëœ ì´ë²¤íŠ¸ ìˆ˜: {len(EVENT_SCHEMA)}")



# ğŸ” ë°ì´í„°í”„ë ˆì„ í¬ê¸° ì§„ë‹¨
print("ğŸ“Š ë°ì´í„°í”„ë ˆì„ í¬ê¸° í™•ì¸:")
print(f"recipes_df í¬ê¸°: {len(recipes_df):,} í–‰")
print(f"recipes_df ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {recipes_df.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB")
print(f"users_df í¬ê¸°: {len(users_df):,} í–‰")
print(f"profiles_df í¬ê¸°: {len(profiles_df):,} í–‰")

print("\nğŸ” recipes_df ì»¬ëŸ¼ í™•ì¸:")
print(f"ì»¬ëŸ¼ë“¤: {list(recipes_df.columns)}")
print(f"id ì»¬ëŸ¼ ë°ì´í„° íƒ€ì…: {recipes_df['id'].dtype}")
print(f"id ì»¬ëŸ¼ ìƒ˜í”Œ: {recipes_df['id'].head(3).tolist()}")

# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸: ëœë¤ ì„ íƒ ì†ë„ ì¸¡ì •
import time

print("\nâš¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸:")
start_time = time.time()
for i in range(100):
    if len(recipes_df) > 1000:
        random_idx = random.randint(0, len(recipes_df) - 1)
        test_id = recipes_df.iloc[random_idx]['id']
    else:
        test_id = recipes_df.sample(1)['id'].iloc[0]
end_time = time.time()
print(f"100ë²ˆ ëœë¤ ì„ íƒ ì‹œê°„: {(end_time - start_time)*1000:.1f} ms")



# ===================================================================
#  Kafka ì „ì†¡ ê´€ë ¨ í•¨ìˆ˜ë“¤ (ìƒˆë¡œ ì¶”ê°€)
# ===================================================================

def delivery_report(err, msg):
    """ ë©”ì‹œì§€ ì „ì†¡ ì™„ë£Œ í›„ í˜¸ì¶œë˜ëŠ” ì½œë°±. ì „ì†¡ ì„±ê³µ/ì‹¤íŒ¨ë¥¼ ë¡œê·¸ë¡œ ë‚¨ê¹ë‹ˆë‹¤. """
    if err is not None:
        print(f"âŒ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {err}")

def send_df_to_kafka(df: pd.DataFrame, topic: str, bootstrap_servers: str):
    """ Pandas DataFrameì„ JSON ë©”ì‹œì§€ë¡œ ë³€í™˜í•˜ì—¬ Kafka í† í”½ìœ¼ë¡œ ì „ì†¡í•©ë‹ˆë‹¤. (confluent-kafka ì‚¬ìš©) """
    conf = {'bootstrap.servers': bootstrap_servers, 'client.id': socket.gethostname()}
    producer = Producer(conf)
    
    print(f"ğŸš€ Confluent Kafka Producerê°€ ë¸Œë¡œì»¤({bootstrap_servers})ì— ì—°ê²°ì„ ì‹œë„í•©ë‹ˆë‹¤.")
    print(f"   - í† í”½ '{topic}'ìœ¼ë¡œ {len(df):,}ê°œì˜ ì´ë²¤íŠ¸ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤...")

    records = df.to_dict('records')
    for record in records:
        try:
            producer.produce(
                topic,
                value=json.dumps(record, ensure_ascii=False).encode('utf-8'),
                callback=delivery_report
            )
        except BufferError:
            producer.flush()
            producer.produce(
                topic,
                value=json.dumps(record, ensure_ascii=False).encode('utf-8'),
                callback=delivery_report
            )
    
    remaining = producer.flush()
    if remaining > 0:
         print(f"âš ï¸ {remaining}ê°œì˜ ë©”ì‹œì§€ê°€ ì•„ì§ ì „ì†¡ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤.")
    
    print(f"âœ… {len(df):,}ê°œì˜ ì´ë²¤íŠ¸ ì „ì†¡ ìš”ì²­ ì™„ë£Œ!")



# ===================================================================
# 5ï¸âƒ£ ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ ì´ë²¤íŠ¸ ìƒì„± í•µì‹¬ í•¨ìˆ˜ë“¤ (í•œêµ­ì‹œê°„ ì ìš©)
# ===================================================================

def generate_event_properties_v2(event_name, context, recipes_df, user_data=None, session_time=None):
    """ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ìš© ì´ë²¤íŠ¸ ì†ì„± ìƒì„± (ì •í™•í•œ ìŠ¤í‚¤ë§ˆ ë°˜ì˜)"""
    
    properties = {}
    
    if event_name == 'view_page':
        pages = ['start', 'main', 'recipe_detail', 'profile', 'search_result']
        properties['page_name'] = context.get('page_name', random.choice(pages))
        
        if random.random() < 0.3:
            properties['referrer'] = random.choice(['https://google.com', 'https://naver.com', ''])
        
        if properties['page_name'] == 'recipe_detail' and context.get('recipe_id'):
            properties['path'] = f"/recipes/{context['recipe_id']}"
    
    elif event_name == 'click_auth_button':
        properties['type'] = random.choice(['signup', 'login'])
    
    elif event_name == 'auth_success':
        properties['method'] = random.choice(['email', 'kakao', 'google', 'naver'])
        properties['type'] = random.choice(['signup', 'login'])
    
    elif event_name == 'search_recipe':
        properties['search_type'] = random.choice(['category', 'ingredient', 'menu'])
        
        if random.random() < 0.7:
            keywords = ['ì¹˜í‚¨', 'íŒŒìŠ¤íƒ€', 'ìƒëŸ¬ë“œ', 'ìŠ¤í…Œì´í¬', 'ì¼€ì´í¬', 'ë³¶ìŒë°¥', 'êµ­ë¬¼ìš”ë¦¬']
            properties['search_keyword'] = random.choice(keywords)
        
        if random.random() < 0.4:
            # ì‹¤ì œ recipes_df ë°ì´í„° ê¸°ë°˜ í•„í„°ë§
            filters_config = {
                'dish_type': ['ë°‘ë°˜ì°¬', 'ë©”ì¸ë°˜ì°¬','êµ­/íƒ•', 'ì°Œê°œ', 'ë””ì €íŠ¸', 'ë©´/ë§Œë‘', 'ë°¥/ì£½/ë–¡', 'í“¨ì „', 'ê¹€ì¹˜/ì “ê°ˆ/ì¥ë¥˜', 'ì–‘ë…/ì†ŒìŠ¤/ì¼', 'ì–‘ì‹', 'ìƒëŸ¬ë“œ', 'ìŠ¤í”„', 'ë¹µ', 'ê³¼ì', 'ì°¨/ìŒë£Œ/ìˆ ', 'ê¸°íƒ€'], 
                'situation_type': ['ì¼ìƒ', 'ì´ˆìŠ¤í”¼ë“œ', 'ì†ë‹˜ì ‘ëŒ€', 'ìˆ ì•ˆì£¼', 'ë‹¤ì´ì–´íŠ¸', 'ë„ì‹œë½', 'ì˜ì–‘ì‹', 'ê°„ì‹', 'ì•¼ì‹', 'í‘¸ë“œìŠ¤íƒ€ì¼ë§', 'í•´ì¥', 'ëª…ì ˆ', 'ì´ìœ ì‹', 'ê¸°íƒ€'],
                'ingredient_type': ['ì†Œê³ ê¸°', 'ë¼ì§€ê³ ê¸°', 'ë‹­ê³ ê¸°', 'ìœ¡ë¥˜', 'ì±„ì†Œë¥˜', 'í•´ë¬¼ë¥˜', 'ë‹¬ê±€/ìœ ì œí’ˆ', 'ê°€ê³µì‹í’ˆë¥˜', 'ìŒ€', 'ë°€ê°€ë£¨', 'ê±´ì–´ë¬¼ë¥˜', 'ë²„ì„¯ë¥˜', 'ê³¼ì¼ë¥˜', 'ì½©/ê²¬ê³¼ë¥˜', 'ê³¡ë¥˜', 'ê¸°íƒ€'],
                'method_type': ['ë³¶ìŒ', 'ë“ì´ê¸°', 'ë¶€ì¹¨', 'ì¡°ë¦¼', 'ë¬´ì¹¨', 'ë¹„ë¹”', 'ì°œ', 'ì ˆì„', 'íŠ€ê¹€', 'ì‚¶ê¸°', 'êµ½ê¸°', 'ë°ì¹˜ê¸°', 'íšŒ', 'ê¸°íƒ€']
            }
            
            # ì‹¤ì œ recipes_dfì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í•„í„°ë“¤ë§Œ ì„ íƒ
            available_filters = []
            for filter_type, filter_values in filters_config.items():
                if not recipes_df.empty and filter_type in recipes_df.columns:
                    # í•´ë‹¹ ì»¬ëŸ¼ì— ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ê°’ë“¤ ì¤‘ì—ì„œ ì„ íƒ
                    actual_values = recipes_df[filter_type].dropna().unique()
                    matching_values = [v for v in filter_values if v in actual_values]
                    if matching_values:
                        selected_value = random.choice(matching_values)
                        available_filters.append(f"{filter_type}:{selected_value}")
            
            # í•„í„°ê°€ ìˆìœ¼ë©´ 1-2ê°œ ì„ íƒ, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
            if available_filters:
                properties['selected_filters'] = random.sample(available_filters, min(random.randint(1, 4), len(available_filters)))
            else:
                # í´ë°±: recipes_dfê°€ ë¹„ì–´ìˆê±°ë‚˜ ì»¬ëŸ¼ì´ ì—†ì„ ë•Œ
                fallback_filters = ['í•œì‹', 'ì–‘ì‹', 'ì¤‘ì‹', 'ë¼ì§€ê³ ê¸°', 'ë‹­ê³ ê¸°', 'ì†Œê³ ê¸°', 'ê°„ë‹¨ìš”ë¦¬', 'ë³µì¡ìš”ë¦¬']
                properties['selected_filters'] = random.sample(fallback_filters, random.randint(1, 2))
        
        # result_countë„ ì‹¤ì œ í•„í„°ë§ ê²°ê³¼ì— ê¸°ë°˜í•˜ë„ë¡ ê°œì„ 
        if 'selected_filters' in properties and not recipes_df.empty:
            # í•„í„° ì¡°ê±´ì— ë§ëŠ” ë ˆì‹œí”¼ ìˆ˜ ê³„ì‚° (ì‹œë®¬ë ˆì´ì…˜)
            estimated_results = random.randint(1, min(50, len(recipes_df) // 10))
            properties['result_count'] = max(1, estimated_results)  # ìµœì†Œ 1ê°œëŠ” ë³´ì¥
        else:
            properties['result_count'] = random.randint(5, 50)
    
    elif event_name == 'view_recipe_list':
        list_types = ['popular', 'recommended', 'search_result', 'trending']
        properties['list_type'] = random.choice(list_types)
        
        displayed_count = random.randint(5, 20)
        
        # contextì—ì„œ ì´ì „ ê²€ìƒ‰ í•„í„° ì •ë³´ í™œìš©
        context_filters = context.get('search_filters', [])
        
        if not recipes_df.empty and 'id' in recipes_df.columns and len(recipes_df) > 0:
            # ê²€ìƒ‰ í•„í„°ê°€ ìˆë‹¤ë©´ í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ë ˆì‹œí”¼ë“¤ ìš°ì„  ì„ íƒ
            if context_filters and properties['list_type'] == 'search_result':
                filtered_recipes = recipes_df.copy()
                
                # ê° í•„í„° ì¡°ê±´ ì ìš©
                for filter_item in context_filters:
                    if ':' in filter_item:
                        filter_type, filter_value = filter_item.split(':', 1)
                        if filter_type in filtered_recipes.columns:
                            filtered_recipes = filtered_recipes[
                                filtered_recipes[filter_type].astype(str).str.contains(filter_value, na=False)
                            ]
                
                # í•„í„°ë§ëœ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ê·¸ ì¤‘ì—ì„œ ì„ íƒ
                if len(filtered_recipes) > 0:
                    if len(filtered_recipes) > displayed_count:
                        if len(filtered_recipes) > 1000:
                            sample_indices = random.sample(range(len(filtered_recipes)), displayed_count)
                            recipe_ids = filtered_recipes.iloc[sample_indices]['id'].tolist()
                        else:
                            recipe_sample = filtered_recipes.sample(n=displayed_count)
                            recipe_ids = recipe_sample['id'].tolist()
                    else:
                        recipe_ids = filtered_recipes['id'].tolist()
                    properties['displayed_recipe_ids'] = [str(x) for x in recipe_ids]
                else:
                    # í•„í„°ë§ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì „ì²´ì—ì„œ ëœë¤ ì„ íƒ
                    if len(recipes_df) > 1000:
                        sample_indices = random.sample(range(len(recipes_df)), min(displayed_count, len(recipes_df)))
                        recipe_ids = recipes_df.iloc[sample_indices]['id'].tolist()
                    else:
                        recipe_sample = recipes_df.sample(n=min(displayed_count, len(recipes_df)))
                        recipe_ids = recipe_sample['id'].tolist()
                    properties['displayed_recipe_ids'] = [str(x) for x in recipe_ids]
            else:
                # ì¼ë°˜ì ì¸ ëª©ë¡ (ì¸ê¸°, ì¶”ì²œ ë“±) - ì „ì²´ì—ì„œ ëœë¤ ì„ íƒ
                if len(recipes_df) > 1000:
                    sample_indices = random.sample(range(len(recipes_df)), min(displayed_count, len(recipes_df)))
                    recipe_ids = recipes_df.iloc[sample_indices]['id'].tolist()
                else:
                    recipe_sample = recipes_df.sample(n=min(displayed_count, len(recipes_df)))
                    recipe_ids = recipe_sample['id'].tolist()
                properties['displayed_recipe_ids'] = [str(x) for x in recipe_ids]
        else:
            # ë¹ˆ ë°ì´í„°í”„ë ˆì„ì¼ ë•Œ ê°€ìƒ ID ìƒì„±
            properties['displayed_recipe_ids'] = [f"recipe_{random.randint(1, 1000)}" for _ in range(displayed_count)]
    
    elif event_name == 'click_recipe':  # ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ì´ë²¤íŠ¸ëª… ë³€ê²½
        # ì´ì „ view_recipe_listì—ì„œ í‘œì‹œëœ ë ˆì‹œí”¼ë“¤ ì¤‘ì—ì„œ ì„ íƒ (ë” í˜„ì‹¤ì )
        displayed_recipes = context.get('displayed_recipe_ids', [])
        
        if displayed_recipes:
            # í‘œì‹œëœ ë ˆì‹œí”¼ ì¤‘ í•˜ë‚˜ë¥¼ í´ë¦­
            properties['recipe_id'] = random.choice(displayed_recipes)
            # í´ë¦­ëœ ë ˆì‹œí”¼ì˜ ëª©ë¡ ë‚´ ìˆœìœ„
            properties['rank'] = displayed_recipes.index(properties['recipe_id']) + 1
        elif context and context.get('recipe_id'):
            # contextì— recipe_idê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            properties['recipe_id'] = str(context['recipe_id']) if pd.notna(context['recipe_id']) else None
            properties['rank'] = random.randint(1, 20)
        elif not recipes_df.empty and 'id' in recipes_df.columns and len(recipes_df) > 0:
            # ì„±ëŠ¥ ìµœì í™”: í° ë°ì´í„°í”„ë ˆì„ì—ì„œëŠ” ì¸ë±ìŠ¤ ê¸°ë°˜ ì„ íƒ ì‚¬ìš©
            if len(recipes_df) > 1000:
                random_idx = random.randint(0, len(recipes_df) - 1)
                recipe_id = recipes_df.iloc[random_idx]['id']
            else:
                recipe_id = recipes_df.sample(1)['id'].iloc[0]
            properties['recipe_id'] = str(recipe_id) if pd.notna(recipe_id) else None
            properties['rank'] = random.randint(1, 20)
        else:
            properties['recipe_id'] = f"recipe_{random.randint(1, 1000)}"
            properties['rank'] = random.randint(1, 20)
    
    elif event_name == 'click_bookmark':
        if context and context.get('recipe_id'):
            properties['recipe_id'] = str(context['recipe_id'])
        elif not recipes_df.empty and 'id' in recipes_df.columns and len(recipes_df) > 0:
            # ì„±ëŠ¥ ìµœì í™”: í° ë°ì´í„°í”„ë ˆì„ì—ì„œëŠ” ì¸ë±ìŠ¤ ê¸°ë°˜ ì„ íƒ ì‚¬ìš©
            if len(recipes_df) > 1000:
                random_idx = random.randint(0, len(recipes_df) - 1)
                recipe_id = recipes_df.iloc[random_idx]['id']
            else:
                recipe_id = recipes_df.sample(1)['id'].iloc[0]
            properties['recipe_id'] = str(recipe_id)
        else:
            properties['recipe_id'] = f"recipe_{random.randint(1, 1000)}"
        
        properties['action'] = random.choice(['add', 'remove'])
    
    elif event_name == 'click_like':
        if context and context.get('recipe_id'):
            properties['recipe_id'] = str(context['recipe_id'])
        elif not recipes_df.empty and 'id' in recipes_df.columns and len(recipes_df) > 0:
            # ì„±ëŠ¥ ìµœì í™”: í° ë°ì´í„°í”„ë ˆì„ì—ì„œëŠ” ì¸ë±ìŠ¤ ê¸°ë°˜ ì„ íƒ ì‚¬ìš©
            if len(recipes_df) > 1000:
                random_idx = random.randint(0, len(recipes_df) - 1)
                recipe_id = recipes_df.iloc[random_idx]['id']
            else:
                recipe_id = recipes_df.sample(1)['id'].iloc[0]
            properties['recipe_id'] = str(recipe_id)
        else:
            properties['recipe_id'] = f"recipe_{random.randint(1, 1000)}"
        
        properties['action'] = random.choice(['like', 'unlike'])
    
    elif event_name == 'create_comment':
        if context and context.get('recipe_id'):
            properties['recipe_id'] = str(context['recipe_id'])
        elif not recipes_df.empty and 'id' in recipes_df.columns and len(recipes_df) > 0:
            # ì„±ëŠ¥ ìµœì í™”: í° ë°ì´í„°í”„ë ˆì„ì—ì„œëŠ” ì¸ë±ìŠ¤ ê¸°ë°˜ ì„ íƒ ì‚¬ìš©
            if len(recipes_df) > 1000:
                random_idx = random.randint(0, len(recipes_df) - 1)
                recipe_id = recipes_df.iloc[random_idx]['id']
            else:
                recipe_id = recipes_df.sample(1)['id'].iloc[0]
            properties['recipe_id'] = str(recipe_id)
        else:
            properties['recipe_id'] = f"recipe_{random.randint(1, 1000)}"
        
        properties['comment_length'] = random.randint(10, 200)
    
    elif event_name == 'create_recipe_success':
        # ìƒˆë¡œ ìƒì„±ëœ ë ˆì‹œí”¼ ID (ì‹¤ì œë¡œëŠ” ê¸°ì¡´ ë ˆì‹œí”¼ ì°¸ì¡°)
        if not recipes_df.empty and 'id' in recipes_df.columns and len(recipes_df) > 0:
            if len(recipes_df) > 1000:
                random_idx = random.randint(0, len(recipes_df) - 1)
                recipe_id = recipes_df.iloc[random_idx]['id']
            else:
                recipe_id = recipes_df.sample(1)['id'].iloc[0]
            properties['recipe_id'] = str(recipe_id)
        else:
            properties['recipe_id'] = f"recipe_{random.randint(1000, 9999)}"
        
        # ì‹¤ì œ recipes_dfì˜ dish_type ì»¬ëŸ¼ í™œìš©
        if random.random() < 0.7:
            if not recipes_df.empty and 'dish_type' in recipes_df.columns:
                # ì‹¤ì œ ë°ì´í„°ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì¹´í…Œê³ ë¦¬ë“¤ ì¤‘ ì„ íƒ
                actual_categories = recipes_df['dish_type'].dropna().unique()
                if len(actual_categories) > 0:
                    properties['category'] = random.choice(actual_categories)
                else:
                    # í´ë°± ì¹´í…Œê³ ë¦¬
                    properties['category'] = random.choice(['í•œì‹', 'ì–‘ì‹', 'ì¤‘ì‹', 'ì¼ì‹', 'ë¶„ì‹', 'ë””ì €íŠ¸', 'ìŒë£Œ'])
            else:
                # í´ë°± ì¹´í…Œê³ ë¦¬
                properties['category'] = random.choice(['í•œì‹', 'ì–‘ì‹', 'ì¤‘ì‹', 'ì¼ì‹', 'ë¶„ì‹', 'ë””ì €íŠ¸', 'ìŒë£Œ'])
        
        # ì¬ë£Œ ê°œìˆ˜ëŠ” ì‹¤ì œ ingredient_list ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ì°¸ì¡°
        if not recipes_df.empty and 'ingredient_list' in recipes_df.columns:
            # ì‹¤ì œ ë ˆì‹œí”¼ì˜ ì¬ë£Œ ê°œìˆ˜ ë¶„í¬ ì°¸ì¡°
            sample_recipe = recipes_df.sample(1).iloc[0] if len(recipes_df) > 0 else None
            if sample_recipe is not None and pd.notna(sample_recipe.get('ingredient_list')):
                try:
                    # ingredient_listê°€ JSON í˜•íƒœë¼ë©´ íŒŒì‹±í•´ì„œ ê°œìˆ˜ ê³„ì‚°
                    import json
                    ingredients = json.loads(sample_recipe['ingredient_list'])
                    if isinstance(ingredients, list):
                        properties['ingredient_count'] = max(1, len(ingredients))
                    else:
                        properties['ingredient_count'] = random.randint(3, 15)
                except:
                    properties['ingredient_count'] = random.randint(3, 15)
            else:
                properties['ingredient_count'] = random.randint(3, 15)
        else:
            properties['ingredient_count'] = random.randint(3, 15)
    
    elif event_name == 'view_ads':
        properties['ad_id'] = f"ad_{random.randint(1000, 9999)}"
        properties['ad_type'] = random.choice(['banner', 'video', 'native', 'sponsored_recipe'])
        properties['position'] = random.choice(['top', 'middle', 'bottom', 'sidebar', 'recipe_detail'])
    
    elif event_name == 'click_ads':
        properties['ad_id'] = context.get('ad_id', f"ad_{random.randint(1000, 9999)}")
        properties['ad_type'] = random.choice(['banner', 'video', 'native', 'sponsored_recipe'])
        properties['position'] = random.choice(['top', 'middle', 'bottom', 'sidebar', 'recipe_detail'])
        properties['target_url'] = f"https://naver.com/promotion/{random.randint(1, 100)}"
    
    # AB í…ŒìŠ¤íŠ¸ ë¡œì§ ì ìš© (user_dataì™€ session_timeì´ ìˆì„ ë•Œ)
    if user_data is not None and session_time is not None:
        properties = apply_ab_test_logic_v2(event_name, properties, user_data, session_time)
    
    return properties

def generate_mature_service_session_flow(user_data, session_time, recipes_df):
    """ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ì˜ ì‚¬ìš©ì ì„¸ì…˜ í”Œë¡œìš° ìƒì„±"""
    
    session_id = str(uuid.uuid4())
    events = []
    current_time = session_time
    context = {}
    
    # ìƒˆë¡œìš´ í™œë™ ìˆ˜ì¤€ ì„¸ê·¸ë¨¼íŠ¸ë³„ ì„¸ì…˜ ê¸¸ì´ ê²°ì •
    activity_segment = user_data['activity_segment']
    daily_events_range = USER_SEGMENTS[activity_segment]['daily_events']
    
    # ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ (ì¼í‰ê· ì˜ 1/2 ~ 1/3 ì •ë„)
    session_lengths = {
        'POWER_USER': random.randint(15, 25),      # 40-50 ì¼í‰ê·  â†’ 15-25 ì„¸ì…˜ë‹¹
        'ACTIVE_EXPLORER': random.randint(7, 12),  # 15-20 ì¼í‰ê·  â†’ 7-12 ì„¸ì…˜ë‹¹
        'PASSIVE_BROWSER': random.randint(3, 6)    # 5-10 ì¼í‰ê·  â†’ 3-6 ì„¸ì…˜ë‹¹
    }
    
    max_events = session_lengths.get(activity_segment, 5)
    
    # ì„¸ì…˜ ì‹œì‘ ì´ë²¤íŠ¸
    start_events = ['view_page', 'click_auth_button']
    current_event = random.choice(start_events)
    
    for _ in range(max_events):
        # ì´ë²¤íŠ¸ ì†ì„± ìƒì„± (ìƒˆë¡œìš´ í•¨ìˆ˜ ì‚¬ìš©)
        properties = generate_event_properties_v2(
            current_event, 
            context, 
            recipes_df, 
            user_data=user_data,
            session_time=current_time
        )
        
        # í˜„ì¬ í˜ì´ì§€ ì •ë³´ ì„¤ì •
        page_name = properties.get('page_name', 'main')
        page_url = f"https://reciping.co.kr/{page_name}"
        page_path = f"/{page_name}"
        
        # context ê°ì²´ êµ¬ì„± (í•œêµ­ì‹œê°„ ì ìš©)
        context_obj = {
            "page": {
                "name": page_name,
                "url": page_url,
                "path": page_path
            },
            "user_segment": str(user_data['demographic_segment']),
            "activity_level": str(user_data['activity_segment']),
            "cooking_style": str(user_data['cooking_style_persona'])
        }
        
        # AB í…ŒìŠ¤íŠ¸ ê¸°ê°„ì´ë©´ contextì— AB í…ŒìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
        if is_ab_test_period(current_time.date()):
            ab_group = assign_ab_test_group(user_data['id'])
            context_obj['ab_test'] = {
                "scenario": AB_TEST_SCENARIO_CODE,
                "group": ab_group,
                "start_date": AB_TEST_START_DATE.strftime('%Y-%m-%d'),
                "end_date": AB_TEST_END_DATE.strftime('%Y-%m-%d')
            }
        
        # anonymous_id ìƒì„±
        anonymous_id = str(user_data.get('anonymous_id', ''))
        if not anonymous_id or anonymous_id == '':
            anonymous_id = str(uuid.uuid4())
        
        # ì´ë²¤íŠ¸ ê¸°ë¡ (í•œêµ­ì‹œê°„ ì ìš©)
        event = {
            'event_name': current_event,
            'event_id': str(uuid.uuid4()),
            'user_id': str(user_data['id']) if pd.notna(user_data['id']) else None,
            'anonymous_id': anonymous_id,
            'session_id': session_id,
            'context': json.dumps(context_obj, ensure_ascii=False),
            'event_properties': json.dumps(properties, default=str, ensure_ascii=False),
            'timestamp': get_korean_timestamp(current_time)
        }
        
        events.append(event)
        
        # ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ (ë‹¤ìŒ ì´ë²¤íŠ¸ì—ì„œ í™œìš©)
        if 'recipe_id' in properties and properties['recipe_id'] is not None:
            context['recipe_id'] = str(properties['recipe_id'])
        if 'ad_id' in properties:
            context['ad_id'] = str(properties['ad_id'])
        
        # ê²€ìƒ‰ í•„í„° ì •ë³´ ì €ì¥ (view_recipe_listì—ì„œ í™œìš©)
        if current_event == 'search_recipe' and 'selected_filters' in properties:
            context['search_filters'] = properties['selected_filters']
        
        # í‘œì‹œëœ ë ˆì‹œí”¼ ëª©ë¡ ì €ì¥ (click_recipeì—ì„œ í™œìš©)
        if current_event == 'view_recipe_list' and 'displayed_recipe_ids' in properties:
            context['displayed_recipe_ids'] = properties['displayed_recipe_ids']
        
        # ë‹¤ìŒ ì´ë²¤íŠ¸ ê²°ì • (ìŠ¤í‚¤ë§ˆ ê¸°ë°˜)
        schema = EVENT_SCHEMA.get(current_event, {})
        next_events = schema.get('next_events', ['view_page'])
        
        # ë ˆì‹œí”¼ í´ë¦­ í›„ ì´ë²¤íŠ¸ íë¦„ ê°œì„ 
        if current_event == 'view_recipe_list' and random.random() < 0.3:
            current_event = 'click_recipe'
        elif current_event == 'click_recipe' and random.random() < 0.4:
            current_event = random.choice(['click_bookmark', 'click_like', 'create_comment'])
        elif next_events and random.random() < 0.8:
            current_event = random.choice(next_events)
        else:
            current_event = random.choice(['view_page', 'search_recipe', 'view_recipe_list'])
        
        # ì‹œê°„ ì¦ê°€ (5ì´ˆ ~ 2ë¶„)
        current_time += timedelta(seconds=random.randint(5, 120))
    
    return events

print("âœ… ì„±ìˆ™ ë‹¨ê³„ ì„œë¹„ìŠ¤ ì´ë²¤íŠ¸ ìƒì„± í•¨ìˆ˜ë“¤ ì¤€ë¹„ ì™„ë£Œ")
print("ğŸ“ ì£¼ìš” ë³€ê²½ì‚¬í•­:")
print("   - ìƒˆë¡œìš´ í™œë™ ìˆ˜ì¤€ ì„¸ê·¸ë¨¼íŠ¸ ì ìš©")
print("   - í•œêµ­ì‹œê°„(KST) íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±")
print("   - KPI ëª©í‘œ ìˆ˜ì¤€ ë°˜ì˜ (ìƒì„¸ í˜ì´ì§€ ì „í™˜ìœ¨ 10%)")
print("   - view_recipe_detail ì´ë²¤íŠ¸ ì¶”ê°€")



# ===================================================================
# ğŸ§ª ìƒ˜í”Œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± í…ŒìŠ¤íŠ¸
# ===================================================================

def generate_sample_events_test(num_users=5, events_per_user=10):
    """ê°œì„ ëœ ë¡œì§ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì†ŒëŸ‰ ìƒ˜í”Œ ì´ë²¤íŠ¸ ìƒì„±"""
    
    print("ğŸ§ª ìƒ˜í”Œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸ìš© ì‚¬ìš©ì ìƒ˜í”Œ
    test_users = users_df.sample(n=min(num_users, len(users_df)))
    
    # ì„ì‹œë¡œ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ (í…ŒìŠ¤íŠ¸ìš©)
    test_profiles = []
    for _, user_row in test_users.iterrows():
        profile = {
            'id': user_row['id'],
            'activity_segment': random.choice(['POWER_USER', 'ACTIVE_EXPLORER', 'PASSIVE_BROWSER']),
            'demographic_segment': random.choice(['20ëŒ€ ë‚¨ì„±', '30ëŒ€ ì—¬ì„±', '40ëŒ€ ë‚¨ì„±']),
            'cooking_style_persona': random.choice(['ê°„í¸ìš”ë¦¬ì¡±', 'ì •í†µìš”ë¦¬ì¡±', 'ì‹¤í—˜ìš”ë¦¬ì¡±'])
        }
        test_profiles.append(profile)
    
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì„¤ì •:")
    print(f"   ì‚¬ìš©ì ìˆ˜: {len(test_users)}")
    print(f"   ì‚¬ìš©ìë‹¹ ì´ë²¤íŠ¸ ìˆ˜: {events_per_user}")
    print(f"   recipes_df í¬ê¸°: {len(recipes_df):,}ê°œ")
    print(f"   recipes_df ì»¬ëŸ¼: {list(recipes_df.columns)}")
    
    # recipes_df ì»¬ëŸ¼ë³„ ê³ ìœ ê°’ í™•ì¸
    print(f"\nğŸ” í•„í„° ê´€ë ¨ ì»¬ëŸ¼ ë°ì´í„° í™•ì¸:")
    filter_columns = ['dish_type', 'situation_type', 'ingredient_type', 'method_type']
    for col in filter_columns:
        if col in recipes_df.columns:
            unique_vals = recipes_df[col].dropna().unique()
            print(f"   {col}: {len(unique_vals)}ê°œ ê³ ìœ ê°’ - {list(unique_vals[:5])}{'...' if len(unique_vals) > 5 else ''}")
        else:
            print(f"   {col}: ì»¬ëŸ¼ ì—†ìŒ")
    
    all_events = []
    
    print(f"\nğŸ“ ì´ë²¤íŠ¸ ìƒì„± ì¤‘...")
    
    for idx, (user_row, user_profile) in enumerate(zip(test_users.itertuples(), test_profiles)):
        
        # í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨í•œ ì„¸ì…˜ ì‹œê°„
        session_time = datetime.now(KST).replace(
            hour=random.randint(9, 21),
            minute=random.randint(0, 59),
            second=random.randint(0, 59)
        )
        
        print(f"   ì‚¬ìš©ì {user_row.id} ({user_profile['activity_segment']}) ì´ë²¤íŠ¸ ìƒì„± ì¤‘...")
        
        # ê°„ë‹¨í•œ ì´ë²¤íŠ¸ ì‹œí€€ìŠ¤ ìƒì„±
        events = []
        context = {}
        current_time = session_time
        
        # ë‹¤ì–‘í•œ ì´ë²¤íŠ¸ íƒ€ì…ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        event_sequence = ['view_page', 'search_recipe', 'view_recipe_list', 'click_recipe', 'click_bookmark', 'view_ads', 'click_ads']
        selected_events = random.sample(event_sequence, min(events_per_user, len(event_sequence)))
        
        for event_name in selected_events:
            # ì´ë²¤íŠ¸ ì†ì„± ìƒì„±
            properties = generate_event_properties_v2(
                event_name, 
                context, 
                recipes_df, 
                user_data=user_profile,
                session_time=current_time
            )
            
            # ì´ë²¤íŠ¸ ê¸°ë¡
            event = {
                'event_name': event_name,
                'event_id': str(uuid.uuid4()),
                'user_id': str(user_row.id),
                'session_id': str(uuid.uuid4()),
                'timestamp': get_korean_timestamp(current_time),
                'properties': properties
            }
            
            events.append(event)
            
            # ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            if 'recipe_id' in properties:
                context['recipe_id'] = properties['recipe_id']
            if 'selected_filters' in properties:
                context['search_filters'] = properties['selected_filters']
            if 'displayed_recipe_ids' in properties:
                context['displayed_recipe_ids'] = properties['displayed_recipe_ids']
            
            # ì‹œê°„ ì¦ê°€
            current_time += timedelta(seconds=random.randint(10, 60))
        
        all_events.extend(events)
    
    print(f"\nâœ… ì´ {len(all_events)}ê°œ ì´ë²¤íŠ¸ ìƒì„± ì™„ë£Œ!")
    
    return all_events

# ìƒ˜í”Œ ì´ë²¤íŠ¸ ìƒì„± ë° ë¶„ì„
sample_events = generate_sample_events_test(num_users=3, events_per_user=8)



# ===================================================================
# ğŸš€ Dask í™œìš© ë³‘ë ¬ì²˜ë¦¬ 10ë§Œê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì‹œìŠ¤í…œ
# ===================================================================

import dask
from dask.distributed import Client, as_completed
from dask import delayed
import time
from datetime import datetime
import pandas as pd

print("ğŸš€ Dask í™œìš© ë³‘ë ¬ì²˜ë¦¬ ì´ë²¤íŠ¸ ìƒì„± ì‹œìŠ¤í…œ")
print("=" * 60)

# 1. ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
print("ğŸ‘¥ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ ì¤‘...")
segmented_users_df = assign_mature_service_user_segments(users_df, profiles_df)
print(f"âœ… {len(segmented_users_df):,}ëª… ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ í• ë‹¹ ì™„ë£Œ")

@delayed
def generate_events_batch_optimized(user_batch, recipes_sample, batch_id, events_per_user=5):
    """
    Dask delayed í•¨ìˆ˜: ì‚¬ìš©ì ë°°ì¹˜ë³„ ì´ë²¤íŠ¸ ìƒì„± (ìµœì í™” + ì‹œê°„ëŒ€/ë‚ ì§œ ê°€ì¤‘ì¹˜)
    """
    import random
    import uuid
    from datetime import datetime, timedelta
    import numpy as np
    
    # ë°°ì¹˜ë³„ ê³ ìœ  ì‹œë“œ ì„¤ì •
    random.seed(42 + batch_id)
    np.random.seed(42 + batch_id)
    
    # ì‹œê°„ëŒ€ë³„ ê°€ì¤‘ì¹˜ ì„¤ì • (í˜„ì‹¤ì ì¸ ì‚¬ìš©ì í™œë™ íŒ¨í„´ ë°˜ì˜)
    hour_weights = {
        0: 0.05, 1: 0.03, 2: 0.02, 3: 0.02, 4: 0.03, 5: 0.08,  # ìƒˆë²½ (2-8%)
        6: 0.25, 7: 0.45, 8: 0.60, 9: 0.75, 10: 0.85, 11: 0.90,  # ì˜¤ì „ (25-90%)
        12: 1.00, 13: 0.95, 14: 0.85, 15: 0.80, 16: 0.85, 17: 0.90,  # ì˜¤í›„ (80-100%)
        18: 0.95, 19: 1.00, 20: 0.95, 21: 0.85, 22: 0.70, 23: 0.35   # ì €ë…~ë°¤ (35-100%)
    }
    
    # ìš”ì¼ë³„ ê°€ì¤‘ì¹˜ ì„¤ì • (ì£¼ë§ í™œì„±í™”)
    weekday_weights = {
        0: 0.8,   # ì›”ìš”ì¼: 80%
        1: 0.9,   # í™”ìš”ì¼: 90%
        2: 0.95,  # ìˆ˜ìš”ì¼: 95%
        3: 1.0,   # ëª©ìš”ì¼: 100%
        4: 1.1,   # ê¸ˆìš”ì¼: 110% (ì£¼ë§ ì¤€ë¹„)
        5: 1.3,   # í† ìš”ì¼: 130% (ì£¼ë§ í”¼í¬)
        6: 1.2    # ì¼ìš”ì¼: 120% (ì£¼ë§ ì§€ì†)
    }
    
    # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì‹œê°„ ì„ íƒì„ ìœ„í•œ í™•ë¥  ë¶„í¬ ìƒì„±
    hours = list(range(24))
    base_hour_weights = [hour_weights[hour] for hour in hours]
    
    batch_events = []
    
    # ê° ì‚¬ìš©ìë³„ë¡œ ì„¸ì…˜ ìƒì„±
    for _, user_row in user_batch.iterrows():
        try:
            # ì‚¬ìš©ì ë°ì´í„° ì¤€ë¹„
            user_data = user_row.to_dict()
            
            # ì„¸ì…˜ ë‚ ì§œ ìƒì„± (6~8ì›”, ìš”ì¼ë³„ ê°€ì¤‘ì¹˜ ì ìš©)
            summer_dates_with_weights = []
            
            for month in [6, 7, 8]:  # 6ì›”, 7ì›”, 8ì›”
                if month == 6:
                    days = range(1, 31)  # 6ì›”: 30ì¼
                elif month == 7:
                    days = range(1, 32)  # 7ì›”: 31ì¼
                else:  # month == 8
                    days = range(1, 32)  # 8ì›”: 31ì¼
                
                for day in days:
                    date_obj = datetime(2025, month, day)
                    weekday = date_obj.weekday()  # 0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼
                    date_weight = weekday_weights[weekday]
                    
                    # ê°€ì¤‘ì¹˜ë§Œí¼ ë‚ ì§œë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (í™•ë¥ ì  ì„ íƒì„ ìœ„í•´)
                    repeat_count = int(date_weight * 10)  # ê°€ì¤‘ì¹˜ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
                    for _ in range(repeat_count):
                        summer_dates_with_weights.append(date_obj)
            
            session_date = random.choice(summer_dates_with_weights)
            weekday = session_date.weekday()
            
            # ìš”ì¼ì— ë”°ë¥¸ ì‹œê°„ëŒ€ ê°€ì¤‘ì¹˜ ì¡°ì •
            adjusted_hour_weights = []
            day_multiplier = weekday_weights[weekday]
            
            for hour_weight in base_hour_weights:
                # ì£¼ë§ì—ëŠ” ì €ë… ì‹œê°„ëŒ€(18-22ì‹œ) ë” í™œì„±í™”
                if weekday >= 5 and 18 <= hours[base_hour_weights.index(hour_weight)] <= 22:
                    adjusted_weight = hour_weight * day_multiplier * 1.2  # ì£¼ë§ ì €ë… ì¶”ê°€ ë¶€ìŠ¤íŠ¸
                else:
                    adjusted_weight = hour_weight * day_multiplier
                adjusted_hour_weights.append(adjusted_weight)
            
            # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì‹œê°„ ì„ íƒ
            total_weight = sum(adjusted_hour_weights)
            normalized_weights = [w/total_weight for w in adjusted_hour_weights]
            weighted_hour = np.random.choice(hours, p=normalized_weights)
            
            session_time = session_date.replace(
                hour=weighted_hour,
                minute=random.randint(0, 59),
                second=random.randint(0, 59),
                tzinfo=KST
            )
            
            # í™œë™ ìˆ˜ì¤€ë³„ ì´ë²¤íŠ¸ ìˆ˜ ê²°ì • (ì£¼ë§ì— ì¶”ê°€ ì´ë²¤íŠ¸)
            activity_segment = user_data.get('activity_segment', 'ACTIVE_EXPLORER')
            base_events = 0
            
            if activity_segment == 'POWER_USER':
                base_events = random.randint(8, 12)
            elif activity_segment == 'ACTIVE_EXPLORER':
                base_events = random.randint(4, 8)
            else:  # PASSIVE_BROWSER
                base_events = random.randint(2, 5)
            
            # ì£¼ë§ ë³´ë„ˆìŠ¤ ì´ë²¤íŠ¸ (ê¸ˆ~ì¼ìš”ì¼ì— 10-20% ì¶”ê°€)
            if weekday >= 4:  # ê¸ˆìš”ì¼ë¶€í„° ì¼ìš”ì¼
                weekend_bonus = random.uniform(1.1, 1.2)
                user_events = int(base_events * weekend_bonus)
            else:
                user_events = base_events
            
            # ì •êµí•œ ì„¸ì…˜ í”Œë¡œìš° ìƒì„±
            session_events = generate_mature_service_session_flow(
                user_data, session_time, recipes_sample
            )
            
            # ëª©í‘œ ì´ë²¤íŠ¸ ìˆ˜ë§Œí¼ ì œí•œ
            session_events = session_events[:user_events]
            batch_events.extend(session_events)
            
        except Exception as e:
            # ê°œë³„ ì‚¬ìš©ì ì˜¤ë¥˜ëŠ” ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì† ì§„í–‰
            continue
    
    return {
        'batch_id': batch_id,
        'events': batch_events,
        'user_count': len(user_batch),
        'event_count': len(batch_events)
    }

def create_100k_events_with_dask(target_events=100_000, batch_size=2_000):
    """
    Daskë¥¼ í™œìš©í•œ ë³‘ë ¬ì²˜ë¦¬ë¡œ 10ë§Œê°œ ì´ë²¤íŠ¸ ìƒì„±
    """
    print(f"\nâš¡ Dask ë³‘ë ¬ì²˜ë¦¬ë¡œ {target_events:,}ê°œ ì´ë²¤íŠ¸ ìƒì„± ì‹œì‘")
    print(f"ğŸ“Š ë°°ì¹˜ í¬ê¸°: {batch_size:,}ê°œì”© ì²˜ë¦¬")
    
    start_time = time.time()
    
    # Dask í´ë¼ì´ì–¸íŠ¸ ì‹œì‘ (ë¡œì»¬ ëª¨ë“œ)
    try:
        client = Client(processes=True, n_workers=4, threads_per_worker=2, memory_limit='2GB')
        print(f"ğŸ”§ Dask í´ëŸ¬ìŠ¤í„°: {client}")
    except Exception as e:
        print(f"âš ï¸ Dask í´ëŸ¬ìŠ¤í„° ìƒì„± ì‹¤íŒ¨, ìŠ¤ë ˆë“œ ëª¨ë“œë¡œ ëŒ€ì²´: {e}")
        client = None
    
    # ë ˆì‹œí”¼ ìƒ˜í”Œ ì¤€ë¹„ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
    recipes_sample = recipes_df.sample(n=min(10000, len(recipes_df)))
    print(f"ğŸ½ï¸ ë ˆì‹œí”¼ ìƒ˜í”Œ: {len(recipes_sample):,}ê°œ")
    
    # ì‚¬ìš©ìë¥¼ ë°°ì¹˜ë¡œ ë¶„í• 
    total_users_needed = target_events // 5  # ì‚¬ìš©ìë‹¹ í‰ê·  5ê°œ ì´ë²¤íŠ¸
    users_sample = segmented_users_df.sample(n=min(total_users_needed, len(segmented_users_df)))
    
    # ì‚¬ìš©ì ë°°ì¹˜ ìƒì„±
    user_batches = []
    for i in range(0, len(users_sample), batch_size):
        batch = users_sample.iloc[i:i+batch_size]
        user_batches.append(batch)
    
    print(f"ğŸ‘¥ ì´ ì‚¬ìš©ì: {len(users_sample):,}ëª…")
    print(f"ğŸ“¦ ë°°ì¹˜ ìˆ˜: {len(user_batches)}ê°œ")
    
    # Delayed ì‘ì—… ìƒì„±
    print(f"âš™ï¸ Delayed ì‘ì—… ìƒì„± ì¤‘...")
    delayed_tasks = []
    for batch_id, user_batch in enumerate(user_batches):
        task = generate_events_batch_optimized(
            user_batch, 
            recipes_sample, 
            batch_id
        )
        delayed_tasks.append(task)
    
    # ë³‘ë ¬ ì‹¤í–‰
    print(f"ğŸš€ {len(delayed_tasks)}ê°œ ë°°ì¹˜ ë³‘ë ¬ ì‹¤í–‰ ì‹œì‘...")
    
    if client:
        # Dask í´ëŸ¬ìŠ¤í„° ì‚¬ìš©
        results = dask.compute(*delayed_tasks)
    else:
        # ë¡œì»¬ ìŠ¤ë ˆë“œ ì‚¬ìš©
        with dask.config.set(scheduler='threads'):
            results = dask.compute(*delayed_tasks)
    
    # ê²°ê³¼ ìˆ˜ì§‘
    print(f"ğŸ“Š ê²°ê³¼ ìˆ˜ì§‘ ë° ì •ë¦¬ ì¤‘...")
    all_events = []
    total_users = 0
    
    for result in results:
        all_events.extend(result['events'])
        total_users += result['user_count']
        
        # ì§„í–‰ìƒí™© ì¶œë ¥
        if len(all_events) % 10000 < 5000:  # ëŒ€ëµì ì¸ ì§„í–‰ìƒí™©
            print(f"   ìˆ˜ì§‘ëœ ì´ë²¤íŠ¸: {len(all_events):,}ê°œ...")
    
    # ëª©í‘œ ìˆ˜ë§Œí¼ ì œí•œ
    all_events = all_events[:target_events]
    
    # DataFrame ë³€í™˜
    print(f"ğŸ”„ DataFrame ë³€í™˜ ì¤‘...")
    events_df = pd.DataFrame(all_events)
    
    # ê²°ê³¼ ì •ë¦¬
    end_time = time.time()
    duration = end_time - start_time
    
    print(f"\nğŸ‰ Dask ë³‘ë ¬ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"â±ï¸ ì´ ì†Œìš”ì‹œê°„: {duration:.1f}ì´ˆ ({duration/60:.1f}ë¶„)")
    print(f"ğŸ“Š ìƒì„±ëœ ì´ë²¤íŠ¸: {len(events_df):,}ê°œ")
    print(f"ğŸ‘¥ ì°¸ì—¬ ì‚¬ìš©ì: {total_users:,}ëª…")
    print(f"âš¡ ì²˜ë¦¬ ì†ë„: {len(events_df)/duration:.0f} events/sec")
    
    # ì´ë²¤íŠ¸ íƒ€ì… ë¶„í¬ í™•ì¸
    if len(events_df) > 0:
        print(f"\nğŸ“ˆ ì´ë²¤íŠ¸ íƒ€ì… ë¶„í¬:")
        event_dist = events_df['event_name'].value_counts()
        for event_type, count in event_dist.head(7).items():
            percentage = count / len(events_df) * 100
            print(f"   {event_type}: {count:,}ê°œ ({percentage:.1f}%)")
    
    # í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬
    if client:
        client.close()
        print(f"ğŸ”§ Dask í´ëŸ¬ìŠ¤í„° ì¢…ë£Œ")
    
    return events_df

# í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ ë©”ì‹œì§€
print("âœ… Dask ë³‘ë ¬ì²˜ë¦¬ ì´ë²¤íŠ¸ ìƒì„± í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!")
print("ğŸ’¡ íŠ¹ì§•:")
print("   - ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ë³„ ì°¨ë“± ì´ë²¤íŠ¸ ìˆ˜")
print("   - ì‹¤ì œ ë ˆì‹œí”¼ ë°ì´í„° ì—°ë™")
print("   - AB í…ŒìŠ¤íŠ¸ ë¡œì§ í¬í•¨")
print("   - í•œêµ­ì‹œê°„ íƒ€ì„ìŠ¤íƒ¬í”„")
print("   - ì—¬ë¦„ ì‹œì¦Œ(6~8ì›”) ì „ì²´ ì»¤ë²„")
print("   - ì‹œê°„ëŒ€ë³„ ê°€ì¤‘ì¹˜ ì ìš© (í˜„ì‹¤ì  í™œë™ íŒ¨í„´)")
print("   - ğŸ“… ìš”ì¼ë³„ ê°€ì¤‘ì¹˜ ì ìš© (ì£¼ë§ í™œì„±í™”)")
print("   - ğŸ‰ ì£¼ë§ ë³´ë„ˆìŠ¤ ì´ë²¤íŠ¸ (ê¸ˆ~ì¼ 10-20% ì¶”ê°€)")
print("   - ì •êµí•œ ì„¸ì…˜ í”Œë¡œìš°")
print("   - Dask ë¶„ì‚° ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”")

# ì‹œê°„ëŒ€ ë° ìš”ì¼ë³„ ê°€ì¤‘ì¹˜ íŒ¨í„´ ì„¤ëª…
print("\nâ° ì‹œê°„ëŒ€ë³„ í™œë™ ê°€ì¤‘ì¹˜:")
print("   ğŸŒ™ ìƒˆë²½ (0-5ì‹œ): 2-8% (ë‚®ì€ í™œë™)")
print("   ğŸŒ… ì˜¤ì „ (6-11ì‹œ): 25-90% (ì ì§„ì  ì¦ê°€)")
print("   â˜€ï¸ ì ì‹¬ (12-17ì‹œ): 80-100% (ìµœê³  í™œë™)")
print("   ğŸŒ† ì €ë… (18-21ì‹œ): 85-100% (ë†’ì€ í™œë™)")
print("   ğŸŒƒ ë°¤ (22-23ì‹œ): 35-70% (ì ì§„ì  ê°ì†Œ)")

print("\nğŸ“… ìš”ì¼ë³„ í™œë™ ê°€ì¤‘ì¹˜:")
print("   ğŸ“š ì›”ìš”ì¼: 80% (ì£¼ì´ˆ ë‚®ì€ í™œë™)")
print("   ğŸ’¼ í™”-ìˆ˜ìš”ì¼: 90-95% (í‰ì¼ ë³´í†µ)")
print("   ğŸ”¥ ëª©ìš”ì¼: 100% (í‰ì¼ ê¸°ì¤€)")
print("   ğŸ» ê¸ˆìš”ì¼: 110% (ì£¼ë§ ì¤€ë¹„ ì¦ê°€)")
print("   ğŸ‰ í† ìš”ì¼: 130% (ì£¼ë§ ìµœëŒ€ í”¼í¬)")
print("   ğŸ›‹ï¸ ì¼ìš”ì¼: 120% (ì—¬ìœ ë¡œìš´ ì£¼ë§)")



# ===================================================================
# ğŸ¯ 10ë¶„ ê°„ê²© 10ë§Œê°œ ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì‹œìŠ¤í…œ
# ===================================================================

def generate_events_by_time_window(window_start, window_end, target_events=100_000, batch_size=2_000):
    """
    íŠ¹ì • ì‹œê°„ ìœˆë„ìš°(10ë¶„ ê°„ê²©) ë‚´ì—ì„œ ì •í™•íˆ ì§€ì •ëœ ê°œìˆ˜ì˜ ì´ë²¤íŠ¸ ìƒì„±
    
    Args:
        window_start: ìœˆë„ìš° ì‹œì‘ ì‹œê°„ (datetime)
        window_end: ìœˆë„ìš° ì¢…ë£Œ ì‹œê°„ (datetime)
        target_events: ìƒì„±í•  ì´ë²¤íŠ¸ ìˆ˜ (ê¸°ë³¸ 10ë§Œê°œ)
        batch_size: ë°°ì¹˜ í¬ê¸°
    
    Returns:
        DataFrame: ìƒì„±ëœ ì´ë²¤íŠ¸ë“¤
    """
    import time
    import pandas as pd
    
    print(f"\nâ° ì‹œê°„ ìœˆë„ìš° ì´ë²¤íŠ¸ ìƒì„± ì‹œì‘")
    print(f"ğŸ“… ê¸°ê°„: {window_start.strftime('%Y-%m-%d %H:%M:%S')} ~ {window_end.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ¯ ëª©í‘œ ì´ë²¤íŠ¸: {target_events:,}ê°œ")
    
    start_time = time.time()
    
    # ë ˆì‹œí”¼ ìƒ˜í”Œ ì¤€ë¹„
    recipes_sample = recipes_df.sample(n=min(5000, len(recipes_df)))
    
    # ì‚¬ìš©ì ìƒ˜í”Œ ì¤€ë¹„ (ëª©í‘œ ì´ë²¤íŠ¸ ìˆ˜ì— ë§ì¶°)
    users_needed = target_events // 8  # ì‚¬ìš©ìë‹¹ í‰ê·  8ê°œ ì´ë²¤íŠ¸
    users_sample = segmented_users_df.sample(n=min(users_needed, len(segmented_users_df)))
    
    print(f"ğŸ‘¥ ì‚¬ìš© ì‚¬ìš©ì: {len(users_sample):,}ëª…")
    print(f"ğŸ½ï¸ ì‚¬ìš© ë ˆì‹œí”¼: {len(recipes_sample):,}ê°œ")
    
    all_events = []
    events_generated = 0
    
    # ì‹œê°„ ìœˆë„ìš° ë‚´ì—ì„œ ì´ë²¤íŠ¸ ì‹œê°„ ë¶„ì‚°
    window_duration_seconds = (window_end - window_start).total_seconds()
    
    for _, user_row in users_sample.iterrows():
        if events_generated >= target_events:
            break
            
        # í•´ë‹¹ ìœˆë„ìš° ë‚´ ëœë¤ ì‹œê°„ ìƒì„±
        random_offset = random.uniform(0, window_duration_seconds)
        session_time = window_start + timedelta(seconds=random_offset)
        
        # ì‚¬ìš©ì ë°ì´í„° ì¤€ë¹„
        user_data = user_row.to_dict()
        
        # í™œë™ ìˆ˜ì¤€ì— ë”°ë¥¸ ì´ë²¤íŠ¸ ìˆ˜ ê²°ì •
        activity_segment = user_data.get('activity_segment', 'ACTIVE_EXPLORER')
        if activity_segment == 'POWER_USER':
            events_count = random.randint(12, 18)
        elif activity_segment == 'ACTIVE_EXPLORER':
            events_count = random.randint(6, 12)
        else:  # PASSIVE_BROWSER
            events_count = random.randint(3, 8)
        
        # ëª©í‘œ ìˆ˜ë¥¼ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ ì¡°ì •
        remaining_events = target_events - events_generated
        if remaining_events <= 0:
            break
        events_count = min(events_count, remaining_events)
        
        # ì„¸ì…˜ ì´ë²¤íŠ¸ ìƒì„±
        session_events = generate_mature_service_session_flow(
            user_data, session_time, recipes_sample
        )
        
        # í•„ìš”í•œ ë§Œí¼ë§Œ ê°€ì ¸ì˜¤ê¸°
        session_events = session_events[:events_count]
        all_events.extend(session_events)
        events_generated += len(session_events)
        
        # ì§„í–‰ ìƒí™© ì¶œë ¥
        if events_generated % 10000 == 0:
            progress = (events_generated / target_events) * 100
            print(f"   ì§„í–‰ë¥ : {progress:.1f}% ({events_generated:,}/{target_events:,})")
    
    # DataFrame ë³€í™˜
    events_df = pd.DataFrame(all_events)
    
    # ì •í™•í•œ ê°œìˆ˜ë¡œ ìë¥´ê¸°
    if len(events_df) > target_events:
        events_df = events_df.head(target_events)
    
    end_time = time.time()
    duration = end_time - start_time
    
    print(f"âœ… ìœˆë„ìš° ì´ë²¤íŠ¸ ìƒì„± ì™„ë£Œ!")
    print(f"â±ï¸ ì†Œìš”ì‹œê°„: {duration:.1f}ì´ˆ")
    print(f"ğŸ“Š ìƒì„± ì´ë²¤íŠ¸: {len(events_df):,}ê°œ")
    print(f"âš¡ ì²˜ë¦¬ ì†ë„: {len(events_df)/duration:.0f} events/sec")
    
    return events_df


# ê¸°ì¡´ generate_events_by_15min_intervals í•¨ìˆ˜ë¥¼ ì•„ë˜ ì½”ë“œë¡œ êµì²´í•©ë‹ˆë‹¤.

def generate_events_by_15min_intervals(start_date, num_intervals, bootstrap_servers, topic):
    """
    [ìˆ˜ì •ë¨] 10ë¶„ ê°„ê²©ìœ¼ë¡œ ì´ë²¤íŠ¸ë¥¼ ìƒì„±í•˜ê³  Kafkaë¡œ ì§ì ‘ ì „ì†¡í•©ë‹ˆë‹¤. (ì‹œê°„ ê²½ê³„ í¬í•¨)
    
    Args:
        start_date: ì‹œì‘ ë‚ ì§œ
        num_intervals: ìƒì„±í•  10ë¶„ ê°„ê²© ìˆ˜
        bootstrap_servers: ì ‘ì†í•  Kafka ë¸Œë¡œì»¤ ì£¼ì†Œ
        topic: ë°ì´í„°ë¥¼ ë³´ë‚¼ Kafka í† í”½ ì´ë¦„
    """
    print(f"\nğŸ• 10ë¶„ ê°„ê²© ì´ë²¤íŠ¸ ìƒì„± ë° Kafka ì „ì†¡ ì‹œì‘")
    print(f"ğŸ“… ì‹œì‘ ì‹œê°„: {start_date.strftime('%Y-%m-%d %H:%M:%S %Z')}")
    print(f"ğŸ”¢ ìƒì„± ê°„ê²© ìˆ˜: {num_intervals}ê°œ (ì´ {num_intervals * 15}ë¶„)")
    print(f"ğŸ”— Kafka Broker: {bootstrap_servers}, Topic: {topic}")
    print("=" * 60)
    
    window_results = []
    
    for i in range(num_intervals):
        # 10ë¶„ ìœˆë„ìš° ê³„ì‚°
        window_start = start_date + timedelta(minutes=i * 10)
        # [ë³€ê²½ì ] ìœˆë„ìš° ì¢…ë£Œ ì‹œê°„ì—ì„œ 1ì´ˆë¥¼ ë¹¼ì„œ êµ¬ê°„ì´ ê²¹ì¹˜ì§€ ì•Šë„ë¡ ì¡°ì •
        window_end = window_start + timedelta(minutes=10) - timedelta(seconds=1)
        
        print(f"\nğŸ“ ìœˆë„ìš° {i+1}/{num_intervals}: {window_start.strftime('%H:%M:%S')} ~ {window_end.strftime('%H:%M:%S')}")
        
        # 1. í•´ë‹¹ ìœˆë„ìš° ì´ë²¤íŠ¸ ìƒì„±
        window_events_df = generate_events_by_time_window(
            window_start=window_start,
            window_end=window_end,
            target_events=100_000 # 10ë¶„ë‹¹ 10ë§Œê°œ
        )
        
        # 2. Kafkaë¡œ ì „ì†¡
        if not window_events_df.empty:
            send_df_to_kafka(
                df=window_events_df,
                topic=topic,
                bootstrap_servers=bootstrap_servers
            )
        else:
            print("âš ï¸ ìƒì„±ëœ ì´ë²¤íŠ¸ê°€ ì—†ì–´ Kafka ì „ì†¡ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        
        # ê²°ê³¼ ê¸°ë¡
        window_info = {
            'window_id': i + 1,
            'event_count': len(window_events_df)
        }
        window_results.append(window_info)
    
    print(f"\nğŸ‰ ëª¨ë“  10ë¶„ ê°„ê²© ì´ë²¤íŠ¸ì˜ Kafka ì „ì†¡ ìš”ì²­ ì™„ë£Œ!")
    total_events = sum([w['event_count'] for w in window_results])
    print(f"ğŸ“Š ì´ ì „ì†¡ ìš”ì²­ ì´ë²¤íŠ¸: {total_events:,}ê°œ")
    
    return window_results


# print("ğŸ¯ 10ë¶„ ê°„ê²© ì´ë²¤íŠ¸ ë¡œê·¸ ìƒì„± ì‹œìŠ¤í…œ")
# print("=" * 50)

# # ì‹¤í–‰ ì „ ì¤€ë¹„ìƒíƒœ í™•ì¸
# print("ğŸ“‹ ì‹¤í–‰ ì „ ì¤€ë¹„ìƒíƒœ í™•ì¸:")
# print(f"   âœ… recipes_df: {len(recipes_df):,}ê°œ")
# print(f"   âœ… users_df: {len(users_df):,}ëª…")
# print(f"   âœ… profiles_df: {len(profiles_df):,}ê°œ")

# # í•µì‹¬ í•¨ìˆ˜ë“¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
# core_functions = [
#     'assign_mature_service_user_segments',
#     'generate_mature_service_session_flow', 
#     'generate_event_properties_v2',
#     'apply_ab_test_logic_v2',
#     'get_korean_timestamp'
# ]

# print(f"\nğŸ”§ í•µì‹¬ í•¨ìˆ˜ ì¤€ë¹„ìƒíƒœ:")
# for func_name in core_functions:
#     if func_name in globals():
#         print(f"   âœ… {func_name}")
#     else:
#         print(f"   âŒ {func_name} - í•¨ìˆ˜ê°€ ì •ì˜ë˜ì§€ ì•ŠìŒ")

# # í•µì‹¬ ë³€ìˆ˜ë“¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
# core_variables = [
#     'EVENT_SCHEMA',
#     'USER_SEGMENTS', 
#     'KST',
#     'AB_TEST_START_DATE',
#     'AB_TEST_END_DATE'
# ]

# print(f"\nğŸ“Š í•µì‹¬ ë³€ìˆ˜ ì¤€ë¹„ìƒíƒœ:")
# for var_name in core_variables:
#     if var_name in globals():
#         print(f"   âœ… {var_name}")
#     else:
#         print(f"   âŒ {var_name} - ë³€ìˆ˜ê°€ ì •ì˜ë˜ì§€ ì•ŠìŒ")

# print(f"\nğŸš€ 10ë¶„ ê°„ê²© ì´ë²¤íŠ¸ ìƒì„± ì‹œì‘...")

# # 10ë¶„ ê°„ê²©ìœ¼ë¡œ 4ê°œ ìœˆë„ìš° (1ì‹œê°„ ë¶„ëŸ‰) ìƒì„± ì‹¤í–‰
# # 2025-09-01 00:00:00 ~ 00:14:59, 00:15:00 ~ 00:29:59, 00:30:00 ~ 00:44:59, 00:45:00 ~ 00:59:59
# start_datetime = datetime(2025, 9, 1, 0, 0, 0, tzinfo=KST)
# window_results = generate_events_by_15min_intervals(start_date=start_datetime, num_intervals=4)

# print(f"\nï¿½ ìµœì¢… ê²°ê³¼ ìš”ì•½:")
# for i, window in enumerate(window_results):
#     print(f"   ğŸ“Š ìœˆë„ìš° {i+1}: {window['event_count']:,}ê°œ ì´ë²¤íŠ¸")
#     print(f"       â° {window['start_time'].strftime('%Y-%m-%d %H:%M:%S')} ~ {window['end_time'].strftime('%Y-%m-%d %H:%M:%S')}")

# total_events = sum([w['event_count'] for w in window_results])
# print(f"\nğŸ“Š ì´ ìƒì„± ì´ë²¤íŠ¸: {total_events:,}ê°œ")
# print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: data/event_logs/events_window_*.parquet")
# print(f"â­ ë°ì´í„° í’ˆì§ˆ: 10ë¶„ ê°„ê²©ë³„ ì •í™•í•œ ì‹œê°„ ìœˆë„ìš° ì ìš©")


# íŒŒì¼ì˜ ë§¨ ë§ˆì§€ë§‰ ì‹¤í–‰ ë¶€ë¶„ì„ ì•„ë˜ ì½”ë“œë¡œ êµì²´í•©ë‹ˆë‹¤.

if __name__ == "__main__":
    # ==================================
    # 1. ì»¤ë§¨ë“œ ë¼ì¸ ì¸ì íŒŒì„œ ì„¤ì •
    # ==================================
    parser = argparse.ArgumentParser(description="10ë¶„ ê°„ê²© ì´ë²¤íŠ¸ ë¡œê·¸ë¥¼ ìƒì„±í•˜ì—¬ Kafkaë¡œ ì „ì†¡í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸")
    
    parser.add_argument(
        '--start-date', 
        type=str, 
        required=True, 
        help="ë°ì´í„° ìƒì„±ì„ ì‹œì‘í•  ë‚ ì§œì™€ ì‹œê°„. í˜•ì‹: 'YYYY-MM-DD-HH'"
    )
    parser.add_argument(
        '--num-intervals', 
        type=int, 
        default=4, 
        help="ìƒì„±í•  10ë¶„ ê°„ê²©ì˜ ìˆ˜. ê¸°ë³¸ê°’: 4 (1ì‹œê°„ ë¶„ëŸ‰)"
    )
    # [ì¶”ê°€ëœ ë¶€ë¶„] Kafka í† í”½ì„ ì§€ì •í•˜ëŠ” ì¸ì
    parser.add_argument(
        '--topic',
        type=str,
        default='replay-user-events', # ê¸°ë³¸ê°’ì„ ìš´ì˜ í† í”½ìœ¼ë¡œ ì„¤ì •
        help="ë°ì´í„°ë¥¼ ë³´ë‚¼ Kafka í† í”½ ì´ë¦„. ê¸°ë³¸ê°’: 'replay-user-events'"
    )
    
    args = parser.parse_args()

    # ==================================
    # 2. Kafka ë° ì‹œë®¬ë ˆì´ì…˜ ì •ë³´ ì„¤ì •
    # ==================================
    KAFKA_BOOTSTRAP_SERVERS = '10.0.128.56:9092,10.0.129.146:9092,10.0.79.163:9092'
    # [ìˆ˜ì •ëœ ë¶€ë¶„] ì¸ìë¡œë¶€í„° í† í”½ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
    kafka_topic = args.topic
    
    try:
        sim_start_datetime = datetime.strptime(args.start_date, '%Y-%m-%d-%H').replace(tzinfo=KST)
    except ValueError:
        print("âŒ ì˜¤ë¥˜: ë‚ ì§œ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. 'YYYY-MM-DD-HH' í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        exit()
        
    sim_num_intervals = args.num_intervals

    print("=" * 50)
    print("ğŸš€ 10ë¶„ ê°„ê²© ì´ë²¤íŠ¸ ìƒì„± ë° Kafka ì „ì†¡ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    print("=" * 50)
    print(f"   â–¶ï¸ ì‹œì‘ ì‹œê°„: {sim_start_datetime.strftime('%Y-%m-%d %H:%M:%S %Z')}")
    print(f"   â–¶ï¸ êµ¬ê°„ ìˆ˜: {sim_num_intervals}ê°œ")
    print(f"   â–¶ï¸ ì „ì†¡ í† í”½: {kafka_topic}") # í˜„ì¬ ì „ì†¡í•  í† í”½ ì´ë¦„ ì¶œë ¥

    # ==================================
    # 3. ë³€ê²½ëœ ë©”ì¸ í•¨ìˆ˜ í˜¸ì¶œ
    # ==================================
    window_results = generate_events_by_15min_intervals(
        start_date=sim_start_datetime,
        num_intervals=sim_num_intervals,
        bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
        # [ìˆ˜ì •ëœ ë¶€ë¶„] ì¸ìë¡œ ë°›ì€ í† í”½ ì „ë‹¬
        topic=kafka_topic
    )